{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 📝 安裝套件"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install jieba -U\n",
    "!pip install httpx -U\n",
    "!pip install sklearn -U\n",
    "!pip install ckiptagger[tfgpu,gdown] -U\n",
    "!pip install beautifulsoup4 -U\n",
    "!pip install pymssql -U\n",
    "\n",
    "'''\n",
    "1. 抓資料\n",
    "2. 資料清洗\n",
    "3. 長詞優先斷詞+jieba斷詞+ckiptagger斷詞\n",
    "4. tf-idf取出關鍵字\n",
    "5. 計算文件相似度\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 1.8 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=a57bc48d87cd89225db41f6d1008f0c55fe7a920448a989e0b509524365ccb4f\n",
      "  Stored in directory: /Users/Ben/Library/Caches/pip/wheels/7d/74/cf/08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Successfully installed jieba-0.42.1\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.9/site-packages (from httpx) (0.13.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/site-packages (from httpx) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.9/site-packages (from httpx) (2.0.4)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.9/site-packages (from httpx) (1.5.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from httpx) (2020.12.5)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.9/site-packages (from httpcore<0.14.0,>=0.13.3->httpx) (0.12.0)\n",
      "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.9/site-packages (from httpcore<0.14.0,>=0.13.3->httpx) (3.3.0)\n",
      "Collecting idna>=2.8\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 1.1 MB/s \n",
      "\u001b[?25hInstalling collected packages: idna\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.5\n",
      "    Uninstalling idna-2.5:\n",
      "      Successfully uninstalled idna-2.5\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "requests2 2.16.0 requires idna<2.6,>=2.5, but you have idna 3.2 which is incompatible.\n",
      "requests 2.25.1 requires idna<3,>=2.5, but you have idna 3.2 which is incompatible.\u001b[0m\n",
      "Successfully installed idna-3.2\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 767 kB/s \n",
      "\u001b[?25hCollecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.1-cp39-cp39-macosx_10_9_x86_64.whl (32.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8 MB 4.1 kB/s \n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 17.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=1edef8350cd46306a193019e319c8f037197dfede0e91882f6c17501f969a3d6\n",
      "  Stored in directory: /Users/Ben/Library/Caches/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Successfully installed joblib-1.0.1 scikit-learn-1.0 scipy-1.7.1 sklearn-0.0 threadpoolctl-2.2.0\n",
      "zsh:1: no matches found: ckiptagger[tfgpu,gdown]\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4) (2.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: pymssql in /usr/local/lib/python3.9/site-packages (2.2.2)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n1. 抓資料\\n2. 資料清洗\\n3. 長詞優先斷詞+jieba斷詞+ckiptagger斷詞\\n4. tf-idf取出關鍵字\\n5. 計算文件相似度\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📝 針對標點符號斷行"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📝 ngram + 長詞優先斷詞 => 取出特殊關鍵詞"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news = '''\n",
    "「通路的優勢是電子支付擴張非常重要的門檻。」這句話，從街口支付產品長范庭甄口中說出來，特別有說服力。\n",
    "\n",
    "2018年初取得專營電子支付機構執照的街口電子支付（以下簡稱街口支付），經過短短3年半的努力，累積了超過482萬用戶，簽下18萬家特店機構，奠定在電子支付產業龍頭地位。范庭甄表示，電子支付產業過去5年多的發展中，大多數的業者投注大筆資源在建立通路，就是希望擴張自家電子支付在市場上的影響力。\n",
    "\n",
    "然而，建立通路是一個非常辛苦的過程，她比喻，就像銀行簽信用卡特店一樣，店家需要繳交許多資料給電支業者，往返審核進行身分確認，若是大型特店還得進行不少系統串接工作。「通常需要3個月到2年不等的時間，才能成功串接一個店家。」范庭甄舉例，街口支付串接大型連鎖速食店麥當勞，從前期洽談、簽約到正式上線，就花了一、兩年的時間。\n",
    "\n",
    "看好跨機構轉帳共通發展，推動第二階段仍有2大挑戰需克服\n",
    "\n",
    "新版電子支付機構管理條例7月上路後，開放跨機構間互通金流服務，目前分兩階段推動，第一階段是「轉帳」，法規要求所有電子支付機構全數加入電子支付跨機構共用平臺。\n",
    "\n",
    "范庭甄提到，街口支付將會在9月底如期上線，一方面是配合政策，另一方面是看好跨機構間轉帳業務共通後的發展。她點出這個共用平臺的重要精神，是將電子支付機構正式納入金融體系。尤其，共用平臺上線後，電支機構將會有屬於自己的金融機構代號，也就是說，未來電支帳戶可與任何銀行帳戶互相轉帳，電支帳戶之間也可互轉，這是第一階段最大的變革。\n",
    "\n",
    "「跨機構間可互轉後，有機會讓P2P轉帳的金錢，從銀行體系分流到電支。」范庭甄解釋，新法有一項重要開放，當用戶在註冊電支帳戶時，業者會將用戶帳號與手機設備唯一識別碼進行綁定，讓用戶後續無須輸入密碼就能直接登入電支App，只有在交易時才需輸入密碼。「用戶對帳、轉帳就是求快」，她認為，電支安控升級後，用戶體驗的改善，也將提高電支轉帳的優勢。\n",
    "\n",
    "轉帳只是跨機構共用平臺其中一項專案，另外，還有購物、繳費、繳稅等專案，將在平臺第二階段才會上線，比如，在購物專案中，可以讓加入的電支業者共享彼此的通路。不過，這些專案並非強制性，電支業者可自行選擇參加。在此前提下，街口支付認為，第二階段要順利推動，將有兩大挑戰。\n",
    "\n",
    "第一是，業者之間的角力，范庭甄提到，大部分業者仍會考量過去投注在通路的成本，以及加入跨機構共用平臺後，究竟是利多或被他人占便宜？甚至，全家便利商店與全聯這兩家以零售進軍電子支付的業者，是否願意貢獻自家零售通路？都是業者不斷思考而且觀望的議題。她認為；「未來通路的變化，取決於擁有更多通路的業者，達成了何種共識。」\n",
    "\n",
    "另一項挑戰則是手續費問題。以往，街口支付可對特店商家收取較高的手續費，或者，為了獨占市場的規畫或特殊商業條件下，街口願意讓利，對特定店家收取較低的手續費。但范庭甄坦言：「這些條件、彈性，會因為通路的共享而消失。」因此，在商業條件、分潤方式的作法上，如何讓自己「舒服」是街口內部重視的課題，街口也會針對這部分議題持續在銀行公會積極參與討論。\n",
    "\n",
    "跨足金融商品跨售，研擬發行附隨電子支付帳戶儲值卡\n",
    "\n",
    "兩法合一後，開放了多項電支可經營的新業務，其中有一項是電支機構可作為金融商品代收付金流的支付工具。范庭甄表示，以往電支業者若要替金融機構代收付如保險、基金、證券等各式金融商品的金流，必須逐項申請。\n",
    "\n",
    "但，新法改成原則開放、例外禁止，等於是只要金管會沒有規定禁止的業務，電支通通都能做，「這也加速了電支機構與其他大型金融機構合作的基礎。」她更透露，街口支付近期將推出首個金融商品跨售，有機會在電支機構與銀行間，建立一個合作金融商品跨售時所需的基礎架構，比如資料交換、合約簽訂、如何授權等流程。\n",
    "\n",
    "此外，街口支付也計畫申請發行附隨電子支付帳戶儲值卡，范庭甄提到，未來用戶使用這張卡消費，就會連動回電支帳戶進行餘額扣款，相當於銀行帳戶與晶片金融卡間的關係。目前，正在研議實體卡與虛擬卡的發行規則與策略。她表示，未來發行街口支付自有的虛擬卡，好處是能夠綁定到Apple Pay、Google Pay、Samsung Pay這3大國際Pay來提升使用者支付體驗。\n",
    "\n",
    "找出價值變現的商業模式，街口切入跨境電商結算與街口券服務\n",
    "\n",
    "不只在國內迅速擴張通路與用戶基礎，街口支付早在2年前，便與蝦皮購物合作推出跨境電商結算服務，也是國內唯二經營跨境支付的電子支付業者，目前使用者人數已突破200萬人，累積超過100億元跨境支付交易量。范庭甄表示，相較於經營境內2C市場的通路業者，經營2B的跨境電商結帳服務更具剛性需求，因為跨境電商必須透過電支機構來處理金流，解決跨境匯兌的問題。\n",
    "\n",
    "對街口來說，蝦皮跨境電商的用戶，因使用這項服務而到街口註冊，帶來街口會員數的成長；同樣的，街口累積的會員數，也能降低蝦皮用戶進入的門檻，比如，3名蝦皮用戶中，只有1名非街口用戶需重新註冊街口帳戶來進行實名制交易。「雙方之間的用戶覆蓋率會越來越高，消費者的體驗也會越來越好。」范庭甄提到，這是經營跨境電商服務的收穫之一，另一項收獲則是可以變現，經營此服務讓街口支付在換匯匯差上創造了不少收入。\n",
    "\n",
    "「街口至少要經營一個非我不可的業務。」她坦言，經營此服務的門檻相對較高，從系統搭建、外匯申報流程、串接金流服務、串接電商合作的物流商等，甚至，街口也為蝦皮做了許多客製化服務。雖然前期投入成本高，不過，街口判斷此業務在1～2年可回收成本，甚至，建立起整個系統並規模化後，可帶來長期的回報。\n",
    "\n",
    "這也是街口支付善用龐大用戶基礎，找出價值變現的方法之一。另一項價值變現作法，是街口在去年初推出的街口券服務，主要透過數據挖掘潛在顧客，協助商家精準行銷，商家可設定性別、年齡、離店距離等條件，透過街口平臺將電子優惠券發送給目標客群，下階段更將新增消費習慣的顧客條件設定。\n",
    "\n",
    "范庭甄表示：「街口特別著墨地理位置行銷的數據」，比如，透過用戶的住家地點、工作地點、慣用交通工具等，藉由一套運算邏輯，來推估用戶屬於哪個生活圈，或透過數據貼標，進一步描繪顧客的輪廓。不過，她提到，店家用的街口券服務已是數據去識別化的分析結果，而且，店家仍得透過街口平臺推薦優惠券給用戶，過程中不會取得任何用戶資料。\n",
    "\n",
    "目前，街口券業務分為兩塊，最大宗的使用是官方街口券，主要是品牌或大型通路平臺委託街口行銷操作；另一塊則是中小型店家，則可在街口後臺自行操作服務。范庭甄提到，未來將持續往活動、議題操作等方向來經營，協助中小型店家行銷，花費更低的成本，帶來更多的來客數。\n",
    "\n",
    "為了提高精準行銷的效果，街口正在思考如何讓貼標系統更為細緻化，未來，希望能做到情境式的金融商品推薦，比如新生兒保險、旅平險等、車險、意外險等，畢竟，「這些金融商品還是非常依賴場景。」加上，用戶打開街口App的機率，比起打開銀行App的機率高出許多，也代表著電支可以增加許多與用戶互動的機會，進而用數據分析推出不同的行銷作法。\n",
    "\n",
    "不過，要做到這件事，范庭甄表示：「街口必須增加場景的覆蓋率，不只是支付服務，更要透過與異業的合作，創造更多、更細緻、更精準的場景。」這些計畫透露了街口支付的發展策略，今年將出現大變革。\n",
    "\n",
    "打造開放平臺將技術標準化，供各異業串接以拓展生態圈\n",
    "\n",
    "街口支付App整合了支付、轉帳、叫車、美食外送、外帶點餐、繳費等多項服務。范庭甄提到，以往，內部會投注許多心力推出一項新服務，可是，隨著生態圈的擴張，想要整合的服務越來越多，街口也越意識到手上資源的有限。因此，去年底，街口開始打造一個開放平臺，要將街口App的技術能力整合到同一平臺中，比如實名驗證、身分確認、支付、載具記錄、發券、數據等能力，一站式提供給合作夥伴串接。\n",
    "\n",
    "街口發展生態圈的策略是，將這個開放平臺的能力標準化，與各產業知名第三方業者合作串接，讓異業藉助街口平臺的用戶基礎，以及這平臺所提供的技術能力，比如，范庭甄透露，下半年街口平臺將上線旅遊服務、街口保險服務等，都是與異業透過此模式結合的應用。甚至，街口想效法微信小程式的概念，讓街口App變成一個應用場景平臺，各業者可在平臺上推出自家服務。\n",
    "\n",
    "不過，街口這個開放平臺，會先以初期合作夥伴的需求，進行第一期的開發，范庭甄表示，目前已有5~10家的夥伴正與街口團隊共同探索需求中。未來，會陸續開放出平臺，採取業者主動申請，並由街口篩選核准。\n",
    "\n",
    "為了擴張生態圈場景，街口也做了不少準備。范庭甄表示，在思維上，必須轉為平臺化的經營策略。而在技術上，一開始便以平臺化架構進行開發，逐一將街口的能力標準化，並讓整體架構更具彈性，尤其是前後端系統更加分離。街口希望做到，同一套API能透過簡單的配置，就能對不同異業夥伴提供高客製化的服務。\n",
    "\n",
    "甚至，街口App介面也將開放用戶自行定義。范庭甄透露，未來，用戶可將常用功能釘選在App首頁，好處是，除了能為用戶打造更好的體驗，更有利於更多第三方異業進駐街口平臺提供服務，對於街口來說，可更為專注在電支的專業，同時又能打造各式場景。\n",
    "\n",
    "此外，她提到，街口會為各家異業提供客製化UI服務，考量街口用戶習慣的風格、流程，更要讓第三方異業服務能融合在街口平臺中，不僅單單只提供導流功能。UI設計上，街口內部已經找來設計師團隊來規畫各種不同的畫面設計樣版，定義出不同的按鈕、文字方塊、輸入框、選單等，變成標準化元件，目的是讓各式服務上線的速度能夠更快。這些都是街口為了要大力擁抱生態圈夥伴，所做的技術儲備。\n",
    "目前市場上共有9家專營電子支付機構，及20家兼營電子支付機構，電支電票兩法合一後，最大亮點之一就是開放跨機構間互通金流服務，財金資訊公司已經建置了一個電子支付跨機構共用平臺，作為跨機構間金流與資訊流互聯互通的基礎建設。金管會增訂經營跨機構間支付款項帳務清算業務的管理機制，來促進通路共享、資金互通，滿足民眾便利支付需求。\n",
    "\n",
    "電子支付起初成立的目的或聚焦服務的範圍，較為著重消費者生活周遭或中小型店家的小額支付，並非大型通路或數位化通路。\n",
    "\n",
    "如果無法沒有一套整合機制讓各家電支互通，對特約商店來說，每多找一家電支業者合作，櫃臺就得多處理一種專屬QR Code，還要不斷確認消費者要用哪一款支付工具付款，更需逐一與不同電支業者對帳，非常麻煩。\n",
    "\n",
    "而對消費者來說，只能對號入座，使用特店合作的電支工具來付款。對電支業者而言，開拓特店的成本相對較高，同一家特店，各家業者要各自洽談、串接系統等。\n",
    "\n",
    "財金資訊公司董事長林國良提到，如何讓電支業者更為方便，更專心發展創新服務，是新法上路後的重要目標。「財金的任務就是扮演好金融輔助業者的角色，來協助電子支付機構發展。」\n",
    "\n",
    "電子支付跨機構共用平臺分兩階段推動\n",
    "\n",
    "電子支付跨機構共用平臺，不只能讓電支機構間金流互通，也打通了電支機構與所有銀行機構帳戶間互轉這個重要環節。林國良解釋，以往，如果一家電支機構，要與本國39家銀行，甚至300多家信用合作社與基礎金融機構串接，不只成本高，管理面也相當辛苦。\n",
    "\n",
    "現在，電支機構就像是拿了一個插頭，都插上跨機構共用平臺後，這些機構彼此就可以互通，也同時與既有的金融機構跨行體系進行了橋接，兩邊也能互通，林國良表示，這正是共用平臺的一大效益。\n",
    "\n",
    "目前，電子支付跨機構共用平臺規畫分兩階段推動。第一階段以轉帳為主，全數電支機構都必須加入互轉行列，財金公司則預計9月底對外開放平臺的跨機構轉帳功能。未來，電支帳戶可與任何銀行帳戶互相轉帳，電支帳戶之間也可互轉。\n",
    "\n",
    "第二階段則包括了購物、繳費、繳稅等多項機制，加入同一項機制的電支業者，將可共享彼此的通路，甚至還可以交換資訊，比如，電支與銀行間身分驗證資訊的交換。林國良表示，目前平臺已準備就緒，後續得視各業者準備的狀況與協調的結果，來決定第二階段上線時程。\n",
    "\n",
    "不過，對於擁有通路優勢的電支業者來說，將多年辛苦簽下的通路共享出來，是一大疑慮。林國良坦言，此觀念需要溝通，當業者不開放通路給其他人使用，同樣的，對方也不會將它的通路開放給你用。他認為，任何一家電支業者都難以成為全臺唯一獨大，在無法獨占市場的狀況下，消費者還是會到各式不同的店家消費。\n",
    "\n",
    "因此，林國良認為，如果能夠打通電支間購物、繳費、繳稅業務，讓持有任何一家電支帳戶的消費者，都能共享各家業者開發的通路，除了能提升消費者與特店的方便度，也能降低電支業者投入成本，甚至，讓業務空間變大。\n",
    "\n",
    "長期發展來看，林國良表示，這個方向對於電支產業、環境、消費者、商家來說，是一種多贏。在市場的競爭下，各家業者得找出有利自身發展的客群與方向，發揮各自所長。例如，有些電支業者的拓店能力有限，就可專注發展顧客服務，拓店能力強的業者則可聚焦發展特店，或是擅長推廣繳費帳單的業者也能有所發揮。\n",
    "\n",
    "打造跨機構共用平臺有3大考量2大設計原則\n",
    "\n",
    "為了支援所有業者和全臺灣消費者共用的超大交易規模，林國良表示，財金公司將ATM與通匯業務等系統所用的即時總額清算（RTGS）機制，也就是實現ATM跨行轉帳的技術，運用到電子支付跨機構共用平臺上，用戶在電支機構間或電支與銀行間的轉帳，同樣也是即時入帳。\n",
    "\n",
    "不過，林國良坦言，打造平臺時面臨了3大考量，包括電支機構規模小，且皆為新創公司，所用的技術新穎，另一項考量是，新創在此階段大多是業務發展為主，勝過資安防護與風險控管。\n",
    "\n",
    "基於這些因素，財金在開發平臺時，沒有選擇傳統大型主機，而是改採開放式架構。林國良提到，平臺架構採取高可用性與可擴充性兩大原則，讓系統具備橫向擴充的能力。交易面則採取業者熟悉的API架構，讓電支業者介接時具備一定的彈性。\n",
    "\n",
    "雖然電支資安等級要求不會比照銀行的水準，不過，他表示，資安防護還是必須做到一定水準，現階段讓業者逐漸加入後，再逐步統一資安規格。後續，會再逐漸與業者分享風險控管面的機制。因此，「在各種考量間如何拿捏，是財金這次建置平臺面臨的挑戰。」\n",
    "為何採用TW QR共通支付標準？\n",
    "\n",
    "為了達到電支跨機構金流互通，跨機構共用平臺採用了TW QR共通支付標準來整合。林國良解釋，一來TW QR本身已是共通標準，國內有30多家金融機構使用，其次，TW QR具備一定的資安程度。\n",
    "\n",
    "另外，考量電支機構未來打穩國內市場後，仍要走向國際市場，而TW QR共通支付標準已經可以整合Visa、Mastercard、JCB、銀聯等國際組織的標準。財金公司已在日本、新加坡、港澳地區完成TW QR商標註冊，目前正在向韓國註冊中。未來，在跨境支付部分，林國良提到，財金希望能扮演整合的角色，與鄰近國家相對應的機構或大型電支業者介接。\n",
    "\n",
    "第二階段機制重點，爆量擴充與多方金流資訊流拋轉\n",
    "\n",
    "因採取即時清算機制，若只是轉帳，用戶跨機構轉帳完成後，會在兩家機構的清算帳戶即時清算，整套運作相對簡單，但若到了第二階段的「購物」項目中，因為電支業者共享了彼此的通路，所以，資訊流與金流上相對複雜許多。財金也在跨機構共用平臺上，設計了一套對應的資訊流與金流運作機制。\n",
    "\n",
    "林國良解釋，假設以街口支付的用戶與Line Pay Money的特店來舉例，當用戶打開街口App掃碼Line Pay Money特店擺出的共通QR Code。首先，街口App要能識別這個共通QR Code，接著，用戶掃碼付款的訊息先提供給街口App，讓街口來驗證這筆交易是否為用戶本人，驗證成功就會在用戶的街口電支帳戶扣款。\n",
    "\n",
    "接下來，訊息會按照訂定的規格打包好送到財金平臺，再透過財金將訊息傳至Line Pay Money，由Line Pay Money確認此店家為合作特店，然後為特店記下一筆來自街口的付款。最後，這項訊息會再回到財金平臺，再透過平臺通知街口，再由街口告訴用戶付款成功。\n",
    "\n",
    "到了每日結帳的時間，則由負責簽下各特店的電支機構來發動，並由財金統一負責金流結清算，等於特店只要跟合作的一家電支機構對帳即可。作法上，財金會告知各家電支業者每日的結算金額，如果某些電支業者當日用戶付款金額，大於店家收款金額，財金就會在電支機構於合庫銀行開立的清算帳戶扣款，並將款項撥給店家收款金額大於用戶付款金額的電支業者，完成清算的動作。\n",
    "\n",
    "未來進入平臺第二階段發展時，為了因應電支業者舉辦的大型促銷活動，財金設計了系統爆量的因應機制，林國良提到，即便碰上臨時的系統瓶頸狀況，也能快速調度設備與資源來因應。\n",
    "\n",
    "甚至，在大型促銷活動如雙11前，財金可依照加入平臺的電支機構之用戶數、特店數、交易訊息數量等，來提前預估所需準備的資源。不過，如果是特店要執行大規模活動，財金偏向電支業者可提前告知，讓他們提前張羅資源，來支持業者的大量交易。\n",
    "\n",
    "為了提高平臺的高可用性，林國良透露，財金正在規畫兩地三中心的備援機制，讓同地具備資訊雙中心營運，異地也要設立第三備援中心。未來，他提到，隨著電支機構的規模逐漸變大，需求增多的狀況下，跨機構共用平臺的架構也將滾動式調整。\n",
    "'''\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def ngram(input_sentence, n = 2):\n",
    "    ret = []\n",
    "    for i in range(0, len(input_sentence) - n + 1):\n",
    "        ret.append(input_sentence[i:i+n])\n",
    "    return ret\n",
    "def removeKey(text, keywords):\n",
    "    ret = text\n",
    "    for word in keywords:\n",
    "        ret = ret.replace(word, '')\n",
    "    return ret\n",
    "def longTermFirst(news, keywords,n_gram_max, threshold):\n",
    "    stop_words_array=[]\n",
    "    with open('stop_words.txt',encoding='utf-8') as f:\n",
    "        stop_words_array = list(map(lambda x:x.replace('\\n',''),f.readlines()))    \n",
    "    for word in stop_words_array:\n",
    "                news = news.replace(word, '，')    \n",
    "    sentenceAry = re.split('，|。|（|）|〕|〔|／|《|》|、|」|！|「|：',news)\n",
    "\n",
    "    for n in range(n_gram_max,1,-1):\n",
    "        words = []\n",
    "        for sentence in sentenceAry:\n",
    "            text_list = removeKey(sentence, keywords)\n",
    "            words.extend(ngram(text_list, n))\n",
    "            \n",
    "        c = Counter(words)\n",
    "        for word, cnt in c.items():\n",
    "            m = re.match('^[\\u4e00-\\u9fa5]+$', word)\n",
    "            if (cnt >= threshold) and m:\n",
    "                keywords.append(word)\n",
    "    return keywords\n",
    "longTermFirst(news, [],12,5\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "news='''目前市場上共有9家專營電子支付機構，及20家兼營電子支付機構，電支電票兩法合一後，最大亮點之一就是開放跨機構間互通金流服務，財金資訊公司已經建置了一個電子支付跨機構共用平臺，作為跨機構間金流與資訊流互聯互通的基礎建設。金管會增訂經營跨機構間支付款項帳務清算業務的管理機制，來促進通路共享、資金互通，滿足民眾便利支付需求。\n",
    "\n",
    "電子支付起初成立的目的或聚焦服務的範圍，較為著重消費者生活周遭或中小型店家的小額支付，並非大型通路或數位化通路。\n",
    "\n",
    "如果無法沒有一套整合機制讓各家電支互通，對特約商店來說，每多找一家電支業者合作，櫃臺就得多處理一種專屬QR Code，還要不斷確認消費者要用哪一款支付工具付款，更需逐一與不同電支業者對帳，非常麻煩。\n",
    "\n",
    "而對消費者來說，只能對號入座，使用特店合作的電支工具來付款。對電支業者而言，開拓特店的成本相對較高，同一家特店，各家業者要各自洽談、串接系統等。\n",
    "\n",
    "財金資訊公司董事長林國良提到，如何讓電支業者更為方便，更專心發展創新服務，是新法上路後的重要目標。「財金的任務就是扮演好金融輔助業者的角色，來協助電子支付機構發展。」\n",
    "\n",
    "電子支付跨機構共用平臺分兩階段推動\n",
    "\n",
    "電子支付跨機構共用平臺，不只能讓電支機構間金流互通，也打通了電支機構與所有銀行機構帳戶間互轉這個重要環節。林國良解釋，以往，如果一家電支機構，要與本國39家銀行，甚至300多家信用合作社與基礎金融機構串接，不只成本高，管理面也相當辛苦。\n",
    "\n",
    "現在，電支機構就像是拿了一個插頭，都插上跨機構共用平臺後，這些機構彼此就可以互通，也同時與既有的金融機構跨行體系進行了橋接，兩邊也能互通，林國良表示，這正是共用平臺的一大效益。\n",
    "\n",
    "目前，電子支付跨機構共用平臺規畫分兩階段推動。第一階段以轉帳為主，全數電支機構都必須加入互轉行列，財金公司則預計9月底對外開放平臺的跨機構轉帳功能。未來，電支帳戶可與任何銀行帳戶互相轉帳，電支帳戶之間也可互轉。\n",
    "\n",
    "第二階段則包括了購物、繳費、繳稅等多項機制，加入同一項機制的電支業者，將可共享彼此的通路，甚至還可以交換資訊，比如，電支與銀行間身分驗證資訊的交換。林國良表示，目前平臺已準備就緒，後續得視各業者準備的狀況與協調的結果，來決定第二階段上線時程。\n",
    "\n",
    "不過，對於擁有通路優勢的電支業者來說，將多年辛苦簽下的通路共享出來，是一大疑慮。林國良坦言，此觀念需要溝通，當業者不開放通路給其他人使用，同樣的，對方也不會將它的通路開放給你用。他認為，任何一家電支業者都難以成為全臺唯一獨大，在無法獨占市場的狀況下，消費者還是會到各式不同的店家消費。\n",
    "\n",
    "因此，林國良認為，如果能夠打通電支間購物、繳費、繳稅業務，讓持有任何一家電支帳戶的消費者，都能共享各家業者開發的通路，除了能提升消費者與特店的方便度，也能降低電支業者投入成本，甚至，讓業務空間變大。\n",
    "\n",
    "長期發展來看，林國良表示，這個方向對於電支產業、環境、消費者、商家來說，是一種多贏。在市場的競爭下，各家業者得找出有利自身發展的客群與方向，發揮各自所長。例如，有些電支業者的拓店能力有限，就可專注發展顧客服務，拓店能力強的業者則可聚焦發展特店，或是擅長推廣繳費帳單的業者也能有所發揮。\n",
    "\n",
    "打造跨機構共用平臺有3大考量2大設計原則\n",
    "\n",
    "為了支援所有業者和全臺灣消費者共用的超大交易規模，林國良表示，財金公司將ATM與通匯業務等系統所用的即時總額清算（RTGS）機制，也就是實現ATM跨行轉帳的技術，運用到電子支付跨機構共用平臺上，用戶在電支機構間或電支與銀行間的轉帳，同樣也是即時入帳。\n",
    "\n",
    "不過，林國良坦言，打造平臺時面臨了3大考量，包括電支機構規模小，且皆為新創公司，所用的技術新穎，另一項考量是，新創在此階段大多是業務發展為主，勝過資安防護與風險控管。\n",
    "\n",
    "基於這些因素，財金在開發平臺時，沒有選擇傳統大型主機，而是改採開放式架構。林國良提到，平臺架構採取高可用性與可擴充性兩大原則，讓系統具備橫向擴充的能力。交易面則採取業者熟悉的API架構，讓電支業者介接時具備一定的彈性。\n",
    "\n",
    "雖然電支資安等級要求不會比照銀行的水準，不過，他表示，資安防護還是必須做到一定水準，現階段讓業者逐漸加入後，再逐步統一資安規格。後續，會再逐漸與業者分享風險控管面的機制。因此，「在各種考量間如何拿捏，是財金這次建置平臺面臨的挑戰。」\n",
    "為何採用TW QR共通支付標準？\n",
    "\n",
    "為了達到電支跨機構金流互通，跨機構共用平臺採用了TW QR共通支付標準來整合。林國良解釋，一來TW QR本身已是共通標準，國內有30多家金融機構使用，其次，TW QR具備一定的資安程度。\n",
    "\n",
    "另外，考量電支機構未來打穩國內市場後，仍要走向國際市場，而TW QR共通支付標準已經可以整合Visa、Mastercard、JCB、銀聯等國際組織的標準。財金公司已在日本、新加坡、港澳地區完成TW QR商標註冊，目前正在向韓國註冊中。未來，在跨境支付部分，林國良提到，財金希望能扮演整合的角色，與鄰近國家相對應的機構或大型電支業者介接。\n",
    "\n",
    "第二階段機制重點，爆量擴充與多方金流資訊流拋轉\n",
    "\n",
    "因採取即時清算機制，若只是轉帳，用戶跨機構轉帳完成後，會在兩家機構的清算帳戶即時清算，整套運作相對簡單，但若到了第二階段的「購物」項目中，因為電支業者共享了彼此的通路，所以，資訊流與金流上相對複雜許多。財金也在跨機構共用平臺上，設計了一套對應的資訊流與金流運作機制。\n",
    "\n",
    "林國良解釋，假設以街口支付的用戶與Line Pay Money的特店來舉例，當用戶打開街口App掃碼Line Pay Money特店擺出的共通QR Code。首先，街口App要能識別這個共通QR Code，接著，用戶掃碼付款的訊息先提供給街口App，讓街口來驗證這筆交易是否為用戶本人，驗證成功就會在用戶的街口電支帳戶扣款。\n",
    "\n",
    "接下來，訊息會按照訂定的規格打包好送到財金平臺，再透過財金將訊息傳至Line Pay Money，由Line Pay Money確認此店家為合作特店，然後為特店記下一筆來自街口的付款。最後，這項訊息會再回到財金平臺，再透過平臺通知街口，再由街口告訴用戶付款成功。\n",
    "\n",
    "到了每日結帳的時間，則由負責簽下各特店的電支機構來發動，並由財金統一負責金流結清算，等於特店只要跟合作的一家電支機構對帳即可。作法上，財金會告知各家電支業者每日的結算金額，如果某些電支業者當日用戶付款金額，大於店家收款金額，財金就會在電支機構於合庫銀行開立的清算帳戶扣款，並將款項撥給店家收款金額大於用戶付款金額的電支業者，完成清算的動作。\n",
    "\n",
    "未來進入平臺第二階段發展時，為了因應電支業者舉辦的大型促銷活動，財金設計了系統爆量的因應機制，林國良提到，即便碰上臨時的系統瓶頸狀況，也能快速調度設備與資源來因應。\n",
    "\n",
    "甚至，在大型促銷活動如雙11前，財金可依照加入平臺的電支機構之用戶數、特店數、交易訊息數量等，來提前預估所需準備的資源。不過，如果是特店要執行大規模活動，財金偏向電支業者可提前告知，讓他們提前張羅資源，來支持業者的大量交易。\n",
    "\n",
    "為了提高平臺的高可用性，林國良透露，財金正在規畫兩地三中心的備援機制，讓同地具備資訊雙中心營運，異地也要設立第三備援中心。未來，他提到，隨著電支機構的規模逐漸變大，需求增多的狀況下，跨機構共用平臺的架構也將滾動式調整。\n",
    " '''\n",
    "# longTermFirst(news, [],12,5)\n",
    "import jieba.analyse\n",
    "\n",
    "tags = jieba.analyse.extract_tags(news,10, withWeight=True)\n",
    "tags\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📝 基於 TF-IDF 的關鍵字抽取"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import jieba.analyse\n",
    "sentence = '''有外貌美麗如女星范冰冰的馮姓女子2008年與陳姓富二代訂婚後無故悔婚，但馮女不告而別2年後，忽然回頭請陳男金援，癡情的陳男不但不計前嫌，對馮女數十次索討生日、情人節等禮物及資助學費等一概答應，竟連她結婚生子後要求生活費，也大方匯給10萬元，直到陳男也結婚，妻發現他竟贈百萬名畫給馮女，陳男才在妻逼迫下告馮女詐欺、侵占，並請求返還借款533萬餘元，但檢方認定陳男自願贈與，將馮女不起訴，台北地院也僅認定2013年間馮女謊稱買房討「房貸頭期款」部分陳男求償有理，判馮女須賠60萬元。'''\n",
    "tags = jieba.analyse.extract_tags(sentence,10, withWeight=True)\n",
    "tags\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📝 抓取IThome新聞資料 (devops)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import httpx\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import asyncio\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'GoogleBot'}\n",
    "start = 1\n",
    "end = 50\n",
    "root_url = 'https://www.ithome.com.tw'\n",
    "url = f'{root_url}/devops'\n",
    "fetched_news_data=[]\n",
    "\n",
    "async def get_news(news_url, page):\n",
    "    req = httpx.get(f'{news_url}?page={page}', headers=headers)\n",
    "    res = req.text\n",
    "    root = BeautifulSoup(res, 'lxml')\n",
    "    if len(root.find_all('div',attrs={'class':'span4 channel-item'}))==0:\n",
    "        print(f'--------------沒有任何新聞內容了~~~~~-----------')\n",
    "        return\n",
    "    news_list = root.find_all(\n",
    "        'span', attrs={'class': 'views-field views-field-created'})    \n",
    "    for news in news_list:\n",
    "        news_div = news.span.div\n",
    "        categories = ','.join(list(map(lambda x: x.text, news_div.find(\n",
    "            'p', attrs={'class': 'category'}).find_all('a'))))\n",
    "        print(categories)\n",
    "        title_div = news_div.find('p', attrs={'class': 'title'})\n",
    "        title = title_div.a.text.strip()\n",
    "        href = f\"{root_url}{title_div.a['href']}\"\n",
    "        content_req=httpx.get(href)\n",
    "        content_res=content_req.text\n",
    "        content_root=BeautifulSoup(content_res, 'lxml')\n",
    "        content=content_root.find('div',attrs={'class':'field-type-text-with-summary'}).div.div.text\n",
    "        print(content)\n",
    "        id=title_div.a['href'].split('/')[2]\n",
    "        print(title)\n",
    "        print(href)\n",
    "        print(id)\n",
    "        summary = news_div.find('div', attrs={'class': 'summary'}).text.strip()\n",
    "        print(summary)\n",
    "        post_date = news_div.find('p', attrs={'class': 'post-at'}).text.strip()\n",
    "        print(post_date)\n",
    "        fetched_news_data.append([id,page,post_date,title,summary,content,href,categories])\n",
    "    print(f'--------------{page}-----------')\n",
    "\n",
    "\n",
    "async def main():\n",
    "    task_list = []\n",
    "    for i in range(start, end+1):\n",
    "        task_list.append(get_news(url, i))\n",
    "    await asyncio.gather(*task_list)\n",
    "\n",
    "s = time.perf_counter()\n",
    "await main()\n",
    "elapsed = time.perf_counter() - s\n",
    "\n",
    "if os.path.exists(\"output.csv\"):\n",
    "  os.remove(\"output.csv\")\n",
    "else:\n",
    "  print(\"The file does not exist\")\n",
    "\n",
    "with open('output.csv', 'w', newline='', encoding='UTF-8') as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow(['ID','page', 'post_date', 'title','summary','content','href','categories'])\n",
    "  for data in fetched_news_data:\n",
    "    writer.writerow(data)\n",
    "print(f\"Script executed in {elapsed:0.2f} seconds.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📝 抓取IThome新聞資料 (big-data)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import httpx\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import asyncio\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "headers = {'User-Agent': 'GoogleBot'}\n",
    "start = 1\n",
    "end = 100\n",
    "root_url = 'https://www.ithome.com.tw'\n",
    "url = f'{root_url}/big-data'\n",
    "fetched_news_data=[]\n",
    "\n",
    "async def get_news(news_url, page):\n",
    "    req = httpx.get(f'{news_url}?page={page}', headers=headers)\n",
    "    res = req.text\n",
    "    root = BeautifulSoup(res, 'lxml')\n",
    "    if len(root.find_all('div',attrs={'class':'span4 channel-item'}))==0:\n",
    "        print(f'--------------沒有任何新聞內容了~~~~~-----------')\n",
    "        return\n",
    "    news_list = root.find_all('div',attrs={'class':'span4 channel-item'})    \n",
    "    for news in news_list:\n",
    "        news_div = news.div\n",
    "        categories = ','.join(list(map(lambda x: x.text, news_div.find(\n",
    "            'p', attrs={'class': 'category'}).find_all('a'))))\n",
    "        print(categories)\n",
    "        title_div = news_div.find('p', attrs={'class': 'title'})\n",
    "        title = title_div.a.text.strip()\n",
    "        href = f\"{root_url}{title_div.a['href']}\"\n",
    "        content_req=httpx.get(href)\n",
    "        content_res=content_req.text\n",
    "        content_root=BeautifulSoup(content_res, 'lxml')\n",
    "        content=content_root.find('div',attrs={'class':'field-type-text-with-summary'}).div.div.text\n",
    "        print(content)\n",
    "        id=title_div.a['href'].split('/')[2]\n",
    "        print(title)\n",
    "        print(href)\n",
    "        print(id)\n",
    "        summary = news_div.find('div', attrs={'class': 'summary'}).text.strip()\n",
    "        print(summary)\n",
    "        post_date = news_div.find('p', attrs={'class': 'post-at'}).text.strip()\n",
    "        print(post_date)\n",
    "        fetched_news_data.append([id,page,post_date,title,summary,content,href,categories])\n",
    "    print(f'--------------{page}-----------')\n",
    "\n",
    "\n",
    "async def main():\n",
    "    task_list = []\n",
    "    for i in range(start, end+1):\n",
    "        task_list.append(get_news(url, i))\n",
    "    await asyncio.gather(*task_list)\n",
    "\n",
    "s = time.perf_counter()\n",
    "await main()\n",
    "elapsed = time.perf_counter() - s\n",
    "\n",
    "if os.path.exists(\"output.csv\"):\n",
    "  os.remove(\"output.csv\")\n",
    "else:\n",
    "  print(\"The file does not exist\")\n",
    "\n",
    "with open('output.csv', 'w', newline='', encoding='UTF-8') as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow(['ID','page', 'post_date', 'title','summary','content','href','categories'])\n",
    "  for data in fetched_news_data:\n",
    "    writer.writerow(data)\n",
    "print(f\"Script executed in {elapsed:0.2f} seconds.\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📝建立tf-idf模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "import re\n",
    "news = pandas.read_csv('output.csv')\n",
    "re_punctuation = \"[^\\w\\s]\"\n",
    "corpus = []\n",
    "titles = []\n",
    "for article in news.iterrows():   \n",
    "    titles.append(article[1]['title'])    \n",
    "    pre_process_content=re.sub(re_punctuation, \" \", article[1]['content'])\n",
    "    corpus_data=' '.join(jieba.cut_for_search(pre_process_content))\n",
    "    corpus.append(corpus_data)\n",
    "    print(corpus_data)\n",
    "    print('--------------------------------------')\n",
    "  \n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 📝查詢相關文章"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_similarity_sentence(articleid):\n",
    "    print('[查詢文章]:{}'.format(titles[articleid]))\n",
    "    cosine_similarities = cosine_similarity(tfidf[articleid], tfidf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[-2::-1]\n",
    "    for idx in related_docs_indices:\n",
    "        if cosine_similarities[idx] > 0.3:\n",
    "            print('[相關文章]:{} {}'.format(titles[idx], cosine_similarities[idx]))\n",
    "get_similarity_sentence(69)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## beauty wall data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pymssql\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "import re\n",
    "conn = pymssql.connect('localhost:9487', 'sa', 'YourStrong!Passw0rd', \"beauty_wall\")\n",
    "cursor = conn.cursor(as_dict=True)\n",
    "cursor.execute('SELECT *  FROM [beauty_wall].[dbo].[Item] A WHERE WebPageID=%s', 'B040F8A0-6959-4C30-97C2-A35BF23ADBFD')\n",
    "#EDB7DCF0-FF4E-433B-8AD2-57454859B9F9\n",
    "#4B373E01-93E2-42E3-BE22-977B56DF0BF6\n",
    "#50E2EC5D-9A67-46E1-9002-DFB872C1C46E\n",
    "#09C926EB-9339-4A11-8AEA-F98EF0B575B2\n",
    "#58A4FC40-A4D7-4E2A-8BBF-170D4281EF4F\n",
    "#B040F8A0-6959-4C30-97C2-A35BF23ADBFD\n",
    "row=cursor.fetchall()\n",
    "re_punctuation = \"[^\\w\\s]\"\n",
    "corpus = []\n",
    "titles = []\n",
    "for article in row:   \n",
    "    titles.append(article['Title'])    \n",
    "    pre_process_content=re.sub(re_punctuation, \" \", article['Title'])\n",
    "    corpus_data=' '.join(jieba.cut_for_search(pre_process_content))\n",
    "    corpus.append(corpus_data)\n",
    "  \n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(X)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_similarity_sentence(articleid):\n",
    "    print('[查詢文章]:{}'.format(titles[articleid]))\n",
    "    cosine_similarities = cosine_similarity(tfidf[articleid], tfidf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[-2::-1]\n",
    "    idx_list=list(filter(lambda x:(cosine_similarities[x] > 0.3) & (cosine_similarities[x] < 1),related_docs_indices))[:5]\n",
    "    for idx in idx_list:\n",
    "        print('[相似內容]:{} {}'.format(titles[idx], cosine_similarities[idx]))\n",
    "# get_similarity_sentence(88)\n",
    "for i in range(len(titles)):\n",
    "    get_similarity_sentence(i) \n",
    "    print('--------------------------')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import jieba.analyse\n",
    "sentence='蔡譯心日本網友評選為最逆天長腿真是極品'\n",
    "jieba.load_userdict('./userdict.txt')\n",
    "tags = jieba.analyse.extract_tags(sentence,10, withWeight=True)\n",
    "tags"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('蔡譯心', 1.7078239289857142),\n",
       " ('網友', 1.7078239289857142),\n",
       " ('評選為', 1.7078239289857142),\n",
       " ('最逆天長', 1.7078239289857142),\n",
       " ('極品', 1.7078239289857142),\n",
       " ('真是', 0.8109688959714285),\n",
       " ('日本', 0.7151635023114286)]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}