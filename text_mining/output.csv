ID,page,post_date,title,summary,content,href,categories
144121,1,2021-05-06,【臺灣SRE實例：Line臺灣】如何確保Line服務天天不中斷，專責SRE扮演開發與維運的橋樑,去年，Line臺灣工程團隊成立了一支專責的SRE維運團隊，就是要為各服務的專案團隊找到開發和維運的最佳作法，進一步確保服務可靠性," Line在臺灣每天傳遞的訊息量，多達10億則，臺灣人的生活可說是離不開Line。為了服務超過2,100萬名的臺灣活躍用戶，3年前，Line臺灣工程團隊就擁抱Kubernetes（簡稱K8s），來提升開發速度，以及因應瞬間流量的挑戰，去年，他們更成立一支專責的SRE維運團隊，就是要為各服務的專案團隊找到開發和維運的最佳作法。
為何Line決定擁抱SRE？得從2018年K8s導入的故事說起。
為了管理大量雲端原生應用，Line臺灣展開K8s導入，要透過微服務、容器和DevOps，更即時調度基礎設施資源的需求。
當時負責開發新服務Line Now、Line Spot應用的Line臺灣資深工程師蔡智強，率先嘗試K8s，發現擴充彈性確實可以更自由，促使Line臺灣技術長陳鴻嘉決定擴大導入。
起初，Line臺灣採取單一叢集的部署策略，各服務共用同一個K8s叢集。然而，陳鴻嘉回顧，這個部署方式，沒有建立一套通用的維運實作範例，導致不同團隊各自調校自身的應用程式時，就可能會影響其他團隊應用程式的運作。後來，各團隊改採自建專用叢集的方式，來避免相互影響，但，專案團隊自建的叢集缺乏穩定度，仍非最佳作法。
2019年年底，Line總部在自家IaaS雲端基礎設施服務Verda平臺上，開發了一套K8s平臺提供容器服務Verda K8s Services（簡稱VKS），而VKS平臺穩定性越趨成熟。在2020年第二季時，陳鴻嘉決定把Line臺灣本地容器化開發專案，全部轉移到VKS上，就不需再自行維護底層K8s叢集，且各團隊可在VKS上使用自己專用的叢集。
為了降低容器化專案轉移到VKS的門檻，陳鴻嘉成立了DevOps任務小組，找來蔡智強擔任組長，教導各專案團隊派出的種子成員，如何轉移專案上VKS，以及如何使用VKS，並幫助專案團隊解決搬遷過程遭遇的問題，所以，小組還扮演著與總部溝通的統一窗口，收集各種VKS使用問題反饋給總部。
然而，考驗緊接而來，越來越多應用搬上容器環境後，不同專案在軟體架構上開始遇到類似的問題，而且都是棘手維運問題。DevOps任務小組開始討論，需要打造哪些工具和維運作法，但小組成員仍各自有專案開發工作，遲遲無法抽身來投入維運工具的開發。
陳鴻嘉表示，那時發現，必須有專職維運團隊，才能滿足各專案共同的維運需求。
所以，2020年第三季，Line臺灣正式成立了SRE團隊，由蔡智強領導這個專職團隊，來打造共用工具，建立一套維運管理作法，來減少各團隊部署容器化應用的時間，加快開發和交付服務的速度，另一方面，也負責彙整VKS平臺使用狀況，回報總部。

為求更即時調度基礎設施資源的彈性，Line臺灣從2018年開始，採用容器來取代VM，先自行建置一套K8叢集，而待總部在基礎設施平臺Verda上，建置了容器服務VKS，去年第二季，更把全部容器化開發專案，搬上VKS，來省去維護K8s叢集的工作，未來，還要進一步轉移所有專案到VKS。（圖片來源／Line臺灣）
Line臺灣SRE團隊3大責任
進一步來看，Line臺灣SRE團隊身負3大責任，第一項是負責開發跨服務共用工具，是現階段主要工作，占了SRE逾一半的工作時間。目前正聚焦觀測（Observability）平臺的開發，再陸續開發追蹤方面的共用工具。
第二項責任是支援開發工作。例如在新服務架構設計階段，協助解決架構問題。或是協助評估新開發項目所需的資源，協助規畫未來的容量需求，或幫忙審視新服務中是否有老舊技術債。特別的是，SRE還會與開發團隊討論新服務的開發作法。
蔡智強解釋，SRE會提出一些與日後維運有關的開發建議，開發團隊若採用，一旦有狀況發生，SRE才可以快速地介入，觀測服務的運作狀況，找出問題，他強調，統一相同開發需求的作法，才可以用最少的資源，並提供最多的支援。
最後一項責任就是，支援維運工作，協助專案團隊處理維運問題，像是調整參數。陳鴻嘉表示，排除問題是SRE的重要工作之一，因為大部分應用程式開發者不熟悉軟體堆疊中，應用層以下每一層的狀況，像是網路層、OS層、容器層等，需要SRE團隊幫忙，在軟體堆疊每一層中找尋問題，再反映給該層的負責人。
Line臺灣向來特別重視工程師文化推廣，因此，陳鴻嘉還找來目前領導DevOps任務小組的Line臺灣首席工程師劉栢峰，協助SRE團隊推廣他們建置的共用工具。劉栢峰過去是QA架構師，也熟悉DevOps、CI/CD、自動化測試等，他以長久累積的經驗，把SRE建立的工具和維運作法，串連成一套流程，讓這一套作法更有效率，方便推廣到每一個專案團隊。
現階段，Line臺灣SRE團隊已經從DevOps任務小組中獨立出來，但與任務小組間的關係仍密不可分，成員會參加彼此的周會。蔡智強表示，SRE需要知道各專案推行上遇到那些問題，才可以找尋解決方式，或是建立工具、機制來幫助他們，相反地，SRE建立了新工具，也需要DevOps任務小組協助推廣。
SE、SRE和DevOps大不同
其實一開始，Line並不是要設立一個專責SRE團隊，而是要設立服務工程師（SE）的角色。但後來陳鴻嘉發現，SE角色同樣也沒有餘力開發新工具。因為SE不只要管理底層基礎架構資源，還要處理許多日常維運工作，或是應用程式工程師的需求，像是準備雲端資源，甚至，服務發生故障時，需第一時間查找問題，所以需隨時待命。
陳鴻嘉指出，建立DevOps文化，也涵蓋開發和維運的流程、機制，但這對Line臺灣來說，還不夠，因為應用程式的需求和變化非常複雜，還需要一套標準化、自動化作法。「要達到自動化，就需要最佳實作的範例。」
因此，Line臺灣決定在開發者和基礎架構團隊中間，設立專責團隊，也就是SRE，來從開發者角度找出基礎設施資源的運用模式，建立標準程序。陳鴻嘉表示，SRE做的不是服務工程師的工作，不會為服務準備機器，在他的規畫中，SRE應是應用程式工程師與服務工程師之間的橋樑，要建立雙邊共通的作法，並以實現自動化作法為目標。
陳鴻嘉形容SRE與DevOps的關係，「如果DevOps是一個架設精緻的時鐘，每一個環節緊密相扣，那麼SRE就是提供源源不絕的動力的軸心，讓每個環節能夠完美結合。」
而和SE（服務工程師）相比，蔡智強解釋，SRE聚焦的是，如何訂定服務的可靠性指標，以持續觀測，再進一步來提升每個服務的效能，SRE（服務可靠性工程師）多了R（可靠性），就是將R可靠性放進組織定位中，他強調，可靠性是Line臺灣SRE工作的主軸。
特別的是，Line這個SRE團隊的成員，全端工程師比例很高。陳鴻嘉解釋，他期望臺灣工程團隊，要有能力鑽研軟體堆疊底層，也從整體堆疊架構角度來思考所開發的服務，才更容易發覺問題，因此，他從先SRE團隊開始，提高Line臺灣工程團隊的全端工程師比例。
另外，DevOps任務小組裡來自各團隊的成員，也肩負了推廣SRE作法的任務，將這些SRE的知識帶回各自的專案團隊，再由擅長全端能力的SRE團隊，從旁協助專案團隊排除問題。
陳鴻嘉表示，SRE沒有交付服務功能的時間壓力，可投入更多精神處理專案團隊的問題，他提到，這也是為什麼他沒有交予SRE服務維運待命（On-call）的輪班工作，他不想將SRE變成了SE。

Line臺灣工程團隊有三大組織策略，其中，新建立的SRE團隊扮演著與總部溝通的統一窗口，反饋各專案使用容器服務VKS平臺的狀況給總部，並進一步建立一套各專案共用的維運管理作法，來加快開發和交付服務的速度。（圖片來源／Line臺灣）
先打造服務觀測平臺，再統一量測標準
有了專責團隊，就可以展開SRE共用工具的開發。Line臺灣SRE團隊首先打造的工具就是，可掌握各服務運作狀況的觀測（Observability）平臺，更進一步再來訂定服務統一的監控量測指標，包含可用性、延遲時間等，來持續觀測服務的可靠度，還有收集服務的量測數值。Line也將觀測平臺打包成容器映像檔，讓開發團隊建立新服務時，直接使用，嵌入服務底層中，不需重新開發，還可加快新服務開發速度，減少了自建追蹤機制的開發工作。
蔡智強解釋，上了雲端，再加上採用容器取代VM，環境變得非常複雜，一個服務可能有30至50個容器，必須深入服務內，觀察每個容器的運作情況，才能掌握整體服務的健康狀況。陳鴻嘉補充，觀測平臺不是單純的console.log追蹤機制，而是日誌和報表系統間的一種觀測工具。
Line臺灣過去缺乏統一的服務觀測方式，導致各專案團隊各自從不同的角度觀測服務，缺少了一致的觀測標準。陳鴻嘉坦言，在管理面上，這個不一致帶來了兩大挑戰，第一，和利害關係人、業務團隊主管溝通系統運作狀況時，缺乏可描述系統穩定性的依據，也缺乏一套比較系統間穩定性差距的統一標準。第二個挑戰是，無法評斷哪個專案團隊的開發效能較好，也缺少最佳實作範例供團隊間相互學習。
蔡智強表示，SRE團隊要通過觀測平臺，來量化服務的可靠度。除了從各方面觀測系統數據的變化之外，還要從同一個角度來觀測服務，像是服務可用程度、回應正確率、回應時間都有一致標準時，就可以供專案團隊對內提升可靠度，或是讓團隊間對外比較可靠度。
但是，要統一各種服務的觀測標準，不是一件容易的事，每個服務面對的狀況不相同。Line SRE團隊會與業務團隊討論，先找出最有價值產品（MVP），再找出單一服務中最重要的功能，然後，從使用者的角度觀測這些功能，來確認這些服務是不是活著。
以觀測網路服務的可用性為例，監控程式會啟動實地測試，掌握連線速度，確認能不能載入服務，再統計單日總測試數中失敗的比例，來了解服務的可用性。目前Line臺灣設定的可用性標準為，至少需達99.95％以上，也就是單日1萬次測試，最多只能有5次失敗。
從使用者角度下手，建立業務有感的量測值
不只是建立觀測標準，陳鴻嘉還期待，SRE要進一步做到，從使用者角度，來量化服務效能或體驗的指標，讓業務團隊也能掌握這些觀測數值所代表的服務實際運作狀況。他解釋，以往與業務團隊溝通服務的可靠度時，像是提出服務延遲時間為0.8秒，然而，業務團隊往往難以了解，這個0.8秒延遲對用戶體驗的影響。為此，Line臺灣工程師早在去年就開始研究Google Web Vitals指標，要來找出如何用指標描述使用者的使用體驗，再進一步連結這些數值和使用體驗間的關連。
不過，去年設計觀測標準時，Line臺灣手上缺少了，以相同標準觀測各服務運作狀況的數值，這也是SRE團隊選擇優先打造觀測平臺的原因，就是為了先蒐集足夠的服務運作狀況數據，才能與業務團隊討論，如何訂定從使用者角度出發的量測指標，來媒合使用者體驗與量化數值。
目前，Line SRE團隊仍在持續擴充觀測平臺的功能，平臺儀表板功能除了可以顯示服務可靠性的各種觀測指標外，還可以呈現所用機器的記憶體用量、CPU數量等資訊，且因這些容器化服務都部署在VKS平臺，也嵌入了VKS相關指標，包含了節點數量、Pod數量、執行效能等。Line臺灣的目標是，將總部基礎設施和網路的相關數據，全部都整合進這個自建的觀測平臺，方便追蹤更多細節。
除了建置觀測工具，SRE團隊還利用開源軟體開發了多種工具，其中，為因應各團隊部署K8s的需求，使用了持續派送工具ArgoCD，結合Git儲存庫，可以做到GitOps。K8s搭配GitOps作法可帶來許多的好處，蔡智強舉例，可以將直接操作K8s叢集的行為最小化，進而降低手動操作造成的叢集不確定因素，還可以追蹤所有叢集的變動及變動的時間點，並可以在同一處管理配置。為了避免發生人工操作的錯誤，來開發更自動化的工具，也是Line SRE確保服務可靠性的一種作法。
專責SRE團隊創造三大價值
Line臺灣SRE團隊成立不到一年，蔡智強表示，但已經帶來了三大價值。首先，專案團隊使用VKS遭遇問題，SRE團隊會收集這些問題與總部討論，找出解決方法。尤其，去年，Line臺灣將所有容器化專案轉移到VKS的初期，遇到了很多除錯需求，許多問題出現在軟體堆疊的底層和中層，都是靠SRE團隊直接向總部反映。
陳鴻嘉表示，專案團隊忙於開發應用，沒有時間查找問題，過去沒有SRE作為中介，每次解法就是重新啟動，所以，現集中透過SRE與總部討論問題，不僅可加快問題查找的速度，各團隊也可更快獲得新作法，大大提升效率。
VKS平臺上線後，過去一年來持續在擴充，有許多異動，經驗豐富的Line臺灣SRE團隊，除協助自家專案團隊排除VKS的使用問題，反過來也協助了不少總部VKS平臺的優化工作。蔡智強道，總部常開玩笑說，我們是他們的SRE。
Line總部建置VKS平臺所用的技術，與Line臺灣早期建立K8s共用叢集的技術類似，兩個團隊經常交流，臺灣SRE團隊也加入了總部VKS維運問題的討論，每周都會討論和交流技術。陳鴻嘉笑言，總部很喜歡我們，因我們不僅常回報問題，且會與他們一起討論、解決。
在技術類似的基礎上，Line臺灣SRE團隊有時可直接向總部提供，平臺建置方式的建議，協助提升平臺的效能，有時會提出應用程式開發端在採用K8s上的需求。蔡智強解釋，因總部從建置基礎架構的角度出發，聚焦提升平臺的效能，缺少與專案團隊直接接觸的機會，而會忽略應用程式端的需求。
VKS平臺穩定性如今大幅提升，起初，臺灣SRE團隊每周需審視兩到三個VKS事故，如今已下降為，每一兩個月審視一到兩個事故。
SRE帶給Line臺灣的第二個價值是，提升工程團隊與利害關係人及使用者的溝通順暢度。工程團隊與利害關係人描述服務的可靠度時，可利用觀測平臺收集的數值，作為依據，不過，SRE仍在持續優化觀測平臺，還有統一量測標準。陳鴻嘉表示，目前還未能完全實現溝通上的價值。
第三個價值是，Line臺灣SRE團隊會逐步打造一套容器化服務的統一自動擴充機制，平時就不需再準備眾多的待命機器，進而節省了基礎設施的花費。但是，Line臺灣目前各專案團隊大多採用自己的擴充作法，還沒有完全統一，也常用手動方式來啟動擴充功能，導致擴充速度還不夠快。
未來，Line臺灣SRE計畫要整合各服務的共通需求，來訂定出可以自動判斷需擴充容量的一套規則，進一步打造最佳化自動擴充機制，以節省各服務的成本。陳鴻嘉表示，流量峰值瞬間可達平時的20倍，甚至100倍，需隨時準備較平時使用量多10倍的機器待命，有了自動擴充機制後，最少可以省下一半待命機器的數量。
解決問題是SRE須具備的核心能力
問及SRE須具備什麼樣的能力？陳鴻嘉不假思索的回答，「很簡單，那就是解決問題的能力。」他表示，SRE需永遠清楚怎麼找到問題，接著，還需知道如何找解決方案，並思考什麼方案才是問題的最佳解，而不是採權宜措施（workaround），把問題留著，服務能繼續運作就好，「這很危險，問題留到最後，會累積大量技術債，反而隨時會出問題。」他強調，找出問題的根本原因，才能長治久安。
成立還未滿一年的Line臺灣SRE團隊，未來將持續開發更多的共用工具，還有建立更多的最佳實作範例。對於SRE下一階段的發展，陳鴻嘉設定了兩大目標，要借助SRE團隊建立的共用工具和作法，新工程師入職當天，如應用程式出現問題，需救服務，新人5分鐘就可進入開發環境，協助排除問題，不像過去得花半天裝環境。如果，需處理新專案，新人也只需半天就可建立模型。
第二個目標是，為了因應流量高峰，每一個容器化的服務都要具備自動擴充功能。去年，Line臺灣先推行每個服務做到具可擴充性，今年進一步針對服務建立最佳化的自動擴充能力，預計明年可以完成。
",https://www.ithome.com.tw/news/144121,"新聞,Line臺灣SRE團隊,Line臺灣技術長,陳鴻嘉,網站可靠性工程,google,SRE,Site Reliability Engineering,Line臺灣,K8s,Kubernetes,服務觀測"
143911,1,2021-04-19,Container周報第137期：K8s今年第一個新版有50項更新，紅帽揭露OpenShift零信任架構未來3大發展方向,OpenShift在三月公布的發展藍圖中，接露了資安上的未來發展方向，將內建零信任架構，包括三大方向，部建階段的偵測能力、部署階段的保護機制和執行階段的應變機制," 4/1~4/15 精選容器新聞
#新版本 #K8s今年第一個K8s新版本1.21出爐，一口氣爆推50項更新
這個K8s新版本一口氣增加了50項更新，比前兩個版本都還要多（前一版才43個），進入穩定版的功能有15項，而新增的實驗性功能則多達19項。不過，也有一項開發中的資安工具Pod資安政策（PSPs）機制將放棄，1.25版會完全放棄，主要原因是此工具程式問題太多將不再投入資源來改善，開發社群會改推新機制來替代。可用來定期（每天或每周等）進行備份、報表製作的定期執行功能CronJobs進入穩定版，另外現在，機密設定Secrets和ConfigMaps新增加不可變動（immutable）的選項，可用來避免有些更新動作會動到這些不能變更的設定或資料，導致應用程式當機。
另外也可以支援IPv4/IPv6雙重架構機制（Dual Stack），讓Pos叢集和服務之間的網路路由可以支援原生IPv6網路，來提高網路擴充能力。另外，優雅節點關機功能進入Beta版階段，可減少突然關閉節點造成的問題。
新增加了持久性儲存Persistent Volume的健康監控機制alpha版，可用來確保本地端檔案型儲存空間的可用性。容器資安公司Sysdig工程師則推薦有幾個不錯的新功能，例如新的記憶體管理機制，有助於確保高耗記憶體類應用，如資料庫的運作穩定性。另外，K8s自動擴充功能（Autoscaling)也多了兩種縮小規模的作法可用，包括半隨機（Semi-random）和成本考量下縮小規模，可增加更多種資源調度的選擇。
#零信任架構 #K8s資安紅帽OpenShift未來要內建零信任資安架構，聚焦三大方向
紅帽最近在更新了OpenShift的發展藍圖，其中一項在資安上的未來發展方向是內建零信任架構，來提供DevSecOps工作流程。這個零信任架構將聚焦三大方向，部建階段的偵測能力、部署階段的保護機制和執行階段的應變機制。在部建偵測功能，包括可用GitHub Action來觸發開源YAML檔掃描工具KubeLinter，另外將提供免根權限的的部建功能獲釋免金鑰的映像檔簽章機制，另外也會支援加密容器功能。而在部署保護上，則會啟用強固多租戶（Hard Multitenancy）來避免有用戶遭感染而被波及，部署階段驗證、支援未來Pod資安政策替代機制、支援美國國防部IT安全組態指南DISA STIG。在執行階段應變機制，則包括了沙盒容器、服務網格政策自動化、Cert管理者的操作機制、k8s用戶端命名空間。不過，紅帽沒有進一步透露這些功能實現的時間點。
#Ubuntu #MicroK8s跟進動作超快，Canonical全面支援到K8s 1.21新版
K8s才剛在4月8日正式發布1.21新版，同一天Canonical也同時宣布，旗下K8s版本同步支援到最新的1.21版。包括輕量發行版MicroK8s、企業級跨雲部署用的發行版Charmed Kubernetes，而Canonical自家K8s部署工具kubeadm也同樣可以支援新版的部署。因為1.21版支援Calica eBPF資料層功能，K8s企業版Charmed Kubernetes也推出的新款的K8s儀表板功能和Charmed operators for DNS功能，更容易測試K8s叢集的網路能力。MicroK8s也有不少更新，例如OpenFaaS外掛新增無伺服器部署或OpenEBS外掛可以支援CAS儲存（Container Attached Storage）
#M1晶片 #DockerDocker桌面版正式支援Apple Silicon，百萬容器開發者能用M1晶片了
Docker官方宣布，支援M1晶片的Docker Desktop for Mac終於推出正式版本。因為超過3百萬開發者使用Mac，而其中有一半的人使用Docker Desktop。因此去年12月官方緊急推出品質甚至不到Beta測試版的Docker Desktop for Mac（Apple Silicon）早期預覽版，社群對於預覽版本反應熱烈，前前後後各個預覽版下載次數達4萬5千次，臭蟲追蹤器也收集到了140個回報，社群在Slack上積極回應，而現在經過約莫4個月，官方終於釋出最新Docker Desktop 3.3.1版本，從這個版本開始Docker Desktop正式支援Apple Silicon。

#OpenShift #AWS AWS提供全託管的OpenShift服務了，紅帽和AWS共同提供技術支援
雲端巨頭AWS終於也推出全託管的OpenShift服務Red Hat OpenShift Service（ROSA）了，可以將部分或是全部的OpenShift部署，搬遷到AWS上，技術支援則由。ROSA服務由紅帽和AWS共同管理和支援，因此用戶可以同時向紅帽以及AWS請求支援服務，但統一由AWS來出帳。可用OpenShift標準API以及現有工具，也可以使用AWS運算、機器學習和網路等各種服務，來擴展或是開發創新應用。目前ROSA已經在許多地區上線，包括美西、美東、南美、加拿大和歐洲，而亞太地區則在東京、首爾、孟買、新加坡和雪梨提供。
#無伺服器 #容器化應用IBM無伺服器容器服務CCE正式上線，要開始收費了
最近正式推出的IBM CCE（Cloud Code Engine），是一個全託管式無伺服器容器運算服務，可用來執行容器化應用的運算工作。這項服務使用了K8s、Knativ、Istio和Tekton來打造，能夠提供從容器應用的建置、部署到自動擴充，也可以將程式碼封裝成映像檔。除了無伺服器服務基本的事件驅動啟動之外，也支援批次啟動容器應用的功能，可以預先排程設定要開啟的容器應用和擴充規模。進入正式版本也意味著IBM這項服務開始收費。這項無伺服器容器應用服務也可以整合IBM自家雲端服務，例如Watson雲端服務或IBM DB2雲端服務。

#K8s重大漏洞 #遭DoS攻擊風險Kubernetes內建GO函式庫發現重大漏洞，可引發DoS攻擊
Palo Alto公司的Unit42研究人員Aviv Sasson發現，Kubernetes的Go函式庫一項重大漏洞，可能導致容器遭到阻斷服務（denial of service，DoS）攻擊。研究人員在K8s運行的一個名為container/storage的Go函式庫中，發現安全漏洞CVE-2021-20291。這個漏洞可以在儲存庫（registry）上傳惡意映像檔時觸發，即當使用者從registry拉取這個映像檔時，造成對CRI-O及Podman兩個容器引擎的DoS攻擊。這漏洞影響層面相當大，因為從Kubernetes 1.20版起，Docker就退役了，唯一的容器引擎是CRI-O及Containerd，這會讓許多使用CRI-O的叢集曝險。
#金融產業雲 #OpenShiftIBM金融雲正式上線，底層是紅帽OpenShift
IBM在2年前和美國銀行（Bank of America）合作打造一朵金融服務專用的公有雲，最近終於進入正式版本，這朵雲部署在OpenShift服務上， 搭配硬體加密，也提供自行保管金鑰（KYOK）的功能。除了美國銀行，後來法國巴黎銀行、三菱日聯銀行、愛沙尼亞地第三大魯米諾銀行也都加入這項計畫。IBM金融雲也可以搭配Cloud Satellite服務，在本地端部署金融應用，但統一由雲端來管理。
#容器資安  #DevOpsVMware推出K8s環境專用可用的容器資安掃描工具，可整合CI/CD流程
最近VMware推出了一款專門用來掃描K8s環境中容器應用的資安掃描工具Carbon Black Cloud Container工具，可以進行弱點掃描和錯誤配置的掃描，另外也支援多種常見的CI/CD平臺，方便企業將這個工具整合到自家的DevSecOps流程中。
#容器映像檔掃描 #雲端資安老牌資安業者Sophos升級雲端資安狀態管理工具，新增容器映像檔掃描功能
越來越多雲端資安管理工具將容器印象檔掃描機制變成了內建功能，最近老牌資安業者Sophos自家雲端資安狀態管理工具，Cloud Optix服務也新增了這項容器映像檔掃描功能，可以掃描容器映像檔中的作業系統漏洞。這個掃描工具也可用用來檢測大型單體應用、容器化應用和微服務應用的之間所用的資安政策是否一致。Cloud Optix可以用於映像檔部署前也可以於部署後掃描。這工具也可以支援Amazon ECR和微軟ACR和慣用的Docker Hub儲存庫。也可整合到Bitbucket和GitHub所用的部建流程工具中也可以使用Cloud Optix的API來進行映像檔掃描。


#DevOps #GitOpsGitHub CLI命令列工具終於支援超強Actions
GitHub CLI命令列工具是很多開發者愛用的本地端GitHub工具，許多可以透過這個工具來建立從本地端到雲端的DevOps或GitOps流程，不過，這個工具一直少了一個重要機制的支援，就是GitHub自家的軟體自動化機制Actions，這也是很多開發者愛用的DevOps工具。最近GitHub CLI釋出一年後，終於新增央向內建指令gh，可以讓開發者在終端機環境中直接驅動各種工作流程的執行動作，開發者習慣將一系列流程觸發動作整理在一個YAML格式工作流程定義檔，現在也可以直接在終端機環境中執行，更方便來管理這個工作流程定義檔。
責任編輯：王宏仁

更多容器新聞 
跨雲部署用的Tanzu Kubernetes Grid服務正式推出1.3版，不過只支援到K8s 1.20版的部署。
VMware正式從Dell分拆，仍然由VMware財務長擔任臨時執行長
",https://www.ithome.com.tw/news/143911,"新聞,容器週報,K8s,Docker,OpenShift,容器資安,DevOps,Kubernetes,IT周報"
143877,1,2021-04-16,搶進RPA市場，IBM收購流程採礦廠商myInvenio,IBM要將myInvenio的流程自動化、文件處理、流程採礦、RPA等技術，納入自家雲端流程服務，以切入日益競爭的RPA市場," IBM昨（15）日宣布收購義大利流程採礦軟體新創業者myInvenio，未來並將整合到IBM雲端流程服務中。
IBM指出，這項收購將可提供企業流程驅動的軟體，以AI技術協助他們找出有問題的業務流程以提升流程自動化，包括業務、採購、生產及會計等。本收購也可強化IBM混合雲，提供AI為基礎的完整AI自動化套件方案。IBM表示預計今年第3季完成這項收購。
所謂流程採礦是指以一組自動化軟體工具，蒐集並分析企業軟體產出的資料及運作情形，以提供流程最佳化的建議。
這項收購也是IBM強化RPA（robotic process automation）方案的策略一環。去年11月IBM已和myInvenio合作，在其雲端產品IBM Cloud Pak for Data及Cloud Pak for Automation整合myInvenio的分析引擎。這兩項服務執行在Red Hat OpenShift上的資料整合及AI服務。而在去年8月，IBM也併購了巴西AI流程自動化業者WDG Automation。
IBM表示，未來這些流程自動化、文件處理、流程採礦、RPA功能等，都會緊密整合於IBM Cloud Pak for Data及Cloud Pak for Automation之中。
IBM最新收購使其成為加入RPA戰局的大廠。雲端業者包括微軟、Google等先後提供RPA產品，讓一般IT使用者以低程式碼甚至無程式碼工具，就能開發流程機器人等程式或設定自動化流程。
",https://www.ithome.com.tw/news/143877,"新聞,RPA,myInvenio,IBM,收購,企業流程驅動,流程採礦,Cloud"
143592,1,2021-04-08,Line AI開發的關鍵基礎架構──ML Universe關鍵功能大公開,涵蓋了從模型實驗、Pipeline的持續部署與交付、自動化建立Pipeline，以及模型的持續訓練、持續部署、持續監測等流程," Line透過MLOps設計了一套標準化的AI開發流程，其中涵蓋了從模型實驗、Pipeline的持續部署與交付、自動化建立Pipeline，以及模型的持續訓練、持續部署、持續監測等流程，若模型發生衰變就會回到模型實驗的環節，重複先前的循環。
為了實現這個開發流程，Line建立起一套加速AI開發的協作平臺ML Universe（簡稱MLU），在平臺中整合多種開源或自建的工具，讓使用者在MLU平臺中，能直接呼叫開發工具來使用，而不用擔心個別軟體的開發環境設定；同時，透過各種開發工具在不同環節的應用，也能作為溝通憑藉，讓不同角色成員更容易介入協作。
「我們希望透過MLU平臺，可以讓開發者更輕鬆創造出許多有價值的AI應用。」Line臺灣研發工程部資深資料工程師孫韻如表示，藉由MLU平臺，Line要在維持模型開發品質的同時，也消除不同角色之間的知識壁壘。

Line透過MLOps設計了一套標準化的AI開發工作流，其中涵蓋了從模型實驗、Pipeline的持續部署與交付、自動化建立Pipeline，以及模型持續訓練、持續部署、持續監控等流程。若模型發生衰變，就會回到模型實驗的環節，重複先前的循環。（圖片來源／Line臺灣）
資料準備與探索階段工具
重點功能：特徵商店（Feature Store）
資料工程師在進行特徵工程時，由於這項工作需經過反覆的試驗，團隊建立了用來管理特徵資料的特徵商店（Feature Store），讓資料工程師能將處理後的資料，透過一個統一的介面輸入特徵商店，將特徵資料以標準化的方式來儲存。
如此一來，ML工程師與資料分析師，也能透過同一個介面來查找所需資料，不用再費時處理資料，藉此達到重複利用特徵資料的目的。
模型開發與訓練階段工具
重點功能：程式碼開發工具Jupyter Notebook
團隊整合了Jupyter Notebook作為協作開發的工具，讓開發者能直接在MLU平臺中開啟Notebook介面來使用，Line也已經預安裝好AI開發常用語言及框架，如Python、Tensorflow、PyTorch、Keras、OpenCV，還有NFS、CephFS、S3FS等文件系統，以及能提供分散式任務調度、排程和基本的I/O功能的PySpark核心，讓開發者不用一一自行安裝，只要點選就能開啟。
Line也同步綁定內部的帳號權限，讓開發者只能開啟權限許可的專案，藉此來進行專案管理。
Line臺灣資料工程部資深經理蔡景祥指出，Jupyter Notebook是現行在開發AI應用時，最常使用的工具之一，這個介於編輯器與IDE之間的開發工具，能較清楚的定義開發流程中的不同階段，有助於釐清不同開發者的業務，且因Jupyter Notebook是建立於Web之上的應用，也能較輕易的在團隊中共享、檢視程式碼。
重點功能：程式碼審查工具Jupyter NB viewer、ReviewNB
Line自行開發了Jupyter NB viewer，讓專案程式碼能被共享與瀏覽，來確保每一份程式碼，都至少有兩個人以上看過。Line也採購了Jupyter Notebook的協同作業工具ReviewNB，來與Jupyter NB viewer交互使用，讓程式開發的協作與程式碼檢視工作都更流暢。
ML流程編輯工具Pipeline Editor

為了減少ML開發者與工程人員的溝通成本，Line自建了一個視覺化ML工作流編輯工具Pipeline Editor，讓開發者在開發完模型後，能直接透過拖拉設定的方式來建立ML工作流程，來取代過去需要手動程式開發的作法。（圖片來源／Line臺灣）
為了減少ML開發者與工程人員的溝通成本，Line自建了一個視覺化的編輯工具Pipeline Editor，讓ML開發者在開發完模型後，能直接透過拖拉設定的方式來建立ML流程。Line更在每一個開發步驟，都設計了編輯器功能，讓開發者從介面設定參數，就能配置每一階段中介產物的來源與儲存位置，進而串起整個開發流程達到自動化。
孫韻如進一步解釋，比如在開發ML模型時，在每個環節都必須要指定中介產物儲存的路徑、命名格式與存取權限，完成後才會依照設定儲存到相應位置，但以往，這些設定必須寫程式去定義，這對ML開發者來說具有一定的開發門檻，通常要靠工程維運的角色將ML流程串起來。
「Pipeline Editor的好處，就是當資料科學家開發完模型，將服務部署上線時，不用從頭到尾寫程式來串起流程上的每個作業，只要透過視覺化的介面，來完成相關設定就好。」孫韻如說。
蔡景祥也回憶，最初在開發ML模型時，全團隊還只有自己一個人，從熟悉的模型開發工作，到流程串接，包括檔案如何放、如何取，全都要靠自己寫程式來配置，「而且只適用這個專案，完全是一個客製化的工程。」直到建置了MLU平臺，將客製化開發轉變為通用性的設定，才讓每個人的ML專案都能快速實現。
工作流管理平臺Airflow
開發者在編輯完Pipeline之後，能透過開源工作流管理平臺Airflow，將Pipeline能自動轉換為Airflow的腳本，來進行後續的部署、CI/CD的工作流程，並能從MLU平臺進行版本控管，讓開發者不需要從零開始學習Airflow工作流的建立，只需進行簡單設定，就能在幾秒鐘內建立一個Airflow實例。
針對Airflow的管理，Line也在Airflow中配置了K8s執行器，來更有效率地管理工作流排程，開發者也能從MLU平臺來監控Logs或是重啟Airflow。
雲端ML平臺NSML
在模型訓練的環節，Line臺灣透過由上百顆GPU支持的NSML平臺來訓練模型，滿足大量的運算需求，並透過視覺化的方式來監控所使用的資源量，且NSML平臺也提供了AutoML的功能，能自動進行超參數調校，來節省部分ML模型需要反覆調校超參數的時間。
模型訓練與測試通用工具
版本管理平臺MLFlow
針對持續訓練時產生的不同模型版本，開源ML平臺MLFlow，能記錄或查詢每一次實驗的程式碼、訓練資料、參數配置及訓練結果，讓開發者能更容易進行版本控管，還能在後續模型測試的階段，進行簡單的分析驗證。
模型部署與監控工具
ML模型部署平臺BentoML
在模型經過驗證後，由於資料科學家要將預測服務產品化，具有一定的開發門檻，Line透過開源ML模型部署平臺BentoML，讓開發者能將選定的模型存取下來，透過簡易的設定，手動或由系統自動打包成Docker Image，再部署到Docker Hub中。接著，透過自動擴充的模型部署工具搭配K8s，就能根據流量來自動擴充運算資源量。
Prometheus+Grafana、BI
在上線後的模型成效監控環節，需監控的面向包括服務本身的健康程度，以及模型是否因環境的變化而衰退，前者可以透過普羅米修斯（Prometheus）搭配Grafana來監控，後者則需要根據業務邏輯來設定監控指標，並透過BI儀表板來監控。若發生模型衰變情形，也將觸發重新訓練來維持模型預測表現。
 從實例看MLU平臺如何加速AI開發 
在MLU平臺中整合了多項ML開發常用工具後，Line在開發ML專案時，就能根據ML專案的特性，選擇不同的工具來加速ML開發。
比如說，Line的關鍵字搜尋推薦模型，是根據使用者查詢的歷史記錄，來建立詞與句子的嵌入模型，進而在搜尋欄位推薦用戶關鍵字。Line臺灣研發工程部資深資料工程師孫韻如指出，由於使用者搜尋的關鍵字，會跟著每天的潮流或趨勢而改變，這類模型對於輸入資料的變化特別敏感，需要頻繁的迭代更新，甚至每天都需要重新訓練，才能維持模型的推薦表現。
因此，在這個模型的維運上，Line臺灣透過MLU平臺整合的儀表板工具，來監控模型服務端的健康指標，自動觸發模型進行重新訓練與迭代更新；而且，為了保障模型品質，團隊也運用MLFlow來進行版本控管與模型驗證，若更新後的模型表現低於設定指標，就會自動捨棄更新後的模型，直接採用前一個版本的模型來進行預測，確保模型品質在一定水準之上，「整個流程都已經自動化。」
除了模型本身的監控，團隊也透過用戶端的監測機制（如點閱率），來分析使用者對於Line所推薦的關鍵字是否買單，進而去判斷，除了模型自動迭代更新，ML工程師是否需要手動重新開發模型，「因為當模型劣化到一定程度，就需要從根本上重新調整。」
另一個同樣運用了MLU平臺的模型，是文章內容推薦模型，比如Line的內容服務就是運用這個模型，推薦用戶相同類型的文章來閱讀。這個ML模型是以ELECTRA框架為基礎來開發，在訓練這類模型時，由於資料集龐大、模型複雜度高，會需要針對超參數進行大量反覆的試驗。
因此，團隊運用MLU平臺中，AutoML自動調整參數的功能，來更有效率的篩選出表現較佳的模型，同時也透過BentoML，來提供服務端可直接呼叫的API，節省部署上線的時間。
除了上述兩個在線上提供預測服務的模型，Line臺灣也開發了線下服務的模型，比如目標群眾鎖定（User Targeting）模型，目的要在最小成本下找到最容易被吸引的使用者群，來生成一份目標群眾的名單，提供後續活動推播時使用。這個ML應用與上述兩者的最大不同，是該模型不是將預測服務打包成API，透過線上呼叫API來取得預測結果，而是在線下生成用戶名單，這類部署方式也能透過MLU平臺來快速交付。
完整系列報導在這裡
",https://www.ithome.com.tw/news/143592,"新聞,ML Pipeline,AI開發,MLOps,AI落地,協作,DevOps,人工智慧,AI應用,MLOps解決  方案,ML模型自動化,AI維運,Line"
143589,1,2021-04-07,【靠ML協作平臺加速AI落地】Line如何用MLOps重構AI開發流程,Line去年正式上線了一套加速AI開發的關鍵基礎架構平臺，要讓不同角色各司其職，藉由更緊密分工協作來系統性落地AI," 近年來，Line積極轉型為一家AI企業，從自然語言處理、語音辨識、電腦視覺、OCR、臉部識別、影音處理、資料分析到語音合成，各種AI技術都要涉獵。打開Line應用程式，無論瀏覽Line Today、Line TV、Line Music或是Line購物的頁面，各種內容的個人化推薦，甚至是聊天訊息的事實查核機制，背後都是靠ML模型來支持運作。
隨著Line運用AI更深、更廣，更加依賴AI來提供各項服務，Line也摸索出一套更快落地AI的方法，循序漸進的實踐MLOps，從剛開始逐一導入輔助開發的工具，到進一步整合多項工具打造了ML平臺，Line一步步重構過去的AI開發流程，就是要讓Line集團的所有AI團隊成員，透過一套更緊密分工協作的開發流程，加速AI規模化落地。
Line如何設計ML平臺加強人員分工協作？
一開始實踐MLOps時，Line韓國總部發起了一個名為Jutopia的ML平臺開發專案，催生了Line當前AI開發的關鍵基礎架構──ML Universe（簡稱MLU）。Line臺灣AI團隊也跨國參與了這個專案，Line臺灣資料工程部資深經理蔡景祥直言，這套系統性AI開發與維運方法就是MLOps。
Line中國的一位負責Jutopia專案的團隊成員Changqin He，在去年底的Line開發者大會上首度公開了這項專案。他一開始就先提問：「資料科學家要透過什麼方式，向企業說明數據分析的結果？資料工程師要如何確保程式的可靠性，維持每小時運行不中斷？ML工程師又該如何保留ML開發過程的迭代，讓其他專案重複使用？」

Line中國負責Jutopia專案的團隊成員Changqin He表示，Line發起一項ML協作平臺專案命名為Jutopia，目標要建立起一套標準化的ML開發工作流，透過系統性的AI協同開發方法，讓AI各階段的開發更順暢。（圖片來源／Youtube）
這三個問題，正是Netflix在思考未來的資料分析工具應具備哪些功能時，預設涵蓋的三個面向，Netflix更以Jupyter Notebook，作為最可能實現上述三個場景的開發工具，決定在企業內深度導入使用。
Changqin He則是引用了這三個問題，點出AI協作的重要性，同樣以Jupyter Notebook為核心發起一項ML協作平臺專案，更取其字首命名為Jutopia，目標要建立起一套標準化的ML開發工作流，透過系統性的AI協同開發方法，拉近開發團隊成員間的距離，讓AI各階段的開發更順暢。
比如說，Line的資料科學家過去在實作一個ML專案時，需要花費許多時間在工程端的程式開發上，身為過來人的蔡景祥形容，開發AI得從頭到尾「手刻」一個ML開發流程，比如設定資料或模型的匯入匯出位置、系統間的串接，甚至是將模型打包成服務、部署上線等工作，全部都要包辦。雖然也能將這些工作交由工程端人員執行，但兩個角色之間也需要頻繁溝通，才能確保開發流程不出錯。
為了克服這個挑戰，Line打造了一個ML平臺（後來稱為MLU）。這個平臺最核心的功能，就將工程師各自打造的ML開發流程，轉變為更容易重複使用的標準化流程，讓工程師實作不同ML專案時，不用再花時間重新打造輪子。甚至，直接透過MLU平臺的編輯器功能，就能快速設定不同專案各自需要的ML流程配置，再由系統自動執行指令，來完成開發環境的配置。
不只如此，MLU平臺還整合了多項開發工具，讓使用者能在平臺上直接呼叫開發工具來使用，而不用擔心個別軟體的開發環境設定，透過各種開發工具在不同環節的應用，不僅能進一步提升AI開發效率，也能同時作為溝通憑藉，讓不同角色成員能更容易介入協作。
「我們希望讓寫模型的人專心寫模型，應用開發的人專心開發應用，不用再費心處理繁瑣的系統串接與維護工作。」蔡景祥表示，讓每個角色都能專注於自己的專業技能，來更有效率地進行AI開發，就是MLU平臺建立的初衷。
Line如何角色分工參與AI關鍵任務開發？
「在AI開發流程中，沒有人可以從頭到尾做完所有事情。」蔡景祥坦言，隨著AI團隊逐漸擴大，會逐漸分化出不同的開發角色，這些角色可能包括了負責特徵處理的資料工程師、負責模型開發的ML工程師、部署模型的IT維運人員，甚至不只是開發與維運端的人員，連商業面的資料分析師或產品經理，都需要在不同的開發階段，運用各自的專業來優化AI。
像是在Line資料工程團隊中，也分化出多元的角色來共同開發AI，分別是資料工程師、ML工程師、ML服務工程師，以及資料分析師4大角色。
若以打造遊樂園來比喻，蔡景祥指出，資料工程師的任務，就是打造遊樂園的基礎建設，透過建立起一個穩固的資料收集設施，來根據需求蒐集資料，需擅長如大數據架構、SQL、ETL、訊息佇列（Message queuing）等技術。
ML工程師，則像是遊樂園的設計師，負責選出適當的資料集與演算法，來建立起合適的ML模型，需具備的技能包括機器學習、深度學習、電腦視覺、NLP等。
ML服務工程師，則像是遊樂園基礎建設的實際施工與維護者，主要負責建立並維運一個ML平臺，需熟悉的技術包括系統基礎建設設計、DevOps。
資料分析師，則需比工程師具備更多的商業思維，要能夠利用統計的方法，來分析模型上線後的實際成效，類似於在遊樂園中觀察哪些設施需要改善的角色，因此需具備商業知識、熟悉統計及資料視覺化等技能。
除了分化出4大不同專業的AI開發角色，Line也將ML工作流程分為6大環節，分別是準備資料、探索資料、開發模型、訓練模型、測試模型與部署上線，蔡景祥也以Line臺灣實作AI的經驗，來說明不同角色如何在各個開發環節中進行協作。
首先，在準備資料的階段，由於領域知識扮演了重要角色，在資料標註的過程中，需要產品端、資料分析與資料工程專家相互協作，來篩選出有效的資料提供後續使用。
接著，進入探索資料階段，則會交由ML工程師，根據資料特性來發掘資料潛在的價值，並透過特徵工程萃取所需的資料特徵。
有了資料，就能進入模型開發的階段，此時，會需透過ML工程師、資料工程師及資料分析師的協作，選擇適當的演算法來開發模型，在這個階段中，演算法的挑選與模型的版本控制，成為協作過程中的重要的課題。
而後進入模型訓練的階段，則會交由ML工程師，負責進行超參數的調整與硬體運算資源的調度。
模型訓練完成後，將進入測試模型的環節，同樣交由ML工程師負責，來驗證模型是否確實有效、是否達到預期的效益。
若沒問題，就會進入最後的部署上線階段，需要ML工程師、ML服務工程師共同協作，來確保模型在實驗環境與線上環境中的表現並不會產生太大偏差，也不會隨著時間衰退，實際部署後也要能應付大流量的預測需求，才能有效擴大提供服務。
「MLOps是一個在ML全生命周期中，涉及到的所有人員共同協作的方法。」蔡景祥表示，該如何讓不同角色在ML開發各階段相互協作，就是Line的AI團隊，想用MLOps做到的事。
完整系列報導在這裡
",https://www.ithome.com.tw/news/143589,"新聞,ML Pipeline,AI開發,MLOps,AI落地,協作,DevOps,人工智慧,AI應用,MLOps解決  方案,ML模型自動化,AI維運,Line"
143586,1,2021-04-06,企業規模化落地AI關鍵是MLOps（下）三大原因助MLOps快速興起,促使MLOps快速成長的原因之一，是COVID-19疫情帶動大環境快速改變，導致許多部署上線的模型在一夕間不敷使用，凸顯了AI維運的挑戰,"  本文上半在這裡 
雖然從2014年開始，就已經出現MLOps的實踐案例，但這套AI協作的概念兩年前被重新定義，形成一股AI開發新趨勢吹進全球。
MLOps興起主要有三大原因。第一，是企業用過去的開發方法來擴大AI應用規模時，開始面臨瓶頸，Line臺灣資料工程部資深經理蔡景祥以自身經驗為例表示，過去只有自己一人開發AI時，能清楚了解每個程式開發步驟的意涵，但這種開發流程過於客製化，一旦有第二個角色要共同協作，就得相互溝通來理解每個開發步驟，徒增許多溝通成本。
勤業眾信去年發布的技術趨勢報告也提到，企業剛開始開發AI時，容易採取英雄主義作法，靠少數資料科學家包辦從頭到尾的開發流程，但這些流程高度手動、難被複製或擴張，會增加協作過程中的溝通成本，難以提升開發速度。藉由MLOps的實踐，才能讓過去自成一格的特製化開發（Exceptionalism），走向快速擴張且更有效率的專業化開發（Professionalism）。
第二，則是AI開發面臨部署上線的挑戰，讓更多企業開始採用MLOps。根據國外企管顧問公司Vantage Partners去年調查，在美國，儘管有91.5%的企業都表示正在持續投資AI，卻只有14.6%的企業已經將AI部署到生產環境，換句話說，實作了AI卻難以部署上線，就是企業應用AI的一大痛點。
IDC在2020年發布的全球AI採用度調查也發現，根據受調查的2,000多位IT或相關主管回覆，仍有約有28%的專案因缺乏專家、生產數據與整合的開發環境，最終以失敗收尾。IDC因此鼓吹，企業必須擁抱MLOps，才能更大規模的實現AI。
勤業眾信風險管理諮詢副總經理廖子毅更以身為資料科學家的開發經驗點出模型部署的難處。他解釋，雖然在AI開發的實驗階段，資料科學家可以在數周內快速訓練出良好準確率的模型，但是，一旦要落地生產環境，就需要根據現實資料進一步調校模型，還要將模型打包成預測服務，手動開發的過程可能要花費數月甚至一年以上。因此，企業得建立起持續交付、持續部署的作業流程，才能加速落地AI。
第三個促使MLOps在一年內快速成長的原因，則是受到疫情帶動大環境快速改變，導致許多部署上線的模型在一夕間不敷使用，凸顯了AI維運的挑戰。勤業眾信內部觀察，疫情期間的「新常態」，導致許多供應鏈需求預測模型，已經無法再仰賴過去的數據和假設，需要滾動蒐集企業與用戶資料，必要時更需重新訓練模型，才能維持預測服務的準確率。
業界也開始感受到MLOps市場升溫，一家MLOps軟體商DataRobot臺灣總經理蔡宜真透露，近一年來，企業對MLOps的詢問度提升，除了疫情驅動企業加速採用AI，連帶的提升對MLOps的關注，更因消費者行為的大幅改變，導致模型表現快速偏移，來詢問的企業正因這個契機重新檢視模型維運的流程，開始意識到MLOps的重要性。
更多AI廠商加入戰局，要瓜分2025年40億美元市場大餅

勤業眾信製作了一張全球MLOps版圖，整理了三大類別的MLOps廠商名單，包括全球六大AI與MLOps服務供應商、從ML平臺跨足MLOps解決方案的供應商、以及僅提供MLOps解決方案的業者。（圖片來源／勤業眾信）
MLOps概念興起後，市場上越來越多AI服務供應商投入這個市場，帶動了MLOps的聲量。比如公有雲大廠如微軟、Google以及AWS，本來就提供完整的AI開發服務，微軟更在2019年的Build大會上，率先宣布了Azure ML服務中的MLOps功能，Google以及AWS隨後跟進，就是讓開發者能透過平臺工具快速建立ML工作流，更著力於AI全生命周期的管理與監控，來加速AI產品化。
勤業眾信內部製作了一張全球MLOps版圖，除了名列三家公有雲業者，更將IBM、SAS與HPE，劃入AI與MLOps大型服務供應商的行列。
MLOps版圖更顯示，在公有雲推出服務之前，市面上也已經有些ML平臺服務供應商，提供企業從開發到維運端的平臺服務，讓企業能快速導入來開發AI應用，比如Databricks、DataRobot、Dataiku、Iguazio、C3.ai、H2O.ai等廠商；後來MLOps興起，這些廠商更進一步聚焦ML部署與維運端的工具，奠基在原本的ML平臺的基礎上提供MLOps服務。除此之外，市場上也出現了單純提供MLOps解決方案的新創企業，比如Dotscience、Algorithmia、Datmo等。
勤業眾信風險管理諮詢副總經理許梅君提供一份內部估計，MLOps市場預計在2025年達到40億美元，複合年增長率為50%，將成企業擴大應用AI的又一大關鍵市場。
除了導入相關工具與平臺，許梅君也提醒，企業需建立一套管理機制，讓AI在合規的前提下快速落地，比如資料治理的規範、資料及專案的權限管理、資安與AI風險的管理，也需透過相關規則的建立，避免AI做出違背常理的判斷或有偏見的決策，且當AI用於個人化決策的場景，更要建立可解釋性AI機制，以及人機協作進行決策的原則或方法。
「導入工具或平臺來解決局部的問題，能夠快速看見AI開發的成效，但光是這樣不能解決企業面臨的所有問題，還要建立起管理機制，帶動組織或文化的改變。 」許梅君說。
 不只講究ML模型自動化，AI維運也是MLOps關鍵 
「過去，資料科學家部署完模型後，就認為工作已經告一段落，沒有模型維運的概念，」DataRobot資料科學家藍秀仁解釋，以前只講Model Management，聚焦開發流程中的版本管理。直到近幾年，模型上線後表現產生偏移而失效，才讓更多人認真的看待模型維運的重要性，在MLOps中，更重視透過監控並迭代更新模型，來維持預測服務的準確率。
MLOps泛指從AI開發到維運各階段的協作，若聚焦在ML部署與維運階段，涵蓋了從模型快速部署、上線、監控到重新訓練等機制。
這個階段不只要讓不同程式語言、架構開發的ML模型，能夠快速部署到生產環境，整合到系統或App來提供預測服務。預測服務上線後，也需透過監控機制來檢視模型表現，來了解部署在本地端、雲端的每個ML模型，每日新進的輸入資料是否漂移、模型的準確率是否下降、預測服務是否健康，更要能長期監控模型表現的變化趨勢，來更全面的評估是否有重新訓練、迭代更新的需求。
藍秀仁也建議，企業應在維運監控階段，納入一般常識檢查的判斷機制，像是，讓上線後的ML模型預測結果，不會違背常理或超出現實，比如若AI預測出年齡超過120歲、日薪超過千萬，或是自駕車辨識道路的信心值不夠高，就會透過一套機制來阻止決策執行。
另外，為了避免模型做出偏誤決策而不自知，企業也應設計偏誤資料的監測機制，在模型輸出不公正預測結果時，找出隱含偏見的訓練資料，再交由開發人員將偏誤資料去除，重新進行模型開發、部署更新的流程。
 如何選擇MLOps工具？
勤業眾信提供了一家AI解決方案供應商Ambiata所製作的MLOps工具比較表，可做為企業評選MLOps商用與開源工具之用。這個比較表將MLOps工具分為四個類別，分別是資料與Pipeline版本控管、模型實驗版本控管、超參數調校、模型部署與監控。勤業眾信提醒，企業得先清楚了解哪一個環節有需求，例如待解決的開發痛點，再來導入相應功能的工具。
由於功能相近的MLOps軟體很多，企業也可以進一步根據自身常用的程式言語與函式庫，比如企業開發AI時，使用Python與R來開發，常用如Tensorflow、PyTorch、Keras、Scikit-learn等函式庫，來選擇可支援開發的MLOps工具導入。
在挑選工具時，也能參考GitHub上的評分星級、貢獻者或員工數量，列為挑選工具的一大考量，前者可作為該工具受歡迎程度的參考，後者則可以作為該工具能否長期支持AI開發的指標。
完整系列報導在這裡
",https://www.ithome.com.tw/news/143586,"新聞,ML Pipeline,AI開發,MLOps,AI落地,協作,DevOps,人工智慧,AI應用,MLOps解決方案,ML模型自動化,AI維運"
143584,1,2021-04-06,【AI開發也要擁抱DevOps】企業規模化落地AI關鍵是MLOps（上）,隨著企業AI走出實驗階段，開始分化出多種開發角色，如何透過打造如產線般緊密分工的協作方法，來加速落地AI？關鍵就是MLOps的實踐," 臉書隨處可見AI應用的身影，從個人化貼文排序、新聞推薦、廣告推播、人臉標註到仇恨言論過濾，背後都靠AI進行自動化決策。這個開發規模有多大？臉書2016年在自家部落格公開了一個驚人的數據，臉書工程團隊在過去短短一年多的時間內，就訓練了超過100萬個ML模型，更達到每秒600萬次預測。換句話說，平均只要1天，就能訓練出兩、三千個AI模型。為何臉書可以這麼大規模的開發出各種AI應用，關鍵就是2014年著手打造的ML平臺FBLearner Flow，這套AI開發流程，大大減少了AI開發過程中的人工作業。
舉例來說，在FBLearner Flow平臺上，提供了多種預定義ML流程（Pipeline），不同的AI專案能根據需求重複利用這些開發流程，甚至還有一個AI實驗管理UI介面，讓開發者不用寫任何一行前端程式，就能快速建立模型實驗的工作流，管理每日上千次的模型實驗結果，更能線上快速檢視模型輸出、修改標籤與原始數據，甚至能啟動大規模部署工作，並監控模型的表現。
這正是臉書訓練出百萬個AI模型的關鍵，不只降低工程師手動開發作業，還建立可重複使用的ML流程，讓工程師能更專注於特徵工程或模型訓練，藉此提升AI開發速度與模型準確率，甚至，非AI專業的軟體工程師，也能用這個平臺來開發AI應用。勤業眾信風險管理諮詢副總經理廖子毅指出，這個作法，正是近兩年崛起的MLOps概念的體現。
MLOps：一種加速AI落地的人員協作方法
什麼是MLOps？為何這兩年，成了企業AI團隊高度關注的議題？
越來越多企業在AI的發展，走出了實驗階段，開始更大規模的落地應用。為了加速AI開發，開始有企業仿效生產線設計，針對AI開發來建立一個系統性作業流程。
尤其，當AI模型進入持續交付、持續部署、成效監控與迭代更新的階段，要串起整個模型從開發到維運的全生命周期循環，更需要AI模型訓練的資料科學團隊，和負責AI應用部署落地的IT團隊，彼此緊密協作，來維持AI上線後的表現。
兩種不同角色團隊協作的概念，聽起來很熟悉，在軟體開發領域一點都不陌生，就是已經盛行多年的DevOps要解決的課題，運用自動化測試、持續整合、持續部署的工具，推動開發與維運人員更緊密協作，來加速軟體版本迭代更新。近來，國外更直接將DevOps概念延伸到AI開發領域，取ML與DevOps的字尾，創造出「MLOps」的名詞，提倡AI開發也應該納入DevOps文化，透過AI、IT團隊不同角色間的緊密協作，來加速AI落地。
不過，比起DevOps的實踐，是在軟體部署的環節，強調開發與維運人員間的協作，MLOps更提倡AI全生命周期各角色的協作，透過將AI開發流程標準化與簡化，建立起一套系統性協作新方法。
因為相較於軟體開發，AI開發涉及的角色與工作流程都更加複雜。從一張在AI領域流傳已久的ML Pipeline流程圖可以了解，企業要落地一個AI應用，需做的事情遠比訓練一個模型多更多，甚至可以說，整個AI開發系統只有非常少部分的程式碼，是訓練模型所使用，除此之外，還需進行環境配置、資料搜集、特徵工程、資料驗證、運算資源管理、實驗分析、流程管理、部署上線及成效監測等工作，更需眾多不同專業角色來共同協作。
「在ML開發流程中，沒有人可以從頭到尾做完所有事情。」Line臺灣資料工程部資深經理蔡景祥格外有體會的說，AI團隊的不同角色都得各司其職，藉由更緊密的分工協作，在不同開發階段優化AI。
他以自家經驗來解釋，Line臺灣AI團隊中，資料工程師負責資料處理相關工程，ML工程師負責開發AI演算法，前者處理後的資料，會成為後者訓練模型的資料來源。因此，兩種角色需共同定義模型開發所需的資料集，資料處理後的儲存格式與位置，以便後者能直接取用符合需求的資料，無縫進行下階段的開發。
又比如資料科學家雖擅長開發ML模型，但有時為了提升1%的模型準確率，開發出上百MB大小的龐大模型，實際上線後，卻可能拖慢了線上服務的效能。這時，負責分析模型上線實際成效的資料分析師，就需要與資料科學家相互協作，來進行模型精準度與效能之間的取捨。
甚至，蔡景祥指出，ML模型上線後，模型表現還會隨著輸入資料的漂移而逐漸衰變，這時，更需要維運與開發人員緊密協作，在維運端觀察到模型衰變後，交由開發端重新調校模型，甚至得以新特徵、新演算法重新開發準確率更高的模型，再交由維運端部署上線，才能維持模型隨時達到精準預測。
而且，也不只是技術團隊成員間要相互協作，技術單位與業務單位也需要協同合作，透過如模型成效分析工具，量化使用ML後的成效數據，來進一步說服業務單位改用AI預測，確保AI能更有效提供商業面的洞察。

MLOps流程包含了多種元素在內，包括模型探索、ML Pipeline的部署、模型打包與部署、模型版本控管、模型監控與管理、模型治理、模型安全等議題，都要透過MLOps來實現。（圖片來源／勤業眾信）
AI成熟度高的企業如何大用MLOps？


勤業眾信風險管理諮詢副總經理廖子毅表示，讓AI開發、部署與維運三大團隊，能透過一個標準化的流程來生產AI，建立像是工廠產線的作業流程，就是導入MLOps的重要指標。（攝影／洪政偉）

像臉書、Line都屬於重度使用AI的企業，所以，才會格外重視AI開發的協作文化。勤業眾信一份內部調查報告就指出，不只臉書，MLOps的早期實踐者如Google、Uber、Netflix、Airbnb等企業，都在加速AI應用落地時，面臨了開發瓶頸，並自建ML平臺來克服挑戰。
因為這些企業不僅擁有自己的資料科學家與工程團隊，面臨更多AI開發需求，已經上線的AI應用，更需要一套維運與管理辦法，來隨時提供精準預測。
比如Uber剛開始開發AI時，沒有遵循一套統一的開發流程，將模型部署到生產環境時，也仰賴工程人員客製化開發來上線服務，導致AI開發技能侷限在少數人手上，應用規模也難以擴大。於是，Uber從2015年開始打造ML平臺Michelangelo，要透過標準化的端到端AI開發工作流，讓更多員工能跨過門檻來參與AI開發。
Netflix則是發覺，不同團隊角色之間，常用的分析軟體與程式語言互不相同，增加了AI開發的協作挑戰，因此從2017年Q3開始，試圖深化Jupyter Notebook作為資料處理工具的應用，更整合了支援Jupyter Notebook的相關函式庫或工具，比如互動式介面nteract、用於參數化與執行Jupyter Notebook的函式庫Papermill、Notebook瀏覽與共享工具Commuter以及容器管理平臺Titus，來建構AI開發的基礎建設。
除了國外的應用案例，臺灣也開始有企業實踐MLOps。比如Line臺灣就在去年底完整揭露了韓國總部建置的ML開發平臺ML Universe（簡稱MLU），平臺中整合了不同的開源與自建工具，讓工程師能透過UI的編輯器功能，簡易設定來建立ML Pipeline，訓練完的模型也能快速打包成Docker Image來進行部署，大幅降低了資料科學家與工程團隊間的溝通成本，更提升了開發效率。
或像玉山銀行在2020年時就透露，採用了MLOps協作方法，讓數據模型或新上線的服務，都能即時、彈性回應使用者需求，更打破了AI團隊既有的職務內容框架，讓開發者能從產品端反過來思考ML應用。
「讓AI開發、部署與維運三大團隊，能透過一個標準化的流程來生產AI，建立像是工廠產線的作業流程，就是導入MLOps的重要指標。」廖子毅強調。
勤業眾信更在2021年技術趨勢報告預測中，將MLOps列為今年度十大趨勢之一，今年將有更多企業面臨MLOps的導入需求，這一套AI開發與維運的方法，更將擴大企業落地AI的規模，促成AI開發走向工業化（Industrialized AI）。
 本文未完，下半篇在這裡 
完整系列報導在這裡
",https://www.ithome.com.tw/news/143584,"新聞,ML Pipeline,AI開發,MLOps,AI落地,協作,DevOps,人工智慧,AI應用"
143763,1,2021-03-31,Container周報第136期：這10個帳號映像檔藏挖礦程式千萬不能用，服務網格Linkerd終於推出擴充套件機制,"2/26~3/31精選容器新聞
#容器安全 #挖礦軟體"," 2/26~3/31精選容器新聞
#容器安全 #挖礦軟體暗藏挖礦軟體的Docker映像檔遭下載2千萬次，這10個帳號的映像檔千萬不能用
安全公司Palo Alto Networks研究人員Aviv Sasson，在Docker Hub上發現的30個惡意容器映像檔，這批問題映像檔主要來自10個帳號，刻意藏有挖礦程式的問題映像檔。總下載次數超過2000萬。其中內含的挖礦軟體九成以上是XMRig，其餘為Xmr-stak。以目標貨幣來看，九成為挖Monero（門羅幣），少部份是Grin（6.5%）及Arionum（3.2%）幣。Sasson檢視這些映像檔標籤，發現有些映像檔針對不同CPU架構或作業系統，使用不同的標籤，顯示攻擊者也企圖對不同受害者OS及CPU架構環境提供「客製化」的映像檔。還有些映像檔包含不同挖礦軟體的標籤，意謂攻擊者可根據用戶硬體，使用最適合的挖礦軟體。
#擴充套件 #服務網格服務網格Linkerd終於推出擴充套件機制，非必要元件可以自訂安裝
服務網格專案Linkerd最近釋出了2.10新版，最大特色是終於增加了擴充套件系統，預設控制平面只留下必要元件，其他非必要元件改以擴充套件的形式提供，也大幅縮減了整體檔案大小，另外，Linkerd 2.10還強化了跨叢集連接安全性，以及對特定類型流量的處理能力。
新增擴充套件機制後，用戶可以準確選擇要在叢集中，安裝哪一部分的元件，對於已經設置叢集外指標工作管線的用戶特別有用，而對Linkerd開發社群而言，在建置特定的Linkerd運作程式和控制器時，不需要更動核心Linkerd CLI。2.10還新增了不透明連接埠（Opaque Ports），增加Linkerd處理特定類型流量的能力，用戶可以將這些連接標註為不透明連接埠，Linkerd就只會代理這些流量，但是不偵測流量協定。
#開放政策代理 #Kong第一個整合開放政策代理的服務網格工具來了
Kong釋出最新版本的服務網格Kong Mesh 1.2，這是第一款整合開放政策代理（Open Policy Agent，OPA）的服務網格工具，用戶可以方便地使用高階宣告式語言，以程式碼編寫政策新版，不需要使用額外的OPA代理工具。Kong Mesh更是直接在資料平面流程中嵌入OPA支援，讓用戶能對Kubernetes和虛擬機器應用OPA政策引擎，進而極大程度簡化監控與管理工作。另外，新版也在全域和遠端控制平面提供身份驗證功能，強化多區域服務網格的安全性，並開始原生支援FIPS 140-2。


#K8s #機器學習Azure Arc混合雲可以執行Azure機器學習服務了
微軟以K8s打造的Azure Arc混合雲產品，除了先前提供的Azure資料服務，現在進一步支援Azure機器學習，可以透過Azure Arc在各種K8s環境上建置、部署和管理Azure機器學習服務。企業使用Azure Arc來訓練AI時，現在不用將自家資料上傳到Azure雲上，現在可以將雲端機器學習服務的訓練放到本地端私有雲來執行。另外，微軟與多個熱門Kubernetes發布版本供應商合作，藉由測試與驗證這些Kubernetes版本，使其能順利支援Azure Arc。包括VMware Tanzu、Nutanix Karbon、紅帽OpenShift、Canonical Charmed Kubernetes和Rancher Kubernetes皆經過測試和驗證，可與Azure Arc穩定整合使用。
#DevOps #YAMLGitLab 13.9增加新的YAML函示，更容易重複使用CI/CD工作管線配置工作
最近GitLab改版，新版繼續增加更多自動化功能，除了強化強化大規模DevSecOps的功能，安全儀表板可以對高優先度警報進行分類，並加入維護模式讓執行個體只能被讀取，另一個好用的更新是新的YAML函示，可以用來加速用戶建置和測試時間。在GitLab 13.9中，用戶可以重用任何工作的CI/CD工作管線配置。過去用戶想要在多個工作中重用配置，需要加入YAML錨點，但這個方法無法跨不同的配置檔案使用，另一個方法則是使用extends，重用整個段落，而現在GitLab加入了新的YAML函式，用戶可以鎖定想要用在CI/CD工作管線的特定配置，即便該配置屬於另外的檔案也沒問題。
責任編輯：王宏仁
",https://www.ithome.com.tw/news/143763,"新聞,服務網格,容器安全,混合雲,K8s,Kong,開放政策代理,OPA,IT周報"
143243,1,2021-03-16,AWS S3滿15周年，已儲存1百兆個物件,AWS首席技術傳教士Jeff Barr表示，Amazon S3於2006年推出後，目前已儲存100兆個物件，以目前全球人口計算，平均每人1.3萬個物件," 在本周（3/15-3/18）線上用戶大會Pi Week前夕，AWS周一宣布雲端儲存服務S3滿 15周年，迄今已儲存100兆個物件。
AWS首席技術傳教士Jeff Barr於2006年3月15日，宣布推出雲端儲存服務Amazon Simple Storage Service (S3)，目標用戶鎖定開發人員，他們可寫程式經由API存取物件。Barr表示，15年後，S3現在已儲存100兆個物件，尖峰值可達每秒數千萬次呼叫。以現今78億人口計算，大約是將近每人1.3萬個物件。在此期間S3陸續推出了多樣服務，涵括儲存、儲存管理、安全、資料搬移等類別，包括冷資料儲存S3 Glacier Deep Archive及Glacier、儲存不經常存取資料的低成本選項的S3 One Zone-Infrequent Access、可自動搬移物件的S3智慧分層（Intelligent-Tiering）以及從本地資料中心將數PB資料搬上AWS的Snowmobile，服務效能及穩定度也相對提升。利用多個儲存陣列、機櫃以及多達77個可用性區域(Availability Zone)，AWS S3號稱服務耐受性最高達到11個9（即99.999999999%）。
微軟去年8月宣布Azure雲端儲存了4兆個物件。Microsoft Azure和Google Cloud也分別宣稱，各自的儲存服務耐受性來到11個9。
最近Amazon再將S3 PUT呼叫延遲性再降低0.01%，Barr指出，這有助於避免客戶呼叫服務逾時的情況。
本周Amazon Pi Week也將是AWS前CEO Andy Jassy接替Jeff Bezos成為Amazon執行長的首次登場。AWS預告大會上將宣布新的S3雲端儲存、資料搬移，以及「零作業」（Job Zero）資安框架。
3月19日內文更正：最後一段「AWS預告大會上將宣布新的S3雲端儲存、資料搬移，以及「零作業」（Job Zero）的安全儲存服務。」關於「零作業」（Job Zero）的敘述有誤，「零作業」（Job Zero）應為S3的資安框架。
",https://www.ithome.com.tw/news/143243,"新聞,Pi Week,AWS,Amazon Simple Storage Service,S3,雲端儲存,Cloud"
142897,1,2021-02-25,Container周報第135期：北歐最大3C電商如何打造內部K8s來省錢？CNCF大使力推的必讀K8s上手書,北歐最大規模的3C零售電商決定擁抱微服務設計，來改造那些用來串接各委外系統間的API，尤其要自己開發一個進階版支付API，來串接電商平臺和店內POS系統，這一批API就部署在K8s上," 2/1~2/25精選容器新聞

#服務網格 #零售業K8s實戰 #POS容器化年營收40億美元的北歐老牌3C電商如何打造內部K8s平臺來省錢？
最近北歐最大規模的3C零售電商Elkjop雲端架構師Henry Hagnäs，揭露了自建K8s平臺，來維運200支微服務應用，降低了8成主機代管費用的經驗。
發源於挪威的Elkjop創立近60年，在北歐5國（丹麥、芬蘭、冰島、挪威和瑞典）以Elgiganten電商聞名，擁有超過4百家分店，員工超過1萬2千人，年營收高達47億美元。過去Elkjop主要採取委外開發，再由小規模IT部門來管理和負責整合，不過，6年前，Elkjop決定擁抱微服務設計，開始改變策略，自己來改造那些用來串接各委外系統間的API，尤其要自己開發一個進階版支付API，來串接電商平臺和店內POS系統。
最初第一批微服務都部署在Azure Web App服務上，後來Elkjop找來顧問，自己發展出一套微服務主機平臺來維運這些微服務。這個平臺有3個目標，功能要類似Azure Web App服務，但得更便宜更容易使用，也需要容易擴充，能統一自動或手動管理調度不同的應用，可以提高開發產量。另外，也希望藉此來建立一個SRE團隊。
Elkjop先將自家應用容器化，部署到K8s上，因為關閉了ingress控制器的TLS功能，所有服務間的呼叫都沒有加密。Elkjop才意識到，需要一個監控矩陣來管理，所以，進一步採用了Linkerd。Henry Hagnäs解釋，透過Linkerd控制介面，可以提供了一種在資料面的微代理伺服器能力，可以用來提供加密或監控能力。
Elkjop利用Linkerd預設的RED（請求數、錯誤數和持續時間）監控矩陣，就足以可以建立足夠的系統可觀測性。另外，也建立了一個全靠記憶體運作的Prometheus伺服器和Gragana實例提供儀表板功能。
將POS後端也搬上K8s後，原本以為就可以正常啟用，卻發現Linux主機啟動失敗率下滑，開始針對請求失敗率來建立系統健康追蹤機制。利用TCP連線的持續時間和是掰率，來監測POS後端每一支系統對內和對外的流量，最後才發現，是銷售網站應用無法重複利用Socket通訊，這個問題無法從SNAT埠監控發現，需要詳細的網路遙測（Telemetry）才能發現，後來透過增加系統對外通訊埠來解決這個問題。
為了優化後續維運，也採取HA架構來部署Linkerd，這個架構也有助於升級，可以輪流升級而不用關閉服務。透過Linkerd的設定註解和標籤，很容易就可以建立HA架構。隨著Elkjop在各國分店陸續用K8s平臺上的POS，Elkjop也建立了一個跨國備援的叢集。Elkjop預計在2021年底，將K8s上的POS，部署到全球各國的分店據點。
#K8s自學教材 #第一手實戰經驗 #雲端原生架構設計14本導入和維運K8s必讀的上手書
CNCF基金會推廣大使Chris Short最近整理了14本K8s上手和維運的必讀上手書，從最基本的CNCF發行的兒童K8s讀本《Phippy and Friends》，到雲端架構部署參考書，如以第一線工程師實戰經驗為主的《97件雲端工程師應該知道的事》，提供多種主流雲端原生架構設計樣式的《Cloud Native Patterns》。還推薦了兩位K8s創辦人Brendan Burns和Joe Beda和另一名作者合寫的K8s實踐書《Kubernetes:Up and Running》，在這本書中，介紹了Google如何在一周內啟用20億個容器的管理秘訣，最後如何實踐到K8s這套開源軟體中，也從一個分散式應用系統的開發周期角度來介紹，如何自動擴充這樣的分散式系統，有那些工具或API可用，或是如何自動擴充到實體環境，甚至是樹莓派單版主機上。
特別一提的是，Chris Short也推薦了赫爾辛基大學開設的線上自學教材《DevOps with Kubernetes》，提供了K3s和GKE的入門線上課程，從微服務架構開發到自動化部署的建置都涵蓋。
#雲端K8s #新特色快速一覽三大雲端龍頭K8s代管服務的2月新功能
三大雲端巨頭的K8s服務GKE、EKS和AKS在這個月有那些新功能呢？快速整理一下，先來看Google的GKE，叢集自動擴充器可以從0節點的資源池開始啟動，自動擴充設定可以預設指定最大支援32個vCPU和128GB記憶體的E2虛擬機器規格。而AWS的EKS在2月的主要新功能則增加了EKS叢集整合OpenID身分提供者（OIDC）的功能，可以用來代替AWS身分識別和IAM管理的替代機制。微軟的AKS服務在2月主要更新是叢集啟動關閉功能進入正式版，也釋出了多項預覽版功能，包括用自訂DNS區域來建立私有叢集，可重複利用負載平衡流出IP作為流入IP，以及pod資安政策預覽版等。
#GPU #K8s維運Nvidia翻新GPU虛擬化軟體，簡化K8s部署GPU的維運框架
Nvidia發布GPU虛擬化軟體12.0新版，除了支援Nvidia去年下半發表的3款Amepere架構GPU之外，更大幅簡化了在Kubernetes環境部署與管理GPU的維運框架Nvidia GPU Operator。可以自動安裝與更新vGPU Software用於容器平臺的圖形驅動程式。Nvidia GPU Operator就能自動決定vGPU Software圖形驅動程式版本，是否相容於容器平臺搭配的Virtual GPU Manager軟體。可用於裸機、穿透虛擬化平臺的GPU（GPU passthrough virtualization），以及GPU虛擬化共享（vGPU），也可支援vCS與RTX vWS。
#服務網格 #容器管理整合VM開源服務網格Istio釋出1.9新版，容器服務網格也能整合VM管理
在2月初，開源服務網格專案Istio發布了1.9新版，最大特色是Day2維運功能的改善，主要是推出了虛擬機器整合機制，可以將虛擬機器的維運和管理整合到Istio服務中，例如套用同一個政策，跨容器和VM都使用同樣的遙測監控機制，開發社群也提供了多份參考文件，例如Istio架構如何整合VM，如何安裝、除錯等。不過，這項VM整合功能目前還處於Beta版本中。其他新功能如請求分類功能（Beta版），可在配置檔中預先設定要蒐集的遙測請求資料類型，方便更精細地追蹤流量。另外也開始實驗性的新功能是新增支援K8s服務（Alpha版）和外部授權驗證系統（實驗版本）等。這次新版功能大多聚焦在 Day2後續維運面的強化。

 
#容器資安 #AzureAzure Functions出現容器脫逃漏洞，惡意程式能進入底層主機
資安公司Intezer研究人員發現微軟的無伺服器運算服務Azure Functions，存在一個特權提升漏洞，且程式碼可從Azure Functions Docker容器逃脫（Escape）至底層的Docker主機，但微軟在收到漏洞報告後，認為這個漏洞並不影響Azure Functions用戶安全，因為即便可以逃脫，但Docker主機本身仍受Hyper-V邊界保護，微軟進一步限制了/etc和/sys的存取來防範。

#GitOPS #企業級K8sKubermatic企業級K8s平臺小改版，強化GitOps政策管理
另一家企業級K8s軟體商Kubermatic推出了最新的KKP 2.16版本，主要新增支援開放政策代理（Open Policy Agent，OPA），讓用戶可以更好地控制政策，並且新增動態資料中心和其他GitOps功能。OPA可以讓用戶用高階宣告式語言來配置政策，KKP 2.16透過整合OPA，讓用戶可以在微服務、Kubernetes、CI/CD工作管線和API閘道器等，集中管理任務，並且強制應用政策。官方提到，用戶現在可以透過Kubermatic API存取OPA，並且在稍晚時，將該功能整合到使用者介面中。
 
#Day2維運 #服務網格網格管理要有企業級工具，Gloo Mesh企業版主推Day2管理觀察工具
FaaS服務新創公司Solo.io正式發布企業級服務網格管理解決方案Gloo Mesh Enterprise，可增加服務網格的可用性和可控制性，簡化Istio在多叢集和多雲環境的複雜操作，同時還可以讓用戶以WebAssembly擴充網格資料平面。
Gloo Mesh強化Day 2操作，藉由進階API和可觀察性工具，協助開發人員監控和維護系統，其提供的Gloo Portal，可以對Istio中運作的API進行分類並且對外開放，讓開發人員或是其他合作夥伴，能夠更容易使用API。隨著企業的服務網格發展，Gloo Mesh可以讓用戶在其網格，加入回退或是委派等進階功能，同時也促進WebAssembly的開發和部署，讓用戶可將WebAssembly擴展多個叢集中，進而供企業自訂出符合特定需求的服務網格。

#政策管理引擎 #OPA開源政策管理引擎OPA專案正式畢業，Google、微軟和VMware將持續維護
經過3年孵化，政策管理引擎開源專案OPA（Open Policy Agent）正式從CNCF基金會畢業，進入獨力發展階段。這是一個通用型政策管理引擎，主要由Google、微軟、VMware和Styra聯手維護，這也意味著前三家主要科技巨頭的混合雲產品都大力支援同一個政策管理引擎。目前已有超過150家企業或組織採用OPA來派送和管理各種系統政策，尤其可以用OPA來管理微服務API授權政策的擴充和分配。其他常見用途則有用來整合K8s管理控制器，或應用程式授權、雲端資安政策等。不少企業則是專門用OPA來搭配K8s管理控制器，進行政策派送。

責任編輯：王宏仁
更多新聞
#Docker與JFrog進一步合作，JFrog用戶可不受限制存取Docker Hub
#Docker將容器註冊表專案Distribution貢獻給CNCF
",https://www.ithome.com.tw/news/142897,"新聞,容器周報,K8s,POS上K8s,Istio,GKE,EKS,AKE,IT周報"
142765,1,2021-02-18,Google推出Service Directory簡化異構環境服務管理,Service Directory服務提供一個全託管解決方案，用戶可將服務註冊到註冊表中，一致地發布、探索和連接服務," Google推出服務目錄Service Directory，讓用戶能夠跨雲和本地端，統一管理所有的服務，降低操作異構環境的複雜性。現在Service Directory已經正式推出，用戶可以將服務註冊到一個完全託管的註冊表中，並升級系統環境，把原本以基礎設施為中心的環境模型，轉換成為以服務為中心的模型
Google提到，企業越來越仰賴跨雲端和本地端的異構服務，像是用戶可能將Cloud Storage等服務，以及MongoDB和Redis第三方服務，還有企業自家應用程式一起使用，而要安全地連接和管理多雲服務，存在不小的挑戰，且還要能快速縮放資源，滿足業務需求。
隨著服務的數量和多樣性增加，維護組織中所有服務的清單也變得困難，為了解決這樣的問題，Google推出了Service Directory，這是一個全託管的解決方案，可以讓用戶以一致且可靠的方式，發布、探索和連接服務，無關乎這些服務所部署的平臺和環境，Service Directory可以在同一個地方，提供所有服務的即時資訊，無論是數個或是數千個服務端點，Service Directory都可以大規模執行服務盤點管理。
Service Directory擁有幾項好處，首先，可以人性化地命名服務，用戶可以在註冊表中，使用人類可讀的名稱命名服務，而非像是service-b3ada17a-9ada-46b2英數字組成難以辨別的字串，能更易於參照與管理。除了控制服務名稱之外，Service Directory還讓使用者可以使用名稱之外的資訊，來註解服務和端點，例如新服務在投入生產之前，先加上實驗性標籤，標記該服務尚在實驗中，而用戶也可以根據自己定義的標籤來過濾服務。
另外，Service Directory還讓用戶透過REST、gRPC和DNS查詢來解析服務，且當服務改變時，Service Directory專用DNS區域還會自動更新DNS紀錄，免除用戶手動添加DNS條目的麻煩。在最新的版本中，用戶可以不需要撰寫程式碼，自動在Service Directory中註冊服務，目前該功能已在內部TCP/UDP和HTTP(S) 負載平衡器中提供，並且之後還會擴充到其他服務。
",https://www.ithome.com.tw/news/142765,"新聞,Cloud,google,註冊表,Service Directory"
142763,1,2021-02-17,Palo Alto Networks買下以色列安全新創Bridgecrew,Bridgecrew打造的架構即程式碼（IaC）平臺，將讓Palo Alto Networks得以打造從開發程序便提供防護的完整應用程式安全解決方案," 美國資安業者Palo Alto Networks周二（2/16）宣布，準備以1.56億美元買下以色列安全新創Bridgecrew，雙方預計於今年4月之前完成交易。
Bridgecrew為一鎖定軟體開發暨維運（DevOps）提供雲端安全服務的業者，可協助企業快速修補雲端上的錯誤配置，或是掃描雲端架構以檢視其安全性，亦能將安全性直接嵌入開發流程或工具中，符合將安全性左移（Shift Left）至開發程序的現代趨勢。
Palo Alto Networks說明，Bridgecrew以開發者為優先的架構即程式碼（IaC）平臺提供開發者與DevOps團隊一個系統性的方法，可確保在整個開發的生命周期中符合基礎架構的安全標準。買下Bridgecrew將可強化Palo Alto Networks旗下的Prisma Cloud雲端安全服務，同時讓該公司成為全球首個可替完整應用程式周期建立安全機制的業者。
事實上，Bridgecrew所打造的開源IaC掃描器Checkov，在去年就有超過100萬次的下載。
Palo Alto Networks執行長Nikesh Arora表示，左移安全是任何雲端安全平臺都必備的服務，它讓開發者不必等到運行時才知道安全機制失效，還可在開發生命周期的早期階段就解決安全問題。
",https://www.ithome.com.tw/news/142763,"新聞,Palo Alto Networks,資安,Bridgecrew,DevOps,安全性左移,Shift Left,收購,併購"
142651,2,2021-02-13,趨勢DevOps遊戲化設計特色大圖解,趨勢星際奇航2020競賽兩大目標是，實際演練假設驅動開發HDD方法，用數據來決策和驗證產品設計對客戶的價值，其次是希望參加者用手上產品專案，在遊戲中真正導入DevOps，如何做到這樣的設計？," １  遊戲化設計畫布是關鍵工具

這個星際奇航遊戲化主要設計者林德政設計了一個遊戲化設計畫布工具，用來持續思考遊戲化設計盲點，也方便與他人溝通。這個畫布分成兩部分，左半循環是定義階段，先釐清遊戲的商業目標，再定義出目標使用者，並規畫想要他們完成的行為。完成第一個循環後，就可以設計使用者歷程，再進入右半邊遊戲化設計階段，包括遊戲化機制、獎勵、動機，來設計想要促成的活動。（圖片來源／趨勢科技）
２  真實專案行為轉化成遊戲活動

「將DevOps的價值與方法實踐於日常工作中」是星際奇航遊戲最重要的商業目標，透過這個遊戲，進一步將各項希望員工實踐的期待行動」，進一步轉化成為符合太空航行使用者旅程情境的「設計活動」，如「提交HDD 計畫」轉化為「制定航行計畫」（Define a Voyage Plan），而上傳DevOps工程實踐報告，就是打怪活動（Fight the Monsters）。（圖片來源／趨勢科技）
３  星際奇航遊戲化設計畫布完成版


這是利用遊戲化設計畫布，最終完成的星際奇航遊戲化設計藍圖，雖然趨勢在遊戲中後期才開始使用這個工具，來檢討和修正遊戲各項設計間的銜接和盲點也方便討論。可從中一窺趨勢DevOps遊戲化設計的全貌，例如在左半邊可以看到趨勢鎖定的使用者包括了有DevOps經驗者與新手兩類，右半邊則可看到趨勢使用了故事敘述、虛擬角色（太空船）、點數激勵等遊戲化設計。（圖片來源／趨勢科技）
４  兩種激勵點數創造差異化遊戲路徑

星際奇航計畫採取的遊戲比喻是，不同團隊各自有自己的太空船，按照各自需求和限制來前往實踐顧客價值提升的目的地。參賽團隊不同的得分策略有不同的太空船頭像。兩種激勵點數機，一種是用來橫量商業影響的Merit Points（功績點），另一種則是衡量工程成效的Mileage Points（里程點），不同打怪活動會在這兩類各有得分，來幫助發展差異化的遊戲路徑。（圖片來源／趨勢科技）
５  打怪活動和HDD演練都重視文件化

遊戲中主要有兩類文件化活動，一是透過「提交航行日誌」來演練「假設驅動開發」方法，可以用來分享實踐HDD方法的過程。（圖片來源／趨勢科技）
６  從3面向來設計遊戲化動機

動機設計是吸引參加者持續投入的關鍵。林德政借鏡了《動機，單純的力量》書提到的三要素，目的、自主權和專精等來分析目標使用者動機，檢驗是否動機能讓參加者採取行動。（圖片來源／趨勢科技）
 相關報導  千人打怪練出DevOps魂

",https://www.ithome.com.tw/news/142651,"新聞,趨勢,DevOps,遊戲化設計,HDD,假設驅動開發,Hypothesis Driven Development"
142650,2,2021-02-13,【專訪趨勢科技執行長陳怡樺】DevOps組織決策不是靠權威，而要憑數據說話,過去組織運作模式是，誰的職位高，誰的決定權就比較大。但是，在DevOps組織中不是這樣的決策模式，而應該是，誰擁有最足夠的資訊，能做出正確的決定，就由他來做決定," 就算在午夜視訊連線，趨勢科技執行長陳怡樺談起這個剛結束的遊戲化活動，依舊興奮不已，滿臉笑容和成就感，直透到跨海這端。她從執行長高度，親自剖析這一年來，DevOps遊戲化活動，如何讓趨勢企業文化轉型成功的關鍵，整理如下：
企業文化是一家公司做事和做決定的依據，DevOps要成功，擁抱新的文化，一定是做事方法和決策方式都要改變。我借用了童軍精神的三個字，智仁勇來解釋這樣的改變。
過去很難知道顧客如何使用產品，現在的DevOps和雲端技術，可以讓你很快知道那些功能有用或沒用。有大量的資料，要善用這些資料，來體貼顧客的使用方法，利用資料做出正確的決定，就是「智」。
有了數據後，能看到顧客如何使用產品，就更能站在顧客成功的角度，而非產品成功的角度就是「仁」，工程師以為顧客想要的是擋住所有病毒，但以同樣人的立場來看，顧客最希望的是準時回家吃飯，周末不用緊急到公司加班。而最後一項「勇」是更重要的是，要讓公司中的每一個人，都能勇於追求成長和承擔所做的決策。
DevOps要成功，需要智仁勇，看著資料做決定，而不是看著職位做決定。體貼客戶，將客戶視為一個整體的人，而不只是產品的使用者，而勇就是每個人都能勇於測試和做決定。DevOps帶來的是文化的改變，不是流程，我希望每一個人都可以具備智仁勇，讓趨勢成為一家「智仁勇」的公司。
第一年先透過各種方式，如讀書會，學會DevOps，第二年就是最有趣的DevOps遊戲化。因為要真的動手做，才能體會DevOps的 內涵，這個DevOps遊戲不是面對虛構的問題，而是真正要解決產品問題，甚至不只是修補一個程式臭蟲，有時更是整個專案流程、定價模式、夥伴參與形式的改變。
在第二波動手做階段，最讓我感動的是，工程師們很快地轉變他們的思考模式，變得更主動了，不再像過去那樣，總是等待PM或有人開出產品規格後，再交給工程師執行。
一旦能讓工程師們放開自己，可以看到客戶是什麼樣的人，有什麼樣的需要，告訴他們公司未來的成長方向。在這個遊戲化DevOps活動中，工程師自己找出要解決的問題，自動自發地探究和解決問題，整個公司的活力和潛力都爆發出來了。
我真的很想告訴其他公司，這種全公司潛力大爆發的興奮，引發這樣由下往上，不需要高層做各種決定，從下面發動的力量非常大。
可是，改變是最辛苦的一件事。就算知道組織改變必須做，但要改變習慣，還是很難。
對主管來說，過去習慣每次遇到問題，就給出回答，但回答了1個問題，就引來10個問題，部屬期待主管給他們更多答案。最困難的就是，主管要習慣不要回答問題，應該回頭檢視數據，若沒有，就想辦法蒐集足夠資料來決定，這是我覺得最痛苦也最難的地方。改不過來的經理人，就沒辦法適應這樣的組織。
這樣的組織就是一種不用權威的領導力（Leading Without Authority），這是來自與這名詞同名一本書的觀念。
過去組織運作模式是，誰的職位高，誰的決定權就比較大。但是，在DevOps組織中不是這樣的決策模式，而應該是，誰擁有最足夠的資訊，能做出正確的決定，就由他來做決定。
還有另一個需要改變的重要觀念。過去，好領導人的定義是，要把團隊照顧得很好，讓我的團隊成員都覺得我是好老闆，這是「我的團隊」（Myteam）的觀念，可是，現在的「我的團隊」不只是向我回報的部下而已，而是任何想要把這件事做成功的人，就都是MyTeam。所以，不管是研發、業務、技術支援都想要這件事情成功，他們就都屬於同一個團隊。
在新的DevOps組織中，大家的腦袋要改變很多。
這時代真的是計畫趕不上變化，你只能希望，企業能夠成為一家靈敏度很高，彈性很高的公司，是一個願意改變和接受挑戰的公司，而我自己則希望成為這樣組織中的一員，而不是絆腳石。
 相關報導  千人打怪練出DevOps魂
",https://www.ithome.com.tw/news/142650,"新聞,軟體開發實踐,遊戲化設計,企業文化,轉型,DevOps,星際奇航競賽,趨勢科技,陳怡樺,智仁勇,領導力"
142648,2,2021-02-12,遊戲化DevOps，如何重塑趨勢科技新企業文化（下）,趨勢科技第二次DevOps遊戲化設計，和失敗的第一次，最根本的差異點在於，從所有人為一艘太空船努力，變成了，可以各自有自己的太空船，按照自己的步調來發展," 前半篇在此：遊戲化DevOps，如何重塑趨勢科技新企業文化（上）
趨勢科技使用者經驗設計部資深專案經理林德政早從2016年，就開始接觸遊戲化設計，因為他的主管要出國參加UX研討會舉辦工作坊，就找林德政設計了一款桌遊「UX in the Jungle」，透過遊戲可以從UX從業人員角度，來體會產品開發流程，大獲好評，後來更持續發行，變成了趨勢科技內部教育訓練的教材。
第二次DevOps遊戲化設計大改變
在2020年2月，林德政加入STOC小組（Stand Tall on the Cloud，躍居雲端之上，此為趨勢內部DevOps大轉型計畫）後，就想要再次透過遊戲化的方式，來設計DevOps轉型活動。
趨勢第二次遊戲化DevOps設計，仍舊沿用了太空旅行的情境，但是，設計方式有了很大的改變。
林德政觀察，趨勢全球超過 5千人，產品團隊超過上百個，每個團隊的需求、限制、產品架構都不盡相同，沒辦法建立同一套標準流程。所以，他當時建議，透過遊戲化的方式，創造一個姜太公釣魚，願者上鉤的環境。讓每一個成員在遊戲化專案中，按照自己不同專案的需求，產品系統的建置，來決定自己在遊戲化專案中，要做什麼樣的DevOps活動。
這正是他提案的第二次遊戲化設計，和失敗的第一次，最根本的差異點。從所有人為一艘太空船努力，變成了，可以各自有自己的太空船，按照自己的步調來發展。
在星際奇航2020遊戲的設計概念是，不是將公司描述成一艘大型太空船、員工當成燃料，而是讓每個團隊自己開一艘太空船，彼此產品不同，所使用的太空船也會因此能力不同而有差異。
DevOps工具或過去蒐集的實踐經驗，都視為是太空船可以裝備的武器，當參加者的團隊用了越多實踐，代表他的太空船就可以越先進，而且每個團隊可以自己選擇要用那些實踐或工具，還有進行的階段和規畫，不一定要走跟別人一樣的發展路徑。

趨勢科技第二次遊戲化DevOps設計，仍舊沿用了太空旅行情境，但從全公司是一艘太空船而員工是燃料的方式，改為各團隊有自己的太空船，透過打怪升級，可按各自步調航向目的地。（圖片來源／趨勢科技）
兩大遊戲化目的：擁抱HDD、導入真正專案
在星際奇航2020遊戲設計中，林德政指出，有兩個希望達成的動手做目標，一個是希望所有參賽隊伍都能實際演練DevOps的「假設驅動開發」（Hypothesis Driven Development，簡稱HDD）方法，這就是趨勢希望轉變為以數據分析來決策、驗證產品設計、了解客戶價值的一套方法。另一個則是希望參加者要用自己手上真實的專案，來加入遊戲，將DevOps實踐到自己真正的專案上。林德政解釋，這是希望參賽隊伍將自己在產品開發中實際導入的DevOps經驗，提交出來接受審核與評鑑，選出公司內部的最佳工程實踐方法，來和更多團隊分享。
另外，趨勢選出了一些希望參加團隊要導入的DevOps實踐，就像是必選課程一樣，把這一個一個實踐都比喻成團隊要打敗的太空怪物，例如，從導入CI/CD來加快部署，就是其中一支重力怪物，擊敗這支怪物的條件是，你要導入CI/CD工具，達到一定標準的派送和部署速度，就算擊敗了怪物，會由裁判團來審查達標程度和給分。最後選出了30～40支各種類型的怪物，讓不同團隊挑戰，團隊可以自己決定挑戰那些怪物。另外，舉辦了多場市集，也就是實體分享會活動，參賽團隊可以把自己開發的DevOps工具或腳本程式碼，釋出到GitHub上，變成可以販售的武器，其他團隊只要在自己的專案上導入了這些釋出的DevOps工具程式碼，就是裝配上了武器，可以得分來升級太空船。在分享活動上，落後團隊也可以向領先團隊交流經驗，甚至直接面對面與裁判團討論，了解自己無法達標的原因和改善對策。
STOC小組找來趨勢內部的DevOps專家，整理出13個DevOps的知識領域，這也就是源自先前已經發展出來的DevOps能力藍圖，再將已經蒐集到的30多個實踐，歸類到不同領域中，讓參賽團隊採用，但也開放讓其他資深團隊，繼續貢獻更多實踐和工具，來補充這個能力藍圖，再分享給其他團隊。
林立仁表示，透過這個DevOps藍圖，蒐集領先團隊的實踐經驗，讓落後團隊跟著藍圖來發展DevOps，中間舉辦市集分享活動讓雙方團隊交流。這也就克服了第一次失敗遇到的實踐經驗不足的困難，變成一個可以自己補充的模式。除了讓資深和新手團隊互相分享，趨勢也對每個團隊安排教練，協助他們將DevOps實踐導入到自己的專案中。
這個星際奇航2020遊戲，採取員工自由報名的方式，主要由不同產品團隊的成員，帶著自己的專案來報名參加。最重要的要求是，「員工要將自己在專案中導入DevOps的過程，不只要做出來，還要文件化。」林德政表示，許多參賽隊伍不斷抱怨大量的文件工作，「周間忙著上班，周末都在趕文件，非常花力氣，一點都不歡樂。」儘管抱怨連連，93個競賽團隊，近半數，42組完成每一道任務，打敗了34項任務的要求和文件化工作，也留下了大量的「DevOps工程實踐報告」。
超過4百多份實踐報告，讓原本只有大致架構，多停留在高層次說明的趨勢DevOps藍圖，可以進一步發展成一個13個領域都滿滿自家真正產品實際導入經驗的DevOps手冊。林立仁強調：「這些都是趨勢產品架構下蒐集，確實可用的經驗，看書只能學到別人的實踐，但這次蒐集到的是自家的實踐。」
工程實踐和資料驅動要求變打怪
趨勢去年4月展開這個星際奇航遊戲，設立了兩大類怪物挑戰，M系列是以擁抱資料驅動轉型，在自己專案導入HDD方法論的挑戰為主的怪物，X系列則是聚焦DevOps工程實踐的怪物。從6月到10月分5批陸續公布，一開始為了暖身，第一批先公布了3隻難度低的怪物，其餘怪物分4批，每批約7～8隻按月陸續公布，讓參加團隊自己來安排打怪進度。
打怪過程，設計了兩種分數，一個是用來衡量商業影響的Merit Points（功績點），另一類則是衡量工程成效的Mileage Points（里程點），M系列得分以功績點為主，X系列得分以里程點為主，最後進入決賽時，並非總分最高前15名入選，而是透過換算公式，商業分數和技術分數各有不同的要求才能入選，不能只有一項很高。從這些隊伍的前6名，就可以參加最終簡報評比，來決定誰能獲得最大獎5萬美元團隊獎金，這也是趨勢科技有史以來最高額的單一獎項。
「將商業和工程得分分成兩種點數，逐漸在過程中獲得隊伍得分的數據後，再進行配分調整，中後期，就不會讓一開始的錯誤設計失控，這是一個遊戲化設計的技巧。」林德政分享。
這個Star Trek遊戲與一般遊戲化活動最大不同是，「真的把工作和遊戲化活動結合，而不是玩一個與工作無關的遊戲。」林德政指出，「以終為始，任何遊戲化架構設計，都要先思考想達成什麼目標，不是為了好玩，而是要讓參加者在專案中動手，我們不斷提醒自己這件事。」這正是趨勢對於一開始對於這一年度的目標，要在真實產品中實際導入DevOps。
除了實質獎金的誘因，過程中，讓員工有主控權，不是公司要求，而是自己決定參加，也能自己調配進度，「這種由下而上的自主性，有很好激勵效果，支撐他們參加到最後。」

STOC小組核心成員趨勢科技研發部林立仁（圖右）和趨勢科技使用者經驗設計部資深專案經理林德政（圖左）是兩位關鍵的遊戲化活動設計者。（攝影／洪政偉）
嚴格審查的裁判團是看不見的成功關鍵
不只參加者辛苦，另一個非常辛苦的團隊是高達60人規模的裁判和教練團，他們一方面要指導參賽團隊，另一方面還要負責審查每一個參賽團隊所提交的每一份文件，而且是得在正職工作之餘來進行這些工作。
林立仁強調，雖然辛苦，裁判團都堅持不能輕易給分，遊戲化的目的是為了公司運用DevOps的成長，而不是繼續強化認知而已。所以，裁判除了嚴格給分，還要一一指出問題，讓團隊了解原因，知道如何改善，也能讓有心投入的團隊，知道真正的問題。甚至，還訂定了非常詳細的文件化範本，參加者繳交的文件，得一一按照要求舉證、說明來解釋，「這也是為了日後其他沒有參加的人，容易看懂你的文件，才能達到分享到全公司的效果。」
最後完成了4百多份DevOps實踐文件，是過去一年累積量的十多倍，其中更有50份被裁判團評鑑為好的DevOps實踐。
趨勢科技在今年1月底，剛舉辦了第二次的DevOps Expo活動，15個表現最好的參賽團隊，都成了這兩天DevOps實戰經驗分享的講者。
遊戲結束了，林立仁表示，下一步，準備訂定出一份趨勢DevOps工程指引，將這次遊戲中蒐集到的13個領域的打怪經驗，變成內部的知識庫，正式釋出。「當初設計出了DevOps藍圖，只是提供了What，現在終於蒐集到了企業文化轉型的How。」如何善用，就是趨勢科技2021年的新課題。
 相關報導  千人打怪練出DevOps魂
",https://www.ithome.com.tw/news/142648,"新聞,軟體開發實踐,遊戲化設計,企業文化,轉型,DevOps,星際奇航競賽,趨勢科技,陳怡樺,智仁勇,DevOps實務,專案,擁抱變革,假設驅動開發,Hypothesis Driven Development,HDD,資料驅動轉型,DevOps工程實踐,DevOps工程指引,林立仁,林德政"
142647,2,2021-02-11,遊戲化DevOps，如何重塑趨勢科技新企業文化（上）,趨勢過去全公司一年只能累積30份實踐，但這一場遊戲活動的產量，是過去一年產出的14倍，最終將集結成為趨勢自己的DevOps工程指南書，這不只是核心知識的管理，也是趨勢新企業文化的實體化成果," 949人，6成來自臺灣團隊，4成跨海從美、加、中、菲主要研發基地遠端連線的工程師，遍及10個部，利用忙碌上班研發工作之外的空檔、周末，長達9個月投入了這個趨勢科技創立30年來，最重要的一場遊戲活動中，也就是「星際奇航遊戲」（Trend Micro Star Trek 2020）。
93個競賽團隊，每隊要面對34個DevOps實踐挑戰，不是紙上談兵，而得用自己手上產品專案，全程導入DevOps技術、流程和作法，並將過程細節一一文件化，變成共享的實務經驗，近半數團隊，42組完成每一道任務，趨勢科技更先後投入了超過30位主管和關鍵推手，15位全程參與，組成了STOC推動小組，將期待全公司超過6千人都要學會的DevOps發展藍圖和標準，變成了一個超大規模的太空打怪遊戲，更出動了58名DevOps專家和老手組成導師團兼裁判，不眠不休，仔細審查93個隊伍，所寫下的每一份文件。不只報名團隊超過預期的3倍，最後產出的DevOps實踐經驗（Practice）數量417份，涵蓋了13個DevOps領域，光是監控與Logging就有64份。
要將開發實踐經驗變成可以分享的知識文件非常困難，趨勢過去全公司一年只能累積30份實踐，但這一場遊戲活動的產量，是過去一年產出的14倍，更有50份評鑑為優秀實踐，甚至有5個團隊撰寫數量超過了30份，一個團隊的成果就是趨勢全公司過去一年的產量，這些最後集結出了一份趨勢自己的DevOps工程指南書，不只是知識管理的核心，也是趨勢新企業文化的實體化成果。
2年前決定展開轉型的那一天
這個故事要從兩年前的一封信說起。
2019年8月5日星期一早上9點多，趨勢科技執行長陳怡樺發了一封信，給全球6千多名趨勢人，宣告了新的DevOps大轉型計畫，也就是STOC計畫（Stand Tall on the Cloud，躍居雲端之上）的啟動。「現在是擁抱變革和抓住機會的最佳時間。」她在信中這樣強調。
趨勢科技是DevOps的先行者，早在2014年全球DevOps風潮興起之前，趨勢科技從2011年就開始調整維運策略，將雲端儲存相關專案的維運工作，改交給具有Ops能力的Dev研發團隊成員接手，例如中介軟體的部署。4年累積下來，更建立了一套趨勢DevOps自動化作業，這個流程涵蓋了程式碼組建、測試、部署、監控機制、自動恢復、系統配置、自動擴充、基礎架構調度等，也有三大類自動監控機制。
在2015年時，趨勢消費端產品研發部門下，超過半數的內外產品的開發專案導入了DevOps流程，當時已有十多位DevOps隸屬在不同的研發專案中負責Ops任務。到了2019年，已有數個核心產品團隊，都大力擁抱DevOps，每年可以累積20～30個經典DevOps實務（Practice）來分享給各部門參考。
「開發者夢想終於成真了。」陳怡樺指出，DevOps整套流程和相關雲端技術終於成熟了。「過去顧客下載軟體後，後續的產品更新是一件苦差事，除錯時更是很難以理解顧客端發生的問題，往返溝通甚至得花上一兩個月。
但是產品上雲，結合DevOps機制，可以擁有大量資料，可以很快知道，那些功能有用或沒幫助，「善用這些數據和技術，可以用非常有效率和效果的方式，來保護我們的顧客。」所以，她決定發起STOC計畫來推動企業文化轉型，不能只有核心團隊採用，不只建立DevOps流程，更要把DevOps變成趨勢科技的新企業文化。
要靠智仁勇改變企業文化
「企業文化就是一家公司做決定的依據和做事的方法，」陳怡樺說：「要改變文化，讓DevOps成功，就要改變思考和決策的方法。」女童軍出身的她，借用了童軍精神「智、仁、勇」三個字，來定調這次趨勢企業文化轉型的方向。
她解釋，利用雲端和DevOps蒐集到的龐大數據來做正確的決定，善用資料來改善決策就是「智」。有了數據後，能看到顧客如何使用產品，就更能站在顧客成功的角度，而非產品成功的角度就是「仁」，工程師以為顧客想要的是擋住所有病毒，但以同樣人的立場來看，顧客最希望的是準時回家吃飯，周末不用緊急到公司加班。
而最後一項「勇」是要求公司中的每一個人，都能勇於追求成長和承擔所做的決策。趨勢過去分工較細，往往是業務或PM提出需求，交給研發團隊開發，也就形成了成功是PM和業務團隊的責任的習慣，就像許多企業內部的責任分工一樣，現在則是希望，不只是PM或業務的責任，而是每一個人都能看重顧客的成功，將客戶價值提升視為每一個人的責任。
所以，趨勢訂出了三大轉型目標，第一是從產品成功導向的思維，轉為以顧客成功導向的思維，其次是要將由上而下決策模式，轉變為資料驅動的決策模式，三是將過去由業務負責營收，研發負責產品的分責模式，轉變為人人看重顧客價值成長的當責模式。
在陳怡樺這封STOC計畫啟動宣告信之後，她找來60多位資深主管，組成了一個跨部門小組，要來討論轉型具體該往那些方向走。

趨勢科技借鏡了童軍精神「智、仁、勇」三個字，來定調這次DevOps企業文化轉型的方向。（圖片來源／趨勢科技）
轉型的第一個問題
「執行轉型的第一個問題是，我們目前走到哪？」STOC小組核心成員之一的趨勢科技研發部林立仁表示。所以，趨勢也先找來不同已經導入DevOps的團隊訪談，也參考業界DevOps框架和內部軟體品質指標，設計了一份DevOps自評表，從產品方向正確性、交付速度、維運確保品質、文化和訓練等面向、來了解趨勢科技DevOps能力的現況。
調查之後才發現，這些團隊已建立了一套DevOps文化和流程，但如何作對產品，如何善用資料來驗證、改善服務的面向上相對較弱。另外，2年前，也缺乏了有效的透明化機制，來了解全公司各部門的整體DevOps發展情況。
第一年目標：喚醒DevOps意識
除了部分研發團隊，趨勢公司其餘人仍不熟悉DevOps，「所以，第一步先從認識DevOps開始做起。」陳怡樺坦言。2019年，趨勢設定的轉型目標是「喚醒DevOps意識」（DevOps Awareness）。STOC小組也分成5個工作團隊，各自負責不同的任務，有的負責訓練，有的負責資訊可視化，有的負責設計DevOps能力藍圖等。後來還發起開發維運學院計畫，透過工作坊、讀書會、團隊分享等方式來推廣。到2019年底，發起了62個讀書會，18次課程訓練超過5百人，不只舉辦20場內部實踐演講，也找了9位外部專家來分享，年底舉辦了線上8千人線下2千人共同參與的大型DevOps博覽會活動。
除了大量培訓之外，原本趨勢每年都會舉辦TEEA獎項，由各團隊主管提名優秀專案的實踐經驗，不限主題，評選後頒發獎金，這個獎項每年也能藉此蒐集到20～30份的開發實踐檔案，可以成為其他人借鏡的參考。所以，在2019年發起轉型後，就直接將評選主題訂為DevOps，更聚焦來推廣和蒐集更多DevOps實踐作法。STOC小組也找來內部DevOps專家，共同訂定了一份DevOps能力藍圖，就像是一份登山手冊一樣，可以讓DevOps初學者有一個按部就班學習的引導工具，可以知道該從那些技術、能力開始著手，以及後續的學習重點。
空有架構而無實踐的藍圖
林立仁坦言，這份能力藍圖規畫了13個DevOps領域，但是，就算趨勢擁抱DevOps多年，所累積的DevOps實踐仍舊不夠多，多數領域只有高層次的抽象概念說明，而沒有辦法提供貼近趨勢自己專案經驗的DevOps實踐作法或案例。
2020年初，STOC小組檢討第一年的轉型計畫成果，決定精簡STOC組織，從5個各自推廣的任務團隊，精簡整併為一個十多人的核心小組來集中火力，林立仁表示，希望進一步從認知提升的Awareness階段再更進一步，STOC就開始思考，如何透過活動，組合已完成的學習藍圖、蒐集更多實踐經驗，來把老手經驗分享給落後的團隊。
第二年目標：動手實踐DevOps
趨勢科技STOC小組對於2020年設定的轉型目標是「DevOps in Action」，真的結合到實際產品中動手實踐DevOps，而不只是喚起意識的認知改變而已。
STOC小組定出了第二階段5項轉型目標，除了第一項是從「喚起DevOps意識」到「DevOps行動化（DevOps in Action）」，林立仁表示，其次目標也不是舉辦大型年會作為成效，而是轉為要聚焦「達成商業影響」的效果，第三是要從動手做工作坊，更進一步真的導入到實際產品專案中。第四項目標是從隨興的Meetup分享會，轉變成認真投入的品質審視共享討論，最後一項是要從單一個別專案成效審視，轉而發展出一個跨部門透明度機制。
趨勢科技使用者經驗設計部資深專案經理林德政，就在這個時候，被林立仁找來加入了STOC小組。林德政成了後來趨勢發展出遊戲化DevOps活動的關鍵人物，他是2020年星際奇航遊戲的主要設計者。

趨勢利用內部原有的Wiki平臺來設計這個遊戲化DevOps計畫的環境，不過，還找來專責工程師支援，開發需要後臺程式，例如每天更新的排行榜。（圖片來源／趨勢科技）
第一次遊戲化設計失敗了
其實，STOC不是第一次要用遊戲化（Gamification）的方式來推廣DevOps，早在2019年發起轉型計畫後，就有另一位趨勢成員，想出了用太空旅程遊戲，來設計DevOps轉型活動的提案。
遊戲化設計是這幾年用戶體驗設計中的熱門話題，透過遊戲機制和情境，來打造提供給用戶的服務或體驗，來吸引或「黏」住用戶的案例和應用也越來越常見。但是像趨勢科技這樣，將遊戲化策略，運用到內部訓練轉型計畫上的案例仍不多見。
趨勢第一次的遊戲化設計概念是，公司的轉型歷程是，一艘太空船要飛向一個美麗境地的星球，而員工是燃料，透過參加不同課程，從事不同的任務，來獲取這艘太空船前進的燃料點數。而且不只是提案，2019年時STOC團隊也開始定義每個課程可以得到多少燃料點，甚至還製作了一支動畫短片，來介紹這個轉型太空旅程的故事。
可是，當時的STOC委員會沒有辦法設計出涵蓋各種DevOps領域的課程，讓參加者得到點數，就像DevOps能力藍圖，欠缺了貼近實際專案的實踐內容，而顯得抽象難實用一樣。林德政坦言：「最後，這個遊戲化概念失敗了」，趨勢科技文化轉型的第一次遊戲化活動，宣告失敗。
本文未完，下半篇更精彩遊戲化DevOps，如何重塑趨勢科技新企業文化（下）
 相關報導  千人打怪練出DevOps魂
",https://www.ithome.com.tw/news/142647,"新聞,軟體開發實踐,遊戲化設計,企業文化,轉型,DevOps,星際奇航競賽,趨勢科技,陳怡樺,智仁勇,DevOps實務,專案,擁抱變革"
142406,2,2021-01-28,【軟體工程老方法為何能解微服務新難題？】10個QA快速認識DDD,近年爆紅的微服務架構，成了企業重新改造IT，打造雲端原生應用的新架構，但是，微服務該怎麼設計，卻是一大難題？十多年前問世的軟體工程老方法DDD，提供了一條尋找答案的途徑," 微服務（Microservice）架構是近幾年最紅的應用程式架構，隨著Web技術、雲端架構、容器技術、DevOps流程等新興開發技術和方法的成熟和普及，將傳統大型單體式應用（Monolithic），拆解、重構成鬆耦合的微服務架構，成為更容易更新、快速發布、彈性擴充的雲端原生應用，不只網路公司必用，更是現在企業IT現代化的新主流作法。
最知名的微服務實例之一，就是 Uber用了約2,200個關鍵微服務，才打造出支援全球超過700個城市，數千萬名代雇駕駛，每天上千萬趟行程的服務架構。Uber的微服務架構圖就像是一張密密麻麻的網狀星雲圖，呈現出數千個微服務相互關連後的複雜性。
複雜性就是微服務的價值和考驗。微服務顆粒度越小（程式越小），就越容易針對單點爆量需求來擴充，功能異動的影響範圍也越小，派送、部署的速度也能越快，但是，代價是顆粒度越小，微服務的數量就得越多，應用架構複雜性也越高，維運和管理的困難度都會跟著提高。
如何拿捏「適當的顆粒度和架構」成了微服務設計時的關鍵，也是最大的難題，可是，這個問題，一直沒有標準答案，而且沒有永遠的答案，甚至10個架構師重構同一個應用，會有10套微服務架構。
早在2003年就問世的軟體開發方法Domain-Driven Design（領域驅動設計，簡稱DDD），提供了一套可以系統性拆解微服務的方法論，也因此再度爆紅，成了不少網路公司、企業用來解決微服務設計難題的新方法。
例如星巴克早從2015年推出的獎勵忠誠度計畫（Loyalty Program），隔年決定重新設計改版的新一代獎勵平臺，就是採用了DDD來設計，才打造出一個有能力處理十億個事件的事件來源引擎，每秒API交易次數達到數千次以上。
臺灣DDD社群核心成員整理了一份QA，可以快速認識這個老方法，一窺為何DDD能成為解決當紅微服務架構難題的新解方。
 Q1：為何微服務當道，DDD重新受到重視？ 
 A  約2013、2014 年間，全球開始興起一波將老舊系統轉型為微服務的話題，當時 《建構微服務》（Building Microservices） 一書的作者 Sam Newman 更在書中開宗明義指出，微服務的設計是一連串現代軟體工程的大成，涵蓋了領域驅動設計、持續交付、按需求虛擬化技術（On-Demand Virtualization）、基礎架構自動化、小型自主團隊（Small Autonomous Team）、大規模系統部署。這些元素都有助於微服務建構和實踐時的參考。
然而，多數人最關鍵的問題在於，試圖將老舊系統拆解成微服務時，每個人對於拆解方式與系統邊界的理解和定義，可能不一致。拆多了，要面臨過度龐大分散式系統的系統通訊與監控的困難。拆得太少，又顯得單一服務的職責太重、太雜，導致每次要修改部分功能，就得重新部署這支單一服務，受影響的範圍過大。
在多種不同的微服務切割方法中，可以回歸軟體建模的根本面，場景驅動的業務表述，大部分商務應用軟體，都循著一系列的應用場景描述開始捕捉，進而分門別類地，收歸其職責畫分到不同的模組底下，對應到分散式系統的開發部署角度上。開發者經常會發現，若能夠從業務場景梳理不同服務與模組之間的關係，能夠較為「有效」地管理跨服務之間溝通的複雜度與頻率，也容易掌握服務與服務之間的上下游關係，進而能指導團隊協作與組織間的協調。DDD是一種在軟體開發生命周期前期，就能投入的系統建構指引，也因此，2003年就出生的 DDD，在2015年後再次重生，閃耀在各大產業面前。
 Q2：DDD、敏捷和DevOps三者有何不同？ 
 A  這三者完全不同，但彼此能夠恰好地補足互相的不足。
簡單來說，敏捷（Agile）是一種軟體開發流程的方法，DDD是一種軟體分析設計的方法，而DevOps則是開發團隊和維運團隊彼此為對方多想一點的文化。（國泰金控數數發中心雲端技術架構師顏勝豪的觀點。）
但是，有些企業導入敏捷時，會遇到企畫端執行敏捷，但需求落地仍然按照既有IT開發流程，導致系統無法快速迭代，細究根因除了敏捷團隊缺乏開發人員以外，也有系統架構耦合性過高、整體開發周期過長等問題。
身兼敏捷及DDD顧問的香港IT顧問Steven Mak對臺灣社群分享時也提到，敏捷的導入，除了價值觀和團隊的建立外，系統架構和軟體開發也是很重要的一環。ThoughtWorks首席科學家，也是《重構》一書作者Martin Fowler曾在演講中指出，現今敏捷遇到的問題之一是，缺乏對技術專業重要性的重視。這些技術專業涉及了打造一個架構整潔、易於維護、品質優良的系統，或是關於如何建置一套高效穩定的開發部署流程，來縮短需求提出到上線的時間，來提升價值交付的速度，但要如何做到，敏捷無法告訴我們。
開發團隊要抉擇，做出「可以動就好的軟體」還是一個「能夠適應改變的軟體」？業務單位要抉擇，打造短期亮點的資訊系統「專案（Project）」，還是一個長期發展的資訊系統「產品（Product）」。
如果答案是後者，DDD、Agile及DevOps的融合，能夠提供一個好的方向，打造出珍視合作互動及軟體工藝、並能持續交付價值的敏捷團隊。
 Q3：國外有哪些DDD知名案例？ 
 A  早在2015年推出獎勵忠誠度計畫的星巴克，在2016年時決定重新設計新版獎勵平臺時，就採用了DDD，打造出一個有能力處理十億個事件的事件來源引擎。英國衛報十多年前的網站改版，就花了2年用DDD重新設計過一次。SalesForce 也曾以 DDD 來面對超過兩萬五千個開發者協同的複雜問題。
 Q4：臺灣有哪些DDD實例？ 
 A  臺灣已有一些早期先行者，試圖在各行各業中實踐。像是 KKDay在 2019年就試圖引入DDD 與事件風暴工作坊 ，來加強業務團隊與技術人員協作時的共同理解。大型企業如國泰世華銀行、中國信託銀行，都分別在 2020年開始投入更多實踐，大家的目標都是在既有系統能因應快速創新的需求下，能將既有資產、系統更好地梳理業務流程，重整出高內聚、低耦合的一套有彈性的軟體，希望未來有機會可以共用這些重新設計過後的系統。為此，越是大型複雜的應用場景中，DDD 幾乎成了現代改造系統架構的首選。
 Q5：想了解DDD最新趨勢，要追蹤那些意見領袖？ 
 A  領域驅動設計之父Eric Evans、中國領域驅動設計傳教士張逸、中國領域驅動設計社群組織者王威、創辦Virtual DDD也是領域驅動設計顧問的Kenny Baas-Schwegler、《領域驅動設計樣式、原理與實踐》共同作者Nick Tune、Event Storming發明人Alberto Brandolini、以及《實現領域驅動設計》作者Vaughn Vernon。
 Q6：上手DDD的第一本書？ 
 A  實現領域驅動設計》(Implementing Domain-Driven Design, IDDD)和《領域驅動設計樣式、原理與實踐》 (Patterns, Principles, and Practices of Domain-Driven Design)。
另有一本《DDD 15年》，這是由23位領域驅動設計專家所共同著作。每一位作者各自撰寫一篇文章，傾注了他們對於領域驅動設計的知識和實務的理解。由於每一位專家的背景和專注的專業領域不同，因此提供了運用領域驅動設計的豐富角度，例如像是從物件導向、函數式來運用DDD，內容非常全面。讀完後可以感受到「原來領域驅動設計還能夠這樣運用！」。本書有多國翻譯版本， DDD TW社群也著手翻譯這本書，近期將以正體中文發行。
 Q7：推薦那些DDD學習資源？ 
 A  有不少Youtube影音頻道可以參考，如包括了Virtual DDD頻道、Domain-Driven Design Europe頻道、Vaughn Vernon頻道、Explore DDD頻道、KanDDDinsky頻道、Domain-Driven Design Barcelona頻道和Domain-Driven Design London，另外也推薦加入DDD TW 臉書粉專和Youtube頻道。另外，DDD TW社群志工fx777，在2019年iT邦幫忙鐵人賽中優選得獎作品「Think in Domain-Driven Design 系列」，以30篇文章詳細介紹DDD和事件風暴的進行方式。
 Q8：企業IT要了解DDD，如何上手？ 
 A  可以加入DDD TW社群，社群提供了許多領域驅動設計的學習資源，可以避免企業在學習過程中的障礙。DDD TW社群會定期與中國和歐美各領域驅動社群或團體交流，來掌握領域驅動設計的理解及新資訊。
 Q9：業務團隊要了解DDD，如何上手？ 
 A  可以先從工作坊，包括Event Storming或Domain StoryTelling著手，先感受領域驅動設計帶來的好處。接著開始著手研讀領域驅動設計戰略部分的資訊，並且內化和整合到自己的業務知識，來理解到如何更好地將自身業務知識傳遞給團隊，來降低溝通成本提高協作效率。
 Q10：臺灣DDD社群目前規模？可提供什麼幫助？ 
 A  這是一個由臺灣軟體現役從業人員所經營的非營利社群，在2021年1月已經達到2,624人。社群將藉由多種不同類型的活動，將領域驅動設計的概念及實務和參與活動的朋友們分享與交流。DDDTW常規活動，有月例會、讀書會和年會。

DDD臺灣社群閃電崛起，接軌全球社群引進跨國開發實務

圖片來源-DDD TW
在2018年底，一個下著大雨的夜晚。DDD TW社群發起人高翊凱和張國昭，在巷口小七超商的一段討論後，花了2年，催生出一個核心志工團隊16人，社群規模超過2,600人的軟體開發社群。
高翊凱和張國昭好幾年來，一直很想在臺灣推廣領域驅動設計，甚至在自身任職公司都嘗試引入實踐，但擴散效益仍舊緩慢。2017年張國昭還自費到北京參加首次DDD中國社群年會，親身感受到海外社群的熱情。2018年夏天，2人決定展開行動，先在臉書成立社群粉專，但是，半年下來仍只有百來人規模。
兩人再次飛往中國參加第二屆峰會，結識了中國社群關鍵組織者王威和張逸，他們都是在中國軟體領域的實踐家和意見領袖，也成了臺灣社群發展跨區域協作的契機。所以，高翊凱和張國昭在下雨那夜訂出5大發展願景，擴大社群觸及人數、組織線下讀書會、透過MeetUp挖掘臺灣專家來交流、接觸全球DDD領域最大社群DDD Europe建立連結、培養社群新血和核心志工。
有了更明確的目標，2019年DDD臺灣社群開始快速發展，那一年就辦了超過20場的線下讀書會和Meetup活動，社群規模首度超過了1千人，透過讀書會也逐漸組成了核心志工團隊。還在年底舉辦了一個連續數周的微服務黑客松開發競賽，也獲得廠商贊助。
中國DDD社群看到了臺灣DDD社群快速崛起，在2019年底的峰會直接邀請高翊凱和張國昭登臺分享，張國昭的演講還獲選為最受歡迎的主題。不只在中國，高翊凱也積極將臺灣社群經驗發布到DDD Europe社群中，因此而結識了歐洲社群的主要組織者，打開了與全球社群協作的管道。
2020年疫情讓遠距協作成為主流，DDD Europe因此成立了一個全球性虛擬DDD社群，更在2020年5月，舉辦了一場24小時馬拉松的全球線上大會，臺灣DDD社群是歐美以外，唯一一個受邀的在地社群。高翊凱和張國昭被安排在第一組講者，後面緊接著登場講者是DDD之父Eric Evans、《實現領域驅動設計》作者Vaughn Vernon和Event Storming發明人Alberto Brandolini等當代一線軟體顧問大師。從此，臺灣的DDD TW社群正式與DDD Europe社群搭上線，多位歐洲DDD專家更在2020年底遠距參與臺灣年會，分享最新DDD經驗。
2020年11月底，舉辦了一連兩天的首屆臺灣領域驅動設計年會，涵蓋了產品、流程、設計三大議題，講者除了來自中國、英國、荷蘭等地社群之外，也有臺灣老、中、青三代的講者。參加者超過330人，3成來自金融業，多家金控也派員參加。除了企業高階主管、IT與研發、也有來自業務、行銷端的從業人員。第二天活動一口氣舉辦了6場工作坊，超過120人參加，最搶手的就是事件風暴工作坊，還得額外加課。
DDD TW社群每個月會找來業界有領域驅動設計實務經驗的第一線專家分享實踐經驗，不只技術，還包含團隊協作與業務分析。對於領域驅動設計經典書籍的讀書會持續進行，未來計畫細分為初階與進階兩個等級。透過DDD Europe社群聯繫，臺灣DDD TW社群也正將2019年在歐洲大賣的新書《DDD 15 Years》（中譯《DDD 十五週年》），透過社群志工力量，翻譯成正體中文版，預定2021年上半年發行。
",https://www.ithome.com.tw/news/142406,"新聞,DDD,Domain-Driven Design,領域驅動設計,微服務,Microservice,敏捷,DevOps"
142477,2,2021-01-27,GitLab更新產品訂閱模型，移除Bronze/Starter訂閱層級,GitLab訂閱層級在移除Bronze/Starter訂閱層級之後，只剩下Free、Premium或Ultimate這3個層級，原Bronze/Starter用戶仍可以續約1年，或是獲得升級折扣," GitLab宣布即日起變更產品訂閱層級，移除Bronze/Starter層級之後，訂閱層級會從原本的4層縮為3層，現階段的Bronze/Starter用戶，有一年時間轉換訂閱層級，可以選擇以當前價格續訂一年，或是以折扣價升級到Premium版本，新用戶將無法選用Bronze/Starter層級。
之所以要淘汰Bronze/Starter這個訂閱層級，是因為GitLab認為，Bronze/Starter不符合最低預期回報率（Hurdle Rate）。過去幾年，GitLab已經逐漸發展成為一個功能強大的DevOps平臺，但是許多Bronze/Starter用戶，僅將GitLab用來管理程式碼（SCM），以及持續整合（CI），但由於Bronze/Starter不符合GitLab期望的最低門檻，同時還限制了GitLab的發展，因此官方毅然決然要放棄Bronze/Starter層級，使得GitLab可以根據用戶的優先需求，加快開發速度，像是提高可用性與效能，甚至是滿足企業對安全與法遵的需求。
由於GitLab的免費層級，就包含了Bronze/Starter中89％的功能，是GitLab提供用戶進入DevOps的入門選擇，而在去年，GitLab也在免費層級，加入了450個新功能，且開源功能繼續維持免費，還有許多套件和功能，都從付費層移動到免費層級中。官方提到，對於需要DevOps功能的用戶，Premium是更適合的層級。
在拿掉Bronze/Starter層級的同時，為了避免SaaS和自我託管的產品命名造成混淆，因此決定對2個部署選項採用相同的命名，Free/Core將統一為Free，而Silver/Premium則變成Premium，原本的Gold/Ultimate層級，在變更後統一為Ultimate。
針對受影響的Bronze/Starter用戶，GitLab提供過渡優惠，當用戶數在25人以下，可以立即登入GitLab用戶入口網站，在2022年1月26日之前續約Bronze/Starter，就可再獲得Bronze/Starter訂閱1年，同樣是每個用戶每月4美元，或是也可以立即免費升級到GitLab Premium，並在未來3年，獲得GitLab Premium折扣價。而25人以上的用戶，則由銷售代表聯絡用戶進行過渡。
即日起，Bronze/Starter將不接受新用戶訂閱，新用戶只能選擇Free、Premium或Ultimate這3種層級開始使用GitLab。
",https://www.ithome.com.tw/news/142477,"新聞,GitLab,訂閱,DevOps"
142463,2,2021-01-27,【獨家披露】台積電數位轉型的下一步，靠AI推動全面轉型（下）,台積電這次AI全面轉型，不只要推動生產製造智慧化，還要將數位科技和資料導向（Data-Driven）作法，應用到更多領域，包括數位供應鏈管理、高效能雲端運算的應用、工作場所現代化，還有在外部客戶、供應商與內部員工的協同合作上。," 上半篇可打開【台積電數位轉型的下一步，靠AI推動全面轉型（上）】
2018年的資安考驗與雲端創新
2018年，對台積電IT來說，是重大考驗與高度創新的一年。一方面在當年8月，發生了電腦病毒感染事件，導致晶圓出貨延遲及成本增加，另一方面，在同年10月，台積電推出了虛擬設計環境VDE（Virtual Design Environment），讓客戶可以透過雲端進行晶片設計。
先來看考驗面，台積電早在2014年報中，就開始將網路攻擊風險列入風險管理中，2016年報中更納入勒索軟體攻擊風險。早在幾年前，台積電也已經在內部中央危機指揮中心運作演練中，增加了資訊系統服務中斷的演練。
但是，2018年這起影響台積臺灣廠區的電腦病毒感染事件，讓台積電進一步在2018年報中的營運風險項目下，納入「資訊技術安全之風險及管理措施」，不像過去列於「危害風險」中。網路攻擊風險也增加了國際雲端供應商遭攻擊的風險。甚至，在2019年的致股東報告書中，台積電對資訊架構和資訊安全的重視程度，拉高到與研發基礎架構並列，都視為要強化的業務基本體質。
病毒事件後，台積電也陸續採取了多項資安作法，尤其要加強開發自動化工具，來減少人為作業造成的資安風險，這些大多是資訊部門的任務。除了建置機臺自動化掃毒及防毒系統，強化網路防火牆與網路控管來防止病毒跨機臺及跨廠區擴散。也依電腦類型建置端點防毒措施，並且投入開發及部署資安監控程式、加強電腦弱點掃描及軟體更新，也要建立一個整合的自動化資安維運平臺。針對人員資安素養強化上，加強釣魚郵件偵測及員工辨識能力測試。還委託外部專家來執行資安評鑑。
另外，台積電積極更加要強化供應鏈資安、推動和發展機臺資安標準，例如在2019年7月成立了供應商資訊安全協會，後續開始定期發布供應鏈資安電子報，溝通資安規範。
推出VDE虛擬設計環境，將傳統晶片設計自動化流程服務上雲
資安考驗，沒有影響台積電創新的腳步，所以，在2018年10月，台積電將OIP所發展累積的數位設計及客製化設計流程，都放到雲端運算環境，推出了這款VDE虛擬設計環境服務，等於是將傳統的晶片設計自動化流程服務上雲，讓客戶也能善用雲端運算力和擴充彈性來設計晶片。VDE結合了製程技術檔、製程設計套件、基礎矽智財以及設計參考流程等OIP晶片設計輔助資料檔。不只如此，還啟動了第五大OIP聯盟「雲端聯盟」，將雲端供應商納入了原本的晶片製造生態系中。
台積電如何用IT和AI驅動全面數位轉型
台積電從2016年進入了智慧製造第三階段，要引進各種數位科技，以機器學習和AI來驅動全面數位轉型，沈文冰在IT線上徵才活動中解釋，這次轉型不只要推動生產製造智慧化，還要將數位科技和資料導向（Data-Driven）作法，應用到其他重要領域，例如數位供應鏈管理、高效能雲端運算的應用、工作場所現代化，還有在外部客戶、供應商與內部員工的協同合作上。
舉例來說，5G結合IoT應用，台積電在2020年中開始規畫5G企業內網，希望能提供更快速、即時和完整的資訊來幫助決策，將應用到機臺控制、生產製造規畫、工安與資訊安全等，尤其在先進製程機臺上，控制裝置感測器產生的資料頻率、數量和種類都暴增，光是一天就會產生1∼2TB的數值和影像資料，所以，台積電也正與內部專家，以及機臺、硬體、雲端業者要共同打造邊緣運算的軟硬體。
軟體開發採取行動優先、雲端優先策略
除此之外，「軟體開發是IT戰力的重要指標。」沈文冰強調。所以，台積電軟體開發策略，在2019年就定調為Mobile-First和Cloud-First，軟體開發團隊也導入了DevOps和敏捷開發。
像是台積電的下一代智慧工廠，就導入了行動應用、MR、IoT、大數據和AI技術。
例如軟體開發團隊協助打造的廠務IoT平臺，可以24小時蒐集生產環境的資料，利用雲端Hadoop來訓練感測器蒐集的龐大數據，建立AI模型，再提供到本地端邊緣運算來進行即時監控，雲端大數據也可作為後續良率分析之用。這套廠務IoT平臺是一個端到端的垂直整合應用，不只要處理的資料量龐大，也需要快速分析。台積電IT也將這套應用系統部署在Kubernetes平臺上，以便快速擴充和管理。
另外像在廠務維運上，也有一套手機App型態的廠務軟體，讓工廠維運人員直接就能透過手機App來管理。
跑在程式碼上的晶圓廠
「The Fab Runs on Code」（跑在程式碼上的晶圓廠）這句話是台積電用來形容IT軟體開發的重要性，一座晶圓廠需要仰賴許多IT團隊開發的軟體產品。台積電IT開發的軟體產品（台積習慣以IT產品來形容自建系統），可以分成兩大類，一類是工廠相關，如MES系統、Fab自動化、良率分析相關的軟體產品，另一類則是與業務部門、商業管理相關的產品。前者包括與製程良率分析（Process Yield Analysis）、品質管理、廠務（Facility）、MES、設備控制、設備自動化、IT維運平臺、資安、資料等相關系統，後者則像是CRM、ERP、eBusiness、Product Data Master、供應鏈、人資、供應商管理等。
跑在程式碼上的晶圓廠這句話是台積電用來形容IT軟體開發的重要性，一座晶圓廠需要仰賴許多IT團隊開發的軟體產品。台積電IT開發的軟體產品包括兩大類如下圖。

台積電軟體開發部門一位主管胡君怡指出，台積電開發團隊這兩年從傳統的瀑布型開發流程，轉型成DevOps模式。開發部門調整開發模式後，有幾個重要改變，她補充，以前產品發布頻率約需要2到3個月一次，但是現在可以做到每周，甚至是每天發布的頻率，「開發速度變快了，而且產品品質可以更好。」
「DevOps可說是IT的數位轉型，」胡君怡認為，當IT在台積公司的角色越來越重要之後，透過IT轉型，可以運用更多數位科技，來強化每一個員工，提高公司的生產力。
當IT的角色更重要之後，新的課題就是如何提高IT工程師的生產力，所以，台積電也有一個專門部門，負責開發 IT工程師每天所用的平臺。
胡君怡也在線上徵才活動上首度公開了台積電自建的雲端開發平臺，透過適當的DevOps工具，可以簡化IT開發流程，例如透過CI/CD部署，快速將應用程式提供給內部使用者。這個開發平臺目前支援了約1千名以上的工程師的開發工作。目前，台積多數應用程式也都導入到K8s環境上，已經有不少系統採用了微服務架構。少數仍在使用傳統語言開發的老舊系統，則正在評估如何移轉。
「我們做全世界最先進的晶片，所以，也要做出全世界最好的AI和開發出最強的軟體。」這是胡君怡對IT開發團隊的期許。
台積電首度公開了自建的雲端開發平臺，透過適當的DevOps工具，簡化IT開發流程，例如透過CI/CD部署，快速將應用程式提供給內部使用者。

2020年底首度公開AI四大類應用布局
台積電現在已經廣泛應用AI，也在2020年底首度公開了AI四大類應用布局。在製程研發面，用AI協助理解高複雜、高維度的製程開發挑戰。Fab量產面像是用AI和ML分析感測資料和檢測影像，來進行品質檢驗、缺陷檢查，協助快速產生高品質的晶圓。業務面，由是在市場動態分析上，大量使用了AI技術，也用來分析顧客行為模式。對IT團隊的IT維運工作上，也利用AI協助IT內部複雜系統的維運，或是用AI來進行異常偵測等。
台積電自己有一套ML開發專屬平臺，可快速調度和提供GPU等運算資源，可提供非結構化資料或結構化資料的儲存系統或資料庫，也用了不少開源AI框架和技術。舉凡最先進的AI技術，聯合學習（Federated Learning），遷移學習，主動學習等，台積電也都會嘗試。
台積電擁抱AI的策略是全面性的推廣，不只有IT，更希望擴大到全公司，從AI文化著手，舉辦多場訓練和工作坊，要讓更多人接觸AI的世界。目前內部已經訓練了1千位的人員，包括不少主管級人員。「想把內部環境，打造成AI Friendly的環境。」台積電負責AI徵才說明的主管林幸怡這樣說。
IT基礎架構三大工作重心，正導入容器化和基礎架構程式化
撐起各項IT應用的基石，就是IT資訊基礎架構。在2020年底，台積電也首度揭露IT基礎架構三大工作重心，更可以細分成9類任務。

第一是要運用各種基礎架構新技術協助企業數位轉型，包括要發展完整行動應用、導入協同合作和線上會議服務、雲端服務整合利用，第二項重心是發展軟體定義的資料中心，所台積電IT基礎架構團隊正努力要將自家資料中心，透過軟體定義轉型成真正的私有雲，未來主要任務，除了繼續使用虛擬化技術，台積電目前也正在發展容器化和基礎架構程式化（Infrastructure as Code）。目前正在將原本系統微服務化，讓原本系統運作的資源，調整成可以自動擴充數量的微服務容器，方便未來可以部署到公有雲上。第三項重心則是要持續進行基礎架構創新，包括導入新世代5G、IoT製造、AIOps技術等。
在基礎架構程式化的作法上，台積電會將各應用環境所需要的主機、網路、儲存所對應的基礎架構資源、組態設定都文件化，變成了範本和政策，搭配已經建立的完整DevOps環境、CI/CD流程，確保可以重複建立完整的環境，減少人為設定疏失，也能隨時用公有雲來建置相同的基礎架構。
「希望台積電未來資料中心，可以像公雲業者的資料中心一樣，建立統一入口，透過程式化的定義來管理。」台積電IT資訊基礎架構團隊負責徵才說明的主管郭清典這樣說。
不只將資料中心發展成軟體定義的私雲，台積電也積極擁抱公雲。為了將內部私雲的管理，延伸到公雲平臺，台積電也訂定了一個公有雲資安藍圖，透過內部資安部門評估，參考外部資安實務，架構出雲端服務資安服務的功能分類和建構流程，作為導入公有雲服務的參考指南。
台積電全面數位轉型的腳步，從2016年先從智慧製造展開，在2020年底最新揭露的轉型策略是聚焦5大領域，包括用AI來打造敏捷智慧製造，例如打造半導體機臺邊緣運算軟硬體、數位供應鏈管理、善用高效能雲端運算，例如要將適合的業務上雲（像是雲端CRM和雲端HCM），也開始聚焦工作場所的現代化（如繼續開發更多內部行動App、推動RPA、智能會議室等），還要發展團隊協作，例如透過AR/MR遠端協作、用MR支援研發部門3D模型設計和模擬流程，或實現以使用者為中心的團隊協作合作平臺等。
台積電不只要用IT重新定義了半導體製造生產，還要用IT和AI重新定義新的自己。文☉王宏仁
更多【台積電全面AI數位轉型大解密】封面故事內容
【獨家披露】台積電數位轉型的下一步，靠AI推動全面轉型（上）【獨家披露】台積電數位轉型的下一步，靠AI推動全面轉型（下）【獨家披露】【加速數位轉型5大發展】台積電為何大動作招募這3類全球IT人才【獨家披露】台積電30年IT和AI發展史（1996～2020和未來）
",https://www.ithome.com.tw/news/142463,"新聞,台積電,數位轉型,TSMC,雲,AI,大數據,智慧製造,資安,DevOps,AR/MR,軟體定義資料中心,混合雲"
142462,2,2021-01-27,【獨家披露】台積電數位轉型的下一步，靠AI推動全面轉型（上）,這是台積電30年來智慧製造的第三度大變革，從2000年邁入全自動，2012年發展出整合平臺和大數據分析，到了2016年進入了智慧製造第三階段，這次大轉型不只是智慧製造生產模式的敏捷革新，更要靠AI展開全面數位轉型，擴及工作場所現代化、數位供應鏈管理、高效能雲端運算和團隊協作創新," 下半篇【台積電數位轉型的下一步，靠AI推動全面轉型（下）】
「台積公司一直用IT重新定義半導體的製造與生產。」台積公司資訊部門一位主管沈文冰的這句話，點出了IT在台積數位轉型大變革中的關鍵地位。在2020年底，台積電有史以來舉辦首次線上IT徵才活動，罕見地揭露了多項推動數位轉型的新戰略和布局。這不是台積電IT第一次大變革，而是30年來的第三度革新。
創造出半導體製造代工服務模式的台積電，非常清楚製造服務業的本質是服務，早在1996年就提出「虛擬晶圓廠」概念，更推動企業組織再造，從生產導向的組織型態，轉變為以服務為本位的服務型組織，要求技術人才要具備行銷技能。
IT，就是讓台積順利將各種製造服務轉為自動化的關鍵。在1996年，台積為了將後勤和財務資訊轉換成管理資訊來輔助決策，展開了資訊系統大升級，當年WWW技術才剛點燃了全球網際網路新浪潮不久，台積就能運用當時的網路技術，推出了全方位訂單管理系統，讓顧客透過電腦網路連線取得訂單和產品生產資訊，這也是半導體代工產業的創舉。1999年更推出供應鏈管理的資訊服務，可以讓客戶透過網路下單、即時查詢晶片生產進度和出貨狀況，早在30年前，台積電就採取了現在網路電商慣用的銷售形式。
由於當時台積早已高度電腦化，許多業務相關軟硬體系統和生產設備，都面臨了2000年年序問題的挑戰，所以，台積電在1997年發起了Y2K專案，提前因應，順利度過Y2K危機。
2000年：智慧製造第一階段，從半自動邁入全自動化
2000年台積晶圓生產製造型態，從過去的半自動，邁入了全自動化時代。
台積電也持續投入電子商務，以成為客戶半導體產品生產的虛擬晶圓廠為目標。不只是可以讓顧客透過網際網路，來進行從晶片設計構思到完成晶片驗證的程序，也推出了TSMC-Online 2.0線上系統，可提供互動式查詢晶圓製造相關資訊，不同客戶角色還可以自訂介面。
台積電在2000年推出了設計服務聯盟（Design Service Alliance）的產業生態系合作模式，將積體電路設計自動化領導廠商、元件資料庫和半導體智財供應商，以及產品設計執行服務業者組成了一個生態系。這種生態系合作模式的作法，台積電後來更用來結合到更多個產業生態系，甚至還擴大套用，連雲端供應商都可以納入半導體產業生態系中。
當時半導體吹起產業解構趨勢，台積看好網際網路技術會推動無阻力事業流程的發展，更加速解構。所以，台積電更在2000年首創eFoundry（後來，台積電用EFOUNDRY來稱呼這個理念所建立的平臺和服務）服務理念，要將更多客戶服務內容，都延伸到網際網路上提供，建立更即時便捷的溝通模式。IT成為台積改造對外服務的關鍵基礎。
這個eFoundry服務（網際專業積體電路製造服務）的基本架構，包括了三大類用途的系統，分別是設計合作、工程合作和後勤合作的系統，整體是以網路為基礎所打造的一套服務系統。例如2002年報就指出，台積電的設計服務，就提供了線上技術資訊查詢服務，客戶能下載台積公司技術文件，來確保製程一致性與包容性。
這個台積電的eFoundry服務，更透過網際網路提供到一天24小時，每周7天的持續服務水準。2011年報指出，設計合作上可以提供每一設計階段準確與最新的設計資訊，工程合作上則可提供客戶晶片良率測試及可靠度相關的工程資訊，而後勤合作可以做到一天提供3次，客戶晶片在工廠封裝測試及運送的多項後勤資訊。
不只用於對外的客戶服務，在台積電發展第一階段智慧製造過程，內部製程和系統也善用IT。台積從2001年初開始建立企業供應鏈管理系統，2002年更有多項改善整體供應鏈效能的跨部門專案，結合IT、資材、財務部門和工廠運作資料，如線上供應（Supply On-line）系統，可整合所有供應商相關資訊給供應商，降低了原料存貨水準。或像是原物料計畫管理系統（Materials Planning Management System, MPMS），來改善生產物料的需求預測，降低缺料的風險。
後續幾年，台積電更持續在運籌管理、生產時程管理、存貨管理、知識管理上善用IT來提高效率。2005年時，物料企畫及庫存管理上持續改善，已經可以透過每周資料更新，有效整合資材與其他相關單位的供需資訊，2007年，繼續精進物料及庫存管理，透過即時資料更新及報表系統，能有效地整合資材及其他相關單位的供需資訊，來提升對物料需求的預測，以利採取快速和正確的因應措施。
為了提供積體電路設計者一套精緻的設計基礎架構，台積電在2008年時，創立了「開放創新平台」（Open Innovation Platform，簡稱OIP），當時納入了電子設計自動化（EDA）流程、通過矽晶片驗證的資料庫和矽智財、模擬及驗證用的設計套件，如製程設計套件（PDK）及技術檔案。雖然，這不是IT主導的研發成果，但是IT協助打造了派送相關資訊到使用者面前的通路，後來在2018年時，台積電更直接改在雲端提供虛擬晶片設計環境，IT的資訊基礎架構能力，更成了建構這個虛擬設計環境服務的關鍵。 
2012再次變革，智慧製造邁入第二階段，發展整合平臺和大數據
2012年，台積電的智慧製造邁入了第二階段，進入整合平臺和大數據分析的時期。在工程效能優化上，除了利用先進機臺控制（Advanced Equipment Control）與即時缺陷偵測（Fault Detection）之外，也開始運用大量工程資料探勘（Engineering Big Data Mining）、中央管理製造平臺（Centralized Operation Platforms），來優化機臺、製程和良率。後來，更發展出利用大量工程資料協助決策分析的「智動化」系統（Intelligent Automation System），來維持機臺高效穩定運轉。另外，在2014年報中透露，台積電也開始導入智慧化行動裝置，由IT開發內部用的行動App。
2016年：智慧製造第三階段，引進各種新科技，更要靠AI全面數位轉型
台積電早在2011年就開始嘗試將AI技術導入晶圓製造，研發智慧化生產流程，2015年報更揭露了機器學習優化工程效能的成果。從2016年開始，台積電全力擁抱各種數位新科技，不只是智慧製造，更決定要用機器學習和AI推動全面數位轉型。
台積電的下一代智慧工廠，就導入了行動應用、MR、IoT、大數據和AI技術。IT軟體開發策略也採取Mobile-First和Cloud-First，靠雲端科技作了很多創新。

台積電這幾年陸續提出「精準製造」、「精簡製造」，2015年報提出了「精實與智慧生產」，後來在2016年報則提出了「敏捷與智慧生產」的理念。這些發展背後都大量運用了IT和 AI。
幾年從大數據到AI技術的投入後，台積電2015年報揭露，已經整合了先進資料分析、智慧診斷、自我反應引擎和生產知識等技術，工廠的生產模式，也從「自動化」進一步發展為「智能化」模式，例如發展出了在製品與生產線管理系統，能夠精準控制在製品水位，還配備了彈性化的需求／產能模型系統。在一些成熟工廠中，更利用IoT和智慧化行動裝置，來改善資料收集、良率追蹤、物料傳送和流程的效率。
隨著先進製程發展上，線寬持續微小化和縮短，台積電面臨了更嚴格製程管制的挑戰，台積在製程管制和分析系統上整合了多種智慧功能，例如開發出了精準即時缺陷偵測分類系統、先進智慧機臺控制和先進智慧製程控制，可以即時監控，來準確調整製程條件。另外，也開發出精準機臺腔體匹配（Precision Equipment Matching）和良率採礦分析（Yield Mining）來降低製程變異和潛在的良率損失。為了找出影響產品品質好壞的關鍵，更打造了一個大數據、AI和ML的架構。除了AI技術研發，台積也開始培訓自己的機器學習人才，舉辦全公司性的訓練課程，2017年時開始規畫要在內部培訓300位ML專家。
到了2018年報透露，台積內部AI應用更廣泛了，包括了排程與派工、人員生產力、機臺生產力、製程與機臺控制、品質防禦以及機器人控制等。台積電的製程管制和分析系統不只可以自我診斷和自我反應，還具備自我學習的能力。
未完，請打開下半篇【台積電數位轉型的下一步，靠AI推動全面轉型（下）】
 
更多【台積電全面AI數位轉型大解密】封面故事內容
【獨家披露】台積電數位轉型的下一步，靠AI推動全面轉型（上）【獨家披露】台積電數位轉型的下一步，靠AI推動全面轉型（下）【獨家披露】【加速數位轉型5大發展】台積電為何大動作招募這3類全球IT人才【獨家披露】台積電30年IT和AI發展史（1996～2020和未來）
",https://www.ithome.com.tw/news/142462,"新聞,台積電,TSMC,AI,數位轉型,智慧製造,DevOps,Cloud,Digital Transformation"
142464,2,2021-01-27,微軟財報出爐：整體營收成長17%，Azure成長50%,受惠於疫情促成的企業數位轉型潮，微軟上一季營收比前年同期成長17%，在個別產品服務中，表現最亮眼的依然是雲端運算平臺Azure," 微軟周二（1/26）公布截至去年12月31日的2021財年第二季財報，該季創下431億美元的營收，比前一年同期成長17%，其中，成長幅度最大的是Azure（50%），由於該季成績超越了華爾街分析師的期待，使得微軟當天的盤後股價上漲了3.7%，股價攀升到240.92美元。
該季微軟生產力與業務流程（Productivity and Business Processes）營收為134億美元，成長13%；智慧雲端（Intelligent Cloud）為146億美元，成長23%；更多個人運算（More Personal Computing）營收為151億美元，成長14%。
在個別的微軟產品或服務中，表現最亮眼的依然是雲端運算平臺Azure，其營收成長了50%，居次的是Xbox的內容與服務，成長40%，Dynamics 365營收成長39%，LinkedIn營收增加23%，Office 365商用服務成長21%。微軟僅揭露各別產品的成長規模，並未公布其確實營收。
另一方面，微軟亦強調包含Office 365商用版、Azure、Dynamics 365與其他雲端服務的商業雲端營收，已達167億美元，比前一年成長34%。
微軟執行長Satya Nadella指出，微軟在去年見證了第二波數位轉型潮的曙光，它席捲每個產業的所有公司，而建置自己的數位能力，已成為每家企業推動成長與提高經營彈性的新籌碼。
",https://www.ithome.com.tw/news/142464,"新聞,微軟,數位轉型,COVID-19,疫情,財報,Cloud,Azure"
142460,2,2021-01-27,GitLab 13.8內建CI/CD工作管線編輯器與DevOps成熟度指標,GitLab現在提供工作管線編輯器，不只讓用戶能夠更簡單地編輯CI/CD工作管線，還能視覺化工作管線圖," GitLab發布最新的13.8版本，把更新重點放在CI/CD上，不只新增了工作管線編輯器，讓開發者能夠以視覺化方法，來定義CI/CD的功能，另外，GitLab現在也提供4大指標DORA 4之一的部署頻率圖表，讓用戶可以評估自家DevOps的成熟度。
過去GitLab用戶都要以gitlab-ci.yml配置檔案，來定義CI/CD的功能，官方提到，以程式碼配置工作管線，代表用戶可以將用於應用程式程式碼的工具，拿來對工作管線進行版本控制，並和團隊成員協作，而且GitLab所提供的進階語法，也讓用戶可以高度客製化複雜的CI/CD功能。
但是這些功能和靈活性，代表著相當高複雜性，因此官方為了讓用戶能夠更簡單地配置CI/CD工作管線，因此提供內建視覺化工作管線編輯工具。從GitLab 13.8開始，用戶將可以使用CI/CD專用編輯器，這是該編輯器的第一個版本，提供靈活的選項，能夠支援各種複雜的工作管線使用案例，用戶不會再被冗長與複雜的語法困擾。
該編輯器能夠同時良好地支援新手和進階使用者，並且作為單一解決方案，在同一個地方提供所有現有的CI編輯功能。除了編輯功能之外，工作管線編輯器還會持續檢查工作管線的配置，在使用者一邊進行編輯時一邊驗證，並且以狀態列明確提示當前配置是否通過驗證，或是存在錯誤，而工作管線視覺工具（Pipeline Visualizer）呈現工作管線配置圖，Lint頁籤則提供工作管線語法驗證功能，提供每項任務的詳細資訊。

除了工作管線編輯器，GitLab 13.8的另一個更新就是提供部署頻率指標，讓開發者能夠衡量DevOps成熟度。官方提到，DevOps研究和評估公司DORA，研究DevOps對企業所產生的影響，結果顯示，DevOps的成熟度越高，業務成果就越正面，包括客戶滿意度越高、更大的市占率以及更高的獲利，而被稱為DORA 4的四個指標，分別是部署頻率、更改的前置時間、服務恢復時間和更改失敗率，則是衡量DevOps成熟度的重要指標。
由於許多GitLab用戶希望能夠使用這些指標，來評估自家DevOps成熟度，但因為要取得相關的系統資料，以計算這些指標並不容易且耗時，因此GitLab決定將這些指標內建到系統中，從GitLab 13.8開始，用戶就可以從CI/CD分析頁面中，查詢部署頻率圖表，官方提到，這只是DORA 4的其中一個指標，他們還會陸續添加其他三個指標。

",https://www.ithome.com.tw/news/142460,"新聞,GitLab,CI/CD,DevOps"
142368,2,2021-01-21,Engine Yard推出NoOps容器平臺EYK,EYK讓用戶使用單一指令，就可將Git專案打包成容器，部署到雲端平臺上," Engine Yard正式發布其容器平臺Engine Yard Kontainers（EYK），這是一個以容器為基礎的全託管基礎設施，可讓用戶不需要擁有DevOps專業知識，就能將應用程式簡單地部署到雲端。Engine Yard在去年7月的時候，推出了EYK Alpha測試版，而現在該平臺已經成熟正式上線。
EYK獨特之處在於提供用戶採用NoOps範式，Engine Yard提到，雖然DevOps能夠提高部署節奏，但也會對開發人員帶來許多負擔，除了必須要學習的DevOps知識外，由於DevOps的實踐方法存在很大的差異，持續升級基礎設施以及缺乏標準帶來不小的挑戰，開發人員必須花費時間資源維護DevOps系統，因而壓縮原本可用來開發產品的時間。
而Engine Yard以平臺即服務EYK來達到NoOps的理想，基於最佳實踐，讓用戶不需要操作各種腳本以及實作，就能夠使用標準堆疊進行部署。EYK能自動化部署應用程式，並且內建監控和自動縮放功能，大幅減少操作時間，開發人員仍可以快速迭代和部署，但還能夠花更多時間專注在軟體開發上。
無論是哪一種容器技術，開發人員都必須克服其學習曲線，才能獲得容器帶來得好處，Engine Yard提到，以EYK應用NoOps，可以消除營運負擔，工作流程中的單一命令就能完成部署工作，消除典型開發生命周期中的程式碼修改、單元測試、提交程式碼至儲存庫等工作，在EYK中，開發人員可以直接從現有的Git專案中，創建應用程式並完成部署。
用戶不需要為EYK準備容器化應用程式，EYK會自動將程式碼打包成一個容器，並且部署到完全託管的Kubernetes平臺上，EYK也會自動監控應用程式，並且根據需求和策略自動縮放容器，用戶還可以直接在EYK中查看應用程式日誌。用戶不需要修改任何程式碼，便可以直接使用EYK平臺，對執行環境有特殊需求，可以使用標準的Docker檔案進行配置，或是使用官方提供用於建構Dockerfile的工具。
EYK的Kubernetes基礎設施目前僅在AWS上運作，預設使用私人叢集部署模式，EYK僅會在用戶專用的帳戶和VPC中執行私人叢集，不會與其他用戶共用，以確保工作負載的安全性。
",https://www.ithome.com.tw/news/142368,"新聞,Engine Yard,容器,DevOps,Kubernetes,全託管基礎設施"
142273,2,2021-01-18,GitLab與IBM Cloud合作提供DevOps解決方案,適用於IBM Cloud Paks的GitLab Ultimate，讓用戶將使用Cloud Paks開發的應用程式，快速部署到雲端環境中," GitLab與IBM共同發布適用於IBM Cloud Paks的GitLab Ultimate，其目的是要提供一個全面且易於使用的DevOps平臺，以提高開發團隊的生產力。用戶使用適用於IBM Cloud Paks的GitLab Ultimate，提高DevOps的成熟度、自動化程度，安全地進行開發工作，並將應用程式部署到選擇的雲端環境中。
不少企業逐漸將工作負載搬遷上雲，不只要建置雲端原生應用程式，也要將既有的應用程式現代化，以支援雲端環境，同時還要避免被特定的工具以及環境綁住，而適用於IBM Cloud Paks的GitLab Ultimate，可以將應用程式部署到，包括雲端以及裸機伺服器等各種環境上，透過使用OpenShift來執行自動化和部署管理工作，而且GitOps搭配適用於IBM Cloud Paks的GitLab Ultimate調度自動化技術，可以和GitLab工作管線結合一併使用。
GitLab全球通路副總裁Michelle Hodges提到，這項合作讓IBM的用戶，能夠將應用程式部署到他們選擇的混合雲環境，借助紅帽OpenShift的優勢，開發者能夠選擇在IBM Cloud、IBM Z、Google Cloud、AWS以及Azure等環境，建置跨雲和跨系統的應用程式。
應用程式建構套件Cloud Paks提供機器學習、IBM Watson等技術，供用戶開發雲端應用程式，而與GitLab合作，IBM便能提供單一且全面的混合雲解決方案，不只能夠方便地部署工作負載，還能滿足安全性與法遵需求。
適用於IBM Cloud Paks的GitLab Ultimate將由IBM提供，支援現在所有IBM Cloud Pak解決方案，包括業務自動化、應用程式自動化、網路自動化和AIOps等，用戶可以選擇自己熟悉的程式語言進行開發，並將應用程式部署到常用的雲端環境。
",https://www.ithome.com.tw/news/142273,"新聞,GitLab,IBM,DevOps"
142133,3,2021-01-11,Google更新Cloud Logging加入結尾紀錄功能,Cloud Logging結尾紀錄讓用戶能夠即時查詢日誌，並且以日誌過濾器篩選出有興趣的紀錄," Google在其記錄檔服務Cloud Logging加入一個新工具，讓用戶將日誌檔案的內容，即時顯示在控制臺中，並且強化日誌搜尋功能，讓結尾紀錄指令可以搭配正規表示式等過濾器功能一起使用。目前Cloud Logging的結尾紀錄功能向所有使用者開放，以供預覽測試。
Cloud Logging服務能在1分鐘內的時間，匯總來自Google雲端、本地端和其他雲端平臺的日誌，並且建立索引，使日誌可供搜尋，還可將日誌匯總到指標，或是掃描錯誤報告中的錯誤，方便用戶排除故障使用。
新的結尾紀錄功能，是模仿Linux中tail -f指令的行為，能在控制臺中即時顯示所有日誌，不只如此，Google強化日誌檢視功能，讓用戶可以搭配使用Cloud Logging日誌查詢語言，執行全域搜尋、正規表示式或是字串比對，來即時找出想查看的日誌記錄。
除了這項更新之外，官方還提到，雲端控制臺現在還可以將日誌串流到Logs Explorer，並且在控制臺直接控制串流、瀏覽與視覺化等日誌功能。
",https://www.ithome.com.tw/news/142133,"新聞,google,log,結尾紀錄,Google Cloud Loggin,日誌檔案,Cloud,雲端"
142124,3,2021-01-08,紅帽準備買下容器安全平臺StackRox,紅帽宣布收購容器與K8s威脅偵測服務StackRox，將其整合至紅帽企業K8s平臺OpenShift," 開源解決方案供應商紅帽（Red Hat）7日宣布，打算收購專門提供容器與Kubernetes威脅偵測服務的新創業者StackRox，將StackRox的技術整合到紅帽的企業Kubernetes平臺OpenShift上，還計畫建立一個統一的平臺，以讓使用者能夠建置、部署及安全執行可於混合雲端上運作的任何應用，雙方預計於今年第一季完成交易。
紅帽表示，Kubernetes為全球成長最快的開源專案之一，它是許多雲端原生應用的基礎，亦為數位轉型的核心，儘管有愈來愈多的生產環境採用容器與Kubernetes，但仍存在著安全上的挑戰，為了解決有關容器與Kubernetes應用的安全、監控、資料管理及網路問題，企業需要相關的解決方案來確保現代任務的安全性。
2014年成立的StackRo定位為Kubernetes原生安全平臺，其軟體藉由在Kubernetes叢集架構中直接部署執行元件並蒐集資料，提供所有Kubernetes叢集的可見性，減少了導入安全所需的精力，簡化安全分析、調查及緩解程序。
StackRox原本即支援各種環境，涵蓋AWS、Azure、Docker、GCP、OpenShift、Pivotal Container Service、Rancher及聯邦機構等。紅帽除了承諾仍將讓StackRox支援OpenShift以外的環境，未來也將開源StackRox技術。
",https://www.ithome.com.tw/news/142124,"新聞,紅帽,Red Hat,資安,容器安全,K8s,Kubernetes,StackRox"
141975,3,2021-01-03,2021加速轉型9大趨勢（三）K8s終於通吃跨雲落地各平臺，將成IT現代化主流標準,不論是哪朵公雲或商業私雲，現在都能靠K8s在任一處部署各種容器化應用," 終於，雲端龍頭AWS也落地，搶進企業商用K8s軟體市場了，這一步也讓K8s成了可以通吃主流公私雲的唯一基礎架構平臺。
AWS在2020年底年度大會上發布了兩項重量級產品ECS Anywhere和EKS Anywhere。前者是雲端容器代管平臺的本地端代理軟體，可以讓雲端ECS服務，也能統一管理和調度企業機房內部伺服器上的容器運算工作，算是雲端容器服務向下的延伸。但後者EKS Anywhere，則是一款徹徹底底的商業軟體產品，可以獨立安裝、部署在企業機房內的伺服器上，完全不需要連線到AWS也能獨立運作。AWS變成了企業基礎架構軟體商，踩進了微軟、紅帽擅長的企業軟體市場。
回顧2年前，各公雲業者紛紛推出K8s雲端代管服務，可以讓企業上雲部署K8s應用，這也讓企業應用打包成K8s應用之後，更容易自動部署到不同公雲環境中來提供服務，等於打通了多雲之間的壁壘。到了2019年，更進一步吹起了混合雲互通的浪潮，不少業者陸續在2019年推出了以K8s為核心的混合雲產品。當年4月，Google先登場，推出混合雲平臺Anthos，可以雲端GKE服務上或機房內的GKE On-Prem上部署K8s應用。下半年，IBM推出了雲端原生軟體包IBM Cloud Paks，以紅帽OpenShift為基礎，打包IBM服務來落地。為搶攻混合雲需求，IBM後來甚至大砸340億美元買下紅帽，將可以混合公私雲的OpenShift平臺軟體變成自家產品。
VMware也從2019年8月底大動作宣布，全面擁抱K8s，先推出可以管理各種K8s環境的新產品線Tanzu，還預告會用K8s重新改造vSphere。
到了2019年底，早就在混合雲市場布局的微軟，推出了新款混合雲解決方案Azure Arc，同樣用K8s打造而成，可用來管理各處的K8s叢集，還可以支援邊緣運算環境。四大公雲，只剩下雲端龍頭AWS，沒有推出K8s混合雲產品。
在K8s落地部署環境上，除了紅帽和VMware之外，原本力推OpenStack的Mirantis，在2019年底買下Docker公司的Docker企業版業務和產品，後來更名為Mirantis Kubernetes Engine也來卡位。
2020年上半，深度整合了K8s的新版vSphere終於正式推出，原生就可以支援K8s的API，能夠通吃虛擬機器和容器型態的工作負載，甚至，企業可以把vSphere轉為K8s容器平臺。企業慣用的虛擬化架構，更容易和容器架構共用同一套管理機制。
儘管疫情打亂了所有人的步調，延緩了K8s版本發布時程，但IT廠商競逐K8s市場的腳步沒有慢下來，甚至，K8s的戰場，從公雲、私雲、混合雲，現在還進一步延伸到邊緣運算裝置上。
企業級Linux業者SUSE在2020年7月，宣布買下另一家容器管理平臺Rancher Labs，就是看上了他們所打造給邊緣裝置專用的輕量級K8s軟體K3s。早一步支援K8s邊緣部署的微軟，則在9月一口氣推出了3款Azure Stack邊緣運算整合應用設備，可在不同型態邊緣設備中部署K8s。紅帽OpenShift在2020年12月初也宣布支援3節點叢集，要搶攻邊緣架構的部署需求。
年終AWS的兩項重量級產品ECS Anywhere和EKS Anywhere，更是確定了K8s加上容器技術，是唯一可以跨主流公雲、混合雲、跨主流私雲，甚至是邊緣裝置的應用程式運算環境。這正是這兩年許多企業發展數位轉型，開始推動老舊AP現代化，或是擁抱雲端原生應用的現代化IT技術時，都同步擁抱K8s的緣故。臺灣已有少數大型企業，開始從虛擬化平臺，轉為擁抱K8s平臺，金控、銀行、高科技製造業都有。甚至如國泰金控、玉山銀行，大力擁抱微服務架構，就是看上容器化應用可以彈性擴充，容易大規模部署的能力。2021年，可以通吃上雲落地的K8s，勢必成為更多企業推動IT現代化的主流，也是唯一的選擇。
",https://www.ithome.com.tw/news/141975,"新聞,K8s,容器,2021加速轉型9大趨勢,數位轉型,數位韌性"
141870,3,2020-12-25,Container周報第134期：Line臺灣K8s導入經驗首度大公開，導入超過20個專案部署50個K8s叢集,目前Line臺灣有超過20個專案部署在VKS上，包括了Line購物、Line音樂、Line旅遊、Line熱點、Line Today、Line訊息查證服務等，超過130個App設定檔，使用了50多個K8s叢集。," 11/25~12/25 精選容器新聞
#K8s #Line臺灣 #VKSLine臺灣K8s導入經驗首度大公開，導入超過20個專案用了50個K8s叢集
不同於先前完全線上進行的日本開發者活動，Line臺灣在年底仍舊可以舉辦實體開發者大會，在開場演講中，Line臺灣技術長陳鴻嘉表示，後疫情時代的新常態，帶來的挑戰是開發團隊需要更快速的開發速度，而且這些新服務要有承載巨大流量和瞬間爆量的能力，甚至像Line Travel服務，隨著國旅需求浮現，光是從2020年6月到9月，流量就暴增了24倍多。過去1年來，Line臺灣開發團隊正是採用容器技術和K8s來因應新常態下的需求爆量挑戰。
原本Line總部就有一套以虛擬化技術為主的IaaS雲端基礎設施服務Verda，可以讓開發團隊自助申請需要的部署資源，另外還有一套提供給外部合作夥伴使用的平臺。但是，陳鴻嘉坦言，自助式IaaS後來出現了兩個挑戰，使用效率問題和維運問題。
原來，大部分團隊為了應付可能的流量高峰，例如過年過節可預期傳訊需求的爆量，這些服務的團隊會事先申請了一堆資源來備用，「如果沒用到，這就浪費了VM資源。」陳鴻嘉表示。
再者，遇到實體機器維修，需要安排新的VM來轉移服務，服務維運團隊還是得花上不少時間來重新部署，甚至遇到臨時故障的處理更是困難。「需要更即時性的基礎架構調度平臺，可以把應用的程式碼和相依性封裝起來，任意部署到不同環境中。」陳鴻嘉點出擁抱容器最大的考量，這也是許多企業轉而採用容器來取代VM的原因。
所以，Line總部開始在Verda平臺上，開發一套K8s平臺來提供一套Veda K8s Services（VKS）容器服務。採用K8s主要有3個考量，第一個原因是K8s的自由擴充彈性，也可以把自己原有的運算資源引進到K8s環境中，其次是易用性，因為K8s已有很多生態系、工具和論壇，而最後一項理由是維運成本較低，因為遇到問題，活躍的社群可以很快幫忙解決問題。
而Line臺灣在VKS上線前，為了解決人力資源調度問題，也開始導入容器化服務，自行在臺灣本地建置了一套K8叢集，第一個導入的服務就是2019年中上線的Line Spot熱點服務。陳鴻嘉當時設定了兩個目標，要透過K8s容器化服務，在新人到任後，半小時就可以部署好開發環境，讓新人立刻加入開發工作，不用像過去得花2週準備環境，第二個目標是，為了因應流量高峰，每一個容器化的服務都要具備自動擴充功能。第一個專案導入K8s嚐到好處後，Line臺灣開始推廣到其他專案。
隨著Line總部的VKS平臺，在去年年底開發完成後，Line臺灣也決定把本地容器化開發專案，也轉移到總部VKS上，就不需要再自行維護底層K8s叢集。從今年第二季時開始進行轉移K8s專案，轉移速度很快，大部分的困難都是搬上新容器環境後所遇到的問題。Line臺灣還成立了一個DevOps專案小組，就由Line Spot團隊工程師擔任組長，來協助更多其他專案將系統容器化，再搬上VKS環境上部署。
越來越多應用搬上容器環境後，不同專案在軟體架構上開始遇到類似的問題，不是原有應用程式開發團隊容易解決的問題，陳鴻嘉表示，這就需要專職的維運團隊，所以，今年第三季，在臺灣成立了SRE團隊，打造了共用的工具和維運管理作法，減少各團隊的部署容器化應用的時間，也加快開發和交付服務的速度。後來，這個經驗豐富的臺灣SRE團隊，更加入總部VKS維運問題的討論中。
不過，目前Line臺灣有20個專案部署在VKS上，包括了Line購物、Line音樂、Line旅遊、Line熱點、Line Today、Line訊息查證服務等，超過130個App設定檔，使用了50多個叢集。應用服務搬上VKS之後，陳鴻嘉表示，傳統應用程式的部署時間需要花上1小時，現在縮短到15分鐘，若是雲端原生應用，原本要6分鐘部署時間，現在可以縮短到只要20秒。不過，陳鴻嘉表示，各專案團隊仍使用自己專用的叢集，Line總部也沒有好的解法，未來希望能找出共用K8s平臺的作法，才不會浪費資源。 
#Windows容器 #OpenShift紅帽OpenShift開始支援Windows容器了
最近紅帽宣布，自家K8s管理平臺OpenShift，也可以開始執行和管理Windows容器了，成了另一個可以通吃Linux容器和Windows容器的管理平臺，可以用來執行.NET Core應用或.NET Framework的應用。為了啟用Windows容器，OpenShift還需要透過一個由微軟和紅帽共同維護的配置維運器WMCO，才能在OpenShift控制臺內管理Windows容器，使用者也可以在混合雲或跨多朵公有雲環境上，使用OpenShift來執行Windows容器，包括AWS、Azure、GCP、IBM Cloud等，未來也會支援VMware vSphre，不過，紅帽還未公布確切的支援時間。
#AWS #容器軟體 #本地部署AWS將ECS和EKS兩大雲端容器服務打包成軟體，要搶攻企業內部機房
在今年AWS年度大會上，最搶眼的重量級產品發表就是ECS Anywhere和EKS Anywhere。這兩項都是軟體產品，前者是將雲端AWS容器代管服務ECS的能力，延伸到企業內部機房，可在斷線時自行運作，可以讓企業用單一的雲端ECS管理介面，來管理各種可執行標準Docker映像檔的ECS容器任務環境，包括了Windows、Mac、Linux環境，甚至支援樹莓派OS。
而第二項產品EKS Anywhere則更像是一款K8s管理平臺軟體，是將AWS雲端EKS服務，整套打包成一個商業軟體版本，可以直部署到企業內部機房中運作，完全不需要連線到AWS也能獨立運作。EKS Anywhere就像是紅帽的OpenShift或是Google的GKE on-prem一樣，可以部署在企業內部機房，是一個可用來建置自家K8s叢集的軟體。AWS還釋出了EKS Anywhere所用的K8s版本EKS Distro程式碼，這是一個K8s上游版本，任何AWS自己的修正，也會貢獻到開源K8s社群中。另外AWS還發布了EKS add-ons外掛功能及可串接第三方工具的整合型儀表板功能。
#Nomad #大規模部署22分鐘能調度200萬個容器，容器調度工具HashiCorp Nomad正式釋出1.0
HashiCorp旗下打著替代K8s為號召的容器調度平臺Nomad正式推出了1.0版，在企業版現在能夠動態調整應用程式的大小，該功能可監控Nomad工作，並且追蹤資源使用，分析歷史資料提供建議，將應用程式調整至可高效率使用資源的狀態。該功能讓企業能以智慧且無中斷的方法，大規模最佳化應用程式資源使用，不需要使用者人工介入反覆試錯。官方實測，22分鐘就可以跨10個AWS地區，在6,000臺主機上調度200萬個容器，相當於每秒要部署1,500個容器的速度。另外也有提供開源版本，能支援命名空間，讓工作與相關物件可以彼此分割，或是與其他用戶分割，以實現多租戶叢集的概念，這是原本只有企業版才有的功能。Nomad目前最大可擴充的節點數超過了10,000個節點。
#微服務管理 #無伺服器應用AWS發表企業架構管理新服務Proton，可以通管容器應用和無伺服器應用
AWS日前發表了一個瞄準微服務管理需求的企業架構管理新服務Proton，能夠自動化管理無伺服器和容器應用程式，以簡化基礎設施配置以及程式碼部署的工作，進而簡化微服務的管理工作，基礎設施團隊可以定義標準模板，讓其他開發者使用模板部署應用程式，基礎設施團隊只要透過管理模板，就能對執行應用程式的基礎設施，進行更新或是維護等操作。
#紅帽 #CentOS不會推任何新版，紅帽決定棄守不再維護CentOS Linux
常被視為免費版RHEL的CentOS Linux，將結束官方支援和維護。紅帽宣布，要將把對CentOS的投資從CentOS Linux完全轉移到CentOS Stream，預計於明年12月31日終止對CentOS Linux 8的支援。根據紅帽及CentOS的規畫，對CentOS Linux 8的支援應該要到2029年的5月才截止，不過紅帽顯然提早結束了CentOS Linux 8的生命周期，而且宣稱不會再有CentOS Linux 9。
#K8s改版 #Docker年終最後一更Kubernetes釋出1.20大更新，但棄用Docker引擎惹爭論
這次發布的K8s 1.20版，是今年版本中，新功能最多的一版。包括進入穩定階段的磁碟區快照操作（Volume Snapshot Operations）以及程序ID（PID）限制功能，而進入Beta階段的功能，則有Kubectl Debug與API優先與公平性（API Priority and Fairness，APF）功能等。Kubernetes的目標，就是要在分散式應用程式，以及底層叢集中間，建立一個抽象層，讓應用程式可以簡單地在各種叢集上運作。而磁碟區快照操作便是達成此一目標的其中一項功能，讓用戶可以在任何Kubernetes環境，不須顧慮底層儲存，就能夠以可移植的方式操作磁碟區備份。
另外一項引起話題討論的就是，在1.20版中，宣布未來將棄用Docker引擎，目前最快要等到2021年下半年的1.23版才會實施，也可能在更晚的版本。K8s官方還特別設立了一個棄用FAQ來澄清，是因為Docker引擎沒有支援OCI標準，才決定棄用。但是，開發者慣用的Docker映像檔格式則已經是業界標準，也會繼續支援、可用，對開發者來說，完全不受影響，但對於維運或管理者而言，得改用其他符合OCI標準的執行環境，例如containerd或CRI-O。
責任編輯：王宏仁
更多新聞
Docker Desktop 3.0.0開始支援漸增更新
GitHub.com上所有Git操作將要求權杖身份驗證
紅帽推出IT自動化工具Ansible Builder以加速執行環境創建
Amazon EMR現可部署到EKS上，提高資源使用以及執行效率
 
",https://www.ithome.com.tw/news/141870,"新聞,容器周報,Line,K8s,VKS,Docker,AWS,EKS,ECS,IT周報"
141433,3,2020-12-03,AWS執行長Andy Jessy提出8大轉型重塑關鍵，還發表更多落地軟硬體產品，連Outposts都新推1U主機,面對疫情帶來的衝擊，AWS執行長Andy Jessy分享如何建立一個具速度和持續創新的文化，來隨時因應周遭環境的變化，歸納出企業轉型的8項組織改造建議。AWS今年也加碼推出更多可部署到企業機房的落地軟硬體產品，EKS Anywhere或更小尺寸的1U伺服器版Outposts等," AWS年度大會re:Invent本周於線上展開，受疫情影響，本次不僅是AWS首度於線上舉辦年度大會，也是AWS第一次將為期一周的活動，展延為三周，總計有超過500場次的議程，目前已有逾40萬人註冊，且預計一周後，將有超過50萬人參與。
「企業需要一直不斷重新塑造自己。」AWS執行長Andy Jessy在主題演講中道。因為疫情，許多企業在今年面臨了前所未有的衝擊，而必須做出改變，改變業務模式、辦公方法等。今年整場主題演講，Andy Jessy都圍繞著轉型重塑（reinvent）這個概念，這也是活動名稱的由來，他不斷強調在這個時刻，企業轉型重塑的重要性。
大會主題演講一開場，Andy Jessy先聚焦於描述公司過去幾年來業務規模的發展。AWS年營收運行率已達460億美元，同比成長達29%。Andy Jessy表示，AWS花了10年才發展成為100億美元的規模，接著，花了23個月增加到200億美元，再花了14個月達到300億美元，12個月後，就增加到400億美元，他強調，AWS的成長率在持續加速，「很大程度是受基礎設施中雲端運算成長的推動。」
Andy Jessy認為，樹立重塑文化，並傾聽客戶的要求，是AWS能成功的兩大關鍵，並提出了8大建立轉型重塑文化的關鍵要素。第一，具有領導創造和重塑的意志。作為一位引領重塑的領導者，必須具狂熱、不間斷、堅持的特質，來了解最真實的現況，包含了解客戶對產品的看法。
第二，認知無法與引力抗衡。退一步時，當發現某些事情將會改變，因為對客戶來說，事物的新樣貌會帶來更好的體驗，這時，須意識無論如何，事情都會發生改變，需採取因應措施，而非與知抗衡。第三，有可望創新的人才。新人才通常更願意打掉重練，因為，既有人才可能不願打掉自己建立起的東西。
下一點，解決客戶真正的問題。確認團隊正在為客戶解決問題，而不是因為喜歡這項技術，所以決定投入發展相關產品。Andy Jessy強調，要確保稀缺的工程師資源，正在處理對客戶真正重要的問題。第五，速度。速度的快慢是一種選擇，須做出選擇，建立一個具緊迫感並想嘗試的文化。Andy Jessy指出，因為非輕按開關鍵就可突然加速。
第六點，不要過於複雜。在進行重大變革的同時，管理技術上，可找合作夥伴，以獲得發展的動力。第七，使用具最多功能和廣泛工具的平臺。這也是避免複雜的方式之一，讓開發者能夠從平臺上，建立他們可想像的任何東西。最後一點，將上述要素都結合在一起，訂定從總體到細節的目標。Andy Jessy強調，避免只做嘗試，須建立機制來檢查是否有循進度前進。    
在今年大會上，AWS也重新改造多款服務，甚至推出更多落地的軟硬體產品，像是容器相關服務。目前AWS提供了3種服務：容器服務Amazon ECS、K8s服務Amazon EKS和無伺服器容器服務AWS Fargate。
Andy Jessy表示，企業正在大量使用3者服務，並依工作需求選擇適合的工具，然而，他指出，企業仍有需在本地端執行的容器，並希望使用與雲端相同的管理和部署機制。因此，他宣布將推出Amazon ECS Anywhere和Amazon EKS Anywhere，來滿足企業的本地端需求，讓企業能夠在自己的資料中心中，執行Amazon ECS和Amazon EKS。
企業將能在自己的資料中心執行Amazon ECS和Amazon EKS
通過Amazon ECS Anywhere，企業可於本地資料中心中，使用與AWS中基於雲端、全託管和高可擴展的相同容器調度服務Amazon ECS。Amazon ECS Anywhere將提供適用於所有基於容器應用程式的工具和ECS原生API，以及與Amazon ECS相同的叢集管理、工作負載調度和監控的經驗。藉由Amazon ECS Anywhere，企業不需要在本地執行、更新或維護自己的容器調度器，可更容易地將容器遷移至雲端，並管理混合雲環境。
另一個Amazon EKS Anywhere將以軟體形式推出，可讓企業在自己的資料中心使用Amazon EKS執行K8s，且新服務可在任何基礎架構上執行，包含了裸機、VMware vSphere和VM，還提供經優化的K8s管理工具，可透過作業系統、容器儲存庫、日誌記錄、監控、網路和儲存的預設配置，來簡化叢集安裝。

圖片來源：AWS
此外，Amazon EKS Anywhere使用與Amazon EKS部署相同的K8s發行版本Amazon EKS Distro，供企業建立符合Amazon EKS最佳實踐（如軟體更新、安全修補等）的叢集，並且，整合了安裝和執行K8s叢集所需的供應商支援協議和工具。Amazon ECS Anywhere與Amazon EKS Anywhere都將於2021年上半年推出。
AWS在大會上宣布了Amazon ECS和Amazon EKS將可執行於企業本地端資料中心的消息，回顧去年，與此同時，AWS則宣布正式開賣伺服器硬體AWS Outposts，供企業能在本地自家資料中心部署一套AWS原生基礎架構，來執行他們的工作負載。AWS Outposts推出一年至今，已有上千個企業在使用，像是飛利浦、豐田汽車等。
AWS Outposts新增1U和2U伺服器款，可部署到空間有限的落地環境
然而，AWS Outposts實體機櫃高達203公分，且以42U機櫃為最小單位運送，這樣的大小和容量讓許多有興趣採用的企業卻步，無法用於受空間限制的工廠、醫院、零售商店等。因此，Andy Jessy於大會上也宣布了兩個小型號的AWS Outposts，分別是採用Graviton2處理器的1U型號（約4.45公分高），提供多達64vCPU、128GiB記憶體和4TB本地NVMe存儲，另外，採用英特爾處理器的2U型號（8.89公分高），提供多達128vCPU、512GiB記憶體和8TB的本地NVMe儲存，可支援加速器，如AWS Inferentia或GPU。

圖片來源：AWS

Andy Jessy表示，1U型號的大小就相當於一個披薩盒子，僅只有既有Outposts的四十分之一大。且相比42U機架的舊型號，兩個新小型號Outposts所需的電力和網路連接性，明顯減少。企業可在有空間、電力或網路限制的地方，還有不需要大運算容量的情況下，依需求選用1U或2U型號。Andy Jessy舉例，醫院、餐廳、零售商店、工廠等，都可以將AWS部署至該邊緣節點。以零售商店為例，用戶可執行銷售或安全系統以實現低延遲，並連線使用AWS地區中的資料湖和機器學習模型來匯總庫存資料，以分析顧客行為。
通過小尺寸的Outposts，企業能在本地使用如Amazon EC2、Amazon ECS、Amazon EKS和Amazon VPC，而AWS會遠端通過企業用戶的網路，連接Outposts管理基礎設施。小型號的AWS Ouptost將在2021年推出。
Andy Jessy今日也再次闡述AWS對混合雲所下的定義，他表示，混合雲基礎架構並不是雲端和本地端資料中心的結合，而是，雲端與本地端可執行運算的各種邊緣節點，包含了資料中心、商店、餐廳等。AWS觀察到企業希望AWS服務能散布在各邊緣節點，並具有與AWS地區相同的API、控制中心、工具，而Andy Jessy表示，「這正是我們認為混合概念正在發展的方向，也是我們正在努力實現的混合體驗。」
主題演講的最後，Andy Jessy強調，企業需認識到周遭的變化，才能重塑自身、重塑提供之客戶體驗，而對於還未展開重塑工程的企業，他提到，如有意且專注，創新和重塑是非常可行的工程。文⊙黃郁芸
",https://www.ithome.com.tw/news/141433,"新聞,AWS,容器,本地端,資料中心,K8s,Outposts,API,重塑"
141337,3,2020-11-27,Container周報第133期：Line臺灣首度公開K8s搭GitOps部署經驗，CNCF調查K8s自建率年年提高,Line臺灣統計到2020年10月為止，已有超過20個專案導入K8s，包括Line Today、Line購物、Line音樂、Line Spot等，部署了超過50個K8s叢集，130多個App配置。," 10/24~11/24 精選容器新聞
#K8s部署率 #雲端原生大調查CNCF雲端大調查：3成企業自建K8s叢集環境
CNCF組織最近公布了2020年雲端原生趨勢大調查結果，在正式環境使用容器技術的比例增加到了92%，比2016年時高了3倍。正式環境使用K8s的採用率，也從去年的78%，增加到今年的83%。持續整合持續部署CI/CD也成了主流，高達82%填答者在正式環境中建置了CI/CD流程來加快部署效率。需要用到服務網格技術（Service mesh）的企業也增加了，達到27%，比去年多了快5成。這次全球大調查的時間是2020年5、6月，調查樣本數達1,324份，填答者過半數來自軟體科技公司，近1成是金融業。另有近3成是超過5,000人規模的大企業。填答者來自全球，歐洲38.1%、北美33.5%，更有22.6%填答者來自亞洲。
根據今年調查，今年採用私有雲的比例反而提高了，從去年的45%，今年增加到52%，而混合雲(公私雲並用者)的比例則從去年的38%，今年些微下滑到36%。CNCF認為，關鍵是Kubernetes和用來跨雲調度工作量的雲端原生工具的蓬勃發展，降低了企業將工作量跨不同公雲環境的調度門檻，不少企業轉而採用多雲策略，今年有26%企業選擇多雲策略。
K8s最常見的執行環境是在本機端虛擬機器中執行K8s的Minikube（38%），不過今年自建K8s叢集環境的企業增加了不少，自建比例從去年的23%，今年增加到31%。打包K8s應用的方式超過6成填答者採用Helm格式，只有約1成用K8s託管服務業者所提供的自訂格式。最常見的CI/CD工具前三名依序是Jenkins（53%）、GitLab（36%）和GitHub Actions（20%）。最多人導入的服務網格工具前三名則依序是Istio、Linkerd和Consul。
#Line臺灣 #K8s導入經驗 #GitOps20個專案K8s實戰經驗，Line臺灣用GitOps強化K8s部署帶來3大好處
最近Line臺灣SRE團隊一位軟體工程師Tsai Chih Chiang在自家開發者日活動上，揭露了Line臺灣2年來K8s導入成果。Line臺灣統計到2020年10月為止，已有超過20個專案導入K8s，包括Line Today、Line購物、Line音樂、Line Spot等，部署了超過50個K8s叢集，130多個App配置。Line導入K8s是為了管理大量雲端原生應用，透過微服務、容器和DevOps來建立現代化基礎架構，提供擴充性、可移動性和加快開發者上工的環境準備。Line臺灣在2018年展開K8s導入，採取「單一叢集部署全部」的策略，不過，針對不同上線階段的環境，分別在開發、準備前臺（Staging）和正式環境各自有自己的一套K8s叢集。K8s調度工具則是使用Rancher，利用Namespaces來隔離不同專案的K8s應用。不過，為了採用K8s，Tsai Chih Chiang指出，主要有6項挑戰，包括了欠缺K8s使用思維、K8s知識不足、配套開發者工具、配置檔管理、叢集操作太自由、缺乏最佳實務。
後來，Line臺灣決定建立GitOps流程，讓開發團隊更容易運用K8s環境，從容器化、建立基礎配置檔（Base Config）、不同環境的配置準備到動態同步叢集變動都整合到同一套自動化流程中。
K8s搭配GitOps的作法可以帶來三個好處，第一是可以建立單一程式碼來源，利用Git儲存庫來儲存各種環境的配置檔，來簡化YAML檔案的管理。第二項好處是開發者友善度高，能讓開發者用他們已經熟悉的Git流程，來管理K8s叢集，而Git歷史就成了K8s物件或叢集狀態的變更日誌los記錄。最後一個好處是，可以將直接操作K8s叢集的行為最小化，一來叢集狀態變更管理更安全、手動操作K8s物件的需求也可以降到最少、所有變動也能經過程式碼審查過程，而叢集即時狀態自動與各種變更行為的結果同步。Line臺灣使用了ArgoCD這套持續派送工具，也搭配Kustomize來管理K8s配置檔，還建立了一套標準化的K8s應用共同預設，例如預設建立觀察控制器、Ingress控制器等方便快速套用。

#雲端資安 #K8s資安第一份CNCF雲端原生資安白皮書出爐
最近CNCF資安工作小組公布了雲端原生資安白皮書1.0，可以適用於所有雲端原生應用上的一套資安建議，另外也特別考慮到金融、醫療產業、政府機關和非營利機構的產業資安考量。雖然K8s用途大多直接用於部署階段，但這份白皮書涵蓋了雲端原生應用生命周期的四個階段，從開發、發布、部署到執行階段（runtime），在每個階段提供了可以適用的K8s資安控制項建議。例如在開發階段的資安控制項，可以用映像檔簽章驗證，搭配映像檔弱點掃描機制。而在發布階段，則可建立不必要特權權限的預先部署檢查，啟用日記追蹤和觀察機制等。另外，白皮書也提供了一個導入雲端原生資安的7字口訣RUNTIME路徑，先閱讀相關資料（Read）、了解自己環境中得挑戰和限制（Understand）、記錄如何將控制項套用到自己的環境（Note），向同事說明自己的觀察（Talk）、帶動其他人參與（Involve）、依據現有資安控制項建立風險檔案（Make）、投入資源和時間到適當刀口項目（Expend）。
#服務網格 #多叢集部署Istio年終最後一次改版，聚焦多叢集網格安裝流程的簡化
Istio團隊依循2020年的發展路線圖，釋出了今年最後一個版本1.8，這個版本目標在提高可用性、安全性和可靠性，特別是在多叢集網格以及虛擬機器工作負載上。1.8版中，官方編寫了新的安裝指南，其中包含跨多叢集安裝叢集的方法，幫助用戶根據安裝的環境選擇配置。另外，新版也簡化了安裝過程，現在可以使用istioctl進行安裝，新的智慧DNS代理功能，讓用戶可以從虛擬機器解析網格服務，而不需要把網格服務以不安全的方式，指向叢集DNS伺服器，這也減少了叢集DNS流量，並降低解析服務IP需要查詢的次數。
#服務網格 #ConsulHashiCorp釋出新版Consul，新增視覺化工具要簡化服務網格管理
HashiCorp最近釋出服務網格工具Consul 1.9新版，可以更容易將宣告式政策套用到不同的跨微服務上，來簡化要部署複雜微服務的門檻。新版也提供了一個視覺化工具，可以更容易以一拓樸地圖的方式來存取各種服務的請求、錯誤率等資訊。其他新功能還有新增安裝到紅帽OpenShift平臺，來整合K8s健康狀態檢查，確保問題流量不會影響到更多Pod。這次改版也減少了Consul伺服器使用串流功能時，在CPU和網路頻寬的要求。
#etcd #CNCF分散式鍵值儲存etcd專案跨入成熟發展，CNCF改列為頂級專案
紅帽在2018年捐給CNCF的分散式鍵值儲存專案etcd，現在已經從孵化器階段畢業，進入頂級專案。CNCF官方說明，etcd有穩定的治理流程，功能已達一定成熟度，年中第三方安全審核，沒有發現etcd核心元件存在重大問題。CNCF技術長Chris Aniszczyk提到，etcd現在是Kubernetes內部的1個重要元件，許多專案都相依於etcd，以儲存分散式資料，因為etcd的規模不斷擴大，在安全審核上表現良好，因此委員會決定讓etcd從孵化器畢業。
#K0s #精簡版部署一行指令就能安裝，更輕量化的Kubernetes精簡版k0s來了
雲端運算服務供應商Mirantis推出了輕量Kubernetes發布版k0s，該版本強調簡單性與強健性，無論是本地端部署，甚至是大規模Kubernetes叢集等，k0s可滿足各種工作負載的需求，官方表示，只要複製k0s可執行檔到每個主機並且開始執行，就能簡單創建Kubernetes叢集。k0s是由Mirantis之前維護開源Pharos Kubernetes發行版的團隊所創建，k0s延續Pharos Kubernetes發行版的精神，要支援各種規模和情境的使用案例。k0s是一款百分百上游香草Kubernetes發行版，適用於各種規模的工作負載，並且安裝簡單，只要一行指令就能完成k0s安裝。
#K8s開發工具 #LensMirantis連連強化K8s產品線，自家K8s開發平臺開始支援第三方套件
去年併購Docker Enterprise的雲端運算服務供應商Mirantis，更新其Kubernetes整合開發環境（IDE）Lens平臺，並釋出了擴充套件API，讓第三方有辦法開發Lens擴充套件，在開發環境增加更多樣的功能，而Lens生態系成員，也都開始支援新的擴充套件API。Lens是Mirantis在今年8月，才剛收購的開源Kubernetes IDE，下載次數超過百萬次。新增加的擴充套件API，提供創建Lens內擴充套件的方法，讓第三方可將各種Kubernetes元件和工具集，整合到Lens介面中，可將Lens從Kubernetes IDE，轉變成為功能完整的雲端原生開發IDE。

#服務網格 #樹莓派叢集 #ARM知名服務網格工具Linkerd釋2.9新版，支援自動mTLS和ARM平臺，連樹莓派叢集都能跑
服務網格專案Linkerd最近釋出了最新2.9更新版本，可以對所有TCP連接支援交互TLS（mutual TLS，mTLS），官方提到，自動mTLS是朝向零信任安全的一大步，透過在Pod邊界執行加密和身份驗證，Linkerd能以零信任的形式，提供加密傳輸。並且新版也增加對ARM平臺的支援，無論開發者是使用基於ARM的機器，像是AWS Graviton，或是在樹莓派叢集上執行Linkerd，Linkerd都能提供良好的支援。另外也增加多核心代理Runtime，進而提高單個Pod的吞吐量。
#映像檔拉取 #Docker映像檔拉取新政策再轉彎，Docker宣布開源專案可以免除次數限制
Docker之前宣布了兩項新政策，第一項是刪除免費帳戶中，超過6個月無人取用的映像檔，官方提到，在Docker Hub上15 PB映像檔，有高達10 PB的映像檔，在6個月內未被取用過，而其中又有4.5 PB無效映像檔來自免費帳戶，不過，Docker已經在日前宣布，暫緩新的映像檔留存政策直到2021年。第二項已經從11月2日開始逐步實施的政策，是限制免費帳戶拉取容器映像檔的次數，匿名的免費帳戶每6小時只能拉取映像檔100次，經過驗證身份的帳戶，則拉取請求限制放寬至每6小時200個拉取請求。不過，為了支援開源社群，Docker提供了開源專案一項計畫，可以讓開源專案繼續自由存取Docker的服務，不受新政策對使用者的限制，任何提出申請並經核准的開源軟體命名空間，沒有資料取用限制。
#AWS #公共容器儲存庫大搶Docker Hub用戶，AWS宣布自己推公共容器儲存庫服務
由於Docker從11月起將限制免費帳號的映像檔拉取次數，針對這群用戶，AWS也在11月時宣布，將推出公共容器儲存庫（container registry）服務Amazon Elastic Container Registry。AWS指出，Docker新政策可能對使用Docker Hub公共映像檔的應用及工具產生節流錯誤（throttling error），像是從主映像檔（parent image）建立應用，或下載公共映像檔執行時，而且也已有許多同為AWS的用戶表達疑慮。未來幾個星期AWS將推出一個公共容器儲存庫服務，供開發人員儲存、管理、及部署容器映像檔，並開放他人下載使用。開發人員可以AWS同時代管私有和公共容器映像檔，減少不同網站和儲存庫的管理麻煩。這些映像檔可依地理區複製以方便各地快速下載。這個儲存庫也允許提供相關檔案，如helm圖表及政策組態等。此外AWS也將推出一個新網站供任何人搜尋及下載公共映像檔用於其自有App中，不論他們有沒有AWS帳號。

責任編輯／王宏仁 
更多Container相關動態
Kinvolk推出K8s UI開源專案Headlamp
K8s自動擴展器KEDA推出2.0，全面升級應用程式擴展能力
",https://www.ithome.com.tw/news/141337,"新聞,Container周報,CNCF,K8s,Line,GitOps,Linderd,服務網格,Docker,AWS,IT周報"
141308,3,2020-11-26,Istio 1.8簡化服務網格操作以提升用戶體驗,在Istio 1.8中，用戶能以更明確的方式在多叢集中安裝Istio，而且安裝過程也會更簡單," Istio團隊依循2020年的發展路線圖，釋出了今年最後一個版本1.8，這個版本目標在提高可用性、安全性和可靠性，特別是在多叢集網格以及虛擬機器工作負載上。
官方提到，重視可靠性的團隊，可能會執行多個Kubernetes叢集，但是要在多叢集間建立服務網格，需要大量繁瑣的設定工作，而且用戶也可能難以抉擇實作的方式。在Istio 1.8中，官方編寫了新的安裝指南，其中包含跨多叢集安裝叢集的方法，幫助用戶根據安裝的環境選擇配置。
同時，Istio 1.8也簡化了安裝過程，現在可以使用istioctl進行安裝，新的智慧DNS代理功能，讓用戶可以從虛擬機器解析網格服務，而不需要把網格服務以不安全的方式，指向叢集DNS伺服器，這也減少了叢集DNS流量，並降低解析服務IP需要查詢的次數。
在安全性方面，現在憑證會從Istiod發送到閘道，而非像過去直接從Kubernetes讀取，這減少暴露閘道特權的機會，進而強化縱深防禦的安全態勢，此外，這種做法的好處還有提高效能，以及減少記憶體占用。Istio 1.8現在還會在發生錯誤時，由istioctl提供錯誤報告，該報告會收集除錯資訊和叢集狀態，讓使用者更容易了解故障狀況。
",https://www.ithome.com.tw/news/141308,"新聞,Istio,服務網格,K8s"
141304,3,2020-11-26,GitLab 13.6可自動部署程式碼至AWS EC2,Auto DevOps現在支援AWS，可以將用戶的程式碼自動部署到AWS EC2中," GitLab推出了最新13.6版本，這個版本提高自動化的能力，藉以改進系統的易用性，並且提升安全性可見度，使得開發者更容易做出決策，VS Code擴充套件也獲得改進，開發者能方便地在VS Code中插入程式碼片段，另外，GitLab也處理了Docker Hub限制拉取請求的問題。
從GitLab 13.6開始，Auto DevOps支援部署到AWS的功能，即便用戶不使用Kubernetes，也可以部署到AWS EC2運算服務。開發者要啟動該工作流程，必須要先開啟Auto DevOps功能，並且定義AWS類型環境變數，利用AWS CloudFormation API來配置基礎設施，接著開發者就可以把之前建置的構件，存放到AWS S3儲存桶，並將內容部署到AWS EC2執行個體，而這個部署到AWS EC2的過程，不用其他手動步驟，GitLab就會建立一個完整的自動交付工作管線，在此後便可自動將程式碼部署到EC2中。
在創建Git儲存庫方面，官方也在最新版本做了小調整。在預設情況，第一個創建的分支會被命名為master，但在社群和Git服務供應商的協調下，GitLab提供開發者更改儲存庫中預設分支名稱的選項，使得預設分支的命名更具描述性。之前，用戶僅能在執行個體層級中，才能自定義初始分支名稱，而從GitLab 13.6開始，允許群組管理員，在GitLab介面創建的新儲存庫，就能配置其預設分支名稱。
官方還更新了專案安全性儀表板，這個儀表板能以專案層級，顯示相關的安全性資訊，包括單位時間內的漏洞數量，或是以過濾器篩選歷史資料，以進行其他分析。現在專案安全性儀表板提供工作管線狀態，當預設的工作管線出現錯誤，則儀表板便會出現錯誤通知，並引導開發者前往工作管線頁面，解決相關的問題。

而專案安全性儀表還加入了漏洞趨勢圖表，官方提到，雖然過去在群組安全性儀表板，以及執行個體安全性儀表板，都有提供視覺化漏洞趨勢圖，但是在專案安全性儀表板沒有，而導致用戶難以快速地從專案層級，掌握漏洞數量和類型的趨勢，現在新的漏洞趨勢圖，可以提供更多的可見性，而且其提供互動性功能，開發者可以打開或是關閉趨勢線，僅顯示需要的資料。
在VS Code擴充套件的更新上，開發者現在可以直接在VS Code，插入GitLab程式碼片段。GitLab的專案程式碼片段功能，可讓用戶在團隊中，方便地共享程式碼，這些程式碼通常是可以在相似的頁面，或是元件中重複使用的片段，過去要在專案中，使用這些共享的程式碼片段，需要複雜地在不同的編輯器切換並複製貼上，而最新的VS Code擴充套件GitLab Workflow v3.5.0，讓用戶可以直接在VS Code中搜尋，並且插入程式碼到工作文件中，而且還能一次插入來自多個檔案的程式碼片段。
之前Docker宣布從11月開始，要限制免費用戶呼叫Docker Hub的次數，而這項變動也影響了GitLab使用者，官方提到，用戶可以使用鏡像註冊表，以減少Docker Hub拉取請求的數量，而對於GitLab SaaS的用戶，GitLab現在使用Google的Docker Hub映像檔鏡像，因此GitLab.com Shared Runner用戶的CI工作，不會受到Docker新政策的影響。
",https://www.ithome.com.tw/news/141304,"新聞,GitLab,AWS,DevOps"
141302,3,2020-11-26,K8s分散式儲存etcd成為CNCF頂級專案,各方面都已證明etcd為一個成熟專案，CNCF決定讓etcd從孵化器畢業，進入頂級專案," 紅帽（Red Hat）在2018年捐給雲端原生運算基金會（CNCF）的儲存專案etcd，現在已經從孵化器階段畢業，進入頂級專案，官方提到，這表示etcd專案採用率持續增加，也有穩定的治理流程，功能已達一定成熟度。
etcd最初由CoreOS所開發，目的是要提供叢集持久且輕量的分散式鍵值儲存，可靠地存放叢集組態資料，從網頁應用程式到Kubernetes，都可以從etcd讀寫資料。etcd現在是Kubernetes內部的1個重要元件，許多專案都相依於etcd，以儲存分散式資料，CNCF技術長Chris Aniszczyk提到，因為etcd的規模不斷擴大，在安全審核上表現良好，因此委員會決定讓etcd從孵化器畢業。
etcd維護團隊由10名成員組成，包括阿里巴巴、Amazon、Cockroach Labs、Google Cloud、IBM、Indeed和紅帽，從etcd在2018年進入孵化器以來，加入了3個維護者，並在過去1年中，有超過200個不同的貢獻者編寫了拉取請求。
CNCF在今年7月的時候，贊助了etcd專案進行第三方安全審核，審核報告顯示，並沒有發現etcd核心元件存在重大問題，倒是在etcd閘道器發現了1個高嚴重性的漏洞，維護團隊目前已經修復該漏洞，並且往前部署到所有支援的版本中。etcd還曾在今年1月接受資安公司Jepsen，針對分散式系統的測試，結果也顯示etcd已經成熟，而維護團隊也接受Jepsen的建議，進行了部分改進。
etcd已經被許多知名公司用於生產環境，包括Amazon、思科、EMC、Google、IBM、Uber、Verizon和紅帽等企業。
",https://www.ithome.com.tw/news/141302,"新聞,K8s,CNCF,etcd"
141191,3,2020-11-19,Kinvolk推出K8s UI開源專案Headlamp,Headlamp提供友善的UI，供Kubernetes使用者控制叢集，Headlamp是一項獨立專案，適用於各種經認證的Kubernetes版本," 雲端原生基礎設施供應商Kinvolk打造了圖形介面，讓Kubernetes使用者不需要使用命令列工具或是配置檔案，就可以方便地管理Kubernetes部署，該專案被命名為Headlamp，完全開源且獨立於所有供應商，Headlamp提供互動式使用者介面，可以進行讀寫操作，而非僅是唯讀的儀表板。
Headlamp是一個通用可擴展的Kubernetes使用者介面，官方希望Headlamp盡可能支援各種不同的使用者，因此無論是剛入門的用戶，或是經驗豐富的專家，以及有著特殊需求的使用者，都能夠使用Headlamp滿足需求，官方提到，由於Kubernetes使用案例太多元，因此下游用戶通常需要自定義UI專案，而Headlamp提供樹外擴充套件系統，來解決這個問題，Headlamp的後端可以載入Javascript檔案，並傳遞給客戶端以動態載入這些擴充套件。
擴充套件系統為Headlamp提供了極大的靈活度，可讓用戶創建各種新功能，官方舉例，用戶可以透過擴充套件系統，在Pod細節檢頁面中添加按鈕，提供Pod運作成本資訊。

而官方開發好用的追蹤小工具Inspektor，來展示擴充套件系統的功能，開發者可將Inspektor小工具安裝在叢集中，在啟用Traceloop小工具後，該工具便會快取Pod所有的系統呼叫，因此用戶就能夠在Pod還在執行的同時，查看Pod的狀態，也能在Pod終止時，查看系統呼叫紀錄，供用戶簡單地調查崩潰紀錄。
Headlamp可根據用戶的權限，變更顯示的介面，官方提到，許多Kubernetes讀寫使用者介面，並無法良好整合底層存取控制，因此部分介面上的按鈕，提供用戶實際上不具備的功能，像是當用戶沒有修改資源的權限，但是介面卻出現創建和刪除按鈕，則可能讓用戶產生誤解。而Headlamp會檢查Kubernetes RBAC配置，僅顯示可執行操作的擴充元件，以提供更好的用戶體驗。
官方提到，大部分Kubernetes UI可分為託管後端，以及本機桌面應用程式兩種類型，而兩種類型各有優缺點。託管應用程式可以透過單一URL，讓用戶在各處存取使用者介面，並且簡單地同步叢集版本，而桌面應用程式無需託管UI應用程式，具備隔離性，但是應用程式更新的負擔落到了用戶身上。Headlamp提供兩種方法，用戶可以透過使用YAML檔案，將UI託管在叢集中，也能在Linux、Mac和Windows上安裝應用程式。
Headlamp是一項獨立於所有Kubernetes發布版本的專案，Kinvolk表示，他們有推出自有的Kubernetes發行版Lokomotive，而Lokomotive的確是使用Headlamp作為其網頁使用者介面，但因為Headlamp為獨立專案的關係，因此Headlamp支援任何經認證的Kubernetes，不僅只有Lokomotive。
",https://www.ithome.com.tw/news/141191,"新聞,Kinvolk,K8s,UI"
141182,3,2020-11-18,Mirantis推出Kubernetes精簡版k0s,k0s擁有輕量核心，不相依於特定主機作業系統版本，簡單易用可滿足各種規模工作負載，包括本機、雲端部署，甚至是邊緣應用," 雲端運算服務供應商Mirantis推出了輕量Kubernetes發布版k0s，該版本強調簡單性與強健性，無論是本地端部署，甚至是大規模Kubernetes叢集等，k0s可滿足各種工作負載的需求，官方表示，只要複製k0s可執行檔到每個主機並且開始執行，就能簡單創建Kubernetes叢集。
Kubernetes常被縮寫成K8s，而Rancher Labs在去年，推出了輕量級Kubernetes專案K3s，專為低資源和低互動系統設計，大小只有40ＭB，目前已經成為雲端原生基金會（CNCF）沙盒專案，而現在知名Kubernetes整合開發環境Lens開發商Mirantis，創建了一個數字更小的Kubernetes發行版本k0s。
k0s是由Mirantis之前維護開源Pharos Kubernetes發行版的團隊所創建，k0s延續Pharos Kubernetes發行版的精神，要支援各種規模和情境的使用案例。k0s是一款百分百上游香草Kubernetes發行版，適用於各種規模的工作負載，並且安裝簡單，只要一行指令就能完成k0s安裝。
官方解釋，之所以k0s中使用零這個數字，代表著幾個意義。k0s最重要的是零摩擦的特性，官方經精心設計，盡可能降低k0s安裝和執行Kubernetes的複雜性，在數分鐘內，就能夠創建新的Kubernetes叢集，沒有Kubernetes經驗或是專業知識的用戶，也能簡單開始使用，而且結合Lens與k0s，用戶就能夠使用視覺化功能，並以直覺的圖形介面控制Kubernetes叢集。
而且k0s是以單個二元檔案形式發布，其中除了作業系統核心之外，沒有包含任何作業系統相依性，不需要使用特定主機作業系統版本，或是安裝其他套件，任何漏洞和效能問題，都可直接在k0s發布版本中修復。k0s還帶有自動叢集生命周期管理功能，可在維持應用程式持續運作的同時，升級叢集到更新的k0s版本。
k0s共同創始人Jussi Nummelin提到，他們想為Kubernetes各種使用案例，提供強大且通用的基礎層，除了保有上游Kubernetes的特性之外，也擁有足夠靈活性，可支援典型雲端部署，以及各種邊緣和物聯網應用，他們不想維護各種作業系統發行版，只想發布單個二進位檔案，將精力專注在處理核心問題上。
",https://www.ithome.com.tw/news/141182,"新聞,Mirantis,K8s,容器,k0s"
141132,3,2020-11-16,Mirantis推擴充套件API，供第三方在Lens IDE新增更多K8s功能,Mirantis現在釋出Lens IDE擴充套件API，供第三方開發Lens擴充套件，將更多Kubernetes功能整合進開發環境," 在去年併購Docker Enterprise的雲端運算服務供應商Mirantis，更新其Kubernetes整合開發環境（IDE）Lens平臺，並釋出了擴充套件API，讓第三方有辦法開發Lens擴充套件，在開發環境增加更多樣的功能，而Lens生態系成員，也都開始支援新的擴充套件API。
Lens是一個熱門的Kubernetes雲端原生IDE，下載量超過一百萬，其提供熱門開發工具，讓開發人員可以利用集中式介面，來管理Kubernetes叢集元件。 Lens是Mirantis在今年8月，才剛收購的開源Kubernetes IDE，Lens最初是由芬蘭新創公司Kontena開發，之後由Lakend Labs擁有，而Lakend Labs在今年3月，將Lens以MIT授權在GitHub上開源。 
只要使用Lens，用戶就能夠配置Kubernetes叢集，並且監控叢集狀態，在出現問題時進行故障排除，Lens提供開發、測試和DevOps人員單一窗口，以快速大規模交付程式碼，Adobe和Apple等多家知名企業，都是Lens的使用者。
而現在Mirantis更新Lens加入了擴充套件API，提供創建Lens內擴充套件的方法，讓第三方可將各種Kubernetes元件和工具集，整合到Lens介面中。
該API以REACT.js為基礎，使擴充套件可以透過Lens使用者介面提供功能，並使用Lens的功能管理存取權限，擴充套件API可讓第三方自定義功能和視覺化效果，以支援熱門的雲端原生技術或是開發流程，而且使用API，除了能開發擴充套件插入至Lens IDE執行外，同時也可整合來自Helm圖表儲存庫的服務，提供豐富視覺化效果。
Lens開源專案創辦人Miska Kaipiainen表示，Lens透過擴充套件API與技術供應商合作，以獲得更好的功能與技術整合，可將Lens從Kubernetes IDE，轉變成為功能完整的雲端原生開發IDE。
目前已經有數個Kubernetes工具供應商，開始提供Lens擴充套件，包括Kubernetes安全解決方案Aqua、Carbonetes，以及API閘道廠商Ambassador Labs，另外，知名API閘道廠商Kong和容器安全平臺StackRox，也正在以該API開發擴充套件。
",https://www.ithome.com.tw/news/141132,"新聞,Mirantis,K8s,IDE"
141086,4,2020-11-13,服務網格Linkerd 2.9新增支援交互TLS以及ARM平臺,Linkerd 2.9開始對所有TCP連接支援交互TLS，因此Linkerd安裝在叢集後，就可以加密和認證叢集中所有TCP連接," 雲端原生運算基金會CNCF底下的服務網格專案Linkerd，釋出了最新2.9更新版本，這個版本對所有TCP連接支援交互TLS（mutual TLS，mTLS），並且增加對ARM平臺的支援，以及增加多核心代理Runtime，進而提高單個Pod的吞吐量。
Linkerd 2.9可以在不需要使用者配置的情況下，自動加密和驗證網格端點之間所有的TCP連接，包括自動輪轉Pod憑證，或是自動將TLS身份綁定到K8s的ServiceAccount中，官方提到，自動mTLS是朝向零信任安全的一大步，透過在Pod邊界執行加密和身份驗證，Linkerd能以零信任的形式，提供加密傳輸。
官方提到，與諸如Istio等其他服務網格相比，Linkerd因為採用以Rust開發的微型代理，因此執行速度超快，且使用極低的記憶體容量，而這是採用單核心Runtime實現的，但單核心提供的功能有限，因此從Linkerd 2.9開始，官方升級Linkerd代理採用多核心Runtime，以提高單個Pod的吞吐量，和並行處理能力。
Linkerd 2.9還加入對ARM的支援，因此現在無論開發者是使用基於ARM的機器，像是AWS Graviton，或是在樹莓派叢集上執行Linkerd，Linkerd都能提供良好的支援。另外，Linkerd 2.9也開始支援K8s的服務拓樸功能，以限制請求留在特定節點中，或是將請求限制在特定地區，這項功能可以有效提升大型應用程式的效能。
",https://www.ithome.com.tw/news/141086,"新聞,服務網格,Linkerd,K8s"
140778,4,2020-10-28,GitLab 13.5加入行動應用程式安全掃描功能,GitLab 13.5的靜態應用程式安全測試也支援行動應用程式，iOS與Android行動應用都能利用SAST進行掃描," 在最新的GitLab 13.5，社群以協作的方式，在GitLab中增加應用程式安全掃描功能，強化iOS與Android行動應用的安全性，另外，這個版本著重在團隊協作上，官方加入了群組Wiki協作功能，還讓團隊可以方便地共享，由多檔案組成的程式碼片段，而官方也提供更多的模板，供團隊專案應用最佳實踐，以及增加一致性。
GitLab SAST（Static Application Security Testing）從這個版本開始支援行動應用程式，透過整合行動安全框架MobSF，包括使用Objective-C和Swift編寫的iOS應用程式，還有用程式語言Java和Kotlin所開發的Android應用程式，現在都可以利用SAST進行掃描，官方提到，這個分析器最初僅支援原始碼分析，但在不久之後，GitLab將擴展功能，提供.ipa和.apk檔案的二進位掃描支援。
這個版本官方還強化了Wiki協作功能，官方提到，對許多團隊來說，使用GitLab Wiki安排計畫和撰寫文件，是工作流程中重要的一部分，但因為過去Wiki僅支援到專案層級，擁有多專案的團隊，需要對每個儲存庫創建獨立的Wiki，因此產生了破碎的使用體驗。
從GitLab 13.5開始提供的群組Wiki，提高了資訊的可存取度，並且讓更多人能夠存取這些Wiki資訊，開發團隊現在可以在群組Wiki中放入範例，甚至是特定於團隊的資訊，或是程式碼撰寫風格。官方提到，這個功能是GitLab代辦事項中，最多使用者要求的功能，但因為要提供群組Wiki有許多困難需要克服，因此經過了一年開發，才在現在釋出該功能。
開發團隊有許多機會需要共享程式碼、可重用元件、日誌或是專案的其他部分，官方現在允許單個程式碼片段加入多個檔案，因此開發者現在可以創建由多個來源組成的程式碼片段，官方提到，這開啟了更多的使用情境，像是程式碼片段現在可以包含腳本以及輸出，也能包含HTML、CSS和JavaScript程式碼，也能含有docker-compose.yml與相關的.env檔案。
在模板方面，GitLab提供開發者AWS EC2和CI/CD模板，幫助開發者入門。在AWS EC2模板中，開發者可以利用AWS CloudFormation API來配置基礎設施，並將程式先推送到AWS S3儲存桶中，再部署到AWS EC2執行個體，而新的GitLab CI/CD模板，可以讓開發者不需任何手動操作，就能設定Terraform工作管線，降低團隊採用Terraform的障礙。
GitLab加入Generic Package Registry支援更多的檔案格式。GitLab已經在Package Registry中支援廣泛的程式語言，但是開發者可能仍需要儲存不支援的二進位格式，因此GitLab現在讓開發者可以將原始套件檔案，添加到Generic Package Registry中，而這將可讓開發者更輕鬆地在GitLab打包和發布軟體。
",https://www.ithome.com.tw/news/140778,"新聞,GitLab,SAST,DevOps"
140765,4,2020-10-26,Container周報第132期：OpenShift 4.6新版推出法遵控制機制，更方便套用不同法遵框架,10/11~10/23 精選容器新聞," 10/11~10/23 精選容器新聞
#K8s #OpenShiftOpenShift 4.6新版釋出更容易跨雲部署的裸機API，還新增法遵控制機制
最近紅帽接露了OpenShift 4.6新版的特色，最重要的更新是4.3版開始測試的裸機API功能，將在4.6版中成為正式功能，這個API可以讓雲端供應商更容易提供裸機部署OpenShift叢集的能力，這也意味著你在自家裸機部署的配置，也可以快速套用到其他公有雲的裸機環境中。
另外，也會推出一個新的遠端Worker節點功能，可以將管理節點放在一個集中式的機房，或是一個在遠端機房建立一個管理各地所有Worker節點的管理節點。管理節點和遠端管理的Worker節點，必須位於同一個網路路由架構中。一旦網路斷線，本地端的Worker節點會繼續執行原有的工作量，等到網路連線恢復後，再重新自動與管理節點連線。為了減少重新連線後的運作衝突，新版也提供了一些判斷選項可供參考。紅帽指出，這個功能不只電信業，零售、運輸業都可以用來建立遠地據點的在地執行環境。新版也新增了OVN開放虛擬網路的外掛機制，現在終於可以將OVN網路設定為叢集預設網路架構了。
4.6版還有一樣重要功能是增加了法遵控制機制（compliance operator），可以將特定法遵框架或資安框架的技術控制要求，變成OpenShift的自動化稽核機制，類似RHEL的法遵控制機制一樣。啟用這個法遵控制機制後，可以針對不同叢集選擇套用預先規畫的法遵框架配置，也可以掃描叢集配置，來產生法遵控制項落實情況的報告。不過，目前預先提供的法遵控制項內容，先以RHEL CoreOS相關的技術控制項為主，後續每隔6到8周會釋出控制項的更新，下一版更新將增加網路資安框架CIS Benchmarks的控制項。
#Ansible #CICD #K8s紅帽將Ansible自動化工具整合到跨雲K8s管理平臺
紅帽宣布將DevOps自動化平臺Ansible整合到進階K8s叢集管理平臺（Advanced Cluster Management for Kubernetes，簡稱ACMK），以實現混合雲環境的管理自動化。
紅帽在2015年收購的Ansible是一個免代理的自動化部署工具，但也有可用於多層部署環境的Ansible Tower，也推出了自動化服務目錄以及自動化分析工具和儀表板。原本Ansibl已經可以支援OpenShift的部署配置。今年7月，紅帽推出了ACMK，可用於混合雲環境管理與擴充OpenShift容器叢集，現在也進一步整合Ansible自動化平臺。
紅帽解釋，企業仍有大量老舊應用，每個都有不同管理工具和流程，形成零散、不相連的工作流程。這兩套產品的整合即在解決這個問題。ACMK中的OpenShift Kubernetes Operator，可以負責管理整個OpenShift環境上的應用和服務。當需要應用層或傳統IT工作流程時，就扮演OpenShift叢集控制臺角色，來驅動Ansible的工作流程管理能力，至於Kubernetes叢集以外的任務，則由進階叢集管理的Resource Operator呼叫Ansible來管理，完成像是部署系統更新、設定負載平衡、擴充伺服器等等。這樣一來只需要單一工作流程來管理混合雲。未來幾周會先釋出預覽版。新版也正式支援Helm 3.3版，在開發者目錄中可以支援不同Helm版本的儲存庫。另外，4.6版的支援周期也將增加到18個月
#K8s採用率 #中國企業調查CNCF中國調查：K8s企業用戶高達72%用於正式環境
最近CNCF基金會釋出了日前在中國進行的K8s用戶2019大調查，上次調查是在2018年底。使用K8s的作答中國企業，高達72%已經在正式環境中使用，相較於2018年調查時，只有40%企業在正式環境中使用，2年來增加了快一倍。正在評估者也還有17%。多數中國企業部署的K8s叢集數量在2到5個之間，但也有超過1成中國企業的K8s叢集數量超過了50個。Helm也已經是中國最主要的K8s應用程式打包方法，過半數有54%企業採用。在部署環境上，目前有4成企業部署在私有雲，混合雲也有約4成。除了K8s之外，過半數企業也在正式環境中部署了Pometheus。另外有4成企業開始在正式環境中使用Istio來管理服務網格環境，其次2成企業Consul來管理。
另外，2018年調查時，中國企業主要在測試環境使用容器，但現在最大宗的容器使用環境已經是正式環境，將近49%企業在正式環境中使用容器技術。對中國企業而言，導入容器主要困難仍舊是複雜性，超過5成企業有同樣的困難，其次是資安和訓練不足。

＃跨雲K8s管理 #電信商美國電信商Verizon也搶進K8s管理工具市場，推出跨雲整合式K8s管理服務
最近美國電信商Verizon旗下商務部門也推出了K8s管理服務，要來搶進K8s管理工具市場，可以讓企業簡化在邊緣環境的K8s管理。例如可以整合到現有VNS（虛擬網路服務），快速讓IT團隊部署邊緣應用程式，而不用處理太多網路環境的配置細節。Verizon商務部雲端技術策略主管Beth Cohen指出，COVID-19許多企業需要擴大主機雲端服務的能力，帶動了K8s叢集的部署需求，尤其是跨地理區域的K8s叢集管理越來越複雜，因此也帶動了雲端管理工具的需求。這些新增的應用程式都會帶動企業對5G網路更大頻寬的需求，因此，連電信業者現在都要開始卡位K8s管理服務市場。
#邊緣運算 #Akri搶攻邊緣應用需求，微軟新Akri專案可將K8s擴展至邊緣裝置
微軟開發全新的Kubernetes開源專案Akri，可以將內建感測器、控制器，並搭載單晶片的邊緣裝置，轉換成Kubernetes叢集中的資源，其提供類似容器網路介面（Container Network Interface，CNI）的抽象層，使得Kubernetes應用程式能夠簡單地使用，諸如攝影機和感測器等邊緣裝置。Akri擴展Kubernetes裝置擴充套件框架，這原本是用在像是GPU或是其他系統硬體等靜態資源，而Akri將這個框架應用到了邊緣，Akri能夠持續偵測有權存取邊緣裝置的節點，並且調度其工作負載，簡單來說就是，Akri能夠自動找到並且使用這些裝置。
Akri設計為可擴展的架構，目前其支援ONVIF和udev探索協定，而在開源社群中，開發者可以在Akri添加更多的協定支援。用戶可以在K3、MicroK8和AKS-HCI等各種經認證的Kubernetes發行版上使用Akri。

#基礎架構現代化 #OpenStackOpenStack未來10年要往哪裡走？基金會CEO揭露4個新趨勢
OpenStack基金會執行長Jonathan Bryce最近在大中華區媒體活動中，揭露了該基金會下一個10年開源基礎設施技術發展新方向。他指出將有4個新趨勢，首先是IT基礎設施將採用更多的開源元件，用於系統構建、測試以及功能整合；其次是運算，儲存和網路硬體架構將走向多樣化。第三個趨勢是，資料中心部署將涵蓋微型架構到超大規模部署，不只雲端，也包含邊緣端IoT設備，基礎設施本身架構靈活彈性將是大考驗。最後一項趨勢是得符合各國政府對於個人資料使用權以及數據隱私的要求。為了要打造可以支撐往後10年發展的下一代開源基礎設施平臺，OpenStack基金會也更名為開源基礎設施基金會（Open Infrastructure Foundation，OIF）。並發起了一項新專案OpenInfra Labs試驗專案，用來連結不同開源社群的開源專案，並在生產環境中來進行統整、優化，來對應到不同工作負載的型態，目前有多家學術、研究機構都參與其中。
責任編輯／王宏仁 
更多Container相關動態
Puppet推出適用於混合基礎設施的安全法遵新工具
",https://www.ithome.com.tw/news/140765,"新聞,容器周報,K8s,OpenShift,OpenStack,紅帽,Ansible,Akri,IT周報"
140199,4,2020-09-26,GitLab 13.4強化安全性，提供K8s代理以及全新安全中心,用戶可以在Kubernetes叢集執行最新的Kubernetes代理，如此便不需要將叢集暴露在網際網路中，就能從GitLab擷取程式碼進行更新," GitLab用戶現在已經可以下載使用最新的13.4版本，在這個版本中，官方強化了安全功能，與HashiCorp Vault進行更好地整合，讓用戶以金庫儲存CI變數，並且還加入Kubernetes代理，提供部署到Kubernetes叢集更安全的方法，同時還重新打造了安全中心，另外，新版本改善全域搜尋列功能，使用者現在可以利用搜尋列，快速存取專案或是問題。
GitLab在過去已經整合Kubernetes，能夠自動將程式部署到Kubernetes叢集上，但缺點是，該叢集必須要暴露在網際網路上，如此GitLab才能夠存取該叢集，並把程式碼推送到叢集上，但將叢集暴露在網際網路上，對於許多企業來說，需要負擔過大的風險，因此考量安全性和法遵等因素，除非用戶使用自定義的工具，否則將無法方便地使用GitLab和Kubernetes的整合功能。
而在最新的GitLab 13.4，官方加入了GitLab Kubernetes代理，其提供使用者一個全新將程式部署到Kubernetes叢集的方法，Kubernetes代理會在使用者的叢集中執行，叢集不需要在網際網路中公開，該代理會自動從GitLab擷取更新來協調部署，而非從GitLab主動推送更新到叢集中。官方提到，這個代理是第一個版本，目前僅提供基礎功能，部分與Kubernetes整合的功能尚未提供。
在GitLab 12.10時，加入了GitLab Runner功能，讓用戶能夠提取並且注入機密到CI工作中，官方現在改進這項功能，在.gitlab-ci.yml文件提供更多新的機密語法，擴充JWT Vault身份驗證方法，讓用戶能夠輕鬆地在GitLab上配置和使用HashiCorp Vault，並在Vault中儲存CI變數。
新版還有一個重要的安全性功能，便是安全中心，不過這項功能目前僅Gold/Ultimate等級用戶可以使用。官方提到，他們對安全的可見性和管理做了根本性的更改，執行個體儀表板現在改成安全中心，而最大的變化就是加入了新的選單結構，將原本單一頁面，拆分為安全儀表板、漏洞報告和配置3個頁面。
專用的漏洞報告頁面，除了具備現有的專案漏洞列表之外，更增加了許多空間顯示重要資訊，而漏洞指標小工具，也就能夠集中成為真正的安全儀表板，而配置頁面，則專門提供執行個體安全配置。
在用戶使用體驗上，官方改進了全域搜尋列功能，官方提到，用戶在GitLab導覽的時候，可能想要跳到特定專案的頁面，而現在能夠在全域搜尋列輸入字串，快速找到相關的問題、群組、專案和設定等。
",https://www.ithome.com.tw/news/140199,"新聞,GitLab,DevOps,Kubernetes"
139896,4,2020-09-09,Nutanix HCI架構採用NVMe SSD和Optane SSD儲存技術，要提升I/O密集型工作負載5成性能,Nutanix HCI架構新採用的儲存技術，可提升大型資料庫、大規模醫療應用程式等工作負載5成的性能。此外，Flow新增了安全監控介面Security Central，可提供單一管理介面，讓企業IT管理人員監控Nutanix基礎設施," Nutanix於本周二（9/9）舉辦線上用戶大會.NEXT，於會中宣布HCI軟體功能的多項更新，還有推出以K8s為基礎，名為Karbon Platform Services的PaaS產品，可讓企業加速建置能在地端和雲端中執行的容器化應用程式。
Nutanix調整了HCI架構，採用基於NVMe SSD和英特爾Optane SSD的儲存技術，可為I/O密集型工作負載，像是大型資料庫、大規模醫療應用程式等，提升5成的性能。同時，VM密度也有所提升，進而降低了應用的整體擁有成本。
另外，Nutanix利用自身新開發的區塊儲存（Blockstore）技術，來提升檔案系統的儲存效率。Nutanix臺灣區資深系統工程經理鄭建華表示，檔案系統裡有許多演算法和儲存資料的方式，而新的技術改善了演算法，進而提升了儲存效率，優化檔案系統。
Nutanix HCI軟體還將支援英特爾SPDK開發套件，使Nutanix成為第一個支援SPDK的HCI產品供應商。該套件讓應用程式可直接存取NVMe容量，避免作業系統或內核層產生負擔，影響了工作負載的性能。鄭建華表示，軟體增加英特爾NVMe和SPDK的支援，皆是為優化驅動程式。
而SDN產品Flow中，此次Nutanix新增了安全監控介面Security Central。Security Central是一個SaaS產品，提供單一管理介面，讓企業IT管理人員可藉此全面掌握，由Nutanix驅動的私有雲和公有雲環境的安全狀況，包含監控網路、檢查合規性等，並會根據企業部署的Nutanix環境的安全狀況，提供改善建議報告。
Nutanix推出K8s平臺即服務，提供託管服務建置容器化應用程式
Nutanix從幾年前開始支援Kubernetes，於2019年4月正式推出企業級Kubernetes版本Karbon，到了今年2月，推出Karbon 2.0版，可整合在Nutanix AOS平臺的Prism Central管理介面。如今，Nutanix在大會上，再推出Karbon Platform Services（KPS），這是一個以K8s為基礎的PaaS產品。
鄭建華表示，Karbon Platform Services事實上就是Karbon的新名字，可視為同一個產品。改名後的Karbon能分離應用程式與底層基礎架構，讓軟體開發人員不需要再管理底層基礎架構，並提供軟體開發人員建置在地端和雲端中執行的容器化應用程式，所需的託管服務，包含K8s-aaS、CaaS、無伺服器運算、AI、Service Mesh等，簡化應用程式的開發和調度工程，快速建置容器化應用程式。
過去，Karbon所使用的容器網路元件為Flannel，而KPS現新增支援Calico，讓企業在建立K8s叢集時，有兩個選項。鄭建華提到，Nutanix已把兩個元件整合進映像檔，所以企業不需安裝作業系統，直接使用KPS提供的映像檔，即可建立K8s叢集，並選擇適合的元件。本次Nutanix於大會上發布的新產品，現在皆已開放使用。文⊙黃郁芸
",https://www.ithome.com.tw/news/139896,"新聞,超融合,K8s,NVMe,區塊儲存技術,安全監控介面,Karbon,PaaS"
139805,4,2020-09-04,Gitlab調降免費用戶CI/CD時數,"從10月1日開始，免費用戶的CI/CD可用時數，從每月2,000分鐘降為400分鐘"," Gitlab在自家部落格寫道，因為提供現行免費用戶產生的CI/CD成本太高，所以他們決定從10月1日開始，縮減免費用戶CI/CD的時間配額，從原本2,000分鐘減少至400分鐘。用戶可以選擇額外儲值時數，或是付費成為更高級用戶，以取得更多CI/CD資源。
官方提到，他們希望各種規模的團隊，都能夠實作DevOps，因此對免費用戶開放許多功能，使更低的訂閱等級，可以獲得相對高的平臺價值，並使更多用戶能夠存取完整的DevOps功能。但是隨著Gitlab的業務發展，使得流量大幅提高，在已註冊的3,000萬會員中，有600萬是免費會員，這些免費會員對CI/CD的用量，增加大量Gitlab營運成本。
官方評估了免費用戶在CI/CD的使用狀況，98.5％的免費用戶每月CI/CD時間為400分鐘以下，因此他們決定，從2020年10月1日開始，將GitLab.com免費層級用戶的CI/CD限制，從每個頂級群組每月2,000分鐘降為400分鐘。官方提到，透過減少每月使用時數，除了使功能與層級價格更加一致之外，也能確保Gitlab能永續提供免費用戶服務。
銅級的CI/CD時數為2,000分鐘，銀級為10,000分鐘，而黃金級為50,000分鐘，官方也釋出CI/CD時數儲值服務，當免費用戶的400分鐘配額用完，可以選擇以10美元的價格，購買1,000分鐘的CI/CD時數，或是直接付費升級成為訂閱用戶。用戶可以用CI/CD時數，運作各種專案需要的執行器程式，系統僅計算GitLab.com上執行器程式的運作時數。
而對於開源、教育和新創計畫的用戶，Gitlab提供金級功能，因此每個群組每月有50,000分鐘的CI/CD時數可用。
",https://www.ithome.com.tw/news/139805,"新聞,GitLab,DevOps,CI/CD"
139671,4,2020-08-28,GitLab 13.3開始提供模糊測試，可發現Go和C/C++應用程式臭蟲,GitLab近期併購Peach Tech和Fuzzit兩間模糊測試公司，現在於GitLab最新版本添加併購而來的技術，方便用戶在開發流程導入模糊測試," 程式碼託管平臺GitLab釋出最新13.3版本，這個版本的最大亮點在於使開發者能夠在開發工作流程中，更簡單地對軟體進行安全性測試，不只導入覆蓋率指引模糊測試（Coverage-Guided Fuzz Testing），還讓用戶按需執行動態應用程式安全性測試 （Dynamic Application Security Testing，DAST），另外，在GitLab 13.3中，用戶也能更全面監控Kubernetes Pod的狀態，儀表板現在會呈現所有Pod原始健康狀態。
GitLab 13.3是第一個導入模糊測試的版本，用戶可以開始對Go和C/C++應用程式執行模糊測試，官方提到，模糊測試能夠發現其他安全掃描程式，或是傳統QA遺漏的安全性問題和臭蟲，因為模糊測試使用應用程式相關的上下文資訊，隨機產生輸入，藉此嘗試觸發程式崩潰或是錯誤，讓問題真正影響用戶之前，可以先被發現並修復。
模糊測試新功能來自於GitLab近期收購的兩間模糊測試公司Peach Tech和Fuzzit，而模糊測試的主要方法有兩種，分別是覆蓋率指引模糊測試，另一種則是行為模糊測試，GitLab 13.3加入的是覆蓋率指引模糊測試，是利用應用程式的原始碼和測試版本，在程式執行過程或是動態地執行新測試，以觀察應用程式各部分的表現，藉此找出臭蟲。
官方提到，過去模糊測試不只困難也很難獲得有效的結果，但GitLab將Peach Tech和Fuzzit模糊測試技術，加入到現有的GitLab工作流程，可讓用戶方便地對Go和C/C++應用程式執行測試，儘早發現漏洞。
在這個版本，所有用戶都可以免費使用靜態應用程式安全性測試（Static Application Security Testing，SAST）功能，同時，ULTIMATE/GOLD等級的使用者，現在可以按需執行DAST安全性測試。GitLab的DAST整合到了DevOps工作管線中，在特定步驟便會觸發掃描，但官方提到，在沒有程式碼變更或是創建合併請求的情況下，有時候用戶也有對已部署應用程式執行DAST掃描的需求，因此現在不需要由程式碼更改等事件觸發，用戶就能夠按需進行掃描，這版本GitLab UI提供掃描配置選項，在掃描時不會對程式效能或是安全性造成影響。
而在GitLab 13.3中，用戶可以在Pod執行狀況指標儀表板中，簡單地查看Kubernetes Pod的狀態，官方提到，無論用戶使用託管的Prometheus執行個體，或是在自有的叢集中執行Prometheus執行個體，只要連接到了GitLab，就能從內建儀表板查看CPU、記憶體和網路等重要指標。
",https://www.ithome.com.tw/news/139671,"新聞,GitLab,模糊測試,DevOps"
139660,4,2020-08-28,Container周報第129期：K8s終於釋出今年第二次更新，Ingress和安全運算模式雙雙進入正式版,原本K8s一年會釋出四次改版，平均每季一次，但是今年受到疫情影響，開發團隊希望參與開發的貢獻者，可以花更多的時間在日常生活，因此延後了發布時程，這次改版距離上一個版本，足足隔了20周，也因此這次改版的幅度很大。," 8/1~8/28 精選容器新聞
#版本更新 #K8s #IgressK8s終於釋出今年第二次更新，Ingress和安全運算模式雙雙進入正式版
K8s官方網站最近宣布終於釋出今年第二次的K8s新版本1.19版。最大特色是用來控管對外連線流量的Ingress機制，終於發布了正式版，而安全運算模式seccomp也同樣成為正式版功能。預計這次改版，一口氣有34項更新，包括10項功能進入穩定階段，15項Beta版和9項新增加的Alpha版功能，例如新增加的Node除錯機制。
原本K8s一年會釋出四次改版，平均每季一次，但是今年受到疫情影響，開發團隊希望參與開發的貢獻者，可以花更多的時間在日常生活，因此延後了發布時程，這次改版距離上一個版本，足足隔了20周，也因此這次改版的幅度很大。
其中第一個重所關心的功能是Ingress成為穩定正式功能。這是一個用來控管K8s叢集對外存取的API，可以用來控制外部對內部微服務的存取路徑和權限，包括來自外部的HTTP或HTTPS加密連線的路由控制，等於這是一個負載平衡機制，可以用來管理K8s叢集內所有節點或應用，對外的網路流量，也是分散調度來自外部存取請求的關鍵API，早在2年前的1.11版就登場，但直到現在終於穩定了，這次也有一點小幅強化，增加了Ingress網路API，可以用來設計存取範本或驗證存取的變動。
K8s安全運算模式seccomp也進入正式版，這是一個利Linux核心來提供的資安機制，可以用來限制一個容器應用所能執行的系統呼叫數量，因此可以做到限制容器應用能力的效果。1.19版中，seccomp也增加了一個功能，可以分別針對單一個Pod叢集或容器，來設定資安政策的seccompProfil檔案，來提高資安控管的精細度。
另外，去年K8s官方找來第三方進行專案稽核，其中有一項件事就是要支援TLS 1.3加密連線，現在也在1.19版中支援了，可以用於Orchestrator調度時改採加密連線的呼叫。另外有一個重要的新功能是Node除錯機制，目前這個功能仍就是Alpha版。Node除錯機制可以在原有主機環境的命名空間中，立即建立和執行一個新的Pod，以便用來除錯找問題。換句話說，一個正在執行中得Pod節點不用關機重開，就能新增一個處在同樣命名空間有同樣存取權限的Pod來除錯。另外，值得注意的是，1.19版也列出了一些老舊不推薦的API功能，這也意味著後續版本將逐漸停止對這些功能的維護。
#CNCF #K3S Rancher捐出超輕量級K8s發布版K3S，正式成為CNCF沙盒專案
去年2月登場的輕量級K8s坂本K3S，最近開發者Rancher決定將K3S捐給CNCF基金會，目前處於沙盒階段，這表示CNCF已取得所有權，但專案還需經過一段時間調整，才能釋出成為推廣孵化的對象。K3S是一個專門用來執行1個節點的輕量級K8s版本，大幅移除了複雜的多節點調度和管理元件，來簡化K8s部署的檔案大小，目的是能夠在運算能力較弱的邊緣運算裝置或筆電中建立一個K8s環境。K3S安裝檔的檔案只有40MB，但已經可以提供內建儲存後端，包括支援Etcd3、MySQL和Postgres資料庫。
#Fargate #容器長期儲存AWS容器無伺服器容器服務Fargate新增檔案儲存功能EFS，可用於長期和有態儲存
最近AWS宣布自家無伺服器容器Fargate服務，增加了新的檔案儲存功能EFS（Elastic File System），可以用來儲存長期使用的資料，不會隨著所用Fargate關閉，就儲存的資料就同步消失，也可用於有態應用，將資料傳遞給下一個應用程式來接手。目前這個功能可以支援到1.17版K8s版，未來幾周才會支援到更新的K8s版本。
#軟體開發 #VS2019 Visual Studio 2019版開始支援Kubernetes本地端連線開發
最近微軟在官方開發部落格上，發布了VS 2019版 16.7版的一項新功能，可以在本地端主機上，針對一項.NET微服務進行開發修改、測試除錯，但又同步連線到遠端的K8s叢集上的其餘所有應用或服務，等於可以將一套微服務其中一項服務拉到本地端來進行程式碼開發和測試，但又同時可以成為遠端叢集中的其他微服務互動，不用像過去得把這個.NET微服務，部署到叢集中執行才能進行測試。
#Docker #映像檔匿名無人用的檔案爆量，Docker決定限制免費帳號的映像檔拉取次數
由於Docker平臺上，超過6個月無人存取的映像檔容量高達10 PB，幾乎占了在Docker Hub上的15 PB映像檔中的三分之二，其中更有4.5 PB來自免費帳號。這些映像檔僅被短暫的使用過，包括了來自結合Docker Hub持續整合工作管線的映像檔，使用者通常會遺忘過程產生的映像檔。因此，Docker官方決定開始實施新的政策，將移除免費帳戶中，長時間無人使用的映像檔之外，而且為了解決匿名帳戶映像檔拉取過於浮濫的問題，也將限制免費使用者拉取映像檔的次數。新的映像檔留存政策將會從11月1日開始實行，系統僅會刪除免費帳戶託管的映像檔，付費帳戶、由官方驗證的發布者以及官方發布的映像檔則不在此限。匿名的免費用戶每6小時拉取次數限制為100次，而經驗證的免費用戶，每6小時的拉取次數限制則為200次，付費使用者則不在此限。

#銀行容器實例 #微服務 #行動銀行兆豐銀新一代行動銀行和網銀全面改用微服務架構和容器
最近，兆豐銀揭露，早在2018年春天，開發新一代行動銀行與網銀時，就積極採用了微服務架構與容器技術來打造。花了一年多時間，兆豐銀去年底上線新一代行動銀行，而與網銀則在今年4月上線。兆豐銀行資訊管理中心副總經理陳國寶提到：「採用容器技術最根本的原因是，讓銀行的反應快，面對爆量需求時，用容器作法，才能橫向擴充。」不過，也不是全部業務都適合用容器技術，他表示，假設無爆發性成長的業務，則不需用到。
#容器安全 #GKE新版GKE資料平面支援eBPF技術，增加容器可見性與安全性
Google釋出最新使用eBPF（extended BPF）虛擬機器技術，和開源網路安全軟體套件Cilium的資料平面GKE Dataplane v2，現在GKE除了支援即時政策執行之外，還能在最低的效能影響下，將政策操作與Pod、命名空間和政策名稱相關聯，對政策進行故障排除，發現異常網路活動。當封包進到虛擬機器中的時候，安裝在核心的eBPF程式將會決定路由封包的方法，不像使用IPTables，eBPF程式能夠存取包含網路政策資訊的Kubernetes特殊元資料，如此eBPF程式不只能決定要允許或是拒絕封包，還可以回報帶註解的操作報告給使用者空間。
#Arm處理器 #EKSEKS現可選用AWS自行設計的Graviton2 Arm處理器
AWS宣布EKS服務也可以使用AWS自行設計的專用Graviton 2晶片來執行工作負載。Graviton 2提供256位元DRAM加密，且支援雙SIMD單元，整個提供的效能，比前一代高了7倍，而且浮點數運算效能也提高1倍，還擁有更大的記憶體通道，在人工智慧的支援上，Graviton 2支援int8和fp16精度運算，能夠大幅提升機器學習預測工作負載的計算速度。
＃服務網格 ＃Envoy微軟宣布捐出自家開發的輕量級服務網格OSM給CNCF
微軟開發了一個輕量級，且可擴充的雲端原生服務網格（Open Service Mesh，OSM），用戶可以一致且安全的方法，管理高動態的微服務環境。OSM解決方案建構在Envoy專案之上，以服務網格介面（Service Mesh Interface，SMI）實作，現在微軟要把OSM貢獻給雲端原生運算基金會（CNCF）。OSM可用來簡化各項服務網格管理工作，像是在常見的部署情境配置流量轉移，或是透過自動mTLS以保護服務間的通訊，也能對服務應用精細的存取控制政策
責任編輯／王宏仁 
更多Container相關動態
Atlassian一口氣推出12項DevOps新功能，能整合GitHub、Git等多種雲端程式碼服務庫的追蹤
Mirantis收購知名Kubernetes IDE Lens
Linux 5.8成為有史以來最大更新版本
GitLab免費使用者帳戶將無法重置多因素驗證
Google推雲端憑證頒發機構服務，支援物聯網與容器等大規模使用情境
",https://www.ithome.com.tw/news/139660,"新聞,容器周報,K8s,K3S,Docker,EKS,GKE,Ingress,IT報告"
139139,4,2020-07-31,Container周報第128期：Line改用K8s建置核心機器學習叢集，vSphere則推公測計畫長期招募新功能試用者,Line機器學習團隊決定，換掉Mesos，改用K8s來建立ML叢集，支援內部各項機器學習計算之用，並且也簡化了ML1團隊K8s運算叢集的任務，將部分長期性任務抽離到外部環境中提供，只留下核心處理和批次型運算任務，以及用來自動優化ML模型的ABTest。," 7/1~7/31 精選容器新聞
＃機器學習叢集 #資料工程 #K8sLine改用K8s取代Mesos自建ML叢集，影像辨識、推薦引擎和使用者圖像預測都靠它
去年Line在東京開發大會上，首度公開了自家資料工程平臺資料特徵服務化（FssS，Feature as a Service）的新架構，這是用來將資料去識別化變成基礎預設功能，在支援龐大資料量分析需求時又能兼顧隱私規範。去年Line揭露FaaS服務時，只透露這是一個專屬的機器學習叢集，但沒有揭露這個叢集是部署在Line私有雲Verda或是後來增加的K8s環境中。
Line原本就利用開源基礎架構軟體OpenStack，自行打造了一套私有雲平臺Verda，每年要維運部署超過2萬個VM，給內部4千個專案使用。因為許多專案規模較小，為了提高主機CPU的利用率，Line基礎架構團隊決定導入一款K8s管理平臺軟體Rancher，來建立方便自動化維運的K8s環境。
去年12月時，Line只先完成了K8s簡單叢集部署機制和維運自動化機制，能支援Line基礎運算需求的應用情境，但還是無法滿足原有Verda私有雲所能支援的各種基礎架構使用情況，也沒有將所有專案都搬上K8s環境。當時Line就預告，將逐漸擴大K8s導入範圍，並且增加更多外掛式設計，當時Line的目標是，要將常用的K8s管理功能變成一套功能化服務。
今年6月底，在一場Data Labs線上招募說明會中，Line日本Machine Learning1（簡稱ML1）團隊經理菊地悠揭露了整套資料工程平臺的基礎架構的最新進展。這個團隊的任務是要建立一套內部標準化和方便運用的機器學習運算工作流程，來強化各種Line服務的競爭力。
ML1團隊所負責的資料工程平臺中，其中一項功能是特徵服務化（FaaS）架構，這是一個用來提供標準化ML流程和服務的框架。這個框架包括了一套集中式的通用特徵服務，也就是使用者特徵相關的z特徵服務，穩搖功能用的Y特徵服務，以及抽取內容特徵的c特徵服務，主要由機器學習團隊維護。不過，要滿足Line對外各種機器學習解決方案，只有FaaS共用服務還不夠，ML1團隊自己還有負責維運了一套全公司通用的機器學習元件服務，以及針對特定服務提供的專門元件服務。另外，其他部門也會自己維護元件
ML1團隊自行管理的機器學習叢集服務則用來提供各種機器學習解決方案，包括機器學習團隊提供的解決方案，和其他部門也會有自行維護的ML專用元件，來滿足各自ML解決方案之用。換句話說，Line雖然有一套共用的私有雲，各部門在機器學習應用上，還是各自建立一套自行維護的專用服務元件，只有各部分通用的共同ML元件和服務，統一由ML1團隊來負責維護。
而ML1團隊除了部分服務使用了Verda私有雲平臺，例如提供z特徵服務的Hadoop資料湖，就是部署在內部基礎架構環境Verda私有雲上，但是ML1團隊也自己另外採用了一款容器管理平臺Mesos，來建立了一套自用的機器學習叢集，作為其他ML元件計算之用。像是常用的Spart的ETL處理，或是一些批次型運算，如影像辨識或音樂分析的DNN深度學習模型訓練、推薦引擎、使用者圖像預測都是利用這套Mesos容器叢集來運算，另外還有一些長期運算任務，例如用來優化機器學習模型用的ABTest功能、相似比對（Look A Like），MAB強化學習計算也會使用Mesos叢集。
但是，隨著Verda私有雲去年開始逐漸大力擁抱K8s，ML1團隊也決定換掉Mesos軟體，改用K8s來建立ML叢集，支援內部各項機器學習計算之用，並且也簡化了ML1團隊K8s運算叢集的任務，將部分長期性任務抽離到外部環境中提供，只留下核心處理和批次型運算任務，以及用來自動優化ML模型的ABTest。
去年Line在開發日時，Line機器學習開發主管並川淳就預告，希望能建立一個所有服務都能通用的自動推薦系統，並且將推薦結果標準化，透過ABTest來了解推薦模型修正的情況，例如採用不同ML推薦模型來提供推薦圖片後，透過ABTest機制來蒐集每一個模型的使用者點擊率評分，作為優化推建模型的參考依據。而且，他希望這樣的推薦機制發展到極致，就可以讓每一個服務，自動透過各自的推薦機制結合ABTest機制，自動優化每個服務各自所用的推建模型，這是他去年揭露的發展方向。而要實現這個目標，並川淳計畫將ML1團隊的機器學習叢集，改為K8s架構，來善用GPU資源的調度。雖然，今年6月的Data Lab說明會中，沒有進一步揭露這樣的推薦結合ABTest自動優化ML的設計，是否已經完成，但至少，Line已經先將機器學習叢集的環境，轉換到主流的K8s架構了。
#vSphere #公開測試招募VMware要找用戶來搶先試用新功能，vSphere推出持續公測計畫
VMware今年推出了史上最大改版的虛擬化平臺vSphere 7.0，將K8s內建到自家核心虛擬化產品中，這個改變將原本封閉專屬架構的vSphre，轉而變成了採用開源技術的開放架構平臺。因為K8s原本就有一套步調更快的產品改版和發布計畫，每年發布4次新版本。VMware也開始調整自家產品的發布計畫，第一個動作就是推出了持續公測計畫（Continuous Beta），只要填妥申請表單，審查通過就能加入。這個計畫將提供兩種測試版本，由VMware環境提供的託管測試版，以及可以讓測試用戶下載安裝的版本。VMware也會派出產品經理、技術支援工程師來了解Beta版的試用情況，並提供了一個內部討論區讓測試用戶交流。測試用戶也可以直接提出功能、配置或使用界面設計的建議。
＃超融合架構 ＃Azure Stack HCI微軟第二代超融合基礎架構產品瞄準混合雲管理，採核心數計價瞄準中小企業需求
微軟在今年7月合作夥伴大會Inspire上，公布了第二代超融合基礎架構解決方案AzureStack HCI（Hyperconverged Infrastructure），主打更強的混合雲管理功能。微軟於去年3月宣布Azure Stack HCI，是該公司第二個超融合架構方案（第一個是Azure Stack Hub）。Azure Stack HCI關鍵是Hyper-V及Windows Server 2019軟體定義資料中心（SDDC）、儲存空間直接存取等。新的Azure Stack HCI是一種Azure服務。它的底層不只是單純的Windows Server，而是原生整合Azure混合雲管理功能（包括備份、安全中心及Azure Monitor）。新版採每核心計價訂閱，可用來建立小型環境，像是遠端辦公室或分公司，例如訂閱8核心伺服器或16以下的VM。

#基礎架構管理 #K8sLyft釋出自家基礎架構管理流程工具，可用來管不同常用工具也能調度K8s
Lyft開源了自家內部使用的基礎設施工具Clutch，可以提供一套工作流程的管理工具，可以讓工程團隊能夠建置、執行和維護工作流程，包括特定的安全機制以及存取控制，另外，Clutch還提供了管理AWS、Envoy和Kubernetes等平臺的功能。這套平臺由兩部分構成，後端是以Go開發，採可擴充設計，可進行一般身份驗證，並且提供系統的可觀察性以及日誌紀錄稽核功能。前端則用React，提供以工作流程來設計UI操作，讓使用者不需要先具備豐富的JavaScript知識，能以更少的程式碼創建新功能，且更易於維護。Lyft預計在2020年底前，內部7個工程團隊都會採用Clutch來統一維運工作的管理。
#CICD #Puppet老牌DevOps工具Puppet更新企業版功能，強化自動化範本共享機制
DevOps愛用的老牌自動化組態管理工具Puppet前幾個版本加入了了計畫（Plans）功能，可以使用程式邏輯，來調度不同的任務與工作流程，這個功能可讓使用者以重複且可擴展的方式，跨基礎設施執行多步驟變更，最近Puppet更新了Puppet Enterprise中，更強化了這個計畫功能，甚至可以整合Puppet Forge中的共享內容，來進行複雜的調度任務和計畫，甚至是部署應用程式。官方舉例，當使用者要準備發布應用程式的基礎設施，需要執行配置負載平衡器、使用VMware配置節點，還有設定Apache伺服器等工作，使用者都能夠直接參照模組來完成這些重複性工作。
#ECS #DevOps自動化AWS容器服務ECS推出新款命令列工具Copilot，更容易建立CI/CD流程
AWS釋出新的ECS命令列工具AWS Copilot，相較於2015年釋出用於容器服務Amazon ECS的命令列工具，Copilot可以讓使用者不用手動管理低階的基礎設施，就能在ECS上部署應用程式。AWS在去年底發布這個新的ECS命令列工具的消息，現在正式更名為Copilot。使用者只需要提供Dockerfile，再加上幾個指令，Copilot就能夠在AWS上創建和啟動容器，自動以高可用性部署，並創建和配置負載平衡器，Copilot甚至可以創建CI/CD工作管線，在開發者將新的程式碼提交推送到儲存庫的時候，自動重新部署應用程式新版本。Copilot還能跨地區和帳號設定測試和生產環境，而用戶也能透過命令列工具，監控系統並且進行除錯。

#Rancher #SUSE ＃併購SUSE終於揭露K8s布局併購成果，買下Rancher Labs強化大規模K8s部署能力
早在去年底，SUSE工程產品創新總裁Thomas Di Giacomo就預告將會透過併購來強化自家K8s產品的布局，在今年7月終於揭露了併購成果。SUSE買下了2014年成立成立的容器軟體商Rancher Labs，其主要的產品為Rancher，可讓使用者管理和大規模部署Kubernetes到資料中心、雲端和邊緣等各種基礎設施上，Rancher目前擁有37,000個活躍用戶，下載量超過1億。另外，Rancher Labs還開發了為Kubernetes叢集設計的Linux發行版K3OS，以及邊緣專用的Kubernetes輕量級版本K3s。Rancher Labs在併入SUSE之後，將繼續維持開放的策略，同時支援多個Kubernetes發行版和作業系統版本。Rancher採用無關基礎設施的架構，支援所有經過雲端原生運算基金會（CNCF）認證的Kubernetes發行版，包括Google GKE、Amazon EKS和微軟AKS等。Rancher Labs執行長梁勝表示，併購程序將在幾年稍晚時結束，他也會進入SUSE領導合併的工程和創新部門。
#K8s #VMwareVMware將K8s輸入控制器專案Contour捐給CNCF
CNCF雲端原生運算基金會宣布接收來自VMware的開源Kubernetes輸入（Ingress）控制器Contour，這個專案原本是一家新創Heptio所開發，Heptio後來被VMware併購，Contour也就進到了VMware旗下。Contour透過部署Envoy代理作為反向代理和負載平衡器，來控制流入Kubernetes的流量，Contour支援動態更新，並可透過限制命名空間支援多團隊的Kubernetes叢集，能夠方便地配置虛擬主機和TLS憑證，並提供進階的負載平衡政策。Contour已經被多家企業使用，如Adobe就用來作為自家多租戶Kubernetes平臺Ethos的輸入控制器。社群也已經制定了Contour明確的發展路線，計畫支援Kubernetes Service API以及跨Kubernetes叢集路由服務，另外，Contour還會擴大支援Envoy，加入速率限制、身份驗證以及存取日誌服務等功能。
#網格服務 #微服務管理網格管理平臺Kuma工具推0.6新版，可支援超複雜異質架構的網路流量調度
知名的開源API管理工具商Kong最近翻新網格管理平臺Kuma釋出0.6，同時也將這個工具捐給CNCF基金會，成為社群自主發展的孵化專案之一。0.6版特色是支援混合通用模式，讓Kuma能夠支援異構環境的複雜應用程式，能跨包括虛擬機器、Kubernetes叢集和多個資料中心，控制網路流量。現在使用者不只可以分別為Kubernetes和虛擬機器工作負載創建不同的服務網格，還能將兩者放到同一個網格中。Kuma 0.6具有自動服務連接功能，可跨企業環境與平臺自動且抽象化服務網格連接，混合通用模式可在整個企業網路中，提供開箱即用的管理功能，而且新的Ingress資料平面模式，可自動地跨平臺和叢集服務網格溝通。另外野心增加了DNS服務探索，更方便管理跨雲架構中的大量微服務。
責任編輯／王宏仁
更多Container相關動態
GitLab新版13.2強化專案工作流程迭代設計，加強支援任務追蹤工具Jira
HPE GreenLake彈性部署服務開始提供Anthos預建置伺服器
 
",https://www.ithome.com.tw/news/139139,"新聞,Line,K8s,vSphere,ECS,機器學習,IT周報"
138970,4,2020-07-23,Puppet Enterprise釋出2019.8版本，強化自動調度功能,Puppet使用者現在可以在計畫（Plans）功能中，參照Puppet Forge中的模組，自動執行一系列基礎設施配置任務," 老牌自動化組態管理工具廠商Puppet，發布最新的Puppet Enterprise版本更新2019.8，這個版本的重點在於讓DevOps團隊，能夠在Puppet控制臺中建置自動化工作流程，除了可以混用Puppet Forge儲存庫中的模組，以組成和調度工作流程之外，Puppet提供新的開箱即用作業系統修復自動化功能，取代獨立的修補程式管理工具。
Puppet在前幾個版本加入了計畫（Plans）功能，讓用戶能以程式邏輯，調度不同的任務與工作流程，這個功能可讓使用者以重複且可擴展的方式，跨基礎設施執行多步驟變更，而在最新的Puppet Enterprise中，Puppet強化了這個功能，讓使用者也能在計畫功能中，使用Puppet Forge中的共享內容。
Puppet Forge是一個開源的模組儲存庫，上面存在為數龐大的模組，用戶能夠利用這些模組自動化操作基礎設施，而現在開發者在Puppet Enterprise控制臺，可以將這些Puppet Forge的共享內容，用在調度流程中，調度複雜的任務和計畫，甚至是部署應用程式。
使用者不需要在計畫中，重寫一遍在Puppet程式碼已經有的內容，只要在既存的計畫中，進行參照就可以了，官方舉例，當使用者要準備發布應用程式的基礎設施，需要執行配置負載平衡器、使用VMware配置節點，還有設定Apache伺服器等工作，使用者都能夠直接參照模組來完成這些重複性工作。
在Puppet Enterprise 2019.8中，官方預建置用於修補作業系統的自動化內容，使用者可以查看Windows和Linux節點上可用的修補程式，在實際應用修補程式後，也能夠得知修補程式，在系統上安裝成功與否，確保系統維持在正常狀態。官方提到，這個修補功能的優點在於，無論作業系統為何，使用者都能夠查看各節點的修補狀態，並且使用同一個工具部署修復程式。
",https://www.ithome.com.tw/news/138970,"新聞,Puppet,IT,DevOps"
138425,4,2020-06-24,HPE推出軟體品牌Ezmeral，挑戰VMware Tanzu、Red Hat OpenShift,HPE Ezmeral的容器平臺，強調能在資料中心、公有雲、代管設施或邊緣等基礎架構上，大量部署及管理容器應用，而且不論是否為原生雲端應用，都可包在容器中執行，無需重新架構," HPE昨（23）日宣布軟體品牌Ezmeral，其中的Kubernetes產品則寄望挑戰VMware Tanzu及Red Hat OpenShift。
Ezmeral命名來自西語中的翡翠，借其預測未來、提升智慧及免疫力、舒緩壓力的力量之意。HPE Ezmeral這個品牌涵括多項產品，包括容器協同與管理/Kubernetes、AI/機器學習、資料分析、成本控管、IT自動化、AI驅動的營運及安全產品等。基本上是以HPE收購的MapR、Scytale等產品為核心提供的IaaS、PaaS產品，作為企業營運基礎架構及管理。
Ezmeral品牌的推出，也是HPE推動軟體訂閱制的策略計畫的一環。去年在Discover年度大會上，HPE宣布推動在2022年前完成軟體轉型為依用量計畫的訂閱制，並推出GreenLake IT-as-a-Service雲端服務。昨日HPE也宣布GreenLake新增二項服務，包括HPE Ezmeral容器平臺（Container Platform）及HPE Ezmeral ML Ops。
HPE Ezmeral容器平臺可以說是Ezmeral的底層基礎。它包含BlueData容器管理控制臺，以及MapR的分散式檔案系統作為持續性儲存體，旨在各種基礎架構（資料中心、公有雲、代管設施或邊緣）上大量部署及管理容器應用，因此不論是否為原生雲端應用皆可包在容器中執行，無需重新架構（refactoring），企業也可以從單一控制介面管理多個Kubernetes 叢集。HPE軟體部門主管Kumar Sreekani在CRN訪問中，更是放話要和VMware Tanzu及Red Hat OpenShift分庭抗禮。
HPE Ezmeral ML Ops則運用容器化技術以便把機器學習模型部署到資料中心、公有雲、混合雲及前端環境。HPE表示，Ezmeral Ops加入DevOps的作法可使機器學習工作流程標準化以減少資料孤島，又能避免資料搬移的成本，可很快從前導專案（pilot）擴充上線，使AI/ML資料科技專案部署時程，由數月縮短到幾天之內。
Ezmeral 容器平臺和ML Ops可透過GreenLake雲端套件方案訂閱。不過Ezmeral ML Ops目前為beta版，預計第4季（10到12月）正式推出。
Ezmeral軟體品牌除了Ezmeral 容器平臺、ML Ops兩項產品外，還包括雲端法遵及成本管理產品HPE Managed Cloud Controls、（來自MapR的）統合式資料平臺HPE Data Fabric、基礎架構管理HPE OneView及營運預測式分析HPE Infosight、以及收購自Scytale並開源的服務驗證技術Secure Production Identity Framework for Everyone (SPIFFE) 及 SPIFFE Runtime Environment。所有Ezmeral軟體都可透過傳統軟體授權訂閱銷售。
",https://www.ithome.com.tw/news/138425,"新聞,HPE Ezmeral,容器,Container,Kubernetes,雲端,AI,機器學習"
138333,4,2020-06-20,GitHub開源適用各種語言的Super Linter,在GitHub.com上的所有程式碼儲存庫，都可以透過GitHub Actions呼叫Super Linter，驗證拉取請求程式碼," GitHub開源原本內部使用的Super Linter，該工具可以避免把有問題的程式碼上傳到主分支中，也能幫助建立多種語言的程式碼最佳實踐，以自動化流程簡化程式碼審查，並建構程式碼布局和格式準則，讓開發者可以交付更乾淨穩定的程式碼。目前Super Linter支援Dockerfile、JavaScript、Markdown、Python3、TypeScript和Ruby等多種熱門程式語言，未來GitHub還會加入更多語言支援。
GitHub提到，要在新的儲存庫，設定適用不同類型程式碼的Linter耗時且繁瑣，開發者需要從眾多選項中，找出適用的工具和配置，而且通常需要一個以上的Linter，才能滿足多種語言的需求。Super Linter是由GitHub服務DevOps工程團隊開發，目的是要用來維持文件和程式碼的一致性，讓企業內的交流和協作更有效率。
而Super Linter其實就是一個打包成為Docker容器的原始碼儲存庫，可被GitHub Actions呼叫，而這樣便可讓在GitHub.com上的所有儲存庫，都能夠使用Super Linter，分析儲存庫中的程式碼。當開發者在儲存庫完成配置之後，在任何時候打開拉取請求，Super Linter便會開始檢查和整理程式碼，並透過Status API回傳結果。
當Super Linter更改任何程式碼或是偵測到錯誤，都會告知開發者位置以及內容，之後開發者便能回到分支修正錯誤，並重新推送拉取請求，而這時Super Linter便會再次驗證更新後的程式碼。開發者可以配置分支保護規則，確保在所有程式碼通過驗證後，才能進行合併動作。
官方表示，要在Super Linter中標準化規則並不容易，因為每個開發者編寫程式碼的方法，都是獨一無二的，因此Super Linter讓開發者可以自己配置適於儲存庫的Linter規則，不過當還沒有定義之前，官方便須提供預設標準，Ruby和Rails的規則集來自Ruby gem: rubocop-github，並遵循用於GitHub.com的規則和版本控制，而其他語言則預設選用coffeelint、yamllint、Markdownlint和pylint。開發者可以立刻開始使用Super Linter，並在需要的時候進行額外的客製化。
",https://www.ithome.com.tw/news/138333,"新聞,GitHub,Linter,DevOps"
137597,5,2020-05-13,OpenStack第21版Ussuri正式發布，自動化調度功能擴及裸機，並聚焦3大面向改版,OpenStack基金會執行長Jonathan Bryce表示，此次改版聚焦於3大面向，第一個是提升核心基礎設施的功能，其次，強化安全性和加密性功能，最後，針對新型工作負載需求，如AI、邊緣運算等，拓展支援的功能。," 受武漢肺炎（COVID-19）疫情影響，OpenStack基金會原定於6月上旬在溫哥華舉辦的上半年度峰會，被迫取消，不過，疫情未打亂該基金會發布新版OpenStack的時程。OpenStack基金會按原定計畫於今日（5/13）釋出代號為Ussuri的第21版OpenStack，並於昨日舉辦的線上記者會中，揭露新版OpenStack的更新重點。
新版OpenStack由188個組織或企業，總計超過1千名開發者共同參與開發，在歷時6個月的開發期間內，逾2.4萬個程式碼獲得修改。OpenStack基金會執行長Jonathan Bryce表示，綜觀來說，此次改版聚焦於3大面向。
首先，在提升核心基礎設施層的穩定性方面，運算服務Nova新增了單元間伺服器冷遷移和大小調整的功能。Jonathan Bryce表示，企業可以在新增伺服器和擴展雲環境時，於不同環境間遷移工作負載。其中，冷遷移功能可讓企業將工作負載從已設定為退役的硬體，搬遷到OpenStack雲環境。
而網路服務Neutron子專案Kuryr增加了對IPv6的支援，還有支援SR-IOV和DPDK，可讓Neutron更好地與現有容器網路框架整合。Kuryr是個整合OpenStack與容器網路的專案，如Jonathan Bryce說明，它是可將K8s或Docker的runtime疊加於OpenStack環境上的一種方式。
此外，裸機部署服務Ironic增加了自動化調度裸機硬體的功能，企業增加新裸機時，維運人員能更易進行管理調度。該服務還增加了認證的支援，使其不侷限於OpenStack環境中使用，其他專案藉釋出的API，可以直接用Ironic管理裸機，像是K8s社群裡的Metal³專案即利用Ironic來管理裸機。Jonathan Bryce表示，相當於K8s網路直接部署於裸機上。
新版OpenStack聚焦的第二面向則圍繞於安全性和加密性功能的強化，負載平衡服務Octavia現支援傳輸層安全協定（TLS），企業可指定被集區（pool）和接聽程式（listener）接受的TLS加密名單，讓負載平衡器強制執行安全上的合規性要求。Jonathan Bryce表示，這可確保通過負載平衡器的所有流量都受到加密和保護。
OpenStack容器化部署專案Kolla也增加了對TLS的支援，進一步來看，Kolla為後端API服務的TLS加密增加了支援，可提供API流量端到端的加密。Jonathan Bryce說明，如此，不同控制層的活動可在雲內部進行端到端加密。
Neutron服務則增加了無狀態安全群組（stateless security group）的主機群組管理模式。過去企業只能建立有狀態（stateful）安全群組，來追蹤所有流量，所以面臨大量網路活動時，網路會開始出現瓶頸和性能下降的情況，如今，可以建立一個無狀態安全群組的叢集，而這個群組不會長期追蹤流量，能讓企業開啟更多連接埠，進而提升網路的性能。
最後一個面向則是強化對新使用場景的支援，特別是針對AI和邊緣運算的應用場景，像是管理硬體加速器的專案Cyborg現與Nova整合，企業可採用Nova啟動伺服器實例，並由Cyborg管理GPU或FPGA加速器。另外，Octavia服務現可讓企業於特定的可用區域部署負載平衡器，從而把負載平衡功能帶至邊緣環境。
Jonathan Bryce表示，OpenStack與K8s的整合也是相當重要的。針對容器的支援，新版Openstack有兩個主要的專案更新，容器基礎架構管理服務Megnum除了支援K8s的升級版本外，還增加K8s叢集（包含主節點和工作節點）操作系統的升級支援。歐洲核子研究組織（CERN）即是利用Megnum管理其於不同K8s環境內執行的500個K8s叢集。
容器服務Zun則新增K8s容器Runtime介面（CRI）的支援，讓Zun成為K8s節點的後端，企業可進而利用Zun的API在Kata Containers中建立K8s節點，來提高安全性和隔離性。
除了發布OpenStack最新版本，OpenStack基金會也宣布建立一個新社群OpenInfra Labs，提供維運人員於實際生產環境中，測試開源程式碼，來為現有和新的工作負載開發完整且可複製的堆疊（stack），進而改善開源基礎設施。文⊙黃郁芸
",https://www.ithome.com.tw/news/137597,"新聞,OpenStack,開源基礎設施,K8s,容器,裸機,冷遷移,雲端,安全性,邊緣運算,人工智慧"
137280,5,2020-04-29,紅帽展開首次線上年度大會，新任執行長Paul Cormier仍混合雲老調重談，沒揭露下一步發展方向,前任紅帽掌門人、IBM新任總裁Jim Whitehurst，代表IBM於會上再次承諾，將保持紅帽自身的獨立性，來確保其於開源生態系的腳色，持續與各方合作。而此次大會少了許多未來性，紅帽也表示，有別與以往，將不聚焦於發布產品的新動向，而是專注提供疫情當前企業或IT人員所需的資源，要與大家共度難關，像是延長部分產品的生命週期。," 紅帽全球年度用戶大會今日登場。如同許多科技年會，受武漢肺炎（COVID-19）疫情影響，活動改於線上展開，紅帽也以線上的方式，記錄其正式被IBM併購後的第一場大會，這亦是邁入第16年的紅帽大會，頭一回以虛擬形式舉辦。
儘管大會改以線上方式進行，參與人數卻創新高。新任紅帽總裁暨執行長Paul Cormier表示，今年總註冊人數超過3.8萬人次，是迄今為止，規模最大的峰會。因為各界都期待從大會中，一探這位新執行長將為紅帽注入什麼新氣象，並如何帶領紅帽實現開放混合雲（Open Hybrid Cloud）的願景。
4月初甫上任的Paul Cormier，原擔任紅帽產品與技術部門執行總裁，自2001年加入紅帽以來，他推動了許多公司重大的轉型策略，包含建立訂閱制模式，還有讓Red Hat Linux從一套可免費下載的作業系統，轉變為核心產品Red Hat Enterprise Linux，以及推動主力混合雲產品OpenShift底層改採K8s的大改版工程，他更是開放混合雲願景的提倡者。
Paul Cormier簡短開場後，便邀請IBM新任總裁Jim Whitehurst，也是前任紅帽掌門人，加入談話。去年大會一開場，Jim Whitehurst也請時任IBM執行長Ginni Rometty，一同於臺上說明兩家公司整併後的運作模式，如今，他轉變身分，代表著IBM，不過不變的是，仍要破除外界對紅帽能否保有完整獨立性的疑慮。
Jim Whitehurst承諾，紅帽將於IBM之下，保持獨立性，他強調，如此才可確保紅帽於開源生態系的腳色，並持續與各方合作，包含IBM的競爭對手。但是，IBM仍會與紅帽有緊密的關係，他提到，IBM將幫助紅帽擴展混合雲平臺，而紅帽Openshift則將整合於IBM軟體中，讓IBM用戶可於各環境部署IBM軟體，也就是IBM去年推出的雲原生軟體產品組合Cloud Paks。
可惜的是，Paul Cormier未於後續的開場演說中，提及紅帽產品下一步的計畫，對公司發展也沒有太多的著墨，僅再次聚焦紅帽一直以來的開放混合雲戰略，強調這仍是他們的願景，使活動缺少了新人新氣象的氛圍。
他著重和參與者回溯開源、虛擬化、混合雲和雲端的歷史。Paul Cormier表示，這些概念都起始於一個構想，而現在已深入地融入我們的生活，尤其是混合雲，他進一步道，為了擴展規模，混合雲需要一個通用的開發、維運、安全和自動化的環境，並強調，混合雲非趨勢，而是勢在必行的戰略。
開場演說後的專場上，紅帽宣布了基於K8s 1.17版本重新開發的新版Openshift 4.4。這個版本增加了衡量指標和監控視圖，供開發者和應用維運者可掌握工作負載的性能。
而針對上周已搶先發布的新版Red Hat Enterprise Linux（RHEL）8.2，紅帽特別開設了一場議程介紹。其中，系統分析工具Red Hat Insights移除了需靠手動調整，才可進行系統分析的機制，以提升用戶管理大型且複雜環境的效率，此外，該工具還新增政策服務，讓用戶可定義和監控重要的內部政策。新版RHEL也增加了新的監視工具Subscription Watch，供用戶管理和查看跨混合雲環境裡，自身的RHEL和OpenShift Container Platform的訂閱服務。
因應疫情，推出4大政策，要與企業和IT人員共度難關
對於活動內容似乎未多加揭露紅帽的下一步，紅帽也表示，此次大會將有別於以往，不聚焦發布產品的新動向，而是專注提供疫情當前企業或IT人員所需的資源，要與大家共度難關。有鑑於此，紅帽宣布了一系列政策，首先，技術客戶管理（Technical Account Management）服務組合將提供新用戶5折優惠，其次，延長部分產品的生命週期，緩解用戶因應版本升級而要面臨的搬遷壓力，像是RHEL 7.6延長更新的技術支援（Extended Update Support）將多提供6個月，延後至明年5月31日結束支援。
第三，提供放無薪假者和求職者免費的技術訓練，像是紅帽系統管理員認證（RHCSA）課程，參與者可獲得RHEL系統的管理知識與技能。最後，開放超過50萬堂線上免費訓練課程，提供所有人使用。文⊙黃郁芸
",https://www.ithome.com.tw/news/137280,"新聞,紅帽,IBM,K8s,混合雲,開源,雲端,Linux,核心系統,疫情政策,產品生命週,訂閱服務期"
137050,5,2020-04-17,Container周報第126期：新版Rancer可支援10萬節點，K8s開始測試API優先權控管,K8s新增加了一個API優先權和公平性設計，可以建立一個流量架構（Flow Schema），來定義不同的流量指標所能擁有的優先權等級，API伺服器再依據不同的等級來安排API呼叫的執行順序，," 4/2~4/14 精選容器新聞
#API優先權 #K8s新功能
K8s 1.18版暗藏未來關鍵新功能，API優先權新設計初測中
3月中釋出的K8s 1.18版中，一口氣多了38項新功能，其中只有15項是正式功能，其他大多是測試功能，甚至有12項是實驗性高的Alpha版初測功能。三位來自Google、螞蟻金服和IBM的工程師，最近特別在K8s官網揭露一個1.18版中新加入的重要功能：API優先權和公平性（API Priority And Fairness）設計，這就是Alpha功能中，少人注意到但影響深遠的改變。這個功能主要用途是讓叢集管理員設計不同的優先權重等級，負責管理K8s所有API的伺服器，每收到任何API呼叫請求時，就會依據這次呼叫所屬的等級，來分配所能得到的流通量。
API伺服器可以用來控制變動或讀取量的上限，來避免主機CPU或記憶體超載的把關者，但是，目前K8s的設計上，只能區分異動用請求和唯讀用的請求這兩大類，而無法進行更細緻的調控，所以，常會出現某一種使用情境的請求特別高的情況。簡單來說，若某一個K8s服務的請求大增，一旦塞爆了這個控制所有API的API伺服器，就會連帶地影響了其他K8s內部服務的呼叫，例如影響到系統控制器的運作，或是一兩個故障節點連續狂送請求，可能就會導致整座叢集大塞車，其實塞住的是那個扮演交流道功能，負責指揮的API伺服器。
這個新增的API優先權和公平性設計，可以建立一個流量架構（Flow Schema），來定義不同的流量指標所能擁有的優先權等級。API伺服器再依據不同的等級來安排API呼叫的執行順序，另外，執行完一次請求要挑選下一次要執行的請求時，也會使用一個公平性演算法來檢查，避免某些重要的請求一直被塞在後面而無法執行，進而影響了整體叢集的運作。
目前，這樣的API優先權設計還有一些不足的機制有待開發，例如對於還必須修改系統監控機制的支援，讓這樣的API優先等級的影響，也能反映到是視覺化監控報表上呈現，這也是下一版要先改良的地方。
#K8s管理 #資安掃描Rancher小改版，可支援到2千叢集十萬節點，未來目標是百萬叢集
K8s管理平臺Rancher最近釋出2.4新版，再次提高擴充能力，這次改版後可支援到2千個叢集，最多共10萬個節點，目前架構設計上，也以百萬叢集為目標來考量。另外也增加了遠端升級功能，可由本地端K3s叢集來決定是否自動升級。另外，新版也開始支援不關機維護機制，可以在不影響應用程式的情況下，來升級K8s叢集。另外一個新特色是，引進了CIS資安掃描，利用公開的100項CIS資安指標，來檢查RKE叢集的資安問題。新版也提供了一個AWS實例的安裝部署套件，方便企業快速建議一個全功能的Rancher伺服器，可達99.9%的服務水準，但若部署在其他雲端平臺則無法保證SLA，如GKE和AKS。
#AIOps #雲端成本管控雲端AI優化工具推出3個月免費，靠AI自動調校K8s工作負載
一家AIOps雲端優化業者Opsani宣布，因應疫情推出3個月免費服務，可用AI技術來優化企業部署在雲端的K8s，自動調度到效能夠用但更便宜的部署環境，來降低企業租用雲端服務的成本。這項服務主要利用AI來追蹤不同K8s應用的執行效能，再依據應用所需的CPU和記憶體用量，將工作量動態調度到成本較低的執行環境，也可協助優化JVM等中介軟體的配置。這個AIOps工具也可整合到常見的DevOps工具鏈的服務或監控服務，例如GitHub、Terraform、Jenkins、Prometheus等。

#PaaS,#SAP,#IBMCloudFoundry基金會開始認證K8s作為CFP內建容器管理平臺
不少雲端PaaS業者採用Cloud Foundry的PaaS作為應用層平臺軟體，例如IBM、SAP，當然還有VMware的雲端平臺都使用了Cloud Foundry PaaS來建置。最近，Cloud Foundry基金會宣布，將開始認證K8s可以作為CF PaaS的內建容器管理平臺，可以用來取代他們原本的Diego容器管理平臺。原本就已經採用Digo的企業，仍舊可以繼續使用，但新的K8s認證措施，也意味著Cloud Foundry PaaS也開始大舉向K8s靠攏了。
#ECS #EFS #AWS FargateAWS雲端容器服務小更新，強化對自家雲端儲存EFS的支援
最近AWS雲端容器服務ECS有項小幅更新，強化對雲端檔案儲存服務EFS的支援，讓靜態容器應用，更容易透過EFS來跨區域部署。另外，AWS也同步更新Fargate容器代管服務對EFS的支援，並且改用Containerd來取代相對較複雜的Docker Engine，來提高容器核心引擎的執行效率。不過，目前這兩項更新都仍是預覽版本。
#持續派送 #ArgoCNCF孵化專案又多了一款持續派送平臺Argo
最近CNCF同意持續派送平臺Argo專案的加入，成為孵化專案之一。Argo是一組Kubernetes原生工具，可用來執行和管理在Kubernetes上運作的應用程式與工作，Argo專案是由一間名為Applatix的企業，在2017年時創建，Applatix在2018年的時候被Intuit收購，之後BlackRock也加入貢獻Argo專案的行列，並且與Applatix共同積極發展專案以及經營社群。

#Krustlet #Virtual Kubelet在K8s上部署WebAssembly應用有新工具
開發者將應用程式編譯成WebAssembly後，可以利用一個新興的部署工具Krustlet工具來部署。Krustlet的設計類似Virtual Kubelet，可以從Kubernetes API事件串流中監聽新的Pod；Virtual Kubelet是一個開源Kubelet實作，而Kubelet則是Kubernetes叢集的必要元件，叢集中每個節點都會啟動Kubelet，來處理主節點派送的任務，以及管理節點上的Pod。
#應用程式交付 #DragonflyK8s雲端檔案發布系統Dragonfly正式進入CNCF孵化器
由阿里巴巴集團貢獻的Dragonfly專案，正式進入CNCF孵化器階段。這是一個K8s專用的雲端原生映像檔和檔案發布系統，也是阿里巴巴容器平臺中的骨幹技術，每年支援數十億次的應用程式交付。Dragonfly在2018年的時候被CNCF沙盒接收，並被中國移動、滴滴和螞蟻金服等企業採用。透過P2P映像檔和檔案發布協定，Dragonfly能有效減輕映像檔註冊表和網路的負載，以提升使用者體驗，由於P2P技術可以充分利用每個同儕的頻寬資源提升下載速率，能節省大量的跨IDC頻寬以及昂貴的跨境頻寬。最新版本Dragonfly 1.0，已經用程式語言Go全部重寫，來提高雲端擴充性。
#Prometheus #日誌分析Grafana Lab推出Prometheus日誌分析平臺的企業級產品Cortex，自己先試用三年
Grafana Lab釋出了Cortex 1.0，這是一款以Prometheus來打造的開源時間序列資料庫與監控系統，具有水平擴展架構，以及幾乎無限的留存資料能力，目前為CNCF沙盒專案。1.0增加了多個讓用戶更容易用於生產的改進，像是提供詳細的部署步驟，以及簡單入門模式。Grafana Lab自己在內部生產環境中用Cortex長達三年，如Grafana Cloud的託管日誌和指標平臺的後端都是Cortex。
#開源專案管理 #按功能付費GitHub核心功能全免費，私有儲存庫的協作人數不再有上限
從「按私密性付費」（Pay by Privacy)，全球最大的開源專案代管平臺GitHub開始轉為按功能付費（Pay by Feature)的模式。最近GitHub執行長Nat Friedman宣布，核心功能將永久免費，尤其是原本私有專案的3名協作者上限，也取消，不再限制人數，現在改為以專案所用的儲存量來計算，免費版只能儲存500MB，超過得使用付費版，另外，免費版的Actions數量也只提供每月每分鐘2千次呼叫。原本付費使用開源Team版本的用戶，現在全部免費。不過，免費版只會提供社群支援，企業級支援得付費才有。
責任編輯／王宏仁 
更多Container相關動態
-VMware修補vCenter Server高風險漏洞
-Canonical推出應用託管服務，可代管10款應用上雲端
",https://www.ithome.com.tw/news/137050,"新聞,容器周報,Rancher,K8s,API優先權,AIOps,CloudFoundry,Argo,IT周報"
136845,5,2020-04-09,可管理K8s應用程式的Argo專案進入CNCF孵化器,Argo可以簡化Kubernetes應用程式的管理工作，提供工作流程引擎讓用戶調度Kubernetes上的工作負載," 雲端原生基金會（CNCF）本周宣布，其技術監督委員會已經投票決議，將Argo專案納入孵化器中託管。Argo是一組Kubernetes原生工具，可用來執行和管理在Kubernetes上運作的應用程式與工作，Argo專案是由一間名為Applatix的企業，在2017年時創建，Applatix在2018年的時候被Intuit收購，之後BlackRock也加入貢獻Argo專案的行列，並且與Applatix共同積極發展專案以及經營社群。
BlackRock資料科學平臺負責人Michael Francis提到，由於事件工作流程在BlackRock資料平臺中，於資料驅動模型中扮演重要的角色，讓公司的投資者和用戶可以使用研究模型存取大量的財務資料，因此BlackRock大量使用了Argo Workflows，並且決定貢獻相依性管理工具Argo Events。
Argo包含了4個子專案，包括用於Kubernetes的容器原生工作流程引擎Argo Workflows，能夠用來平行調度Kubernetes工作；Kubernetes事件相依管理器Argo Events，則是事件驅動工作流程的自動化框架，可用來啟動Kubernetes專案或是無伺服器工作負載等；還有支援Kubernetes資源宣告式GitOps部署的Argo CD；同時Argo也有能夠控制發布策略的工具Argo Rollouts，可以支援宣告式漸進交付策略，像是金絲雀部署和藍綠部署等。
Argo提供用戶一種簡單的方法，讓用戶在Kubernetes上創建應用程式和工作時，可以整合服務、工作流程和基於事件三種運算模式，Argo可以用做Kubernetes控制器也可以作為客製化資源，與其他諸如Prometheus和gRPC等CNCF專案結合使用。
目前已經有超過100個企業組織，積極將Argo用於生產中，包括Adobe、Google、GitHub和Volvo等，在GitHub上，Argo的社群也已經茁壯發展，Argo專案有8,300顆星並擁有425位貢獻者，CNCF提到，在Argo專案加入CNCF之後，會專注在微服務交付和機器學習應用程式的發展。CNCF技術長Chris Aniszczyk表示，Argo團隊致力於簡化Kubernetes的使用，以及發展GitOps應用，與CNCF社群的發展目標相符。
",https://www.ithome.com.tw/news/136845,"新聞,Kubernetes,CNCF,Argo,K8s"
136799,5,2020-04-07,Krustlet可讓用戶在K8s上簡單部署WebAssembly工作負載,Krustlet可接收Kubernetes API調度Pod，並在WASI Runtime上執行WebAssembly工作負載," 雲端開源工具廠商Deislabs釋出了一個名為Krustlet的工具，Krustlet這個字是結合Kubernetes-Rust-Kubelet創造出來的，說明Krustlet是用程式語言Rust所開發，用來提供類似Kubernetes Kubelet功能，Krustlet可簡化用戶在Kubernetes上，部署WebAssembly工作負載任務。
之所以要在Kubernetes中支援WebAssembly，Deislabs提到，Linux容器和WebAssembly各有優點，可以成為互補的技術。Linux容器提供了作業系統等級的虛擬沙盒，可以讓用戶在單個主機上執行多個隔離的Linux系統，容器直接在物理硬體上執行，不需要進行模擬，因此執行的額外成本很小；而WebAssembly則是一種新的二進位開放格式開放標準，具有記憶體安全以及可移植的特性，能以接近原生效能執行，目前Rust、C/C++與AssemblyScript都可交叉編譯成WebAssembly。
一開始WebAssembly是為瀏覽器所發展的，但是隨著發展，Mozilla開始把WebAssembly擴展到瀏覽器之外，建立了WASI（WebAssembly System Interface）標準，讓WebAssembly的功能可以擴展到作業系統，有了這個抽象層，開發者的WebAssembly程式，就能夠在任何支援WASI的地方執行，達到一次編譯，隨處執行的目的。
Deislabs表示，Linux容器與WebAssembly並不處於互相競爭的位置上，Linux容器目的是要提供作業系統層級的沙盒環境，由於要靠Linux核心提供沙盒環境，因此在英特爾晶片編譯的程式碼，就無法在ARM硬體上執行；而WebAssembly是可移植的二進位格式，無論底層硬體為何，只要是支援WASI的硬體，WebAssembly程式就能夠在上面運作，不過由於WebAssembly是二進位格式，無法提供跟作業系統沙盒相同的靈活性。
因此開發者可以依據需求，將編譯程式放在Linux容器上執行，或是將應用程式編譯成WebAssembly，而後者就可以利用Krustlet工具來部署。Deislabs提到，Krustlet的設計類似Virtual Kubelet，可以從Kubernetes API事件串流中監聽新的Pod；Virtual Kubelet是一個開源Kubelet實作，而Kubelet則是Kubernetes叢集的必要元件，叢集中每個節點都會啟動Kubelet，來處理主節點派送的任務，以及管理節點上的Pod。
現在Kubernetes API也可以調度Pod到Krustlet上，並在waSCC或是WASI Runtime上執行，同一個Kubernetes叢集，可以同時擁有傳統Linux容器工作負載與WebAssembly工作負載，兩者也可以互相溝通。
Deislabs現在釋出的是Krustlet第一個版本0.1.0，0.2.0版本將會支援卷宗掛載，並提供更多範例，及補充Krustlet文件。Krustlet專案完全開源，想搶先嘗試的用戶可以在GitHub上取得程式。
",https://www.ithome.com.tw/news/136799,"新聞,Kubernetes,K8s,Krustlet,WebAssembly"
136747,5,2020-04-05,Container周報第125期：2019年CNCF雲端原生大調查出爐，75%企業在正式環境用K8s了,K8s的普及速度更快了，全球在正式環境使用K8s的組織超過了75%，比2018年的5成多增加了許多。高達19%企業在正式環境中的容器數量超過了5千個。," 3/26~4/1 精選容器新聞
#CNCF、#K8s2019雲端原生大調查出爐，75%企業在正式環境用K8s了
CNCF基金會最近公布了一年一度的雲端原生大調查2019年報告，調查了全球1,337家企業或組織，其中3成是規模超過5千人的大企業。根據這次調查結果，在正式環境擁抱容器企業的比例已經高達了84%，在開發環境導入者也高達9成。高達19%企業在正式環境中的容器數量超過了5千個。在CNCF已經畢業的專案中，K8s的普及速度更快了，全球在正式環境使用K8s的組織超過了75%，比2018年的5成多增加了許多，而Prometheus專案的在正式環境使用的比率，在2019年也快速接近75％。另一個開始大量正式使用的專案是CoreDNS。
K8s的用量調查上，大多數企業正式環境中管理的K8s叢集約2到5個，4成企業都是如此。但也有1成企業的K8s叢集超過了50個。K8s應用程式的打包機制以Helm為主，超過6成應用程式都支援這個格式。在本地端開發環境上，最主流的K8s環境是Minikube（39%），其次是Docker Kubernetes(32%)，使用雲端業者提供的託管K8s者和自建整套本地端K8s者都是只有2成多。
導入無伺服器架構的企業也增加很多，至少有41%的作答者已經採用。在雲端，最多人使用的雲端Serverless服務是AWS Lambda，超過了5成採用率，其次是Google Cloud Functions，但不到2成採用率。而微軟Azure Functions排名第三，略低於GCP。而在自建平臺上，最多人利用Knative來自建Serverless平臺（34%）。
目前已有18%組織導入服務網格技術，所用相關專案中，以Consul專案在正式環境的採用率最高，但Istio評估採用者很多，有後來居上的潛力，排名第三高的是Linkerd。
CI/CD是雲端原生應用的關鍵流程，越來越多CI/CD工具的問世和普及，也讓企業可以加快應用程式的開發和釋出周期，從應用程式改版釋出的步調更可以看出企業CI/CD流程的成熟度。根據2019年調查，可以做到每天釋出新版的企業，從去年的15%，今年大幅增加到了27%，而2019年可以做到每周釋出的企業也有28%，等於有6成企業都具備了在一周內改版的能力。
#DevSecOps、#跨K8s叢集資安新創Zettaset資料加密平臺可以支援K8s多叢集了
主打軟體加密的資安新創Zettaset最近宣布自家資料加密平臺可以支援K8s跨叢集了。企業可以用一套K8s來管理跨叢集間的加密資料流通，可以自動將加密政策管理發布到各叢集，來建立更大規模的DevSecOps計畫。原本K8s就有一套機密資料的加密保護機制，Zettaset則是提供了一個加密外掛工具，可利用軟體金鑰來進行K8s機密資料的加密，來取代常見用硬體金鑰加密的作法。另外，Zettaset指出，因為採取軟體金鑰加密的作法，企業將K8s上的加密資料處理延伸到更多DevOps流程上，讓其他微服務也能存取加密過的機密資料。
#監控維運、#K8s管理開源監控平臺OpenTelemetry進入Beta階段，提供6種語言SDK
Google在去年開源釋出了一項整合式的追蹤監測平臺OpenTelemetry，這個工具可以蒐集或發送監測資訊到Prometheus、Jaeger、Cloud Monitoring、Cloud Trace等平臺，來打造一個K8s整合式監測管理基礎之用，蒐集Ap層的監控陣列資料，也支援分散式追蹤架構。在3月底時，Google終於宣布，OpenTelemetry推出了第一個Beta版本，提供了6種語言的SDK，可以用來串接和蒐集不同語言所開發的應用系統，包括了 Erlang、Go、Java、JavaScript和Python和微軟.NET的SDK支援。

#持續整合、#GitHub容器CI/CD核心元件官方版來了，Docker釋出第一個GitHub Action
GitHub去年推出了Action功能，可以透過事件來驅動指定的專案動作，成了開發者打造CI/CD的關鍵功能，不少用Docker容器也建立整套CI/CD流程的開發者，也自行打造了Docker的Action功能來驅動這些流程。現在Docker終於推出的自家的第一個官方版GitHub Action功能（專案名稱build-push-action），從Docker預安裝、在雲端配置到執行部署，都能支援，像是用git SHA來進行Tagging、用OCI的標籤來進行Labelling、也支援部建階段參數和多階段版控，另外還有提供Push filter可以用來更清楚的設定，何時才需要進行容器映像檔的部建。
遊戲主機調度、Agones全球AB測試也能自動化，Google推出K8s遊戲叢集服務
Google新推出K8s遊戲主機託管服務Game Servers，可以自動擴充或縮小全球各地的遊戲叢集，也可用來進行A/B或是金絲雀測試。2017年Google與法國知名遊戲開發公司Ubisoft合作，利用容器調度工具Kubernetes打造開源平臺Agones，可讓用戶直接在Kubernetes上託管、執行和擴展專有的遊戲伺服器，Agones可取代原本的伺服器管理和擴展方式，以Kubernetes來分配遊戲資源，並且管理遊戲伺服器的生命周期。現在Google推出的遊戲伺服器服務測試版，可說是一項付費的Agones託管服務。
使用者能以kubectl結合yaml，或是Kubernetes API來定義單一的遊戲伺服器，或是大型預啟用的遊戲伺服器機群。甚至，遊戲開發者很容易進行A/B測試，或是在進行配置變更時，先進行金絲雀測試，並在發生問題時，快速回退到穩定版本上。
#應用程式派送、#CI/CDAkamai強化CI/CD支援，應用全球派送速度縮短到以分計算
網路派送服務商Akamai最近宣布自家大力擁抱DevOps方法，因此，提高了應用程式全球派送的速度。原本Akamai就支援DevOps工具Terraform，讓開發者可以將應用程式派送整合到自家CI/CD工作流程上，現在則加快這個派送速度，可以讓開發者調整部署配置後，數分鐘就能套用。另外，Akamai的邊緣運算機制EdgeWorkers也新增內容快取的控制，開發者可以利用快取內容來進行A/B測試或實驗新功能
#CIO大調查、#IT人才臺灣重度上雲企業更多了，2成企業大搶基礎架構人才
臺灣已有近2成企業是重度雲端化的企業，內部半數應用都已經搬上了雲，根據iThome今年1、2月間，針對全臺373家兩千大規模企業IT主管的調查，基礎架構人才開始成了搶手人才之一，包括了機房維運、虛擬化管理、容器技術、K8s技術、雲端維運人才等，平均臺灣有2成大型企業今年都有相關職缺，尤其是金融業者高達45.7%要搶，政府機關也有4成要招募基礎架構人才。網路維運人才依舊熱門，有一成企業開缺，但是也有5.9％企業指明要找容器技術人才，4.8%企業有K8s人才的職缺。

責任編輯／王宏仁 
更多Container相關動態
對抗疫情，SUSE宣布將提供醫療製造業業免費容器技術支援
WireGuard VPN 1.0.0隨同Linux 5.6正式出爐
",https://www.ithome.com.tw/news/136747,"新聞,容器周報,K8s,CNCF,基礎架構人才,OpenTelemetry,IT周報"
136685,5,2020-04-01,GitLab開源18個DevOps付費功能，免費供所有用戶使用,這18個功能原本存在於不同的付費層級中，現在全部開源，讓所有用戶都能在GitLab上執行完整的DevOps," GitLab共同創辦人暨執行長Sid Sijbrandij在重新審視了GitLab現有功能後，決定開源DevOps生命周期7個階段裡的18個功能，讓社群能夠更方便地進行協作。這18個功能將會從原本的付費計畫層級中，下移到免費的Core/Free層級裡。
GitLab的定價模式使用基於買家的開放核心模式，鎖定不同的目標族群，提供不同的功能，這些目標族群被分為4種層級，分別是鎖定個人工作者的Core/Free層級，給管理者的功能則在Starter/Bronze層級中，而為經理設計的功能，則放在Premium/Silver層級，高級主管才會用到的功能，放在Ultimate/Gold層級裡。
也就是說對特定族群有用的功能，才會放在相對應的計畫層級中，而成本越高的計畫鎖定位階越高的買方族群，Sid Sijbrandij提到，這種定價模式提供良好的服務，因此GitLab也一直致力發展這樣的模式，但在這個過程中，他們很少對現有功能進行審查。因此Sid Sijbrandij親自審查每一個層級的功能後，決定開放18個功能。
這18個功能各來自DevOps生命周期中的7個階段，這些階段分別為計畫（Plan）、創建（Create）、驗證（Verify）、套件封裝（Package）、發布（Release）、配置（Configure）和防護（Defend），這18個功能將會從各計畫層級，往下到移動Core/Free層級。
將從計畫階段開源的4個功能，可以讓用戶更簡單地進行協作和計畫專案，包括相關問題、導出問題和發布儀表板聚焦模式都會下移到Core/Free層級，另外，還有一個服務臺（Service Desk）功能也會開源，能讓團隊直接在GitLab中，不需要使用任何外部工具，透過電子郵件與外部聯繫，消除了不同工具切換的複雜性，縮小回饋到軟體更新的時間。
DevOps創建階段的兩個網頁環境開發功能，網頁IDE中的網頁終端機，以及同步檔案至網頁終端機功能將會開源，而且設計管理功能也會開放給Core/Free層級的用戶使用，讓用戶可以上傳設計構件到GitLab問題（Issue）中集中儲存，用戶可從問題中的設計管理頁面存取這些構件，確保問題是功能開發的唯一來源。
驗證階段的程式碼品質回報功能也會開源，該功能可以確保專案程式碼簡單和可讀性，而在套件階段，則會加入一系列套件管理器，包括Conan、Maven、Npm和NuGet，讓用戶能夠集中管理套件。發布階段開源了4個功能，包括金絲雀部署、漸增部署、功能旗標以及部署儀表板，讓用戶能夠更可靠的部署應用程式新功能。
而且Core/Free層級用戶也將能使用多重Kubernetes叢集功能，簡單地將分段（Staging）和產品環境，部署到不同的Kubernetes叢集中。最後，為了提升用戶應用程式和基礎設施的安全性，GitLab開源了DevOps防護階段的容器網路安全性政策，供所有用戶使用，用戶可以將網路政策安裝進GitLab管理的Kubernetes叢集中，以限制Pod之間的通訊。
這些開源的功能，將可讓用戶在GitLab上執行完整的DevOps生命周期，GitLab已經將這些功能標記出來，並且邀請需要使用這些功能的用戶，幫忙移動程式碼至開源的儲存庫中。
",https://www.ithome.com.tw/news/136685,"新聞,GitLab,DevOps,開源"
136584,5,2020-03-26,Container周報第124期：2020年第一個K8s新版1.18來了，38項更新的大亮點是Kubectl除錯,Kubectl這次增加了一個關鍵新功能「除錯指令」，這是開發者期待已久的功能，可以在一個特定Pod中建立容器，來進行網路、資料或系統問題的除錯，目前仍是Alpha版," 3/19~3/25 精選容器新聞
#K8s、#除錯功能2020年第一個K8s新版1.18來了，大增38項更新
Kubernetes已經成了企業IT新一代基礎架構的核心，每次改版重點，也會帶來企業架構的新可能性。在3月中旬，K8s釋出了今年四次改版的第一個版本1.18，官方宣稱，這是一個不錯的合適完成版，因為高達15項功能，終於從Beta階段進入了穩定階段，另有11項先前發表的功能進入Beta，再加上新增加的12項功能，還處於最初期的Alpha測試版。這次改版一口氣多了38項更新。
開發者感受最明顯的改變是K8s命令列工具Kubectl，一來部署指令更簡化了，過去可以用來部署4種不同的環境，容易混淆，現在統一只能用於建立pod叢集。再者，Kubectl這次增加了一個關鍵新功能「除錯指令」，這是開發者期待已久的功能，可以在一個特定Pod中建立容器，來進行網路、資料或系統問題的除錯，目前仍是Alpha版。另外，現在要定義一個Ingress控制器時，規則可以支援萬用字元，讓定義更彈性。
儲存安全性也強化了，引進了檔案群組異動政策，可用來指定Pod群組檔案屬性的改變規則。K8s還增加了一個新的水平擴充式Pod的自動擴充API，可以根據這類Pod的行為，自動進行擴充或縮小叢集的規模。原本，K8s也有多種排程調度機制，而且可以同時執行，但這也衍生了除錯和管理上的複雜性，現在多了一個排程機制的配置檔功能Scheduling Profiles，可以用來規範不同排程器各自的調度行為，避免不同Pod叢集各自調度器之間的干擾。
#專案管理、#GitHub行動版GitHub正式上線，審查和合併PR都能一指完成
開源專案管理平臺GitHub先前發表了手機版App的試用版本，經過數萬人測試後，終於在3月中正式上線了，包括免費的iOS和Android版本都有。這個行動版GitHub可以讓開發者在手機上，用手指滑動來組織和安排群組任務，也能直接對特定議題（Issue） 給回覆，來與其他專案成員討論。最重要的功能則是審查和合併來自其他開發者提交的合併請求Pull Request，換句話說，開發專案的負責人或審查者，就算人在車上，也能直接用手機來進行各項程式碼提交審查，不用打開筆電。所有專案上的檔案或程式碼，也都可以直接在手機版GitHub上瀏覽。另外，為了整合行動版GitHub上的訊息，GitHub也更新了Web版的通知功能，可以更容易在桌機上檢視來自行動版發出的訊息，方便開發者切換不同的開發裝置，還能延續同樣的開發流程。

#Ubuntu、#MicroK8sCanonical三大K8s商用產品跟進升級，支援1.18最新版
就在K8s新版發布不久，Ubuntu作業系統開發商Canonical也宣布全面支援到新版本，包括Ubuntu作業系統內建的多雲版本Charmed Kubernetes，邊緣裝置專用的輕量版MicroK8s和提供K8s商用支援的kubeadm版本。另外，Canonical也在不同的K8s發行版中各有更新。更新最多的是MicroK8s，內建的etcd升級到3.4版，CoreNDS外掛也支援到1.6.6版等。而在Ubuntu內建多雲版中，則提供了Ubuntu 20.04 LTS版的預覽版本，並且支援開源文件儲存系統CephFS，另外在Pod叢集上也增加了多重虛擬網路介面的支援。
#VS Code、#Python部署容器化Python應用更方便，VS Code Docker擴充套件1.0正式版出爐
微軟推出Visual Studio Code的第一個Docker擴充套件主要版本，強化了對Python網頁框架Django與Flask的支援，並且為Python和.NET Core開發人員，提供與Node.js相同的Compose支援，開發者使用Docker擴充套件建構、執行和除錯容器化應用程式，將會更簡單。
用戶可以自定義各種命令，像是執行映像檔時，指定擴充套件將產生的容器放置在特定的網路上等。最多使用者要求的更新，是希望在執行像是啟動、停止或是刪除映像檔等命令時，可以一次選擇多個容器或是映像檔，因此微軟這次新增了功能，讓用戶可以一次選擇多個容器或映像檔，並從右鍵選單選擇要對選定項目執行的命令。

#Node.js、#Npm要強化百萬套件開源供應鏈的安全，GitHub買下JavaScript關鍵套件工具Npm
去年GitHub才發表自家套件工具，最近就決定乾脆買下Node.js套件的管理工具Npm。Npm目前有130萬個套件，使用者人數約為1,200人，每個月套件下載次數達到750億次。GitHub提到，開源程式的安全性是一個重要的問題，他們能利用GitHub Security Lab和安全性審查，來提升Npm套件的安全性。GitHub和Npm整合在一起，能夠提高開源供應鏈的安全性，讓開發者可從GitHub的拉取請求，追蹤到其Npm套件版本變更。
對於原本使用Npm Pro、Team和Enterprise計畫的付費使用者，不受併購影響，GitHub會繼續如常提供服務。而對於GitHub自家的套件服務GitHub Packages，他們也進行了大量的投資，作為與GitHub完全整合的多語言套件註冊表中心，在今年稍晚，GitHub會將Npm付費客戶的私有套件移動到GitHub Packages中，讓Npm成為一個真正的JavaScript大型公共註冊表服務。
#居家上班、#遠端桌面新版遠端桌面軟體瞄準在家工作潮，靠容器搬遷老舊資料庫應用上雲
趁著武漢肺炎疫情衍生的居家上班需求，一家服務遷移商Intact推出了一款遠端桌面軟體ReAccess，可以讓企業居家上班的員工，連線到Azure上，來存取自家企業內部原有的資料庫應用系統。要使用這個軟體得搭配Intact的託管式雲端應用派送自動化服務PowerLine，先將企業本地端的資料庫應用系統，利用容器技術，快速打包後，自動搬上微軟Azure平臺。
在微軟結束Windows 7的支援後，企業許多老舊的資料庫型應用系統的搬遷需求，Intact看上這塊市場需求，先前就推出了PowerLine搬遷服務，現在進一步搭配遠端桌面，打造出居家上班輔助軟體。該公司執行長Larry Aultman解釋，ReAccess會利用Azure上的Cosmos DB雲端資料庫，來建立一個企業本地端資料庫的副本資料庫，由PowerLine派送工具自動更新資料庫的內容，另外，也會建立一份副本（包括資料庫跟軟體）在員工本地端電腦，因此就算網路斷線，也能暫時離線使用，等到連線時再同步。
#CIO大調查、#臺灣企業2成臺灣金融業今年要導入K8s，服務業也有1成多
根據iThome今年1、2月間，針對全臺373家兩千大規模企業IT主管的調查，今年有高達2成的金融業者，要導入K8s，服務業和醫療業也各有1成多的企業要用，就連一般製造業者，也以2.2％的企業表明想用。這也反映出，Kubernetes不只是少數企業偏愛的新架構，開始成為更多企業擁抱容器架構的選擇。例如已有大型公股銀行和大型民營金控，開始導入紅帽容器平臺OpenShift；老牌點數平臺Happy Go也成立新團隊來評估Docker技術，更有超商的資訊主管開始構思，要結合自家APP和容器技術的可能點子。

責任編輯／王宏仁
更多Container相關動態
Sysdig支援Prometheus，資安DevOps平臺儀表板更容易整合開源平臺資料流
Platform9推出更多K8s託管方案，免費版叢集可用800個虛擬CPU
",https://www.ithome.com.tw/news/136584,"新聞,容器周報,K8s,Kubernetes.kubctl,GitHub,VS Code,IT周報"
136528,5,2020-03-24,Google推出遊戲伺服器託管服務，讓遊戲開發商用K8s管理全球遊戲伺服器機群,新推出的遊戲伺服器託管服務，是基於Agones開源遊戲伺服器託管平臺，專為管理全球規模遊戲伺服器機群設計," Google發布了雲端遊戲伺服器服務Game Servers，這是一個Kubernetes遊戲伺服器託管平臺Agones服務，可讓企業簡單管理全球多叢集遊戲伺服器機群，提供自動縮放排程規畫，也可用來進行A/B或是金絲雀測試。
2017年Google與法國知名遊戲開發公司Ubisoft合作，利用容器調度工具Kubernetes打造開源平臺Agones，可讓用戶直接在Kubernetes上託管、執行和擴展專有的遊戲伺服器，Agones可取代原本的伺服器管理和擴展方式，以Kubernetes來分配遊戲資源，並且管理遊戲伺服器的生命周期。使用者能以kubectl結合yaml，或是Kubernetes API來定義單一的遊戲伺服器，或是大型預啟用的遊戲伺服器機群。
現在不少遊戲皆提供多人連線服務，Google提到，遊戲開發者通常會使用專門的遊戲伺服器，實作玩家連線功能，但是管理遊戲伺服器機群並非簡單的事，尤其是要將遊戲服務擴展到全球的時候，遊戲商如果不想要從頭自己打造專有的解決方案，就是選用預打包的的方案。
開源的Agones提供了另外一種選項，是由開源社群開發的替代方案，讓開發者可以在多雲、本地或是本機環境上，無縫託管和擴展遊戲伺服器機群。Agones適合用來管理區域遊戲伺服器叢集，而現在Google所推出的遊戲伺服器服務測試版，是一項付費的Agones託管服務，適合用於全球規模的多叢集遊戲伺服器機群管理。
現有的Agones用戶，可以隨時將工作負載加入到Google的遊戲伺服器服務機群中，只要使用新的Game Servers API在託管的Agones遊戲伺服器叢集中註冊，就能選擇加入託管服務，而當用戶想要手動管理伺服器，也可以隨時退出託管服務。另外，用戶還可以將叢集以Kubernetes叢集的邏輯群組分組，如此就能定義遊戲伺服器配置與擴展政策，簡化跨地區和跨叢集的機群管理，但同時又能保有系統可控制性與可見度。
Google提到，遊戲伺服器服務可以讓用戶簡單地安排計畫以應付各種情境，像是在遊戲舉辦特別活動時，可以按日期事先安排額外的容量，滿足可能出現的流量高峰，又或是進行每日排程自動縮放容量，在各地區每日流量高峰時擴展機群，並在非高峰時間縮減機群。而且遊戲伺服器服務還能讓開發者方便地進行A/B測試，或是在進行配置變更時，先進行金絲雀測試，並在發生問題時，快速回退到穩定版本上。
",https://www.ithome.com.tw/news/136528,"新聞,google,Ubisoft,Agones,遊戲開發,Kubernetes,K8s"
136462,5,2020-03-20,"Container周報第123期：1,600個微服務怎麼管？英國當紅網銀Monzo秘訣大公開","Monzo第一年不過數百個微服務，但到了2019年11月初達到了1,500個微服務，甚至去年12月更暴增到1,600個已上。這些微服務間互相的不重複呼叫超過了9,300個。"," 3/1~3/13 精選容器新聞：微服務管理實例
#微服務管理,#數位銀行如何在K8s管理1600個微服務？英國當紅數位銀行秘訣大公開
日前，英國數位銀行Monzo兩位資深工程師Matt Heath和Suhail Patel在倫敦一場研討會上，揭露了如何管理1,600個後端微服務的經驗。這間設立超過5年的英國挑戰者銀行，一般金融用戶超過了4百萬人，去年9月更進軍美國市場，目前也正在開發企業用的數位銀行服務。Monzo所有金融服務都是透過手機App提供，也因此，他們一開始就決定建立分散式架構，而不是建置一套龐大的銀行核心系統。最初先採用Mesos來建立容器叢集，在2016年時則全面換成了現在當紅K8s，來打造了一個執行各種金融微服務的平臺。Monzo是少數很早就開始壓寶K8s的企業業者，也將基礎架構搬上AWS平臺，來減少維運人力。

Monzo使用了容易水平擴充的NoSQL資料庫Cassandra，後端系統主要開發語言則是簡潔的Go，他們的理由是，這個語言保證向下相容，所以，遇到語言改版時，例如有次新版增加了垃圾蒐集功能，原有程式碼不用修改，直接用新版Go重新編譯後即可執行，就能使用新功能來提高記憶體管理效率。
這是一家喜歡自己開發工具的公司，若有需要串接第三方系統或支付平臺時，Monzo都盡可能自製開發整合機制，來提高效能，避免採用第三方整合工具，而帶進了許多額外不需要的程式碼，例如他們就開發了一個互動工具，來串聯AWS環境和K8s環境，讓開發者透過一個pull reques指令，就可以快速進行部署或恢復舊版部署。
在微服務設計上，Monzo將每一個微服務，都跑在一個Docker容器中。容器化微服務的程式碼，還分為兩層，一層是所有微服務都必須內建的共用核心函式庫層（Shared Core Library Layer），包括了RPC、Cassandra、鎖定機制、Log記錄機制、監控Metrics、Queuing等六大類函式庫，另一層則是業務層，也就是這支微服務要放進入的程式碼。

Monzo拆分微服務顆粒度的原則是，進可能地拆解到越細小的程度，他們解釋，拆解得越細，可以將變動風險降到最低，例如更新單一功能，能減少對其他微服務的影響。但是，微服務顆粒度越小，代價是會產生大量的微服務。Monzo統計，第一年不過數百個微服務，但到了2019年11月初達到了1,500個微服務，甚至去年12月更暴增到1,600個已上。這些微服務間互相的不重複呼叫超過了9,300個。

因為所有服務都在線上，Monzo希望盡可能落實零信任安全制度，因此，採取白名單方式來管控每一個微服務可呼叫的其他微服務名單。起初，微服務數量不多時，這份白名單採人工維護，但是，數量達到數千，甚至近萬個時，維護工作非常複雜，因此，Monzo決定改開發自動化維護工具。
習慣自己開發工具的Monzo先挑了安全管控最嚴格的一支微服務service.ledger來測試，利用K8s的網路政策資源，在配置檔中建立一個呼叫白名單。這是一支負責跨帳戶移動金錢的微服務。
接著，Monzo開發了一個微服務通訊剖析rpcmap，可以自動分析每一支Go語言程式，找出對service.ledger微服務的所有呼叫來源，來建立白名單。
有了名單之後，Monzo下一步是利用K8s的NetworkPolicy資源來執行過濾，在service.ledger所屬的ledger服務配置檔中建立網路政策，只有加上可允許標籤的網路流量來源才可以放行，並在ledger程式碼目錄中，放入一份授權來源的白名單檔案。一旦有其他開發團隊想要取得呼叫權限時，就得更新這個白名單檔案，並且重新部建ledger服務（因為程式碼內的檔案有異動）後才能生效，ledger開發團隊在部建階段就可以審查這個新增的外部呼叫。
不過，測試後發現了幾個問題，多了不少人工審查呼叫的負擔，也會提高微服務回復舊版本的風險，再加上開發團隊習慣手動編輯配置檔，每一個人都能修改呼叫白名單，而難以管控。後來，Monzo決定導入開源的K8s網路安控專案Calico，在每一個微服務上建立一個微型防火牆功能，來管理存取。另外，Monzo也大力提高微服務管理的資訊透明度，如自製微服務剖析工具，方便開發團隊查詢每次程式碼checkout後，微服務所用API的清單和狀態資訊，並且大量採用視覺化監測工具來追蹤流量和用量。
除了工具面的管理機制，Monzo也製作了一份後端工程師101指南，要求開發團隊第一次撰寫後端程式就要開始遵循，內容從新服務建立，RPC處理程序導入、資料庫查詢、如和透過Firehose發布和使用訊息、如何撰寫單元測試，到如何部署，都有詳細的說明和規定，並提供了一個Slack頻道來討論這套後端應用規範的上手問題。Monzo要求，每一個開發成員都要遵守這個規範來開發後端的微服務。
Monzo解釋，微服務的顆粒度越細，儘管有助提高彈性，但是，需要搭配一致的程式碼架構和工具，透過標準化讓工程師聚焦在業務問題，持續改善工具和功能，才能快速進行一系列的微幅迭代修改，來打破大型金融應用的複雜性，又能降低風險。
 
#Docker,#雲端部署戰略轉向AP部署和派送流程，Docker公開未來產品藍圖
Docker在自家部落格說明了未來營運新戰略藍圖，將會花更多的資源強化開發體驗，使開發人員可以更方便地讓程式碼，部署到多雲應用程式Runtime中。Docker將進一步發展基礎Docker工具、Docker Desktop以及Docker Hub來加速這個過程，除了改善Docker Desktop的開發體驗，並與生態系合作，且使Docker Hub能夠整合、配置和管理，建構應用程式和微服務所需要的應用程式元件。Docker Hub將不只是一個註冊表服務，而將會成為工具生態系中心，Docker Hub會提供各種工作管線選項，範疇從抽象功能到讓開發者自己從頭打造的元件都有。

#GCP,#Istio,#Envoy微服務平臺Istio大力擁抱WebAssembly，1.5新版推出全新套件擴充模式
開源微服務平臺Istio是Google混合雲平臺Anthos的核心套件之一，最近釋出了1.5新版，最大特色是推出了新的擴充套件模式，可以讓開發者使用WebAssembly檔案，快速透過Istio內的Envoy proxy來發布或執行程式碼，整合到遠端環境中，也可整合政策管理系統、路由控管機制，甚至修改派送的訊息內容。官方指出，這個新模式可以讓開發者更彈性地將一個複合式的元件，先各自分開執行初始元件再組合。另外，命令列工具istioctl增加了十多項改善，因此進入Beta測試版，而安裝管理機制則仍舊在alpha測試版中，預計將發展成一個功能更完整的維運工具API。另外，在安全強化上，資安政策工具Auto mTlS也進入測試版本，可以支援否定語法，來強制某些控制機制的政策不會被覆蓋而出錯。在透明度上，Telemetry第二則新增加原始TCP連線的監控支援。
#VMware,#K8sK8s重新改造的新版vSphere 7正式發布，5月正式上市
VMware在3年前開始投入K8s技術開發，甚至找來，兩位K8s創辦人加入VMware，全新的K8s產品線Tanzu和改用K8s重新設計的新版vSphere 7終於亮相，VMware在vSphere底層放入了一套K8s，提供了一個底層K8s超級節點，可以同時執行VM和K8s容器化應用，也能直接在虛擬層上提供K8s叢集。VMware執行長Pat Gelsinger直言，這是vMotion問世以來，最重要的虛擬化技術變革。Tanzu產品線則要用來管理和串接，各種不同環境的K8s，公有雲、私有雲、第三方版本等，來提供一個統一的K8s部署和管理介面。開源的Tanzu元件先釋出正式版，而vSphere 7新版則預定在今年5月1日正式上市。
#Ansibl,#DevOps擔心疫情失業潮，知名K8s DevOps工具書一個月免費要讓工程師自學
擔心武漢肺炎疫情重創科技業，恐出線工程師失業潮，知名軟體工具書Ansible DevOps作者Jeff Geerling最近決定，將自己兩本熱門工具書，免費提供下載1個月，讓工程師可以自修來強化自己的能力。他在LeanPub電子書初版平臺上，提供《Ansible for DevOps》和《Ansible for Kubernetes》這兩本書，訂購者可自訂要購買的價格，到最低的0元。

#機器學習,#Kubeflow開發、訓練到部署一套搞定，K8s機器學習工具包Kubeflow終於有正式版
超過2年開發，開源的K8s機器學習版終於釋出了第一個正式版本。Kubeflow原本稱為TensorFlow Extended，是Google內部用來部署TensorFlow模型到Kubernetes的方法。在2017年底在美國Kubecon中對外開源，之後專案便蓬勃發展，現在有來自30個組織上百位的貢獻者，參與Kubeflow專案的開發。Kubeflow 1.0提供了一組穩定版本的應用程式，提高開發者在Kubernetes上進行開發、建置、訓練和部署模型的效率。包括Kubeflow的使用者介面Central Dashboard以及Jupyter筆記本控制器，還有用於分散式訓練的Tensorflow和PyTorch運算子，同時也提供管理多重使用者的配置文件管理器，和部署升級工具kfctl。
#容器OS,#BottlerocketAWS自製容器專用OS，配置異動和搬遷都能靠API
AWS推出專門為容器主機最佳化的Linux作業系統Bottlerocket，包含容器主機所需要的元件，並且整合了現有容器調度工具，支援Docker映像檔以及OCI（Open Container Initiative）格式的映像檔。特別之處在於其更新以及API設計上，用戶可以利用呼叫API來調整配置，而不需要手動更改，並且這些更改還可以在更新時自動搬遷。Bottlerocket不使用套件更新系統，而是使用基於映像檔的更新模型，這個模型在必要時可以快速且完整的回退，Bottlerocket中幾乎所有的地方元件，都是以Rust開發而成，而Rust能夠消除某些類型的記憶體安全性問題，並且使開發者以較安全的模式開發程式。
責任編輯／王宏仁
更多Container相關動態
GitHub買下Node.js套件管理器Npm
微軟釋出VS Code Docker擴充套件1.0
",https://www.ithome.com.tw/news/136462,"新聞,容器周報,數位銀行,Monzo,微服務管理,K8s,Docker,IT周報"
136324,5,2020-03-13,Cloud周報第57期：VMware終於全力擁抱K8s，新版vSphere 7將於5月1日前推出,新版vSphere 7內建了K8s，可直接建置和部署K8s叢集。VMware目標是推動現代化應用，而這需要現代化基礎設施的支援，才可實現，VMware技術長暨雲端平臺業務部門副總裁Kit Colbert解釋，vSphere 7的改變，就像是「根本地實現了vSphere自身的現代化。」," 重點新聞（2020/03/05～2020/03/11）
  K8s     vSphere 7     上市時間   
經過逾半年時間，VMware終於在3月10日，透過線上媒體發布會，進一步揭露更多新產品線Tanzu的內容。新產品線Tanzu有3個關鍵產品，首先是提供了單一控制機制的Tanzu Mission Control，可用於管理不同環境的大規模K8s叢集；其次是Tanzu Application Catalog，這個目錄列出了Bitnami技術打包的標準化K8s應用包，供企業快速部署選用；最後是VMware自家的K8s發行版本Tanzu Kubernetes Grid。
而內建K8s的新版vSphere 7，除簡化生命週期管理機制，也強化了內部安全機制，且為因應AI和機器學習等新型應用程式，不只新增了GPU虛擬化，還改變DRS既有演算法，從每5分鐘執行一次，提高為每分鐘執行一次。此外，VMware也一併發布了新版的VMware Cloud Foundation 4，將其定位成，為傳統和現代化應用設計的混合雲平臺，可支援原生K8s。
不過，現階段僅有Tanzu產品線的3個關鍵產品：Tanzu Application Catalog、Tanzu Kubernetes Grid和Tanzu Mission Control，已發布正式版。其餘的新產品，包含此次發布會的核心產品vSphere 7和VMware Cloud Foundation 4，還有VMware VMware vSAN 7、VMware vRealize Automation 8.1和VMware vRealize Operations 8.1，都將於5月1日前，才會推出正式版。（詳全文）
  GCP平臺     雲端地區    中東  
Google一口氣宣布4個新雲端地區的建置計畫，首度插旗中東市場

Google近日宣布新一波雲端地區的建置計畫，將於印度德里、卡達杜哈、澳洲墨爾本和加拿大多倫多，建立新的雲端營運中心。這些新雲端地區將具有3個可用區域，企業可藉此分散工作負載和應用，來防止服務中斷，而新地區將提供的是GCP平臺的標準服務項目，包含Compute Engine、GKE、BigQuery等，不過，Google尚未透露新地區的啟用時間。
除了卡達之外，Google在印度、澳洲和加拿大已皆有一個雲端地區，分別是在孟買、雪梨和蒙特婁，所以一旦當地的第二個雲端地區啟用後，將可為企業的關鍵任務應用程式提供境內的災難復原服務。而杜哈不僅是Google在卡達境內的第一個雲端地區，更是其在中東市場布局的第一個雲端地區，Google是三大公有雲業者中，最後一家插旗該市場的業者。Google表示，卡達雲端地區將不只鎖定中東企業的用雲需求，也會將觸角延伸至非洲市場。（詳全文）
  微軟     Azure    中斷  
Azure美東地區發生故障事件，歷時逾6小時

微軟Azure的美國東部雲端地區，於當地時間3月3日早上9點半，發生服務故障事件，主因是資料中心溫度過高。故障期間，幾乎所有的Azure服務都出現了儲存或連線的問題，且持續長達逾6個小時。微軟於事故發生後3日，就該突發狀況發布了一份事故調查分析報告。微軟表示，部分用戶無法連線美東地區的雲端資源，是因資料中心的溫度自動化控制機制發生故障，而導致多個機房空間的溫度急遽上升，進而影響儲存、運算、網路等相關服務。
儘管冷卻系統已採取N+1備援的方式，但是，微軟指出，該故障導致冷卻氣流大幅減少，因而引發後續一連串的問題，包含網路設備無反應、VM關機，以及部分儲存硬體設備下線。微軟透過重新設定冷卻系統的控制器，來修復溫度自動化控制機制的問題，並待機房溫度恢復正常後，由工程師手動重新啟動受影響的硬體設備，以恢復該地區的雲端服務。微軟表示，正著手檢查該資料中心的自動化溫度控制系統和冷卻系統，一旦發現問題，將同步調整其他資料中心的設定。（詳全文）
  分散式資料庫     免費用量     Azure  
微軟為分散式資料庫服務Azure Cosmos DB增加免費使用等級帳戶

微軟於3月6日宣布，為分散式資料庫服務Azure Cosmos DB新增免費的使用等級，可用於建立新應用，或是用於開發、測試和執行小型的工作負載。採用該等級的企業，每月可以獲得400 RU/s和5 GB儲存空間的免費服務用量，若超過該使用額度，則依照該服務的標準定價模式付費，目前該服務以用戶每小時配置的吞吐量和使用的儲存空間來計價。此外，企業的應用程式如含多個容器，可以在共享的吞吐量資料庫（throughput database）中，最多建立25個容器，讓這些容器共同使用每月400 RU/s的免費額度。
過去，微軟已提供兩種可試用Azure Cosmos DB的途徑，一個是使用該服務的本地模擬器，另一個則是使用該服務的30天試用版。微軟表示，與這些試用選項相比，新的免費等級對服務可用性和範圍的限制較小。 不過，該等級在使用上也有限制，每個Azure訂閱用戶最多只可以取得一個免費帳戶。（詳全文）
  電信業     Google雲端     邊緣環境   
Google推出專為電信業打造的Anthos for Telecom 
鎖定電信產業的轉型需求，Google雲端近日宣布電信市場的3大布局策略，並發布專屬該產業的平臺和解決方案。首先，因應5G時代，Google雲端將提供電信業者建置商業服務平臺所需的服務；其次是藉由資料分析的服務，增加電信業者與客戶間的互動；第三，聚焦改善電信核心系統的營運效率。
同時，Google雲端發布了全球行動邊緣雲端（Global Mobile Edge Cloud，GMEC）平臺，這是一個5G解決方案的市集，也是一個開放的雲端平臺，可供各大電信業者開發各種以網路為中心的應用。另外，針對電信產業的需求，Google還把以K8s打造的跨雲管理平臺Anthos，帶到了邊緣環境，以打造專屬該產業的解決方案，藉此提供網路導向（network-centric）的應用程式一個開放平臺，讓電信業者可在任何地方執行應用程式。（詳全文）
  AWS     銷售團隊     公雲競爭   
面對日益的競爭壓力，AWS計畫今年翻倍銷售人員的數量
AWS日前於一場銷售人員的聚會上宣布，將於今年大幅度地提升銷售團隊的人數，以提升銷售業績。身為公有雲龍頭的AWS，雖一直保持領先者的地位，但相對主要競爭者去年的表現，微軟Azure成長約64%、Google雲成長更達87%，其則僅成長32%，反映其成長出現放緩的現象。面對競爭壓力日益提升，AWS計畫讓銷售團隊的規模翻倍，將聚焦招募網路安全、人工智慧、資料分析等領域的專家，來強化銷售團隊的專業技術背景，以回答企業用戶提出的技術問題，特別是針對大型企業的疑問。AWS希望藉此加快交易的速度，同時，提升銷售業績。（詳全文）
圖片來源／VMware、Google雲端、微軟
  更多Cloud動態  
1. 甲骨文預測，至2025年，於雲端共用的敏感性資料將增加600倍（詳全文）
2. Google雲端為語音轉文字服務新增支援，聚焦ML訓練資料較缺乏的7種語言（詳全文）
3. 因應疫情，Google開放Hangouts Meet進階功能給所有G Suite和G Suite for Education的用戶，於7月前免費使用（詳全文）
4. 南非標準銀行正在將自家SAP ERP搬上微軟Azure，以改善客戶體驗（詳全文）
資料來源：iThome整理，2020年3月
",https://www.ithome.com.tw/news/136324,"新聞,K8s,vSphere 7,上市時間,GCP雲端地區,卡達,Azure中斷,分散式資料庫"
136270,5,2020-03-10,VMware終於全力擁抱K8s，新版vSphere 7和全新產品線Tanzu更多細節揭曉,VMware執行長Pat Gelsinger更表示：「擁抱K8s，這是10多年來vSphere最重要的架構，自vMotion發布後，我們從未如此興奮。」," VMware早在去年產品大會上，就揭露了將改用K8s重新打造下一代vSphere的消息。經過逾半年時間，VMware終於在今日（3/10）透過線上媒體發布會，揭露了更多新產品線Tanzu的內容。該產品線是VMware在去年VMworld上發布的重磅消息，是其第一個聚焦K8s的產品線。
幾家基礎架構主要平臺商，如微軟Windows或IBM的紅帽，早在幾年前就全力擁抱容器和K8s，連Google都推出K8s本地端混合雲軟體，終於，VMware也開始加速進軍K8s市場。VMware營運長Sanjay Poonen在今日的記者會上表示，在基於容器技術的微服務世界，「VMware將擁抱K8s，想要成為最佳的企業容器平臺。」VMware展現了積極追趕對手的企圖。
Sanjay Poonen表示：「容器技術的出現，讓虛擬化的疆界逐漸模糊。」過去６年，不斷有人問他，「容器何時會淘汰VM？」直到現在，VMware終於揭曉答案，「VMware將在虛擬層上發展容器平臺。」這也揭示了VMware的新產品戰略。再加上近期各項收購案的軌跡，以及新產品線的發展，更反映出VMware下一階段的目標是，發展現代化應用及雲端原生技術。
新產品線Tanzu有3個關鍵產品，首先是去年年度大會上，已經搶先發布的Tanzu Mission Control（Tanzu任務控制器）。該控制器提供了單一控制機制，來管理大規模的K8s叢集，且部署於不同環境的叢集也可管理，除了VMware自家雲端服務外，該控制器也支援AWS、Azure或代管式K8s服務，甚至是企業自行建置的客製K8s。
透過Tanzu Mission Control，維運人員不只可調度K8s叢集，還可建立關於存取、備份和安全的核心政策，包含身份存取、安全配置、法規遵從性和資料保護。同時，這個控制器可以結合VMware雲端監控服務Wavefront，提供一站式的視覺化監控功能，也可整合VMware自家服務網狀網路（Service Mesh）功能，可用於管理K8s應用的各項服務。
其次是由Bitnami技術所支援的Tanzu Application Catalog，這是一個應用程式目錄，列出了那些用Bitnami技術打包的標準化K8s應用包，可供企業快速部署選用。第三個產品是VMware自家的K8s發行版本Tanzu Kubernetes Grid，源自Enterprise PKS，可用於跨雲環境，並提供K8s叢集的全生命週期管理機制。
今天揭露的其他Tanzu產品還有，由Pivotal打造的框架Spring Boot，可供企業建立以Spring為基礎的應用程式，而透過Tanzu Application Service，企業能派送軟體到安全且自動化的平臺，最後，Tanzu Observability by Wavefront可供企業觀察應用程式端、基礎設施端的分析結果。
而此次產品發布會的重頭戲是，代號太平洋計畫的新版vSphere，這個第七版vSphere的最大亮點是，內建了K8s，可直接建置和部署K8s叢集。VMware執行長Pat Gelsinger更表示：「擁抱K8s，這是10多年來vSphere最重要的架構，自vMotion發布後，我們從未像今天這樣如此興奮。」
VMware目標是推動現代化應用，而這需要現代化基礎設施的支援，才可實現，VMware技術長暨雲端平臺業務部門副總裁Kit Colbert解釋，vSphere 7的改變，就像是「根本地實現了vSphere自身的現代化。」
VMware重新架構了vSphere，將vSphere的核心ESXi換成了一個超級K8s叢集，同時，將K8s API整合到vSphere的API中，讓企業能以ESXi管理VM的方式，來運用K8s的能力。不過，Kit Colbert強調，vSphere 7仍可支援企業既有的應用程式。
vSphere 7有三大功能調整，第一，簡化生命週期管理機制，針對數百、數千個vSphere實例的管理情況來優化，當企業進行預期狀態（desired state）的管理時，可指定單一ESXi主機映像像檔，並能將該狀態的管理套用至其他主機。第二，新版聚焦內部安全機制的強化，簡化憑證管理，減少了管理員需管理的憑證數量，來確保他們握有最新的憑證。
最後，應用程式方面，為因應AI和機器學習等新型應用程式，VMware除新增GPU虛擬化外，也改變DRS（Distributed Resource Scheduler）既有演算法，從過去每5分鐘執行一次，提高為每分鐘執行一次。
VMware也一併發布了新版的VMware Cloud Foundation，並將其定位成，為傳統和現代化應用設計，包含支援原生K8s，所提供的混合雲平臺。
不過，vSphere 7對舊有產品的支援，VMware對此語帶保留，未詳細說明升級的細節，僅強調，vSphere是整個Tanzu產品線的核心，許多產品已因應新版本做更新，接下來幾個月內，會持續新增可支援vSphere 7的產品。
按過去每次VMware推出新版產品的慣例，在正式版發布時，會提供向下相容比較矩陣（compatibility matrix），來說明版本升級的衝擊。
VMware原定明日（3/11）於美國舊金山舉辦產品發布會，但受武漢肺炎（COVID-19）疫情的影響，該活動已改於線上舉辦。
",https://www.ithome.com.tw/news/136270,"新聞,K8s,現代化應用,容器,虛擬化,微服務,生命週期管理，vSphere 7,Tanzu產品線"
136105,6,2020-03-03,BMC收購老牌大型主機軟體商Compuware,基於傳統大型主機應用開發市場，正逐漸轉向DevOps，促使系統管理軟體供應商BMC，決定買下Compuware以取得主機軟體開發及生命週期管理解決方案," 為力拚大型主機的管理市場，系統管理軟體供應商BMC周一宣布從私募基金業者Thoma Bravo手裏收購老牌主機應用開發、交付及支援軟體公司Compuware。
2014年Thoma Bravo才以24億美元收購Compuware，當時雙方並未透露交易金額。
這項交易將結合BMC的大型主機系統管理、儲存管理，包括自動化大型主機智慧（Automated Mainframe Intelligence，AMI）、Topaz套件與ISPW技術，及Compuware的主機軟體開發及生命週期管理產品線。BMC指出，新合併的公司將可協助客戶實踐DevOps策略，強化大型主機運作、安全、應用開發、資料及儲存，且無縫整合主機平台開發和管理流程。
BMC總裁暨執行長Ayman Sayed也指出，現在整合Compuware產品是最佳時機，因為傳統大型主機AppDev（應用開發）市場，正逐漸轉向DevOps。
BMC於2013年自公開股票交易市場下市，而在2018年自己也被私募基金公司KKR以超過80億美元收購。該公司目前擁有一萬多家企業客戶，包括航太大廠洛克希德馬丁、SAP及倫敦交通局等。
BMC在收購市場上仍相當活躍。去年底BMC先是買下安全資訊及事件管理（Security Information and Event Management，SIEM）廠商CorreLog，上個月再收購專攻IBM Z主機的軟體商RSM。
大型主機在企業市場上多年來一直屹立不搖，也成為新技術廠商爭相吸引的對象。Google最近收購Cornerstone，以吸引主機客戶將應用搬上雲端，而IBM也推出適應多雲環境的最新一代主機z15。
",https://www.ithome.com.tw/news/136105,"新聞,BMC,大型主機,Compuware,DevOps"
135923,6,2020-02-20,Red Hat 5月終止支援CoreOS Container Linux,主要有三種轉換選項，除了Fedora CoreOS，也可改用由CoreOS Container Linux分叉出的Flatcar Container Linux，此外，Red Hat Openshift也內建RHEL CoreOS," Red Hat本周宣布將在2020年5月26日，終止對CoreOS Container Linux的支援，呼籲用戶儘速轉換到其他作業系統，像是Fedora CoreOS。
5月底CoreOS Container Linux來到生命周期終點（EOL）後，用戶將無法獲得安全及功能更新。
CoreOS Container Linux是很適合跑容器的輕量級作業系統，支援多種叢集架構，並具備自動更新功能，容器runtime可以選擇Docker或CoreOS自有的Rocket（rkt）。Red Hat2018年初買下CoreOS公司，但之後宣布以Red Hat CoreOS及Fedora CoreOS取代CoreOS Container Linux。Red Hat稱Fedora CoreOS為CoreOS Container Linux的「正式繼承人」。
Red Hat指出，Fedora CoreOS是專為大規模而安全執行容器化作業而設計的Fedora版，結合了ContainerOS的調撥（provisioning）及自動更新工具，以及封裝技術、OCI映像檔格式支援及SELinux安全存取技術。
RedHat去年年中釋出Fedora CoreOS預覽版，上個月釋出正式版。
今天起，AWS Marketplace上的CoreOS Container Linux將不再接受新訂閱戶。原有訂閱戶仍可使用，也不影響透過CoreOS官網以AIM ID啟用的Container Linux。最後一版CoreOS Container Linux將自5月26日釋出。但之後任何臭蟲及安全漏洞，都不會有修補程式。
而從9月1日起，CoreOS Container Linux的所有相關公開資源，都會刪除或僅提供唯讀服務。用戶將無法下載OS、CoreUpdate伺服器也會關閉，AWS、Azure、Google Compute Engine上的OS映像檔也會移除。GitHub上的issue tracker和文件將只提供純讀取。現有CoreOS Container Linux機器還是可以跑，只是不會有更新。未來在公有雲上，也將無法啟用新的CoreOS Container Linux機器，除非有事先準備。
此外，9月1日後，Red Hat也會加強力道來移除CoreOS Container Linux物件和映像檔，以防止這些OS在沒有安全更新下繼續使用。
Red Hat也提供從CoreOS Container Linux搬移到Fedora CoreOS的指示。但也提醒Fedora CoreOS目前還無法取代CoreOS Container Linux所有應用情境，包括不支援Azure、DigitalOcean、Google Cloud Engine、Vagrant，不包含rkt container runtime。此外，Red Hat 警告，Fedora CoreOS雖具備相當穩定性，但可能在某些情況中還是會出錯。
如果用戶不想用Fedora CoreOS，Red Hat建議用戶也可改用由CoreOS Container Linux分叉出來的Flatcar Container Linux。此外Red Hat Openshift也內建RHEL CoreOS。
",https://www.ithome.com.tw/news/135923,"新聞,CoreOS Container Linux,終止支援,安全更新,Fedora CoreOS,Red Hat,容器,Container"
135875,6,2020-02-18,Amazon EBS布建IOPS SSD現可同時連接多個EC2執行個體,EBS儲存磁碟區啟用多重附加功能後，最多可連接16個EC2執行個體，AWS提醒，應用程式需要具備寫入排序功能才能維持資料一致性," 在AWS EC2上執行Linux的用戶，現在可以將布建IOPS SSD（Provisioned IOPS，io1）Amazon EBS儲存磁碟區（Volume）附加到多個EC2執行個體上。布建IOPS SSD是專為需要維持低延遲的交易工作負載設計，是Amazon EBS最高效能的SSD磁碟區。
每個EBS儲存磁碟區啟用多重附加（Multi-Attach）選項之後，可以最多連接16個EC2執行個體，而每個Nitro EC2執行個體，也都支援連接多個啟用多重附加功能的EBS儲存磁碟區，AWS提到，多重附加功能可讓具有寫入排序功能以維持儲存一致性的應用程式，更容易達到高可用性。
AWS提到，由於多個執行個體同時寫入資料，存在資料被覆蓋而產生不一致的問題，因此用戶的應用程式必須要具有寫入排序的能力，以維持儲存的一致性。Linux可以使用單一寫入器與多重讀取器的方法，只開放給一個執行個體讀寫，並限制其他執行個體只能讀取，另一種方法為，用戶直接在應用程式程式碼中強制管理寫入排序，以維持資料寫入的一致性。
用戶可以使用AWS命令列工具或是控制臺設定多重附加磁碟區。在AWS控制臺中，用戶可以在EC2的頁面創建磁區，在磁區類型選擇布建IOPS SSD，並且輸入需要的大小和IOPS，然後勾選多重附加選項即可，而用命令列工具也很簡單，同樣使用EC2創建指令，並且加上—multi-attach-enabled選項即可。
用戶可以使用Amazon CloudWatch指標來監控啟用多重附加功能的磁碟區，並且使用Linux iostat工具監控每一個執行個體的效能，AWS提醒，創建的附加磁碟區以及執行個體必須要在同一個可用區域（Availability Zone ）中。用戶不需要為布建IOPS SSD的多重附加功能支付額外的費用，目前在美東維吉尼亞北部和俄亥俄、美西奧勒岡、歐洲愛爾蘭以及亞太首爾地區開放。
",https://www.ithome.com.tw/news/135875,"新聞,AWS,EBS,io1,Linux,EC2,IOPS SSD,SSD磁碟區,低延遲,Cloud,雲端"
135869,6,2020-02-17,AWS CloudFormation StackSets跨帳戶跨地區部署堆疊更簡單,只要在AWS Organizations和CloudFormation StackSets共享資料，StackSet就能在多帳戶和地區調度CloudFormation相關服務," AWS簡化AWS Organizations多帳號使用CloudFormation StackSet的方法，現在用戶可以跨多個AWS帳戶和地區，集中調度協調任何支援AWS CloudFormation的相關服務。另外，用戶也能設定帳戶在加入或是從Organization中刪除時，系統會自動加入或是移除堆疊資源
AWS CloudFormation讓用戶能夠自動化雲端基礎設施，以基礎設施即程式碼（Infrastructure-as-code）的方式，透過機器可讀的文字檔案，像是JSON與YAML，或是開發者熟悉的Java、Python或TypeScript等程式語言，來管理和創建IT基礎設施。
而CloudFormation StackSets則可以讓用戶快速地在多個AWS帳戶和多個區域中，快速部署CloudFormation堆疊。在AWS推出StackSets功能時，對帳戶分組以方便收費，而在AWS Organizations上線後，用戶已經可以根據各種業務需求，集中管理多個AWS帳戶的帳單、存取控制、法遵要求、安全性和資源共享。
AWS進一步整合CloudFormation StackSet和AWS Organizations，簡化CloudFormation StackSet跨帳戶權限的配置，AWS舉例，現在用戶能夠部署集中式的AWS身份和存取管理（IAM）角色，並且在組織中跨AWS地區和帳戶，配置EC2執行個體或是AWS Lambda函式。
要啟用這項新功能，用戶需要在控制臺設定共享StackSets以及AWS Organizations間的資料，接著便能夠在Organizations的主帳號中，使用StackSets部署堆疊到組織中的所有帳戶，而用戶能夠方便地選擇服務託管授權，StackSets便會自動配置堆疊必要的IAM權限。
除了配置權限之外，CloudFormation StackSets現在還提供了另一個自動化選項，當新AWS帳戶加入Organization時，StackSets會自動創建CloudFormation堆疊，而有帳戶離開Organization時，也會自動刪除堆疊。用戶也可以決定堆疊要部署到整個Organization，也可僅是一個或是多個OU（Organization Units）。目前這項新功能在所有StackSets可用的AWS地區提供。
",https://www.ithome.com.tw/news/135869,"新聞,AWS,CloudFormation,基礎設施即程式碼,雲端,Cloud,帳戶管理,帳號管理"
135818,6,2020-02-14,GCP改善單租戶節點更新功能加入即時搬遷政策,用戶選用即時搬遷政策，可以在不停機且以花費最低的授權許可下，執行主機維護事件," Google更新單租戶節點功能，用戶可在Windows自有授權（BYOL）的固有節點池中，進行即時搬遷（Live Migration），且節點群組現在還具有自動縮放功能，目前這兩個功能仍在測試階段，另外，Google讓工作負載可在單租戶與多租戶節點之間搬遷，提升用戶在專用硬體上部署的靈活性。
現在單租戶節點用戶能選用新的節點群組維護政策，擴展用戶在專用機器上的控制，只要使用這個新配置，用戶就可以指定單租戶節點群組的執行個體，在主機維護事件時的行為，以避免用戶在使用以核心或是處理器為單位的授權時，產生額外的授權許可成本，同時還能維持最新核心和安全更新。
新的節點群組搬遷（Migrate Within Node Group）維護政策，不只透明化核心更新的安裝過程，而且虛擬機器還不需要停機，同時也可以將物理核心使用量降到最低。在主機維護事件過程，透過將即時搬遷執行個體的範圍，限制在固有的單租戶節點池中，用戶可以動態地在已授權的伺服器間移動虛擬機器，以避免授權污染。
透過即時自動搬遷功能，主機能獲得最新的核心更新，用戶可在授權許可成本、工作負載運作，以及平臺安全性間取得平衡。當然用戶也可以在節點群組使用預設選項，而這將會使執行個體，在維護事件時移動到新的主機上，或是就地重新啟動，不過這將會暫時終止執行個體，在主機維護事件後，才在同一臺物理伺服器上重新啟動。
Google也為節點群組新增自動擴展器，當用戶有動態容量需求時，單租戶節點群組自動擴展器將會自動管理單租戶節點池，當單租戶節點群組無法容納新執行個體時，自動擴展器會增加節點群組的容量，並在偵測到有空節點時，自動縮小容量，可提高資源使用率，並降低基礎設施的成本。
另外，Google為了提升工作負載的靈活性，用戶現在可以根據安全性、法遵要求與效能隔離需求，決定將執行個體移入或是移出單租戶節點。當用戶要應付大型線上購物節日或是遊戲上線等特殊事件時，可選擇將執行個體移入單租戶節點，以取得最佳效能或是更進階的控制。
",https://www.ithome.com.tw/news/135818,"新聞,GCP,單租戶,BYOL,Cloud,雲端"
135534,6,2020-01-27,Google雲端Spark叢集服務Dataproc現可運用GPU加速運算,Dataproc用戶可以在叢集中附加GPU，在工作流程中混合Spark機器學習與GPU深度學習演算法運算," Google更新雲端原生Apache Spark和Hadoop叢集服務Dataproc，可讓用戶使用新的開源工具、演算法和程式語言，來處理大量資料集，新功能還可讓用戶以個人化開發環境，建置生產系統。
這個版本Dataproc簡化開發環境，提供自動擴展和筆記本的功能，讓資料科學家可以在熟悉的筆記本環境工作，不需要更改底層資源或是與其他人競爭叢集處理資源。Dataproc自動擴展功能，用戶可以在隔離且客製化的小型叢集上工作，進行建置或是開發自定義套件等工作。
當分析工作開發完成，準備應用完整資料集運算時，用戶只要啟動自動擴展功能，就可以在相同的叢集和筆記本環境進行分析，叢集會自動擴展至處理整個資料集需要的規模，並在處理完成後自動縮小，用戶不用麻煩地搬遷工作到其他容量更大的伺服器上。Google表示，結合自動擴展和筆記本環境功能，提供用戶適當的叢集規模，以及良好地協作環境，可快速地將開發的成果過渡到生產環境中。
使用Dataproc Jobs API，用戶可以透過HTTP呼叫Jobs.submit，提交工作到現有的Dataproc叢集上。現在Dataproc正式支援新的SparkR工作類型，用戶可以記錄和監控SparkR工作，並更容易地以R程式碼建構自動化工具。
另外，Google提到，通常Spark和Hadoop框架是預處理的工具，適合創建可用於GPU深度學習模型的資料集，因此Dataproc現在可附加GPU到叢集中，讓使用者省去重新配置底層叢集資源的時間與手續。
在單個工作流程模板中，用戶可以自動化一系列混合Spark機器學習和GPU深度學習演算法的工作，當需要擴展單個GPU記憶體上的資料集時，Dataproc上提供RAPIDS框架，用戶可以使用GPU和Dataproc的功能，以API呼叫的方式啟動和控制虛擬機器叢集。
Dataproc還提供了排程刪除叢集的功能，不少模型建立與SQL查詢工作，都要花費一整天的時間，用戶可能會在開始一項長期工作後，暫時離開工作崗位甚至放假回家，雖然使用更多的運算資源，可以加速取得結果的速度，但是無人看守的工作，使用更多的資源代表可能需要支付更多的費用。現在當用戶利用Dataproc Jobs API提交工作時，可以同時使用叢集刪除指令，在空閒時間自動刪除叢集，讓用戶可以不用一直檢查叢集工作進度，並自動刪除完成工作的叢集。
",https://www.ithome.com.tw/news/135534,"新聞,google,Dataproc,GPU,Cloud,Apache Spark,Hadoop"
135525,6,2020-01-25,Google雲端T4 GPU現降價超過60％,以在us-central1地區為例，按需T4 GPU從原本0.95美元降價63.2％，現在價格為0.35美元," Google宣布將其T4 GPU價格降低超過60％，目前成為Google雲端上價格最低的GPU執行個體。T4 GPU具有混合精度和16 GB記憶體，適合用於機器學習工作負載。Google提到，T4 GPU用在機器學習的效能，使用ResNet 50模型，以128批次大小與Int 8精度運算，每秒可處理4,267個圖像，相當於n1虛擬機器1個小時，能處理1,500萬個圖像預測。
以在us-central1地區來說，按需1個小時T4 GPU的附加價格，原本為0.95美元，現在只要0.35美元，降幅達63.2％，而以先占式虛擬機器來說，原本附加1個T4 GPU的成本為0.29美元，現在則只要0.11美元，降幅也有63.1％。實際價格在每個地區有所不同。

Google是全球第一個提供T4 GPU服務的主要雲端供應商，現在Google升級T4的網路速度到100 Gbps，目前仍是測試版，之後會在其他地區陸續升級。除了機器學習，T4 GPU執行個體也可以靈活地用在其他工作負載，其支援自定義n1機器類型，用戶可以依需求調整vCPU、記憶體和T4 GPU的使用容量。
",https://www.ithome.com.tw/news/135525,"新聞,google,GPU,T4,機器學習,Cloud,雲端"
135518,6,2020-01-24,CircleCI推出自動化部署配置工具Orbs，可整合AWS、GCP以及K8s,持續部署配置工具CircleCI Orbs可簡單地連接CI/CD工作管線到雲端平臺上，執行應用程式自動化部署," 持續整合與交付平臺CircleCI發表了配置套件CircleCI Orbs，用戶可將CI/CD工作管線，與20多個服務供應商，包括AWS、GCP和Salesforce等連接，執行自動化部署工作。也就是說，CircleCI Orbs讓開發人員可以直接從持續整合工作管線中，自動執行軟體部署工作。
CircleCI提到，要在CI/CD工作管線中，設定自動化部署主要有兩項障礙：程式碼覆蓋率與CI/CD工作管線不支援。對程式碼沒有信心的團隊，不應該採用自動化部署，而為了解決這個問題，CircleCI Orbs具有可用於測試程式碼的服務，可以讓用戶增加程式碼覆蓋率，並彌補缺少測試的地方。
另外，企業使用的CI/CD工具，可能不支援部署至AWS ECS或是Google Cloud Run等雲端服務的功能，過去企業需要自己撰寫整合程式，而現在可以使用CircleCI Orbs簡化連接工作。
透過CircleCI Orbs，開發者不需要大幅更動現有的基礎設施，只需要在配置中，增加幾行預打包的程式碼，就能完成自動化部署的設定工作，而這將使開發團隊更快地發布新功能。官方提到，企業可以直接在自家的CI/CD工作管線使用CircleCI Orbs，只要數分鐘就能完成設定，將應用程式自動部署到任何測試或是生產環境。
CircleCI Orbs主要有三個分類，分別是部署至雲端、Kubernetes以及其他服務。雲端平臺支援Amazon ECS、Cloud Foundry、Google Cloud Run和Heroku等，而Kubernetes平臺則有紅帽OpenShift、Helm、Google GKE、Amazon EKS和VMware Code Stream等，其他服務平臺則有Pulumi、Spinnaker與Salesforce等。
",https://www.ithome.com.tw/news/135518,"新聞,Circleci,CI/CD,DevOps,開發,自動化部署,雲端平臺,Kubernetes,K8s,持續整合,持續交付"
135409,6,2020-01-17,Google雲端推出高級支援計畫，將由深入了解用戶專案的專家提供意外事件協助,高級支援專家將會了解用戶特殊的系統以及實作細節，以求在意外事件發生時更快速地支援用戶," Google雲端發布新的高級支援（Premium Support）服務，目的是要更全面地支援，將關鍵應用放在Google雲端基礎設施上的企業。
Google提到，這項服務是利用目前的技術客戶經理以及15分鐘SLO（Service-Level Objective）構成，以更積極主動的方法服務用戶。訂閱高級支援服務的用戶，將會直接由了解用戶的專家服務，這些專家會了解用戶專有的應用程式堆疊、基礎架構以及實作細節，並與技術客戶經理合作，以更快的速度和客製化的方式支援用戶。
高級支援的定價，比起過去的Google雲端支援產品，定價更加簡單，雖然高級支援根據用戶每月的花費而定，但其價格依然不便宜，最低價格每月約為12,500美元。該支援計劃將為P1事件，包括生產應用程式和基礎設施無法使用等情況，提供15分鐘的回應時間，其他服務特色還有提供訓練，以及新產品介紹，與第三方系統的故障排除等支援。
另外，為支援更多元的商業形式以及特殊的需求，高級支援提供了進階的加值服務供用戶購買，包括進階事件管理服務，用戶可以要求支援團隊更深入的審查基礎架構，並提高對高峰事件的準備程度，這項服務可供用戶單獨購買。
還有，用戶也可以擴大技術客戶經理的服務範圍，當企業散布在多個時區，用戶可以在其他地區的工作時間，購買技術客戶經理支援服務。另外，Google將會在稍晚的時候，推出網站可靠性工程（SRE）服務，可以評估並幫用戶針對最重要的關鍵專案，設計可支援性打包（Wrapper of Supportability），與用戶之間建立緊密連結，可使用預定義的戰情室解決重大事件。
",https://www.ithome.com.tw/news/135409,"新聞,google,支援,SRE,Cloud,雲端"
135398,6,2020-01-16,CNCF為K8s提供漏洞賞金計畫,Kubernetes漏洞賞金計畫獎勵研究人員發現核心元件漏洞，以及Kubernetes建置與發布等供應鏈環節的漏洞," 雲端原生運算基金會（CNCF）發布了新的Kubernetes的漏洞賞金計畫，以獎勵發現Kubernetes漏洞的研究人員，給予100美元到1萬美元不等的獎金。這項計畫由CNCF、Google和漏洞賞金計畫廠商HackerOne合作提供。
Kubernetes是CNCF旗下的專案之一，受到廣泛的使用，其安全性受到高度的重視，在之前從孵化器畢業時，CNCF就出資對Kubernetes進行了首次的安全審核，作為畢業的檢驗標準，該次審核發現並且解決了一些過去未知的安全問題，而Kubernetes也已經成立了自己的產品安全委員會，成員包括了來自Google Kubernetes Engine安全團隊的工程師，負責修補新發現的漏洞。
早從2018年開始，Kubernetes產品安全委員會就開始討論啟動正式的漏洞賞金計畫，以吸引新的安全研究人員為社群工作。新推出的賞金計畫的涵蓋的範圍，包含了GitHub儲存庫中所有Kubernetes核心元件的臭蟲，包括遠端程式碼執行、特權升級或是身份驗證錯誤等。
另外，由於Kubernetes是一個社群專案，因此在Kubernetes供應鏈中的臭蟲也是這項計畫的獎勵對象，像是建置和發布的過程，可能允許惡意人士未經授權存取提交，或影響其他建置生成檔案的臭蟲，也在獎勵範圍。不過，官方提到，社群管理工具、容器跳脫（Container Escape）、Linux核心攻擊，或是其他相依相目，則不在計畫範圍之內。
視研究人員發現的臭蟲嚴重程度，CNCF提供100美元到1萬美元不等的獎金，這項計畫已經秘密進行了幾個月，透過邀請研究人員提交錯誤以測試分類程式，而現在這項計畫正式啟動。與其他漏洞賞金計畫不同的是，CNCF沒有規定Kubernetes測試的標準環境，研究人員能以不同的方式配置Kubernetes，CNCF希望尋找出現在各種情況的漏洞。
特別的是，這是少見為開源基礎設施設置的漏洞賞金計畫，即便目前有一些開源的賞金計畫，像是網際網路漏洞賞金計畫，是針對跨環境部署的核心元件，而絕大多數的漏洞賞金計畫，都還是只針對託管的網頁應用程式，而Kubernetes卻擁有超過100個認證發布版，這項計畫是針對支援這些發布版，所共同使用的核心程式碼。
CNCF提到，Kubernetes漏洞賞金計畫最困難的部分，是確認漏洞賞金計畫廠商以及訓練第一線的研究人員，使其具備足夠的Kubernetes知識，以測試所有錯誤報告的有效性，HackerOne團隊也通過了Kubernetes管理員認證（CKS）測驗。
Google積極參與這項漏洞賞金計畫建置過程，從提出程序、廠商評估、定義初始範圍、測試程序以及幫助HackerOne上線等工作。CNCF則提到，他們盡可能透明地建立這個計畫，包括從最初的提案開始，到評估廠商以及相關工作草案等工作。
",https://www.ithome.com.tw/news/135398,"新聞,CNCF,Kubernetes,google,K8s,資安,漏洞,漏洞通報,臭蟲,漏洞獎勵"
135284,6,2020-01-16,【IT十年關鍵浪潮 4】DevOps：開發與維運的新典範,數位世界的競爭靠速度決勝負，但是，企業IT應用得越深，開發與維運的分工和合作就越複雜，敏捷開發只做了一半的工作，DevOps平臺和工具的成熟，讓開發團隊帶頭當責，從AP開發源頭，就開始加速到最後的維運," 在2010年世代才出現的數位世界是，大型科技業者的開發與維運高度分工化，全球使用者市場的變化越來越快，需求壽命越來越短，而企業可因應的時間越來越短，開發與維運任何一點的複雜度，都會變成拖累速度的大問題。
但是，傳統的企業IT發展上，隨著IT應用越廣、越深，規模越大，也就需要更多的人力和專業分工的團隊架構，但是，專業分工帶來的挑戰就是，開發跟維運之間的溝通複雜度越來越高，也就拖慢了企業回應需求的速度，還有新服務搶上市的時程。企業IT運用越深，開發與維運越是成了企業IT的新瓶頸。
DevOps的誕生，就是要解決這兩者之間的鴻溝，從AP的開發源頭開始，一路到部署、維運都自動化，讓開發團隊來當責，誰開發、誰負責到底，就是DevOps的精神。
2009年，來自Flickr員工在一場會議中所揭露了如何改善Dev和Ops的合作，達到了單日10次發布的高速度，催生了後來的DevOps運動，從比利時，迅速吹向全球。
DevOps的目標是，透過IT自動化和持續整合，來加速企業各項資訊服務推出的速度，但是這又牽涉到整個作業流程和組織文化的調整，才能兼顧發布速度和服務品質，而這正是企業數位轉型想要實現的目標之一，不少企業也將DevOps列入了數位轉型要實現的任務。
Docker和Kubernetes等容器技術的出現，讓IT基礎架構的管理，變成了可以程式化控制的手段，更讓DevOps如虎添翼，雲端服務的自助式服務和高度自動化維運，更大大降低開發團隊管理維運工作的負擔，透過DevOps流程和工具，來建立起從開發端的容器化應用，到雲端部署環境的維運，成了主流的新作法。
在2010世代，上雲是新創和網路公司的基本要求，他們都是雲端原生公司，而DevOps就成了這群挑戰者企業的基本能力。對傳統企業而言，數位轉型的課題就是要向新創公司學習，擁抱DevOps就成了必須面對的課題。
導入DevOps最基本要考慮的是工具面和組織流程面，得先知道有哪些工具，再來選擇合適者。從XebiaLabs設計的DevOps周期表中，可以快速一窺DevOps工具和平臺的成熟化。DevOps工具可以分成了程式碼管理、資料庫自動化、持續整合、測試、配置、部署、容器、發布協調、雲端平臺、AIOps、分析、監控、資安和協作等類型。

XebiaLabs設計的DevOps周期表。
不過，許多企業不見得，也不需要導入全套DevOps，而是先從持續整合（Continuous integration）來改善服務發布速度，但又同時搭配敏捷方法Agile的方法論和思維，來縮短開發週期，加快服務改版發布的速度。臺灣不少企業，尤其是大型金融業者，為了加快消費者端行動App的改版速度，更快回應使用者的新需求，近年來推動數位轉型計畫時，也會先從擁抱敏捷思維和持續整合著手。
 相關報導  數位轉型浪潮的源頭(上) IT十年、數位轉型浪潮的源頭(下) IT十年
",https://www.ithome.com.tw/news/135284,"新聞,數位轉型,回顧,技術,DevOps,XebiaLabs,DevOps周期表,開發,維運"
135278,6,2020-01-16,【IT十年關鍵浪潮 1】Cloud：IT資源全球調度力的關鍵架構,上雲，成了企業因應爆量需求、嘗試各種創新技術的關鍵架構，容器技術和Kubernetes技術的商品化，更大大降低了企業調度全球雲端資源的門檻，也是企業迎戰數位全球市場的武器," 花了10年，雲端運算技術，終於走出了一片雲端產業，上雲，企業可以快速具備全球化調度IT基礎架構資源的能力。上雲，也就成了過去10年來，企業數位轉型最重要的IT現代化策略之一。
Google帶頭將雲端運算拱成了2008、2009年的熱門IT話題，而AWS則用EC2、S3服務，將雲端VM和儲存做成了一門服務生意，連微軟都在2009年加入雲端市場競爭，正式推出了Azure雲端服務，形成了雲端多強競爭的局勢。
當時機房主流技術是VMware的虛擬化技術，同樣以虛擬化技術為主的AWS和Azure雲端VM服務，成了新創快速擴張市場的關鍵，當時，剛轉型線上影音服務的Netflix就是大膽上雲，利用AWS而不自建機房，快速擴大服務規模的經典例子，也成了企業上雲數位轉型策略的實證。
在2010世代的上半場，也就是2010～2015年間，越來越多企業開始願意將自家應用搬上雲端，也帶動將自家大型應用（Monolith），拆分成微服務型態的風氣，Restful API風格開始成為微服務架構的標準訊息傳遞方式後，企業更容易串接自家應用與雲端服務的資源，也降低了不少上雲門檻。
不過，這個時期也是VMware虛擬化技術的全盛階段，甚至2014年進一步將虛擬化技術延伸到儲存、網路，催生了新的超融合式架構，只需標準x86伺服器，就可以動態調度來支援運算、儲存或網路的需求，也實現了軟體定義的資料中心。企業可以自己打造一朵私有雲，在自家機房內，享有高可用性、彈性擴張的IT基礎架構調度能力。私有雲技術的成熟，儘管企業都對上雲有高度興趣，但又不需要急著上雲，只是用於實驗性專案或新興應用，還沒成為多數企業取代機房的主流選擇。
另一個影響企業上雲意願的關鍵是，各大公有雲平臺的高度不相容，即使都是採用虛擬化技術，但彼此所用的映像檔格式、配置設定、服務的API呼叫方式，差異很大，幾乎是，企業得針對不同的公有雲環境來客製化自己的AP才行，跨雲高門檻，造成了企業被廠商綁定的問題，成了上雲的一大阻礙。
上雲不只是機房的替代品，更是解決爆量和擁抱創新的關鍵
到了2010世代的下半場，2015年後，雲端服務不再只是扮演企業機房資訊基礎架構的替代品，Big Data和海量資料分析和零售爆量用戶承載的需求，讓雲端服務成了企業的關鍵選擇。
開源雲端運算平臺的OpenStack在2010世代中期問世，成了許多大型企業擺脫廠商綁定，自行打造全球性雲端架構來因應爆量用戶的新選擇，像美國零售龍頭Walmart，就是靠著10萬顆核心的OpenStack叢集，才撐住2014年黑色星期五的爆量搶購人潮。許多零售電商、電信業者都積極擁抱OpenStack來發展自己的雲。
2014年，Docker公司將自家PaaS平臺所用的應用程式封裝技術，變成了「容器」（Container）產品，在2010下半年掀起了雲端服務的新變革，甚至Docker被譽為次世代雲端技術。容器技術將應用程式的程式碼、配置和所需的執行元件，全部封裝起來，變成了一個可攜式軟體包，能快速部署到各種容器環境。
虛擬化技術也有類似的應用程式打包封裝作法，可以將應用程式打包成VM的映像檔來移動，但是容器不需要連同作業系統一起打包，大大縮小了映像檔的檔案大小，甚至只需要百分之一，幾MB的映像檔就夠了。再加上宣告式的開發環境和部署配置的描述方式，將基礎架構資源的管理程式化，變成了可以版本控管的環境。Docker成了可以取代虛擬化技術的新選擇，甚至連虛擬化技術龍頭都在2014年第一時間搶先支援Docker，而微軟則直接在自家Windows內建了同樣的Container標準技術。Container掀起了傳統IT架構下個十年的變革之路。Docker源自雲端服務，雲端供應商也紛紛推出雲端容器服務，將雲端變成了新興技術的實驗場所。
不過，容器技術仍有不足之處，只有滿足軟體生命週期中前半段的開發到部署的標準化封裝需求，還沒有涵蓋到應用程式完成部署，正式上線之後的維運階段，例如沒有納入運算資源擴大或縮小的調度作業。Kubernetes正是彌補了這一段需求的缺口，將容器技術擴大應用到了維運期，甚至可以應用到大規模部署和調度，將全球性基礎架構維運能力，也變成了一種商用化的企業級產品。全球爆紅Pokemon Go遊戲在2016年打造出GCE史上最大Kubernetes叢集，成了Kubernetes有能力提供全球性資源調度的最佳實證。
身為雲端服務先鋒的Google，直到2016年，才決定全力加入雲端全產品線供應商的競爭，選擇從大規模資料分析、Big Data、容器等新興技術應用領域切入競爭，帶動了雲端服務類型的多元化競爭。
近幾年，藉助雲端運算能力，需要大量數據蒐集和分析的深度學習技術，開始走向商用化，也成了雲端大廠競逐的新興服務，甚至可以說，想要打造AI服務，上雲租用AI基礎環境，反而比在內部機房自建更快、更容易也更方便。
不論是AWS、Azure或GCP，也紛紛建立一套從AI開發到部署所需的雲端工具和服務，甚至拿了就可直接用的特定用途AI，例如雲端翻譯、雲端文字辨識，甚至雲端AI客服、雲端AI推薦等。
最近2、3年，隨著企業逐漸將上雲視為數位轉型的關鍵策略，但雲端當機事件仍不時耳聞，企業不想只壓寶一朵雲，也迫使雲端產業的發展，開始聚焦跨雲和多雲管理的課題，公有雲大廠紛紛落地，私雲業者則紛紛上雲，或是發展出可因應斷線、離網的邊緣運算架構，例如AWS的Outposts主機或是GCP的Anthos私有雲軟體，而VMware則直接跟公雲合作，將VCF私雲平臺整套搬上雲，Kubernetes更成了多家公雲或私雲業者的共通平臺，紛紛將自家產品改用Kubernetes重新設計，來提高跨雲多雲的相容性，例如IBM、VMware等。
過去10年，Cloud成了企業調度全球IT資源的關鍵架構，下個10年，Cloud技術將邁向大整合和標準化，不論上雲、離雲、遠端或邊緣都可能納入同樣一套資源調度和管理架構，讓全世界變成一朵企業容易取用的共同雲資源。
 相關報導  數位轉型浪潮的源頭(上) IT十年、數位轉型浪潮的源頭(下) IT十年
",https://www.ithome.com.tw/news/135278,"新聞,數位轉型,上雲,雲端,Cloud,回顧,技術"
135109,7,2019-12-31,VMware完成27億美元的Pivotal收購案,這項收購案有助於VMware這家虛擬機器業者，轉型成雲端原生服務供應商," VMware在12月30日宣布，已完成27億美元的Pivotal收購案，同一天Pivotal也已被紐約股市除名，成為VMware的子公司。
Pivotal主要提供雲端平台代管及顧問服務，此一併購案將有助於VMware從一個單純的虛擬機器業者轉型成雲端原生服務供應商，可管理VMware原本所仰賴的基礎設施。
未來Pivotal將成為VMware Tanzu產品及服務的核心，而VMware Tanzu則是一個基於Kubernetes的平台，可協助客戶建置、執行與管理各種現代化的應用，並協助客戶將它們部署到資料中心、雲端或邊緣環境。
為此，VMware設立了一個新的現代化應用程式平台部門，整合了Pivotal及VMware雲端原生應用程式團隊，並指派VMware技術長Ray O'Farrell擔任新部門的負責人。
此次的交易同時結合了現金及股票，VMware以每股15美元的價格買下了市面上流通的Pivotal的股票，再以每股Pivotal換得0.055股VMware的比例，交換Dell手上的Pivotal股票，Dell總計取得了720萬股的VMware股票。
",https://www.ithome.com.tw/news/135109,"新聞,併購,收購,Pivotal,VMware,Tanzu,Kubernetes,K8s"
135084,7,2019-12-30,【2020年CIO必看趨勢8】雲端原生架構成主流，加速帶動企業IT現代化轉型,隨著容器、微服務、CI/CD、DevOps等雲端原生技術的成熟和商品化，雲端原生架構成企業資訊架構新主流，臺灣已有不少企業展開IT架構現代化工程，來擁抱這些新技術," 國泰金控、彰化銀行、凱基銀行、華南銀行、第一金人壽、和泰產險、營建署、鼎鼎聯合行銷、遠傳電信、中華電信等，這幾家都是近2年積極展開IT現代化大轉型的臺灣企業或政府機構，而且不約而同地，這些臺灣大企業所擁抱的IT技術，大多聚焦在容器、微服務、上雲、DevOps的相關技術或產品。當然不只有這些公司，早在今年年初的iThome 2019 CIO大調查發現，早就開始推動數位轉型的臺灣大型企業中，已有2成企業擁抱容器和微服務架構。甚至，金融產業更是積極，近3成企業已經開始或決定將擁抱微服務。
到了2019年底的企業雲端大調查結果，更反映出企業數位轉型的關鍵之一就是上述技術，21.6％臺灣企業為了上雲，有意採用微服務架構，18.7％則想用Container技術。高度雲端化企業中，更有45.7%明年要導入雲端CI/CD、28.6％要採用更多Container。
容器、微服務、DevOps這些技術通通指向了一個共同的目標，那就是雲端原生（Cloud Native）架構，而上述提到的那一群臺灣企業，就是開始邁向雲端原生架構的臺灣企業，而且不只有這些，雲端原生架構早就是臺灣網路公司、新創公司的必備基礎設施，沒有第二選擇，只有導入深度和廣度的差別。
雲端原生一詞，最早可以是2015年VMware旗下Pivotal公司提出來，當時強調的雲端原生特徵是，微服務架構、自助式服務、敏捷架構、API化、12因素的設計，尤其要拆解過去、傳統的大型單體應用系統（Monolithic）的架構。
雲端原生這個概念雖然獲得不少網路科技公司的青睞，但真正擁抱這個架構的傳統企業卻不多，關鍵就是相關的技術和商用產品並不多。隨著上雲逐漸成為企業資訊架構的新選擇，三大公有雲龍頭AWS、Azure和GCP逐漸吸引了大量新創和老企業、大公司的採用，上雲成了企業基礎架構的可行選項。
再加上Docker所帶動的容器浪潮，以及隨後發展出來的Kubernetes，讓不同公有雲、甚至是混合雲之間有了一套可以互通、共用的執行和部署環境，也就是K8s，連前一代壟斷企業基礎架構平臺的虛擬化龍頭VMware，都在今年自家年度大會上宣布，下一代核心產品虛擬化平臺vSphere，將會改用Kubernetes重新打造。
VMware這次大改版，不是披上Kubernetes外套的拉皮工程而已，而是真正砍掉重練的新設計，vSphere改將VM平臺，部署到Kubernetes上來執行。vSphere徹頭徹尾地變成了一個Kubernetes應用。
不只VMware，IBM也重新用Kubernetes改造了自家雲端平臺，甚至重金買下紅帽，就是看上Kubernetes平臺產品OpenShfit，未來在混合雲架構上的關鍵角色。連Google都用Kubernetes開發了一套落地的私有雲產品，而微軟則挖角Kubernetes創辦人之一來發展自家的Azure雲端平臺。
這些雲端原生相關技術和平臺的成熟，才真正讓雲端原生架構，可以實踐到企業商用市場中。
力推Kubernetes的CNCF組織全名就是Cloud Native Computing Foundation（雲端原生計算基金會），觀察雲端原生架構的發展，最好的方式，就是從CNCF的雲端原生技術地圖（Cloud Native Landscape）。
雲端原生產品市場規模近8兆美元
在這份技術地圖上，整理了361個雲端原生技術專案和產品，其中不少也有商用等級的企業版產品。CNCF基金會估計，投入這些產品的創投資金，超過了47.6億美元，但創造出來的整體市場規模，達到7.98兆美元的驚人規模，這也反映出，採用雲端原生架構和技術的市場規模，這已經是一個龐大的成熟技術市場，而不是新興市場。
從分類上，更可以看出雲端原生技術的發展逐漸邁向高度分工專業化，從資料庫、串流和訊息平臺、應用定義和部建、持續整合開發、排程和調度、協調和服務探索、RPC、服務Proxy、API閘道器、服務網格、資安和法遵、金鑰管理、監控、Logging、追蹤、混沌工程、Serverless等，以及最核心的平臺類技術、包括了開源K8s版本、K8s託管服務、K8s安裝軟體、PaaS服務等。這個地圖和產品清單，也可供企業一窺有哪些關鍵技術和產品，作為擁抱雲端原生架構導入的參考。
這麼多選擇，從哪裡開始著手？CNCF更提供了一份雲端原生上手地圖（Cloud Native Trail Map），整理出企業邁向雲端原生架構的10個階段，列出可採取的行動建議和推薦先導入的產品或專案，讓企業一步步循序漸進。這個地圖，也正是許多網路公司或大型企業邁向雲端原生架構的重要參考之一。技術成熟，商用產品到位、市場成形，企業想要擁抱這個IT現代化的新架構，也就不難跨出第一步了。
 相關報導  2020年CIO必看10趨勢
",https://www.ithome.com.tw/news/135084,"新聞,CNCF,DevOps,容器,資訊架構,Cloud native,微服務,Kubernetes,IT現代化轉型,數位轉型,Container,雲端CI/CD"
135083,7,2019-12-30,【2020年CIO必看趨勢7】K8s成混合雲互通新標準，企業擁抱多雲更不怕廠商綁定,企業將面對各雲端業者支援K8s的產品間，定價、介面等差異，IT團隊也必須投入資本與時間成本來上手。企業若不投入K8s，會被多雲環境淘汰," 混合雲早已不是雲端領域的新鮮事，但，過去企業發展混合雲架構有一大痛點，那就是雲端業者各自發展混合雲環境，導致各環境缺乏互通的標準。在2019年，這個相容性難題出現了解套方法，那就是以K8s作為互通的標準，多家雲端業者推出以K8s為基礎的混合雲產品。
混合雲的採用率穩定成長中，特定產業對資料因有較高的安全要求，許多企業規畫上雲策略時，採用混合雲或多雲的架構。從RightScale的2019年年度全球雲端大調查的報告中，可以看到84%的企業採取多雲策略，其中，導入混合雲架構的企業占58%，跨多個公有雲環境的企業占17%，而跨多個私有雲的企業則占9%。混合雲的部分，相比去年微幅跨過5成的關卡，占比為51%，2019年成長7%，比例近逼6成了，可視混合雲已進入主流，開始被企業納為雲策略的選項。
儘管，採用混合雲架構可讓企業利用公雲服務，同時，保留關鍵的業務資料和工作負載在本地端，但，企業面臨了環境互通的挑戰，這也是許多企業持觀望態度，遲遲未發展混合雲架構的主要因素。IDC的調查顯示，47%的CIO將混合雲管理視為非常困難的任務，特別是有5成5企業視相容性為採混合或多雲環境的挑戰。因缺乏共通標準，企業於不同雲端環境間轉換時，需時間重新規畫、管理。
K8s具平臺擴充性，還具高可用性管理介面，以及可自動化平衡負載，而這些特性可因應混合雲的管理挑戰。主流雲端廠商近年已逐漸向K8s靠攏，各自推出K8s服務或平臺，像是Amazon EKS、Azure AKS、Google GKE等，而隨著K8s技術更為成熟，雲端業者支援其的力道也越來越強勁。
主流雲端業者皆以K8s為基礎，打造新的混合雲產品
2019年尤為顯著，從僅提供限於自家環境使用的K8s服務，如今，為站穩混合雲市場，主流雲端廠商更進一步推出，以K8s為基礎的混合雲產品。這些新產品有幾個共同特色，不僅可管理部署於本地端以及自家雲環境的叢集，還可管理部署於第三方雲端環境的任何K8s叢集，或是可於各種環境部署自家服務。
由公有雲老三Google率先登場，於4月宣布，推出混合雲平臺Anthos。該解決方案以K8s為基礎打造，排除VM的支援，可部署於GCP中的GKE服務，或企業機房的GKE On-Prem，執行應用程式。除此之外，Anthos還可執行及管理部署於AWS和Azure等第三方雲端服務上的工作負載。
相隔4個月，瞄準混合雲市場的需求，IBM推出了雲原生軟體產品組合IBM Cloud Paks，底層由以K8s為基礎的Red Hat OpenShift支撐，讓企業可在傳統機房、私有雲、公有雲和整合式一體機等環境部署，該依企業常見需求打包多個IBM軟體的多項服務套件。
而虛擬化龍頭VMware在推出混合雲解決方案VMware on AWS後，成功卡位公雲市場，據RightScale的調查，該公雲採用率已超越IBM Cloud，排名第四。如今，VMware更進一步決定，全面擁抱K8s，於8月底宣布新產品線Tanzu，裡頭包含多雲管理工具Tanzu Mission Control，可管理任何環境中的K8s，包括AWS、Azure、GCP、IBM雲。另外，VMware宣布代號Project Pacific的新版vSphere由K8s主管，也就是將VM部署到K8s環境。VMware on AWS環境未來勢必會採用K8s的vSphere版本。
2019年壓軸加入此股浪潮的則是微軟，其在11月初宣布新的混合雲解決方案Azure Arc，現為預覽版。一樣用K8s打造，該解決方案讓用戶可部署Azure服務在任意位置，並能透過單一介面，管理任何基礎設施上的K8s叢集。
現階段，公雲三巨頭就差龍頭AWS未推出支援K8s的混合雲產品，AWS以硬體主機形式推出的混合雲產品Outposts未來是否加入行列，值得關注。
擁抱K8s不容易，企業需重整系統和架構，並考慮微服務
通過K8s，混合雲各環境間的隔閡被打破了，甚至，進一步實現跨雲的架構。然而，扛著傳統應用的包袱，企業想要擁抱K8s並不容易，需開始關注應用轉型的技術，思考現有架構和系統的狀態，再一步一步重整。
首先，企業需跨出第一步，全面盤點系統，檢討每一個系統的需求性，以進行調整工作，像是刪除已停止使用的系統，或是整併相同業務的系統。待系統都就定位後，企業才能進入下一階段，展開翻新架構的工程。企業可考慮採用微服務架構，將大型應用拆分為多個獨立的服務模組，如此更改和更新單一服務時，不會影響其他服務，而容器技術是使應用可拆分為微服務的關鍵。
企業打造微服務架構，解構大型應用程式，同時，還需導入容器技術，進而用K8s管理容器，以控制於應用外運作的元件間之存取。目前，臺灣已經率先導入K8s的企業，多集中於金融、電信和電商產業，因業者對自身提供的服務要求高，較為積極轉型應用。IDC預測至2022年，全球4成5企業會將應用程式部署在容器化的多雲環境。
將來企業還需面對各雲端業者支援K8s的產品間，不同的定價模型、管理介面等差異，IT團隊必須經訓練以實際操作，勢必需投入一定的資本與時間成本。不過，IDC強調，企業若不投入K8s，會被多雲環境淘汰。
 相關報導  2020年CIO必看10趨勢
",https://www.ithome.com.tw/news/135083,"新聞,混合雲,雲端,K8s,Kubernetes,資訊架構變革,微服務"
135021,7,2019-12-24,Container周報第119期：Spotify揭露第三代ML平臺，2020年改用K8s調度運算資源,Spotify決定，進一步連ML工作流程和運算資源都進一步建立標準化，開始導入了Kubeflow Pipelines（KFP）。這個架構會將主要的運算元件先打包成Docker容器化應用，再利用Kubernetes來部署成容器應用，和調度運算資源支援龐大運算所需," 12/1~12/21 精選容器新聞
＃Kubeflow #K8s叢集Spotify揭露第三代機器學習架構，2020年改用K8s調度運算資源
最近知名音樂串流平臺Spotify在先前北美Kubcon大會上，對外分享自家機器學習平臺的發展歷程，並首度公開了2020年要上線的第三代機器學習平臺架構，採用了Kubeflow，改以K8s來作為算機器學習運算資源的主要調度平臺。Sptify經常需進行大量機器學習訓練和推論，來分析音樂風格和提供用戶各種個人化推薦音樂。2018年，Spotify自行利用開源資料分析技術，後端採用Scala語言，再搭配Python相關工作流程工具，自建了第一代的機器學習平臺，方便分析團隊快速進行各種ML專案。
第一代的特性是，提供了一系列的選項套餐，方便專案人員運用到不同需求的機器學習應用。但是，Scale語言對資料分析人員來說太難，前後端技術的切換成了不少專案開發的困擾，要統一不同模組間的功能、版本和配置難度也頗高。所以，2019年，Spotify團隊決定，改用Google的Tensorflow Extended（TFX）工具，建立機器學習專案開發的標準化，從儲存形式、預設函式庫、到ML工作流程都有一套制式作業規範，尤其盡量採用Tensoflow擴充元件如Tensorflow Transform、Tensorflow Model Analysis、Tensorflow Serving等，來建立跨團隊的共用標準。
最近，Spotify決定，進一步連ML工作流程和運算資源都進一步建立標準化，開始導入了Kubeflow Pipelines（KFP）。這個架構會將主要的運算元件先打包成Docker化容器應用，再利用Kubernetes來部署成容器應用，和調度運算資源支援龐大運算所需。Spotify表示，先前為了標準化而改用TFX的各種努力，成了後來導入KFP流程的成功關鍵，分析團隊不用重新學習另一套ML任務的管理方式。
另一個KFP的好處是，其SDK允許建立共享的元件，分享給其他流程之用。因此，Spofity產品主管Josh Baer撰文透露，其中一個團隊建立了一段不錯的流程和元件組合，可以分享給其他團隊使用，不用重複造輪子，更有助於建立所有團隊的共通工作流程範本。
下一步，Spofity透露，將進一步發展成分析特徵的共享化，將重要的ML功能變成內部共享的微服務，來加快組合運用的方便性，目前他們正在進行機器學習模型服務化的設計。
#雲端供應商標籤 #新版K8s今年最終版釋出，Kubernetes 1.17來了
Kubernetes繼續維持著一年四次更新的步調，在12月9日，釋出了今年最後一次的更新1.17版。這個版本最大特色是，雲端供應者標籤成了正式功能，開發者可以用這個標籤，在節點或儲存空間建立時，來標記所用的雲端供應來源或服務所在位置，通常是用來標記這個節點位於哪一個雲端供應者的那個地區（zone）或區域（region），方便辨識和管理分散在不同公雲或私雲平臺上的K8s運算資源。另一方面，等於也可以透過K8s排程器（Scheduler）來調度和部署跨雲K8s節點的優先順序了，或是可以確保某一個儲存空間，都會在同一個雲端供應商區域，避免因跨區儲存而增加了傳輸費用。另外有幾個儲存功能進入了Beta測試版，可預期明年會成為正式功能，包括了儲存快照功能和儲存介面標準CSI都在1.17進入了Beta1版。

#K8s管理 ＃混合雲管理D2iQ發表企業級K8s叢集管理工具
雲端維運軟體商D2iQ正式推出了企業級家K8s跨叢集管理工具Kommander，可以跨公雲或私雲K8s叢集，自動派送各種治理政策，來建立一個全生命週期的聯合管理流程，要專攻Day2維運市場。這套軟體提供了一個集中式的跨叢集管理介面，也可監控混合雲架構的K8s叢集，也可針對不同叢集進行配置和政策派送、安全規範、更新等管理措施。另外，Kommander還提供了一個資安控管機制，特別用來管理不同應用程式的存取和派送途徑，已確保具有合法權限者才能存取這些應用服務。
#軟體更新 #CNCFCNCF第一個畢業的規範，軟體更新安全規範The Update Framework出爐
軟體更新安全開源規範The Update Framework（TUF）已經達到CNCF（Cloud Native Computing Foundation）的專案畢業狀態，而TUF也是第一個從CNCF畢業的規範（Specification）專案。TUF專案內含有一組函式庫、檔案格式和公用程式，讓用戶能夠保護新的和現有的軟體更新系統。TUF設計提供最小化影響的方法，並且能彈性地滿足各式軟體更新系統需求，且容易與現有的軟體更新系統整合，包括AWS、Google、Cloudflare、微軟、Docker、IBM、紅帽與VMware等大型企業都採用。CNCF技術長表示，現在開源軟體無所不在，並且在許多裝置上無縫地更新，而TUF在軟體供應鏈上扮演重要的角色。
#GCP #VMware #ServerlessCloud Run for Anthos加入流量管理功能且支援VMware叢集
GCP的無伺服器容器服務Cloud Run for Anthos，最近新增了多項功能，不只加入了流量管理，也讓Cloud Run現在可以在企業就地部署的VMware叢集中執行，另外還整合了Stackdriver監控服務，讓用戶能直覺查看多項重要服務指標。在可以按配置比例，隨機路由請求或是RPC到不同的服務修訂版本，這項功能可以讓用戶對不同版本的應用程式進行測試，像是對新版應用程式進行金絲雀部署，先發送少量流量到新版本的服務，接著再逐漸提高流量比例，以確保服務的可靠性。
#GKE #AnthosGoogle揭雲端原生資安新模式，將支援GKE和Anthos
最近Google悄悄地揭露了詳細的雲端原生資安的新模式，稱為BeyondProd。Google在2014年提出以零信任設計為主的網路安全架構BeyondCorp，現在進一步將資安防護架構，延伸到機器、工作量和各種雲端服務，設計出這個新的BeyondProd。Google訂出了幾項安全原則，包括了在邊緣端保護網路、禁止內部服務共用信任、只用信任機器執行來歷清楚的程式碼、跨服務使用同一套服務阻斷點政策，變更改版要簡單自動又標準化、跨工作量要隔離。Google也將這套資安框架套用到自家產品上，可利用雲端GKE服務和混合雲平臺Anthos和幾個開源資安工具，例如可透過Envoy來管理TLS流量的政策，可用gVisor容器沙箱技術來建立工作量隔離，來設計一套符合BeyondProd原則的資安作法。而Anthos更參考這個資安框架，建立一套自己的現代化應用程式資安建議。
責任編輯／王宏仁
更多Container相關動態
CoreDNS釋出1.6.6版，增加新bufsize外掛

＠資料來源：iThome整理，2019年12月
",https://www.ithome.com.tw/news/135021,"新聞,容器周報,K8s,GKE,Anthos,Spofity,Kubeflow,雲端原生資安"
134833,7,2019-12-15,Atlassian發表企業級雲端應用開發平臺Forge,Atlassian雲端應用程式開發平臺Forge，可讓開發者簡單地整合Atlassian雲端服務，並且快速建置跨平臺介面," PaaS服務供應商Atlassian宣布推出應用程式開發平臺Forge，可讓開發人員簡單地在雲端應用程式整合Atlassian的產品，平臺有三個主要元件，包括無伺服器函式即服務（Functions-as-a-Service，FaaS）託管平臺、宣告式UI語言Forge UI以及Forge命令列工具。
Atlassian提到，Atlassian生態系社群擁有超過25,000名的開發者，包括為團隊建置自定義應用程式的內部開發人員，以及在Atlassian市集發布應用程式的第三方開發人員。而為了更好地支援開發生態系發展，Atlassian發布了雲端開發平臺Forge，讓開發者可以更簡單地建置和執行整合Atlassian服務的雲端應用程式。
Forge由三個元件組成，第一個是無伺服器FaaS託管平臺，開發人員可以在應用程式加入Atlassian營運的計算與儲存功能。該平臺採用AWS的無伺服器函式服務Lambda，官方也提到，Forge無伺服器FaaS模型，可以讓開發人員只撰寫單個函式，而非一定要建置整個網頁應用程式，減少需要撰寫程式碼的數量，不用擔心程式碼執行的地方，FaaS託管平臺也可讓開發人員，簡單處理身份驗證和擴展等常見問題。
Forge第二個元件則是聲明性UI語言Forge UI，開發人員只需要撰寫幾行程式碼就可以在網頁和其他裝置上，建置互動式用戶體驗。 Forge UI讓開發人員以聲明性的方法建置UI介面，其預設內建的應用程式安全性配置，可以保護個人資料隱私與安全性，透過抽象化渲染的方法，Forge可以確保應用程式安全地呈現與傳輸資料，而且Forge UI還可以讓開發者建置一次，就可以在網頁和行動裝置上執行，為終端使用者提供一致的產品體驗。
第三個元件則是Forge命令列工具，開發者可以用來管理Forge應用程式，Atlassian也正持續改進工具功能，提供直覺的指令以及易於使用的模板，而Forge的DevOps工具鏈可用在應用程式創建、測試和部署等程序，Forge整合Bitbucket Pipelines支援應用程式持續交付。
Forge的目的是要消除建置應用程式過程的複雜工作，解決實際遇到的開發問題，官方提到，建置、託管和營運雲端應用程式，需要許多雲端基礎架構和管理的專業知識，Forge可以減輕開發人員所面對的負擔。
",https://www.ithome.com.tw/news/134833,"新聞,Atlassian,雲端開發,無伺服器,DevOps"
134801,7,2019-12-12,VMware首度在臺介紹新一代K8s產品線Tanzu，臺灣市場先聚焦金融業,Tanzu的產品和服務組合牽涉應用轉型，VMware臺灣總經理陳學智表示，金融業對所提供的服務要求高，也相對積極轉型應用，因此，VMware於臺灣市場推行Tanzu，首先聚焦金融業。," 面對K8s席捲IT產業的浪潮，虛擬化龍頭VMware於今年的年度大會VMWorld上，由執行長Pat Gelsinger親自宣布，VMware將推出全新產品線Tanzu，來布局K8s市場。本周，VMware也首度在臺對企業介紹Tanzu產品線，準備為日後產品引進臺灣做暖身。
Tanzu的產品和服務得搭配企業應用的轉型，VMware臺灣總經理陳學智表示，臺灣市場以金融業最為積極進行數位改革，他進一步解釋，因為金融業對所提供的服務要求高，相對的應用轉型的需求較其他產業高。因此，VMware在臺將先聚焦金融業，推行Tanzu，再依轉型應用的需求壓力，依序進攻流通業，再到政府部門，接著是高科技業等市場。
Project Pacific為Tanzu產品線的核心，要將vSphere轉換為K8s原生平臺，換句話說，將VM部署到K8s環境中，由K8s主管。陳學智說明，這相當於把K8s和VM二合一，讓容器可以直接跑在虛擬層上。
VMware總部資深產品經理傅博進一步介紹VMware Project Pacific。他特別點出，Project Pacific以命名空間（Namespace）作為管理應用的單位，每一個應用皆有一個相對應的命名空間，可直接以此配置執行參數。
管理員能以命名空間配置應用的執行參數，這背後的關鍵是，每一個命名空間已包含了組成該應用的所有VM和容器。過去，管理員需為應用的每一個VM，單獨配置執行參數，像是加密機制、儲存可靠性等級等，相當耗時，通過Project Pacific，管理員可用Namespace指定該應用的服務品質、安全性等執行參數，而Namespace概念其實就是來自K8s環境中 。
臺灣已有製造業採用VMware on AWS，但多僅用於開發、測試階段
瞄準企業用戶的混合雲需求，VMware上半年則已在臺推出了混合雲解決方案VMware on AWS，目前，已經有臺灣用戶正式採用。以製造業最為積極，像是電子製造業，陳學智指出，他們從成本考量出發，用於非長期性使用的服務，或處開發、測試階段的服務或企業內部應用，因服務、應用具不確定性，待進入生產階段時，再移回私雲環境。不過，他也提到，針對金管會開放金融業上雲，儘管VMware on AWS為了搶攻這塊市場，也有相應的應變計畫，但金融業仍持觀望的態度。
有別於採用其他公雲環境，用戶需訓練一組人員考取證照，並熟悉環境，VMware主打既有用戶不重新學習，直接使用vCenter即可管理VMware on AWS環境。但，陳學智指出，該服務有最低採用門檻，從3個節點起步，因此非各規模企業都適用，他進一步表示，適合中型以上規模的企業，單次需求達幾十個VM層級。
當前臺灣CIO對IT基礎架構有三大焦慮，容器、上雲和資安
另外，陳學智也於媒體聯訪中，分享了近期臺灣CIO常向他提出，對IT基礎架構新技術的各項焦慮。「IT有點慌張。」他道。首先，是對容器技術的焦慮，應用開發單位利用K8s、容器技術開發新服務，但往往該單位非資訊部的直屬單位，雙方缺乏橫向溝通，而如今，應用進入導入IT系統的階段。陳學智指出，IT需學習如何維運，而焦慮如何建立新的容器環境以因應。
另一項CIO的煩惱是上雲焦慮，企業採用公雲已不再只用單一業者的公雲，而是朝多雲架構發展。然而，上雲的搬遷成本高，陳學智表示，根據統計，搬遷1千個VM約需花費3千萬元，及歷時約兩年才可完成，且將工作負載搬遷回本地端的成本更高。另外，企業用戶需安排人員考取證照，以熟悉公雲環境的服務，這些皆為CIO上雲的焦慮來源。
資安則為CIO的第三個焦慮，企業每年平均投入25%至30%的IT預算於資安防護，但，現今攻擊多屬未知型態，防禦困難。
",https://www.ithome.com.tw/news/134801,"新聞,K8s,容器,混合雲,虛擬化,VMware,資安,金融業,基礎架構"
134658,7,2019-12-12,【擁抱K8s、微服務和通用資料平臺新架構】AI轉型也得換體質，LINE資料平臺和IT架構雙雙大翻新,為了全力發展AI，LINE不只提出了2大資料治理原則，也展開資料平臺大整合，不只整合了上百PB的大數據平臺，私有雲基礎架構也開始擁抱K8s，自建微服務框架，來提高自動化維運的效率," 從2017年全力衝刺AI轉型之際，LINE也展開了IT體質的大改造。一來將發展多年的私有雲Verda升級，不只引進Kubernetes和Knative，來發展雲端原生架構的資源調度彈性，另外，LINE也展開了100PB大數據資料各叢集的整併工作，並開始打造新的資料工程平臺資料特徵服務化（Feature as a Service），將資料去識別化變成基礎預設功能，來兼顧隱私和龐大資料量分析的需求。LINE在東京開發者大會上，也揭露了這兩大技術體質改造工程的細節。
強制改用雲端原生架構，導Rancher讓K8s維運管理自動化
LINE很早就用OpenStack建置了一朵私有雲稱為Verda，但隨著LINE各式各樣的服務快速成長，對於VM的需求也越來越大，今年6月時所承載的VM數達到3萬5千個之多，其中光是過去一年就增加了2萬個VM的需求。
在LINE原本的開發流程中，從AP的開發、部署到維運，都可以由AP工程師完成，唯有私雲運算資源的準備，則由私有雲服務自動調度。但是，LINE現有4千個專案，每個專案每次需要的運算資源規模大小不一，有些只是要執行一小段腳本程式，但還是得呼叫一個VM來執行，導致Verda中有6成伺服器的CPU利用率低於10％，仍有9成閒置算力，相當的浪費。
後來，維運團隊決定導入Kubernetes，要求AP工程師，必須改採雲端原生架構，將每一支AP的需求，都建立在AP配置描述檔中，而運算需求較低的腳本程式，則改用Knative來提供無伺服器服務，讓一個VM可以執行更多腳本程式，而不是每支腳本程式就占用一個VM。
LINE Verda平臺開發團隊經理Yuki Nishiwaki表示，連私雲都強制要求採用雲端原生架構有兩大好處，AP工程師不用再擔心基礎架構的管理，而維運團隊也不需要與AP工程師溝通了解所需資源的細節，才能進行優化調度。
LINE採用了Rancher來進行跨叢集的維運自動化管理，包括部署、更新和監控作業都可以自動化。目前只需要5個人就足以管理130個叢集的2千個節點。
不過，目前只能提供基礎的運算需求調度，例如簡單的HA叢集、外掛管理、維運自動化。LINE下一步，不只要支援更多種外掛，還希望可以開始考慮到AP效能來調度資源。
自行開發微服務框架，強化非同步通訊能力
除了改造基礎架構資源來提高調度彈性之外，在應用程式架構上，LINE Messenger原本就按AP的特徵（Feature）來開發各自的專用、簡單的App伺服器，方便擴充之用，例如授權機制有6支服務，貼圖小舖有超過20個服務，LINE@帳號或Bot後端更有超過40支微服務，但幾年發展下來，變成了一套龐大的微服務架構。目前LINE微服務架構上已有超過2,500個微服務。
採用微服務架構的好處是，可以加快開發速度，減少各服務間的功能衝突，但缺點是網路失效的頻率增加了，服務配置檔的管理複雜度越來越高，甚至潛在雪崩式錯誤的風險也越來越高，光是貼圖小舖的微服務，就需要25個人力來管理。
負責LINE Messenger微服務架構的LINE Z部門團隊成員Masahiro Ide指出，現有龐大複雜的微服務架構，需要增加三大功能，強化網路連接性、建立目錄服務和強化路由能力。
後來，LINE決定自己打造微服務框架，稱為Armeria，設計了自己的RPC分層架構，可提供非同步的RPC層通訊需求，也將基礎通用功能，變成微服務框架的預設功能，來簡化重複建置的工作，如Logging、用戶端負載平衡、監控整合、追蹤、重試機制、健康檢查等。另外，還針對文字類配置檔，如JSON、YAML、XML，打造了一個儲存庫服務Central Dogma，可提供高可用性、版本控制和進階查詢機制，來強化配置檔的管理，將這兩項技術，與LINE自己用Erlang打造的事件派送閘道器LEGY（Line Event Delivery Gateway）搭配使用。LINE也將Armeria和Central Dogma兩項技術開源釋出。有了這兩大武器之後，下一步，LINE就準備進一步細分拆解現有的微服務架構，從「按特徵拆解」細化到更小顆粒度的「按功能拆解」來設計新的微服務架構。
兩階段用叢集邦聯串接龐大Hadoop叢集
除了基礎架構體質改善之外，LINE的另一個大改造工程是資料基礎架構。因為採取隱私優先政策，每一件與資料相關的事件，都需要進行隱私、安全的審查，但是跨不同子公司、不同系統的資料運用方式非常複雜，再加上LINE的資料量非常龐大，光是LINE Messenger一天的訊息就高達1兆筆，每天新增的資料就算壓縮後仍多達390TB，各種資料處理查詢任務，一天也高達7萬個。其他服務的資料再加總起來的量更是龐大，如何兼顧隱私權和大量資料的挑戰，Verda部門主管Yoshihiro Saegusa指出，有三大問題要解決，包括了資料可用性（Accessibility）、多人使用管理（Multi-tenancy）和資料品質（Data Quality）。
LINE的策略不是把現有的大數據叢集全部打掉重建，而是將幾個主要叢集連結起來，建立了一個共用流程，透過單一登入服務，來控制誰可以使用哪些資料，讓跨服務的工程師，就可以用到其他服務產生的資料。
更進一步來看，LINE用Hadoop來儲存多達100PB的異質資料，包括了資料庫、原始Log、前端Log、伺服器Log等資料。總共有超過10個叢集，節點總數達到2千個，其中最大一個叢集，甚至多達1,200個節點。LINE沒有採取，先建立一個超大新叢集，再搬遷所有資料的作法，也不是直接對所有叢集進行整併，前者得準備一倍的伺服器，成本太高，後者不同Hadoop叢集所用的版本甚至不一樣，直接整併叢集的複雜度太高，資料損失的風險也太大。
後來，LINE的作法是，先挑出幾個重要的大型Hadoop叢集，將其他小型、次要的Hadoop叢集，整併到這幾個大叢集中，再透過Hadoop的Cluster Federation功能，來建立跨叢集的通用管理層，並且透過單一個YARN資源管理系統，來管理這些串連後的Hadoop叢集。
建立資料特徵服務架構，用混淆工程去識別化來保護隱私
另外，LINE還將資料分成兩大類，一種是原始資料，另一種是經過特徵抽取的資料，LINE打造了一個資料特徵服務（Feature as a Service）架構，先透過第一層的ETL工具梳理資料來減量，再透過特徵工程技術，將內容轉換成不同特徵的向量數值，再結合用戶行為和內容特徵，就會變成了用戶個人的使用特徵Y Feature，並且利用了混淆工程技術，來進行去識別化處理。
因此，就算是跨團隊的工程師拿到了一批資料，他們都無法知道用戶真實是資料是什麼，資料工程師只會看到一筆筆轉換過後的特徵向量數據，各自對應著不同的內容類型或行為特徵的強度。
「透過這樣的技術，就可以同時解決隱私和資料量的問題。」LINE臺灣資深技術總監陳鴻嘉強調，不論是哪一種資料分析，都需做到合法、合情和合理才能用。IT基礎架構和資料架構的體質大改造工程，正是LINE可以安心衝刺AI發展的關鍵。
 相關報導  LINE全面進攻AI
",https://www.ithome.com.tw/news/134658,"新聞,K8s,微服務,通用資料平臺,數位轉型,AI轉型,Line,雲端原生架構,Rancher,Hadoop,資料特徵服務架構,混淆工程,去識別化,隱私,個資"
134644,7,2019-12-06,IDC預測2020台灣科技趨勢：企業若不擁抱K8s，將被多雲環境淘汰,市場調查機構IDC針對臺灣ICT市場，提出2020年10大趨勢預測，企業轉型從專注「數位技術」轉為「數據驅動」，其中，尤以AI轉變最突出，從朝融合式發展到走向端雲共生，再結合自動化，另外，IDC也聚焦混合/多雲架構、5G、中小企業轉型、資安在地化、新型穿戴裝置、遊戲產業全通路，還有萬物即服務," 2020年即將到來，市場調查機構IDC發布了2020年臺灣ICT市場10大趨勢預測。綜觀發展，IDC認為，2020年全球企業數位轉型工程，將進入「轉型2.0」的世代。隨著技術導入越趨快速、成熟，下一波轉型重點為「數據驅動」，以數據為核心，驅動新的營運模式。IDC臺灣區總經理江芳韻建議，臺灣CIO特別關注AI的轉變，不管是朝融合式發展，或是走向端雲共生，還有結合自動化，這些趨勢相互關連著，且將加速轉型。
首先，IDC提出，AI朝融合式發展，指的是AI在數據資料、演算法和流程三個面向融合新元素。數據資料的分析來源從僅限靜態歷史資料，轉為融合動態即時情境，像是加入影音串流資料，以提升AI的預測能力；演算法則從單一功能導向，轉變為情境式導向，融合分析情境的變因，像是交通監控除了辨識車輛車牌，也需辨識車速、即時天氣等，讓演算法的執行結果更為精準；
AI分析及應用流程則會融合透明化與自動化，明確定義流程，掌握使用情境，還有需收集的資料類別，改善過去AI使用單位與開發單位間，資訊不透明的情況，同時，企業可以使用公雲業者和新創推出的AI開發平臺，自動化建模，讓AI應用的成效極大化。IDC預測，臺灣AI採用率在2021年達到43%。
第二項趨勢為端雲共生。過去，因終端裝置缺少運算能力，端點與裝置僅能執行輕量的AI運算，以至AI運算多於雲端執行，不過，隨著神經網路演算法、晶片異質整合、記憶體內建運算等技術升級，IDC預期端點算力將提升。
換句話說，因終端裝置的AI能力大躍進，未來，終端裝置可聚焦AI「推論」，而雲端則專注AI「訓練」，走向端雲共生。電腦運算、消費裝置、零售、製造、醫療、能源、汽車和智慧城市將是8大重點應用產業。IDC預期，2024年全球超過5成的人機介面會基於AI電腦、視覺、語音、自然語音、AR/VR等技術，以產生多元且直覺的使用者體驗，而推進至2025年，全球5成終端裝置都會具備電腦視覺，以及與語音辨識相關的AI神經網路運算能力。
相容性為採混合／多雲環境的最大挑戰，容器與K8s技術可望因應
另外，IDC指出，混合/多雲架構為企業創新的關鍵，是2020年第三大趨勢。根據調查，2019年全球8成企業採用混合或多雲的環境，臺灣則僅有4成6企業採用，且多處於試行階段。IDC歸納企業部署混合/多雲環境遭遇多項挑戰，其中，最大的挑戰就屬相容性，因企業於不同雲端環境間轉換時，需時間重新規畫、管理，而造成5成5企業對採混合或多雲環境有相容性疑慮。另外，企業還面臨人才、資安和工作負載調度等挑戰。
IDC表示，容器與K8s可因應這些挑戰。容器與K8s平臺具平臺擴充性，還具高可用性管理介面，以即可自動化平衡負載，近期，不僅公有雲業者一一投入K8s的行列，連硬體供應商像是英特爾、Nvidia等，還有商業軟體也開始支援K8s。IDC指出，K8s成為多雲平臺的共通標準，預期多雲以K8s作為主軸。
目前，臺灣已經有金融、電信和電商業者部署K8s環境。IDC表示，企業若不投入K8s，會被多雲環境淘汰，預測至2022年，全球4成5企業會將應用程式部署在容器化的多雲環境，臺灣企業則7成4部署混合/多雲環境。
企業內部的工作流程也隨技術趨勢的發展，走向智慧化與自動化。IDC預期，明年已是企業環境發展重心的RPA，結合AI發展為IPA（Intelligent Process Automation），以因應企業內外部爆量的各類結構與非結構資訊。IDC預估，2024年全球企業的知識密集型人力2成與IPA技術搭配，實現人機協作的情境，同時，企業內結構型的重複性工作5成由自動化取代，尤以金融、醫療和政府單位特別值得關注。
5G明年在臺上路，電信市場競爭規則將受改變，遊戲產業則走向全通路
臺灣5G頻譜競標將在下周二（12/10）登場，5G明年正式在臺灣商轉。IDC預測，5G會改變臺灣電信市場的競爭規則。觀察已正式於今年4月商轉5G服務的鄰近國家—韓國，該國5G電信方案針對有較高電信品質要求的消費者設計，吃到飽資費僅出現於初期的優惠方案，並搭配手機費用補貼，以提升用戶升級的意願。
IDC預期，臺灣市場將採同樣的銷售模式，主攻需高品質電信的用戶，再加上電信業去年經歷499吃到飽的競爭壓力，5G吃到飽方案預估僅於初期推出。此外，5G通訊技術採開放式架構，因而有資安攻擊的威脅，對此，IDC認為，5G資安防護是電信業者必須開始正視和面對的課題。
隨著5G及雲端遊戲串流服務興起，IDC提出，明年遊戲產業走向全通路。該趨勢具有三大特性，首先，打破硬體裝置的限制，進而提供跨裝置的遊戲體驗，以及遊戲平臺將相互整合內容。全通路型的遊戲更將進一步改變產業的生態圈，開發方面，從分散是走向集中式，並且營運模式因訂閱制的出現，改變長久的販售方式，從而衝擊硬體供應商和遊戲平臺商。
數位轉型則持續上榜，不過，明年IDC聚焦的是中小型企業加速數位轉型的趨勢。IDC調查發現，2019年全臺近6成企業啟動數位轉型計畫，但是，中小型企業僅1成3展開數位轉型。資源與成本是阻礙中小型企業轉型的兩大因素。現在，許多資訊服務供應商因應中小型企業的需求，提供了多種數位服務，可降低轉型成本，以及降低轉型的技術門檻。IDC預估，至2021年底，臺灣中小型企業有47.8%進行數位轉型。
政治環境也影響著ICT市場的發展，地緣政治風險促成了資安在地化的趨勢。過去1年，中美貿易戰的戰火持續延燒，造成許多不確定性。IDC表示，國際競爭已從軍事抗衡，轉為科技、數位主權之爭。資訊大國從網路安全著手，提出網路言論危害國安的對策，同時，培育資安人才，以及建立生態系統。
而其他國家則從高度仰賴美國的資安產品與技術，轉為強化與其他國合作，以因應不確定的國際局勢，長期來看，自主發展關鍵技術更是非資訊大國的發展重點。IDC預測，至2022年，4成高速發展數位基礎建設的國家走向資安在地化。臺灣具特殊的政治經濟背景，IDC認為，臺灣不僅需順應國際局勢，強化自主關鍵技術及資安人才培育，更要把握發展資安產業的優勢，這是臺灣的機會。
穿戴裝置方面，現階段，穿戴裝置在臺灣的普及率僅達14.5%。不過，隨著邊緣運算的發展，IDC認為，該類裝置與使用者間的互動將提高，甚至，透過資料收集、分析，能提供貼近個別使用者需求的體驗，明年，尤以保險、醫療和飯店業會運用穿戴裝置。IDC預估，2022年該類裝置在臺灣的普及率達26%。
最後一項趨勢則為萬物即服務，新興商業模式和服務隨著5G、AI，以及IPV6等技術的發展出現。IDC指出，新商業模式和服務具4大特質，包含隨行隨用、非一次性買斷、收費機制以服務為導向，還有滾輪式的客製化服務，進而萬物皆可成為服務。文◎黃郁芸
",https://www.ithome.com.tw/news/134644,"新聞,IDC,趨勢預測,數據驅動,人工智慧,5G,自動化,混合雲,K8s,容器"
134504,7,2019-11-29,Container周報第118期：紅帽CodeReady大改版，介面更像Visual Studio,CodeReady新的UI介面，更像是微軟Visual Studio的操作體驗，而且CodeReady還特別讓可以支援微軟開發工具VS Code所的擴充外掛，直接在CodeReady中執行。," 11/16~11/29 精選容器新聞
＃K8s應用開發 #紅帽
紅帽K8s開發工具CodeReady介面大改版，還支援VS Code的外掛
最近紅帽推出了K8s開發工具CodeReady Workspace第二版，最大特色是，採用了新的UI介面，更像是微軟Visual Studio的操作體驗，而且紅帽還特別讓CodeReady可以支援微軟開發工具VS Code所的擴充外掛，直接在CodeReady中執行。紅帽解釋，因為太多開發者抱怨，CodeReady和主流IDE介面差異太多，導致學習門檻很高，所以，才決定重新改版自家IDE的介面。另外，新版還增加了一項air-gap安裝模式，不需要預設建立與公開程式碼儲存服務例如GitHub的連結。最後一項更新是推出了配置檔共享格式Devfile，可用來描述儲存器設定、所用runtime、部建工具甚至用了哪些IDE外掛，方便團隊進行協同開發。也可以提供除錯器、開發語言執行伺服器、單元測試工具的複製，方便將這些開發者常用工具鍊都集中成一包來管理。

#容器資安 #Quay #Clair
紅帽開源釋出容器註冊器計畫Quay，連同容器漏洞掃描工具
為了擴大容器生態系的深度，紅帽不斷推出自家產品的社群開源版本，最近則開源了一個原屬於CoreOS下的容器註冊器專案Quay。CoreOS在2014買下了Quay，成了自家容器註冊器核心，Quay後續還整合了容器資安掃描工具Clair，後來，紅帽買下了CoreOS，這個產品就成了紅帽後來推出的Red Hat Quay。目前，紅帽將Quay和Clair的原始碼都放上了GitHub開源，可供開發社群使用。Clair可以在容器映象檔放上註冊器儲存時，可以自動掃描是否有已知的漏洞，這也是紅帽商用版環境所用的漏洞掃描機制。紅帽也揭露後續發展計畫，要進一步提供程式碼清理機制，增加註冊器鏡像副本功能，也要提供部建管理工具和新的UI介面，還有更多API。

 
#容器資安 #資料保護
Trilio免代理程式資料保護工具可以原生部署K8s環境了
資料保護業者Trilio最近公開了自家資料保護產品TrilioVault的新技術預覽版，最大特色是可以原生在K8s環境中執行無代理人模式的資料備份和復原任務，計畫在明年正式推出。Trilio也在Kubecon大會上正式展示新版的操作。這個新版本目前已經通過紅帽OpenShift的容器認證，Trilio希望可以支援更多商用K8s環境，而且不論是公雲或私雲環境都要支援。Trilio過去主推OpenStack環境的資料保護方案，現在開始跨入了容器環境，這次預覽版是他們的第一步。
#Docker  #挖礦木馬
駭客掃瞄網路Docker植入挖礦程式，還修改設定、留下後門
隨著愈來愈多關鍵應用搬上Docker，也成為駭客下手的目標。安全廠商發現駭客近日正在網路上掃瞄曝露出的API，意圖植入挖礦程式利用受害者系統資源謀利，還會關閉系統的防護機制或留下後門。
Bad Packets偵測到從11月24日午夜起，出現針對Docker系統的罕見大量掃瞄網路活動，利用掃瞄工具Zmap掃瞄TCP port 2375、2376、2377、4243。這波流量疑似是駭客攻擊前的偵察性掃瞄。目前駭客一共掃瞄了高達近5.9萬個IP網路來尋找曝露的Docker執行個體。一旦找到受害系統的API，攻擊者就會利用API端點啟用Alpine Linux容器，並執行指令來下載、執行Bash script，目的在安裝Monero挖礦程式XMRig。而在觀察到這波流量後2天，駭客已經挖到價值740美元的Monero幣。
#監控服務 #AWS
AWS推ServiceLens視覺化監控服務，以圖表現分散式應用程式與相依關係
AWS推出了Amazon CloudWatch的視覺化監控解決方案ServiceLens，讓用戶可在同一個介面，就能掌握無伺服器和容器分散式應用程式，監控其可用性等運作狀況，而且還整合了金絲雀測試服務Synthetics，用戶可監控應用程式的金絲雀測試狀況。ServiceLens可以將所有指標、日誌和應用程式追蹤（Trace），全部集中到統一的地方顯示，強化了服務和應用程式的可觀測性。ServiceLens整合了CloudWatch與分散式追蹤系統AWS X-Ray，提供應用程式端到端檢視圖，並重點顯示每個節點與其連接的流量、延遲和錯誤，用戶可以針對單一節點查看該服務的相關指標、日誌和追蹤細節。
#SRE #混沌工程 #K8s
Gremlin混沌工程工具現支援Kubernetes
混沌工程工具廠商Gremlin在其可靠性即服務（Reliability as a Service）平臺加入對Kubernetes的支援，用戶現在可以用網頁應用程式與API來探索、視覺化，以及鎖定Kubernetes物件，並由Gremlin平臺自動選取所指定Kubernetes物件下的容器，用戶不用麻煩地從列表中選擇目標容器。
Gremlin更新對Kubernetes的支援，用戶只要利用Helm Chart更新Gremlin客戶端之後，就能啟動Gremlin網頁應用程式開始創建新的攻擊，直接鎖定建構在Kubernetes物件上的特定服務。用戶透過下拉式選單探索Kubernetes叢集以及命名空間列表，還能夠進行搜尋或是過濾操作，以找到想要實驗的Kubernetes物件集。
#DevOps #CLoudFormation
AWS開源CloudFormation CLI工具，可讓用戶打造資源供應程式
AWS的基礎設施即程式碼服務（Infrastructure As Code，IaC）CloudFormation釋出CLI工具，讓用戶與第三方廠商能夠建立資源供應程式（Resource Provider），並希望透過開源的形式提升其可擴充性。另外，AWS還推出了CloudFormation註冊表，為用戶和廠商提供一個通用的框架，用戶可以在CloudFormation模板中使用豐富的第三方資源類型。AWS也宣布與多家第三方供應商合作，包括Atlassian、Datadog與Fortinet在內的7家廠商會建立資源供應程式，供AWS用戶在CloudFormation模板中使用。目前所有的公開AWS地區，都已經支援CloudFormation CLI。
責任編輯／王宏仁
更多Container相關動態
HPE最近發表了自家容器平臺軟體產品
Portworx擴充容器儲存產品線，新增災備復原工具
AWS雲端開發套件開始支援Java和.NET

＠資料來源：iThome整理，2019年11月
",https://www.ithome.com.tw/news/134504,"新聞,CodeReady,紅帽,Quay,容器資安,容器周報,IT周報,混沌工程,K8s"
134468,7,2019-11-28,Fintech周報第123期：加拿大純網銀EQ Bank宣布把銀行核心系統搬上雲端,加拿大首家純網銀EQ Bank宣布，已將整個銀行核心系統搬上雲端，此舉也使EQ Bank成為加拿大第一家完全採用公有雲架構託管的銀行。," 1123-1129
 純網銀   EQ Bank   Cloud   銀行核心系統 加拿大純網銀EQ Bank宣布把銀行核心系統搬上雲端加拿大首家純網銀EQ Bank在11月21日宣布，已將整個銀行核心系統搬上雲端，此舉也使EQ Bank成為加拿大第一家完全採用公有雲架構託管的銀行。EQ Bank現在將利用Azure作為其提供金融服務的的雲端平臺。2016年成立的EQ Bank，是由加拿大第九大獨立銀行Equitable Bank旗下子公司，成立3年時間，客戶存款已超過了25億加元。
EQ Bank表示，這將建立更好的金融顧客體驗，包括將降低間接成本，並把節省下來的成本回饋給顧客；二是基於Temenos T24 Transact創造更加敏捷的系統，EQ Bank提到，Temenos T24 Transact是下一代銀行核心系統，可以更快速地升級產品和服務；三是為下一個銀行創新，準備好系統；第四點則是藉公有雲來強化EQ Bank的資安基礎。 
Equitable Bank資深副總裁暨資訊長Dan Dickinson表示，把EQ Bank銀行核心系統遷移到雲上，是一個產業領先變革，朝向金融服務新未來邁進。Equitable Bank總裁暨執行長更提到，EQ Bank會建立數位基礎設施，不只要為客戶提供先進的數位體驗，更要為Open Banking做好準備。
 金管會檢查局   監理科技   RegTech 金管會檢查局導入API，2020年1月將上線自動排程申報機制

為了因應金融科技的快速發展，金管會也得與時俱進，建置數位監理環境。金管會主委顧立雄表示，在檢查作業電子化部分，金管會要優化現行單一申報系統，2020年起將導入API，自動排程申報，減少人工申報錯誤發生。以及建置檢查放表功能，上傳檢查所需資料，記錄作業軌跡。還要建立數位化查核程序，自動化檢核產出案件明細。
金管會檢查局副局長張子浩補充，今年9月已與幾家金融業者進行測試，目前採取鼓勵金融業者內部建立系統，能以API與金管會介接，進行自動申報。張子浩表示，檢查局預計2020年1月1日開始，上線自動排程申報機制，並將與現行單一申報機制雙軌進行。
此外，金管會也要研擬純網銀監理系統規畫及建置方案，對純網銀業者的重要性指標與流動性風險的即時監控。未來，計畫逐步導入票券業者、銀行，甚至是保險，都能做到即時監控，金管會也為此成立監理科技專案小組，共同研議監理科技。 
 視障者轉帳   無障礙網銀   行動銀行App 金管會要擴大無障礙網銀與行動銀行服務，明年6月全面開通轉帳功能為了提升視障者使用金融服務的便利性，金管會主委顧立雄在11月22日宣布，將推動銀行無障礙網路銀行與行動銀行App，全面提供約定與非約定轉帳功能，目標2020年6月底前，全臺37家銀行要上線運作。經金管會清查，目前37家本國銀行(含中華郵政)無障礙網路銀行中，已有36家有查詢服務功能，34家有約定轉帳功能，有3家有非約定轉帳功能。但是，行動銀行App部分，沒有一家銀行有提供視障者相關轉帳功能。 
為加速無障礙友善環境建構，顧立雄表示，已與所有銀行達成共識，以明年6月底前上線為目標，各銀行的無障礙網路銀行與行動銀行App，全面提供約定與非約定轉帳功能，且轉帳限額與各該銀行一般網路銀行及行動銀行App限額一致。金管會要求，在功能上線前，希望銀行能邀集視障者或團體測試，確保符合身心障礙人士的需求。 
 玉山銀行   Pi拍錢包   信貸   電商 玉山銀行攜手Pi拍錢包推信貸服務，把融資金融嵌入電商新零售場景

為了打造無斷點的金融服務，玉山銀行合作Pi拍錢包，推出信用貸款服務「拍享貸」，藉由API串接的方式，將玉山銀的數位貸款服務，嵌入在行動支付Pi拍錢包App中，讓顧客登入後即可檢視客製化的貸款額度、利率與費用方案，顧客同意提出申請後，除了可在線上追蹤申辦進度，完成對保後，在營業時間內最快2小時可取得資金。玉山銀行表示，此服務可即時滿足顧客緊急資金週轉的需求，並縮減線上申貸所需時間。而這也是玉山將融資金融，嵌入電商新零售場景中的作法。
 華南銀行   AI行動銀行 AI語音助理技術加持，華南行動銀行App用說的就能查、轉帳

華南銀行和IBM合作推出AI行動銀行，讓華南銀行用戶只要用說的，就能查詢匯率、存款餘額，甚至是轉帳匯款。華南AI行動銀行具備三大功能：AI全功能導航、支援全面聲控輸入、多輪對談。例如華南AI行動銀行具備超過100項功能，用戶不需思考層層功能路徑，只要說出想要尋找的服務，內建的小n機器人就會自動找到該服務。
小n機器人的背後主要運用了IBM Watson的AI語意理解技術，且可支援多輪對話應答。華南在AI行動銀行中，特別針對用戶經常會用到的帳務查詢、轉帳、明細查詢做到多輪對談。不過，目前多輪對談僅限於使用單一服務，例如轉帳或查詢帳務，小n機器人尚無法理解複雜的請求，像是「幫我查詢帳戶內的存款金額，再轉帳給爸爸100元」這類摻雜兩種行動的語句。
華南銀行指出，相較於其他同業推出的語音轉帳是以「關鍵字」，需要精準的辨識搜尋，否則會出現牛頭不對馬嘴的情形，小n採用AI語意理解，以瞭解使用者的意圖，不需依靠特殊的語音指令，提供創新的行動銀行服務體驗。 
 企業區塊鏈   KYC   金融   勤業眾信 勤業眾信：企業區塊鏈市場逐漸成熟，金融應用型態開始多元勤業眾信亞太區塊鏈實驗室經理Kelvin Wong，在一場活動上分享區塊鏈最新應用趨勢。他認為，現在的區塊鏈市場更加成熟，已有越來越多企業導入相關應用。比如，勤業眾信輔導一個香港區塊鏈應用是香港金管局，這個機構在去年底推出了「貿易聯動」（eTradeConnect）的服務，這是香港銀行業中，第一個應用區塊鏈技術的大型金融資訊共享平臺，截至去年底就已經有12間銀行參與，來解決傳統貿易融資借貸的弊病。
此外，他還提到，金融業區塊鏈也能應用在客戶到銀行開戶時，透過客戶過去在其他銀行的KYC資訊，分享給現正申請的銀行來認證，加快銀行進行信用評估的時間。也就是說，客戶要向銀行B申請開戶，可以向開戶過的銀行A發送請求，運用個資與銀行帳戶資料來構成KYC，銀行將會在區塊鏈帳本中找到該筆資料的雜湊值並回傳給客戶。 
 Paypal   購物優惠平臺Honey 支付巨頭搶進EC，PayPal以40億美元買下購物優惠平臺HoneyPayPal宣布將斥資近40億美元收購用戶近2,000萬的購物優惠券平臺Honey的母公司Honey Science。PayPal表示，本交易將可提升PayPal消費用戶的購物經驗，同時擴大店家的銷售額及客戶互動。這樁交易也是PayPal迄今最大宗收購案，預計2020年第一季完成。PayPal全球消費產品暨科技資深副總裁John Kunze指出，Honey的產品與優惠券搜尋、價格追蹤、客戶忠誠方案將整合到PayPal和Venmo服務中。
圖片來源：攝影／洪政偉、李靜宜、蘇文彬責任編輯／李靜宜 金融科技近期新聞 1.  街口電子支付因辦理業務與資訊作業有4大內控缺失，遭金管會罰180萬元，創下電支業者裁罰首例2.  推出3年不到5％客戶使用，荷蘭銀行將關閉自家Wallet App服務3.  國發會主委陳美伶喊出，臺灣行動支付消費金額年底前要破1千億4.  Monero官網遭植入惡意程式，用戶加密貨幣錢包被清光資料來源：iThome整理，2019年11月。
",https://www.ithome.com.tw/news/134468,"新聞,純網銀,EQ Bank,銀行核心系統,Cloud,金管會檢查局,監理科技,FinTech周報,Regtech,視障者轉帳,玉山銀行,Pi拍錢包,信貸,FinTech,IT周報"
134209,7,2019-11-15,StackRox發布K8s安全平臺3.0，加入配置與漏洞管理功能,K8s安全平臺3.0提供互動式儀俵版，用戶能一目瞭然Kubernetes的配置錯誤以及存在的漏洞風險," 雲端資安公司StackRox推出了Kubernetes安全平臺3.0，這個版本加入了配置與漏洞管理，讓用戶能有效掌握雲端原生容器應用程式的安全性。
Kubernetes安全平臺為Kubernetes配置管理，提供了儀表板以及相關的工作流程，以減少用戶錯誤配置的可能性。互動式儀表板可以讓用戶針對風險的等級，查看錯誤的Kubernetes配置，並能進一步了解錯誤配置的訊息，以及修補所需要的相關背景資訊。
而Kubernetes安全平臺也會持續監控帳戶的權限，避免用戶意外地對帳戶授予不必要的權限，減少可能被攻擊的面向，而且還能辨識潛在錯誤配置和提供風險分析。另外，該平臺會監控Kubernetes機密資訊的存取，控制可存取機密資訊的部署，並限制不必要的存取。
在漏洞管理方面，Kubernetes安全平臺同樣也提供互動式儀表板功能，根據用戶的環境，突出顯示映像檔和Kubernetes存在的漏洞，StackRox提到，針對Kubernetes產品團隊以及安全性審核所揭露Kubernetes本身的重大漏洞，Kubernetes安全平臺會提供必要的警示，範圍包括相關的Kubernetes API伺服器。該平臺也會掃描容器映像檔，尋找跟程式語言相關的漏洞。
除了配置和漏洞管理，Kubernetes安全平臺3.0還增加對各種生態系統平臺的支援，像是支援目前正在CNCF孵化器下的CRI-O（Kubernetes Container Runtime Interface），這是一個專為Kubernetes最佳化，且與OCI相容的輕量級Runtime的實作，也支援Kubernetes在由D2iQ維護的DC/OS平臺上的使用，還與Microsoft Teams整合，可以跨安全和DevOps團隊交付警告通知。
",https://www.ithome.com.tw/news/134209,"新聞,StackRox,K8s,映像檔"
134073,7,2019-11-07,Container周報第116期：SQL Server 2019正式在臺上市，主打K8s大數據叢集新特色,這個大數據叢集功能（Big Data Cluster），可以透過K8s來建立一個大數據叢集，再搭配Azure Data Studio工具來管理、部署和查詢多個資料庫實例中的資料，但不直接支援Windows版SQL Server，得透過Polybase來串接。," 11/1~11/7 精選容器新聞
#資料湖、#大數據叢集、 #SQL Server新版SQL Server 2019正式在臺上市，主打K8s大數據叢集新特色
微軟新版資料庫產品SQL Server 2019正式在臺推出，微軟MVP楊志強強調，新版最大特色之一是新的大數據叢集功能（Big Data Cluster），可以透過K8s來建立一個大數據叢集，再搭配Azure Data Studio工具來管理、部署和查詢多個資料庫實例中的資料。這就像是在建立一個資料湖，透過統一的資料湖介面來存取多個資料庫，可說是一種資料虛擬化。大數據叢集可支援SQL運算節點，以及部署在分散式儲存HDFS上的Spark節點或SQL Server節點。因為，這個大數據叢集只支援K8s環境中的Linux版SQL Server，要整合原有Windows環境的SQL Server，則得透過外部資料源介接機制Polybase，將外部資料庫上的資料表，嵌入大數據叢集後，成為資料湖的資料園。PolyBase同樣也可用來串接甲骨文資料庫、mongoDB和Teradata。
楊志強指出，儘管新版的大數據叢集功能，無法直接調度和部署原有Windows的SQL Server，但改用K8s架構來管理數據叢集後，最大好處是可以快速將這個大數據叢集搬上雲端。所以，這個大數據叢集不只可調度本地端K8s環境，也可將雲端K8s環境中的SQL Server節點整合到單一資料湖中。目前，SQL Server 2019可支援所有版本的K8s，包括Azure Kubernetes服務或Red Hat OpenShift。
在計價方式上，微軟表示，2019大多如前一版計價方式，但新推出Azure雲端軟體保證服務（Software Assurance），加購SA者，在Azure上部署SQL Server則只需負擔IaaS費用，而不用額外購買SQL Server授權，採1比8的比例，購買10核心本地端授權者，加購SA可免費使用80核心的雲端SQL Server部署授權。若是在其他雲端業者上部署，則需另外購買SQL Server授權。
#混合雲、#OpenStackOpenStack釋出第20個版本了，美國、中國用最多
OpenStack釋出代號為Trian的第20個OpenStack版本，這個名稱來自美國丹佛，今年上半年度的峰會主辦地，由於當地火車頻繁往來，而由此命名。 該新版本強化了安全機制，像是提升軟體RAID的支援能力，裸機部署服務 Ironic可在磁盤故障時，保護服務免受影響，還有提高AI和機器學習加速器的支援能力，提供加速器周期管理服務，並改善資源管理與追蹤的能力，統一資源管理功能Placement正式成為獨立的服務。中國是全球第二大採用OpenStack軟體的市場，且中國僅次於美國，為OpenStack最新版 Train的程式碼第二大貢獻者。
#Azure、#混合雲微軟利用K8s推出混合雲解決方案Azure Arc
微軟在Ignite大會上推出新的混合雲解決方案Azure Arc，讓使用者的工作負載可以跨企業內部、混合雲或是邊緣運作，Azure Arc可以讓用戶將Azure的服務部署在任意位置，並透過統一的入口網站進行管理。另外，微軟也持續擴充可將Azure服務部署在私有雲上的Azure Stack，新增人工智慧託管設備Azure Stack Edge。Azure Arc擴展了Azure管理功能到Linux、Windows伺服器上，甚至是在任何基礎設施上的Kubernetes叢集，包括企業內部部署、多雲以及邊緣環境。
用戶可以使用更加一致且統一的方法，以Azure資源管理器、Azure Cloud Shell、Azure Portal、API以及Azure Policy來管理混合環境，而藉由Azure Arc，開發者也可以使用各式開發工具建置容器化應用程式，IT團隊也能基於GitOps來配置管理部署。在身分驗證上，Azure Arc在跨環境採用了集中式角色存取控制以及安全性政策。臺灣微軟Azure雲端平臺事業部副總經理李啟後表示，未來也會把Azure Arc引進臺灣。

#Java、#紅帽紅帽要讓K8s上的Java應用更瘦身，推出JVM優化框架Quarkus
最近紅帽宣布JVM優化開源專案Quarkus終於推出1.0版，這是一個用來優化K8s上部署Java應用環境的工具，目標是盡量縮減JVM的檔案大小，來加快在K8s上的部署和建置速度。根據紅帽測試，傳統雲端原生的Java應用需要136MB的映像檔，同樣軟體層，改用Quarkus架構後，可以縮減到12MB，光是在K8s上的啟動速度上，可以從0.943秒，縮短到只需要0.016秒。另外，Quarkus也利用Vert.x來建立一個資安層，可用來強化與Java Spring框架應用間API串連的安全性。
#虛擬桌面、#ChromeChrome Enterprise 78開始支援虛擬桌面、Linux容器預設啟用GPU
剛推出的Chrome 78在企業版也有新功能，像是Chromebook新增虛擬桌面功能，可以減少桌面工作混亂，還強化了Linux容器的支援。用戶能利用虛擬桌面功能，創建最多四個工作區，Chromebook會將虛擬桌面視為獨立的工作區域，這項功能可以在不同的專案和活動間創立界線，避免因為混亂進而提升生產力。Google在Chrome 73開始加入Linux容器，讓開發者可以使用自己喜歡的開發工具，在Chrome 78還加入了備份還原和預設啟用GPU的功能。
#雲端IDE、#Visual Studio Online未來微軟開發環境用起來如何？Visual Studio Online終於對外開放預覽版
微軟在Ignite大會釋出Visual Studio Online開放預覽的消息，開發者可用來建置長期專案，也能方便地快速創建新功能雛形，或是用於查看拉取請求等短期任務。開發者可以使用Visual Studio Code與Visual Studio IDE來存取Visual Studio Online，也能使用瀏覽器編輯器。開發者可以從開發工具或是網頁入口網站啟動Visual Studio Online，該服務會配置開發工作需要的一切環境，包括原始碼、Runtime、編譯器、除錯器、編輯器等擴充套件。微軟強調，這個環境是可讓開發者完整配置的，依照專案需求做精細的調整，開發者也可以安裝擴充套件，或是定義自己的Dockerfile來控制環境。Visual Studio Online託管在Azure雲端，開發者可以創建專案，並在需要額外運算容量時，啟用進階環境以取得更多的CPU和RAM資源。Visual Studio Online按需計價，當用戶創建環境使用6分45秒，就只需要支付6分45秒的費用。

#跨雲網路管理、#CNI、#K8s
Arista Networks推出新版網路OS，可用來管理跨雲K8s應用的網路
最近網通公司Arista Networks推出了新版雲端網管作業系統CloudEOS，可用來管理跨公有雲間的網路架構，也主打可部署在容器或K8s叢集上的部署版本，目前可支援AWS和Azure，預計下一季才會支援GCP。企業可用CloudEOS來建立跨公有雲間的網路拓樸，可以即時動態調度網路流量或監控跨不同公有雲上應用的網路用量。CloudEOS會自動加密跨公雲間的網路封包。另外，CloudEOS也支援K8s網路標準介面CNI，可用於管理容器化應用的網路流量，等於，可用來統一管理企業在不同公有雲上的容器化應用所用的網路環境。
責任編輯／王宏仁
更多Container相關動態
Kasten推出K10資料保護軟體新版，新增K8s權限管理
Repl.it開源通用套件管理器UPM
＠資料來源：iThome整理，2019年11月
",https://www.ithome.com.tw/news/134073,"新聞,容器周報,K8s,大數據叢集,SQL Server,Azure Arc,混合雲,IT報告"
134017,8,2019-11-05,微軟利用K8s推出混合雲解決方案Azure Arc,微軟新推出的混合雲解決方案Azure Arc，可無縫橋接企業內部、多雲以及邊緣環境資源," 微軟在Ignite大會上推出新的混合雲解決方案Azure Arc，讓使用者的工作負載可以跨企業內部、混合雲或是邊緣運作，Azure Arc可以讓用戶將Azure的服務部署在任意位置，並透過統一的入口網站進行管理。另外，微軟也持續擴充可將Azure服務部署在私有雲上的Azure Stack，新增人工智慧託管設備Azure Stack Edge。
微軟在2016年的時候推出Azure Stack混合雲端平臺，其結合了IaaS和PaaS，為無法使用公有雲的用戶，提供Azure的本地部署。Azure Stack的功能和Azure很相似，採用相同的標準化架構、應用程式模型以及工具等，只不過Azure Stack是Azure的延伸，讓企業可將Azure安裝在自己的資料中心裡。企業開發人員只要撰寫一次應用程式，就可以在Azure雲端上執行，也能部署到Azure Stack。
而微軟最新發表的Azure混合雲解決方案Azure Arc，集結一系列的技術，將Azure服務和管理功能，帶上各種基礎設施，更加靈活地支援混合應用。Azure Arc擴展了Azure管理功能到Linux、Windows伺服器上，甚至是在任何基礎設施上的Kubernetes叢集，包括企業內部部署、多雲以及邊緣環境。
用戶可以使用更加一致且統一的方法，以Azure資源管理器、Azure Cloud Shell、Azure Portal、API以及Azure Policy來管理混合環境，而藉由Azure Arc，開發者也可以使用各式開發工具建置容器化應用程式，IT團隊也能基於GitOps來配置管理部署。在身分驗證上，Azure Arc在跨環境採用了集中式角色存取控制以及安全性政策。
Azure Arc讓使用者可以在任何地方執行Azure資料服務，可達到以秒為單位的部署速度，在各式基礎設施上動態擴展。用戶在需要的時候，能於任何Kubernetes叢集部署Azure SQL資料庫和Azure Database for PostgreSQL Hyperscale，並且透過Azure Portal取得跨本地端和雲端的總覽，還能跨環境一致地應用政策、安全性和資料治理。也就是說，當用戶的本地系統容量使用完了，可以立刻在Azure的Kubernetes服務（AKS）擴展其他Kubernetes叢集，無縫地取得更多的運算能力。
此外，微軟也繼續擴展Azure Stack產品組合，新增能支援人工智慧運算的託管設備Azure Stack Edge，將運算和儲存帶到邊緣使用案例，其內建FPGA可加速人工智慧的推理工作負載，用戶可以在容器上執行應用程式，並在需要的時候，透過將虛擬機器搬遷到其他伺服器，達成故障轉移的功能。
Azure Stack Hub也有數項更新，Azure Stack Hub是一個雲端原生整合系統，可讓用戶從自家資料中心，或是由其他服務供應商直接交付Azure服務。Kubernetes現在於Azure Stack Hub正式支援Kubernetes，用戶可以用單一的工具來開通、部署和管理Kubernetes叢集，對於調度工作來說會簡單許多。
",https://www.ithome.com.tw/news/134017,"新聞,微軟,混合雲,K8s,Azure"
133976,8,2019-11-01,Container周報第115期：義大利郵政PSD2微服務架構大公開，Rancher容器儲存專案長角牛將捐給CNCF,義大利郵政分三階段，第一先導入DevOps和OpenShift 3.9平臺，第二階段則再加上Kafka來建立資料彙整架構，第三個階段開始導入API閘道器，來管理對外TPP的API串接," 10/25~10/31 精選容器新聞
#微服務架構、#OpenShift義大利郵政靠K8s和Kafka，三階段打造開放銀行微服務架構
全義超過1萬2間個郵局據點，擁有13萬名員工的義大利郵政，因為歐盟PSD2指令要求，早在一年前就開始建置一個開放銀行（Open Banking）架構。兩位義大利郵政IT和解決方案架構師Pierluigi Sforza和Paolo Gigante，最近分享了這個開放銀行架構背後所用的關鍵技術，就是商用K8s平臺OpenShift和開源串流分析平臺Kafka。
義大利郵政分三階段打造這個架構，第一階段先導入DevOps和OpenShift 3.9平臺，先應用到7個大型單體應用上，來測試DevOps模型和工具。有了經驗後，就進入第二階段，目標是透過DevOps、OpenShift再加上Kafka建立一個資料彙整架構，將來自各種資料源的串流資料和各種資料檢視模式，都集中到單一平臺上來提供。新平臺上線後，前8個小時就完成了第一波5億筆資料的彙整，達成了這個階段的目標。
第三個階段，義大利郵政PSD2平臺，開始導入API閘道器，來提供對外第三方業者（TPP）的API串接管理，並用OpenShift建置了一個微服務中臺，包括9大類功能，例如信用卡、付款、資金查核、帳號管理、註冊開戶、詐欺資訊分析等，再串接到後端的現有系統。
另外，義大利郵政也建立了雙層式的異地雙活備援架構，在羅馬跟690公里外位於北義的杜林，各建置了一套鏡象副本PSD平臺，採取雙活（Active-Active）設計，另外在羅馬當地，還在兩座相隔1公里的機房，各設立一套，來建立本地端（羅馬當地）的異地備援，而杜林則是遠地的異地備援，等於這個PSD2平臺使用了3座機房，另外還搭配一家公有雲來提供備份。這個PSD2平臺上線1年後，義大利郵政現有13套叢集，所用的總核心數達到1,300個。已有4套系統正式在這個微服務架構上運作，另有15項新專案正在開發階段。參與的開發人力有353位，每個專案會用到3組Jenkins流程，涵蓋1,200項任務。
不過，兩位維運成員也坦言，Kafka的好處是可支援大量的跨App通訊，也能與傳統儲存相容，但建置成本不低，後續維運和擴充的難度也比較高。下一階段，他們計畫改用支援一家專供K8s版Kafka套件的公司KStrimzi的套裝產品，來取代自行建置整套Kafka的作法，降低自行維護和後續新部署的複雜度，目前正在測試。

 ＃服務網格、＃維運監控大熊貓公司AIOps平臺大更新，推出服務網格即時拓樸功能
大熊貓公司（BigPanda）最近翻新了自家AIOps平臺，可以讓IT維運人員、NOC網管人員和DevOps團隊共同調查維運事件和排除問題。新版增加了服務網格的即時拓樸繪製功能，可即時呈現出企業現有系統或服務之間的呼叫關連，另外也增加了事故原因變更追蹤機制。這個追蹤機制會從監控系統上，蒐集各種系統異動資訊，再利用機器學習技術，來分析這些變動之間的關連，供管理人員找出造成一項問題背後的的關鍵因素。而服務網格拓樸則可彙整字配置管理系統、雲端或虛擬化管理平臺、服務探索機制、PM和CMDB工具的資料，來畫出即時的IT服務架構。

#容器儲存、#RancherRancher決定把容器儲存專案Longhorn捐給CNCF
最近容器廠商Rancher Labs宣布將自家容器儲存專案Longhorn，捐給CNCF，CNCF接受其成為早期孵育的沙箱計畫之一。Longhorn是一套用來管理K8s上靜態資料的容器儲存方案，目前是0.6.2版，主要特色包括了提供企業級分散式區塊儲存、Volume快照、內建備份復原機制、即時更新，也可以跨叢集災難復原，並提供一鍵快速安裝。CNCF技術委員會主席Liz Rice指出，Longhorn列入沙箱計畫後，有助社群進一步發展出更成熟的持久性區塊儲存產品。
#JCP、#AWSAWS宣布加入Java平臺標準組織JCP
最近AWS負責維護OpenJDK發行版本Amazon Corretto的團隊主管Yishai Galatzer宣布，AWS將正式加入Java平臺標準制訂組織JCP（Java Community Process）。Amazon表示，自己有上千個使用Java的正式服務，所以，從2016年先開始提供OpenJDK的二進位發行版，後來，2018年將這個版本也就是Corretto開源釋出，並且更積極參與OpenJDK的開發。Amazon也將自己修補的更新程式，捐給OpenJDK使用，在JDK 8和JDK 11版中各有不少。今年，Amazon先是提供了OpenJDk的加密操作功能，現在又積極參與Java標準的訂定。
#容器管理、#K8s新版才滿月，K8s儀表板工具Kontena Lens再次大更新
免費的K8s叢集管理儀表板工具Kontena Lens桌面版最近連連大更新。一個月前，才剛推出的重要的2.0新版，最近四個禮拜一連推出了19次小改版，目前是2.3版。2.3版主要改善是效能，這也連帶提高了可以管理的K8s叢集數量，根據官方壓力測試數據，2.3版可以管到2萬個pod，仍有一定的順暢度。另外，新版可以提供叢集圖示客製化功能，方便管理人員來分類不同用途的K8s叢集。Kontena Lens有推出企業版，主要企業版功能是，獲得授權後可用來管理AWS EKS和GKE上的K8s環境。

#FaaS、#無伺服器無伺服器框架的狀態保存需求有解了，有態FaaS框架現身
開源串流處理框架Apache Flink開發商Ververica推出了一個新的有狀態分散式應用程式框架Stateful Functions，降低建置以及調度分散式有狀態應用程式的複雜度，Stateful Functions能結合Apache Flink以及函式即服務（Function-as-a-Service，FaaS）的優點，提供事件驅動基礎架構的抽象。Ververica特別解釋，Stateful Functions框架並不是用來取代FaaS或是其他無伺服器服務的，而是要提供一種同時具有無伺服器服務的特性，但又適用於解決狀態中心問題的解決方案。
#K8s、#Google、#紅帽K8s專案最高技術委員會添新人，4名新委員有2人來自紅帽
Kubernetes計畫日前宣布了最近一次的技術委員會票選結果，這次選出了4名新的委員，Christoph Blecker和Derek Carr來自紅帽，K8s大規模部署產品軟體商Loodse也有一人入選，另外還有一位Paris Pittman則來自Google。他們四人任期2年，將與現有3名委員共同主導K8s的未來發展戰略方向。現有3人，其中2人來自VMware，1人來自Google。這意味著，這意味著K8s技術委員會中，Google、紅帽和VMware的人數相當，將成為三巨頭主導發展K8s的局勢。
#可用性、#K8sK8s下一階段要改善可用性，可用性小組最新計畫公布
今年7月時，K8s創辦人之一Brendan Burns，發起了一個新的研究小組SIG-Usability，要來改善K8s專案的各種可用性設計，希望能降低K8s使用門檻。這個小組已經展開多次聚會，最近提出了新的計畫，希望可以在皆下來的1.17或1.18版中開始改善。初步計畫是，一來要了解各種類型的K8s使用者，其次要找出如何協助人們順利導入，以及容易取用K8s的方法。其中一項改善是針對kubectl get事件的功能，希望增加更多事件處理功能，但又不變動kubectl的get功能，例如增加預設的事件排序方式，或是提供更多watch指令的擴充行為。
責任編輯／王宏仁
更多Container相關動態
CockroachDB獲得紅帽容器產品認證
Netflix開源多語言開發筆記本Polynote
K8s 1.17版即將在11月14日凍結功能
＠資料來源：iThome整理，2019年10月
",https://www.ithome.com.tw/news/133976,"新聞,容器周報,義大利郵政,微服務,K8s,OpenShift"
133911,8,2019-10-30,微軟DevOps資安實務大公開，側重威脅模型建立與自動化,在DevOps的流程設計中，從提交前到維運等5大階段，都有可以提升資安的工作要執行，微軟專家技術部雲端架構技術顧問黃承皓強調，所有階段都要加入回饋的機制，不斷去優化流程上的安全，以達快速回饋與修正。," 在近年DevOps風潮下，帶動軟體開發人員與IT維運技術人員，密切溝通合作的文化，但為避免事後才發現安全被忽略，如何將相關安全融入持續整合、持續交付過程，也成關切焦點。
在今年10月中舉行的DevOpsDays臺北場，微軟專家技術部雲端架構技術顧問黃承皓，也提出建言，教大家分享在DevOps過程中，將安全納入考量。
以開發者與維運者而言，都有許多需要注意的安全要項，黃承皓表示，微軟在實作上就是依循微軟安全開發生命週期（SDL），以及營運安全保證Operational Security Assurance（OSA），而重點更是要把這兩項結合在一起，成為能夠順利協作的過程。
同時，人員心態的改變也是一大重點，他並列出幾個要項，包括建立威脅模型，程式碼審核、安全測試與依循SDL，以及紅藍隊攻防演練、集中安全監控與滲透測試，並要思考如何偵測到攻擊，以及事件處理與恢復。

對於實務上開發人員和維運者所遇到的一些問題，以開發者的面向來看，最常見到的狀況，就是設計一開始就沒有考慮到安全，或是程式碼審查（code Review）時只檢查功能，沒有檢查安全，黃承皓並認為第三方Library的使用問題，將會越來越嚴重；而在維運者的面向來看，則是在於系統記錄的細節程度、權限的管理，以及自動政策檢查等方面。
他並舉出四個最常見的情境，例如，在老闆指示很重要的服務要立即交付的壓力下，安全就容易被犧牲，其次，維運者可能為了方便，往往希望透過一個Command指令就能直接登入到伺服器，但時程越趕，通常會導致失誤越容易發生；第三是維運者可能認為設定簡單，不會誤用，但設定錯誤的問題其實很常見；最後，抱持自己的系統都沒問題的錯誤觀念。


要如何確保上述狀況不會發生？怎樣在過程中能逐步變得更安全，對應開發者與維運者的面向，黃承皓表示，微軟在實作上就是依循微軟安全開發生命週期（SDL），當中包含了12項要點，以及營運安全保證Operational Security Assurance（OSA），這部分有也11項要點必須注意。

從威脅模型建立做起，並要重視使用開源的安全管理
要尋找系統潛在威脅，建立威脅模型很重要。黃承皓指出，例如，微軟使用自行開發的威脅模型化工具Threat Modeling，可以顯示系統上所有用到的元件，並容易將各個組件關聯畫出，以瞭解可能的漏洞與安全防範建議。
為了讓安全與DevOps更具效率，黃承皓特別說明，他們現在的作法，是將大型系統整合測試（SIT），拆散成單元測試的形式，並且是放到最前面的階段去做，這樣的好處是，帶來效率上的提升，減少開發完交付測試後所需要的時間。
對於使用開源的安全問題考量，他認為，一般開發團隊可能沒有特別去注意，原因是很花時間，因此，他建議最好能找一些商業軟體來輔助，以掌握使用的程式庫是否過期或有已知漏洞等。
同時，他也列出了不少可用的工具，包括NPM Audit、OWASP Dependency Check、GreenKeeper、Snyk、WhiteSource Bolt與DevSkim等，而他們自己是使用WhiteSource的產品。
 
為了更容易挑選適用的工具，由於相關工具的使用都需要去適應，因此在選工具、選流程時，一定要有自動化執行的機制，他建議，不要挑選太複雜會花很多時間的工具。
還有常見的問題在於，像是程式碼寫死（Hard Code）的問題，他表示可使用一些帳密掃描（Credential Scan）工具，在CI/CD的過程中，檢查程式碼中有無帳號密碼等敏感資訊。
關於身分權限安全方面，黃承皓表示，由於身分盜用對企業的傷害相當直接，因此他強調，應確保各個使用者帳號要是最小權限原則，並可採用多因素驗證，或是IP位址限制等方式，防範外部的入侵，而這些偵測過程，也可透過自動化作法去進行，以隨時監看是否有違反政策的情形。

另外，如果是使用Azure的用戶，他也建議，可以參考Secure DevOps Kit的作法，這裡包含了六大重點環節，能夠幫助使用者瞭解如何設計安全的應用程式，其中，他並強調，建立完善的log機制，可供事後分析或是事前警報。

最後，他也指出在流程設計中，從提交前、提交、驗收、生產到維運這5大階段，都有一些要注意的面向，例如，可以透過掃描工具輔助檢查，而相依性的程式庫一定要掃描，而且要懂得實現Infrastructure as code（IaC）的重要性，以及可利用煙霧測試（Smoke test）來檢測報警監控機制是否完善。他強調，必須要在每個階段都加入回饋的機制，並要作為下次更版的改善目標，才能不斷去優化安全流程。
DevOps的5大階段安全策略與建立回饋機制

關於整體流程上的安全考量，黃承皓提出5大階段的安全建議。例如，在一開始的Pre-Commit階段，可使用威脅模型、整合環境安全外掛，以及pre-commit hooks工具、安全程式碼標準，他並指出透過掃描工具去檢查是不錯的選擇，而同儕審查（peer review）也很重要，畢竟人可以看的程度不同。
在提交（Commit）階段，包括靜態程式碼、安全單元測試與相依性管理。他並強調，相依性的程式庫一定要去掃描，否則永遠不會知道發生什麼事。而在驗收（Acceptance）方面，黃承皓指出Infrastructure as code（IaC）的重要性，在實際布署上，有一些作法可以避免產品被入侵後，需要辛苦重建的過程，便於大型災難復原。例如，透過IaC保留現在的Config環境，甚至在每次布署時都使用IaC的方式去重新布署，可以降低被滲透的機會。這是因為APT攻擊的潛伏時間很長，如果自身的環境是不斷被刪掉重建，相對而言，較不易遭受APT入侵。並要執行安全掃描、雲端組態與安全驗收測試（Security Acceptance Testing）等。無論如何，在CI/CD中加入安全機制，確保線上安全品質，才能不斷確保目前線上的安全，並將修正加入CI/CD流程。
在最後兩階段中，其實也有不少需要進行的資安工作。在組態檢查與滲透測試之外，他也指出在紅藍隊情境可用煙霧測試Security Smoke Test，來檢測報警監控機制是否完善，最後並要有持續的監控、威脅情資、滲透測試與非指責性事後調查。另外，他也特別強調，在這五大流程設計中，其實都要有回饋並能加入下一次迭代，才能不斷優化安全流程。
",https://www.ithome.com.tw/news/133911,"新聞,DevOps,DevOpsDays"
133815,8,2019-10-25,Container周報第114期：更多銀行擁抱容器和微服務，彰銀從分行端末系統擁抱K8s，華南則用微服務改造銀行中臺,「沒有踩進去，就無法知道前置作業得準備到什麼程度才夠，做過一次就知道。」彰化銀行資訊處處長陳顯龍決定，先從分行端末系統開始擁抱容器技術和微服務，讓IT團隊練手," 10/17~10/24精選容器新聞
#彰化銀行 #核心系統改造彰化銀行不只展開核心系統大升級，還準備擁抱K8s
最近彰化銀行資訊處處長陳顯龍透露，百年歷史的彰化銀行，最近正在思考銀行架構的大改造，不只要展開銀行核心系統大升級，為了更快速反應市場變化，陳顯龍還計畫，引進最夯的微服務架構、容器技術、商用Kubernetes產品等，來優化現有的系統。他希望改用「服務」來取代過去以業務為導向的功能模組，打造一套可以彈性組合和擴充的新一代分行端末系統。陳顯龍早在多年前就推動過一波彰銀IT集中化架構的改造，可以做到全球全行一日結帳。相比自己過去熟悉的VM、SOA架構，他認為，容器和微服務架構的核心概念其實也很類似，開始導入這些技術時，銀行IT團隊仍然大概可以知道該如何進行。但是，「沒有踩進去，就無法知道前置作業得準備到什麼程度才夠，做過一次就知道。」他坦言：「第一次不見得能做好，就算這次失敗，下次就可以調校得更棒。」所以，趁著核心系統升級之際，他打算先從分行端末系統開始擁抱容器技術和微服務，讓IT團隊練手。
#華南銀行 #微服務 #銀行中臺華南銀行展開銀行中臺系統大改造，準備擁抱微服務架構
華南銀行近年也全力推動數位轉型，華南銀行營運管理事業群副總經理許柏林指出，數位金融的時代來了，各家銀行也都逐漸走向這種可以因應不同需求的新架構。尤其，「前端需求越來越多元，不同時間點的需求也不同，銀行需要一套更容易調度資源的新架構。」因此，華南銀行在幾個月前，也展開了銀行中臺系統的大改造。目前華南計畫擁抱微服務架構和容器技術，許柏林比喻，過去的應用系統是大型單體應用，要跨大服務容量，得複製全套系統來建立新主機才行，但是改用微服務架構後，可以針對其中一項功能性服務來進行擴充。例如遇到大型活動，需要大量轉帳交易時，就可以直接擴充負責轉帳交易的那一組微服務，來滿足臨時暴增的需求。不過，華南銀行還需要一段時間，才能完成這個中臺架構大改造。
#容器安全 #雙因素驗證Docker Hub現支援TOTP雙因素驗證
現在Docker Hub開始支援雙因素驗證，官方採用了比SMS更強的基於時間的一次性密碼（Time-Based One-Time Password，TOTP）身分驗證，使用者可以在帳戶設定的安全選項中啟用，而在啟用雙因素驗證後，Docker CLI將要求使用個人存取令牌而非密碼登入。目前雙因素驗證功能仍在Beta測試階段，在不久之後將會正式發布，之後官方計畫增加其他身分驗證控制，包括對WebAuthn的支援，讓用戶可以使用支援WebAuthn的安全金鑰和瀏覽器執行雙因素驗證，之後也會提供強制組織使用雙因素驗證的控制選項，讓組織管理員可以強制要求所有成員使用雙因素驗證，並對無法使用的人提供額外的支援方法。

#微服務 #應用程式開發微軟開源微服務應用開發套件Dapr專案
微軟近日發表了新的開源專案Dapr，它的全名為分散式應用程式執行環境（Distributed Application Runtime），目的在於協助開發人員更容易建置微服務應用程式。Dapr是由一套建置區塊所組成，可透過標準的HTTP或gRPC APIs來存取，每個區塊都是獨立的，可在應用程式中選用全部或其中幾個，同時微軟也歡迎開源社群貢獻更多的區塊與元件。目前的Dapr專案處於alpha階段，因此僅提供最常用的建置區塊，像是服務調用、狀態管理、服務之間的出版與訂閱通訊、事件驅動的資源綁定、虛擬模型，以及服務之間的分散式追蹤。開發人員已可藉由GitHub存取Dapr程式碼與範例，微軟亦替Dapr建立了專屬網站以供開發人員交流。


#挖礦綁架 #軟體供應鏈風險 #DockerDocker Hub上映像檔被發現存在挖礦綁架蠕蟲
資安公司Palo Alto Networks威脅情報小組Unit 42發現一種新型的Graboid挖礦綁架蠕蟲，目前已知這個蠕蟲已經感染了超過2,000臺不安全的Docker主機，用於挖掘Monero加密貨幣，研究人員提醒，雖然這個挖礦綁架蠕蟲沒有複雜技術或是程序，但是由於他有能力從C2（Command and Control）伺服器下載新腳本，因此可以簡單地轉換成勒索軟體或是任何惡意軟體，企業應提高保護自家Docker主機的能力。研究團隊分析了蠕蟲使用的主機列表，其中包含2,034臺易受攻擊的主機，57.4％的IP來自中國，而13％位於美國，在Graboid使用的15臺C2伺服器中，主機列表中列了其中的14臺，這表示攻擊者會控制易受感染主機的Docker守護行程，在上面安裝網頁伺服器容器，並將惡意載體放在上面。
#AMP #OpenJS #網站開發Google決定放手，讓前端框架AMP專案加入OpenJS基金會
Google發起的網頁前端框架AMP專案，最近宣布將申請加入OpenJS基金會的孵育計畫，未來將成為OpenJS管理的計畫，不再由Google維護。Linux基金會旗下的OpenJS基金會是由Node.js基金會與JS基金會合併而成，主要以推動網頁開發技術為主的中立組織。不過，Google自己也是OpenJS基金會的成員，也可以繼續餐與AMP專案的維護，只是不再是主導者。去年底，AMP社群擔心這項專案與Google綁太緊，反而失去了擴大發展的機會，所以，Google決定放手，讓AMP專案改採開放治理模式，交給OpenJS基金會管理。未來將由OpenJS基金會的跨專案委員會負責。另外，AMP加入後，也需符合OpenJS今機會的準則，對所有廠商平等對待，不能有差別待遇。另外，目前AMP的runtime仍放置於Google環境中，未來將透過其他OpenJS基金會的管道來提供，類似jQury CND服務來釋出，不會只有Google一個來源。
#Kubeflow #機器學習 Ubuntu釋出19.10版，更容易用Kubeflow來建立機器學習計算用的K8s叢集了
開發者愛用的作業系統Ubuntu釋出了19.10版，這是一個短期支援的版本，不過，新增了不少開發者期待的功能。其中最受矚目的一項是過去得自行安裝的機器學習部署工具Kubeflow，現在直接成了Ubuntu內建的輕量型K8s套件MicroK8s的外掛之一，這意味著開發者可以快速透過MicroK8s來建立一個機器學習專用的大型K8s叢集，以執行各種Tensorflow任務。另外，這個版本也採用了LZ4壓縮技術，來加快開機速度，並實驗性地提供ZFS檔案格式的支援，這是源自Solaris作業系統的檔案格式，擅長用來建立一個大型邏輯磁碟管理，能整合數十臺實體硬碟的容量。
#服務網格 #OpenShift紅帽OpenShift小改版，內建服務網格功能正式上線
熱門的商用K8s管理平臺紅帽OpenShift最近推出了4.2新版，強化了與無伺服器技術的整合，主要有四大新功能。第一項是OpenShfit內建服務網格功能正式推出，可以成為K8s維運器之一，來快速部署新的服務網格。其次，OpenShift現在可以在本地端建立執行環境了，開發者可使用紅帽CodeReady容器映像檔，快速在自己的筆電上，建立一個OpenShift環境，進行各種測試或開發，不需像過去得使用雲端OpenShift環境來測試了。第三個新特色是開始支援無伺服器開發框架Knative，這是由Google主導的開放無伺服器運算框架，目前OpenShift可提供預覽版支援。最後一項新特色是支援K8s原生的CI/CD工具Tekton，這是一個可以快速建立CI/CD流程，來串接K8s資源和開發環境的工具。

責任編輯／王宏仁
更多Container相關動態
SUSE決定退出OpenStack雲市場，改聚焦應用交付產品
微軟和Firefox聯手推出網頁開發用的新除錯工具
Perl 6正式改名為Raku了
Python則釋出了3.8版

＠資料來源：iThome整理，2019年8月
 
 
 
 
",https://www.ithome.com.tw/news/133815,"新聞,容器周報,銀行,彰化銀行,華南銀行,微服務,容器,K8s"
133810,8,2019-10-24,AI趨勢周報第106期：自然語言生成新成就！微軟UniLM更勝BERT達SOTA等級,微軟研究院在GitHub上釋出一套自然語言處理（NLP）預訓練模型UniLM，可完成單向、雙向和序列至序列預測，並可針對自然語言理解（NLU）和自然語言生成（NLG）來微調。它在NLP基準測試如SQuAD 2.0和CoQA問答任務方面皆優於BERT，而且在5項NLG資料集上達到SOTA等級，包括摘要生成、問題生成和回答問題等。," 重點新聞(1018～1024 )
NLP    微軟     UniLM  
自然語言生成新成就！微軟UniLM更勝BERT達SOTA等級
微軟研究院日前在GitHub上釋出一套自然語言處理（NLP）預訓練模型UniLM，它在NLP基準測試如SQuAD 2.0和CoQA問答任務方面皆優於BERT，而且在5項自然語言生成（NLG）資料集上達到SOTA等級，包括摘要生成、問題生成和回答問題等。
研究團隊指出，目前NLP預訓練技術已有許多新進展，但Google BERT透過左右雙向來預測詞意的方法，難以勝任NLG任務。因此，團隊提出一套預訓練模型UniLM，可完成單向、雙向和序列至序列（Sequence-to-sequence）預測，並可針對自然語言理解（NLU）和NLG來微調。UniLM是一個多層類神經網路，由數個經大量文本預訓練而成的Transformer AI模型組成。團隊表示，UniLM與BERT相似，都可微調，來適應下游的多元任務。但與BERT不同，UniLM可使用不同的自我注意力遮罩來設置，以匯總不同語言模型的語境（Context）。此外，由於預訓練的統一性，Transformer網路可共享參數，讓學習到的文本特徵更加通用，來減輕單一任務過度學習（Overfitting）的狀況。（詳全文）
  Nvidia   Aerial      OpenShift  
Nvidia推出5G訊號處理SDK Aerial
看好5G和邊緣運算發展，Nvidia在剛揭幕的洛杉磯世界行動通訊大會MWC上發表可處理5G訊號的軟體開發套件Ariel，由自家邊緣運算平臺Nvidia EGX支援，可助電信業者建立完全虛擬化的5G無線接取網路（5G vRAN）。
Aerial包括了2個關鍵SDK：CUDA虛擬化網路功能（cuVNF）和CUDA基頻（cuBB），其中，cuVNF提供了優化的輸入／輸出和封包（Packet）處理功能，可直接將5G封包傳送到GPU來處理。而cuBB則提供了GPU加速的5G訊號處理工作流程，來提高吞吐量和處理效率。Aerial除了能在EGX上執行，Nvidia也與紅帽合作，讓紅帽的Kubernetes容器平臺OpenShift可管理和自動化執行Aerial 5G RAN、容器網路功能和其他邊緣運算新服務，要提供電信業者大規模部署和管理現代化基礎架構的服務。（詳全文）
  Ubuntu     K8s    AI開發  
Ubuntu 19.10版終於釋出！聚焦K8s邊緣功能、AI整合開發
歷經25周開發，開源作業系統Ubuntu 19.10版近日終於釋出，亮點包括了新增的Kubernetes邊緣功能、AI開發整合體驗，以及號稱最快速的GNOME桌面環境效能。首先，新版本對MicroK8s的限制更嚴格，來提供完全隔離、高度安全的K8s環境。MicroK8s一個較輕量的K8s，可在終端工作站或邊緣裝置執行，而新版Ubuntu可透過單一指令，在邊緣裝置部署MicroK8s的附加元件，像是Istio、Knative、CoreDNS、Prometheus和Jaeger等。
至於AI部署方面，在Ubuntu 19.10中，K8s的機器學習套件Kubeflow可作為MicroK8s的附加元件來使用，讓開發者在幾分鐘內就能建立環境、開發、測試和擴展AI模型。此外，新版搭配的GNOME 3.34桌面環境大幅提高執行速度，就算在舊硬體上執行，也能享有新性能。此外，使用者現在還可試用ZFS檔案系統支援。（詳全文）

  國網中心    智慧醫療建模平臺     生醫資料庫  
國網中心整合軟硬體資源與生醫資料庫，12月要推出智慧醫療建模平臺
國網中心自今年開始提供臺灣AI雲（TWCC）服務後，為降低生醫領域跨足AI應用的門檻，也著手整合各類生醫資料庫與軟體技術，結合TWCC的運算資源推出智慧醫療建模平臺，預計12月開放學研和產業界申請使用。
智慧醫療建模平臺整合了多項服務，在軟體技術部份整合了國網中心與各大醫院、學校合作的成果，包括與長庚醫院合作開發的睡眠呼吸中止症評估平臺、與臺大獸醫系的數位病理標記與分享系統等。在資料庫整合方面，國網中心建置國網生科雲LIONS，串接各類生醫研究常用資料庫的API，讓研究人員可同時查詢多種資料庫。由於智慧醫療建模平臺建立於超級電腦臺灣杉一號的雲服務上，使用者可運用LIONS的資料庫來建模、執行AI運算，再下載模型、透過網頁或App來提供服務；而國網中心也會提供常用的模型，並協助訓練模型、調整參數達到最佳化。（詳全文）
  SOTA   AI模型評估     Sotabench  
想評測GitHub上SOTA等級模型，就來Sotabench網站
機器學習資源網站Paper with Code日前發布一個免費網站Sotabench，專門用來評估和測試GitHub上達SOTA等級的模型。Sotabench團隊已建立了8個基準測試，包括了ImageNet 影像分類、COCO Minival物件偵測、WMT2014和WMT2019英文-德文機器翻譯、WMT2014英文-法文機器翻譯、WikiText-103語言模型、SQuAD1.1 dev和SQuAD2.0 dev問答能力等。每個基準測試頁面都有一個排行榜，來總結現有模型的排名，此外還有一列清單，顯示Paper with Code上現有但未經測試的模型。
另一方面，團隊也鼓勵大家貢獻更多基準測試，貢獻者可免費使用GPU資源來進行開放的模型基準測試，並可將測試結果與研究論文結果比較，以實現可重複性。（詳全文）
Delta Lake    資料湖     Linux   
開源資料湖專案Delta Lake將交由Linux基金會管理
由Apache Spark技術團隊所創立的資料科學公司Databricks宣布，旗下開源資料湖專案Delta Lake將由Linux基金會託管。Databricks 4月時開源了Delta Lake，受到廣泛的使用，為進一步擴大社群，Databricks與Linux基金會合作，透過Linux基金會的影響力來發展開源專案。
此外，Databricks也與阿里巴巴、Booz Allen Hamilton、英特爾和Starburst合作，讓Delta Lake不僅能支援Apache Spark，還能同時支援Apache Hive、Apache Nifi和Presto。接下來，Delta Lake會採取開放治理的模式，鼓勵社群參與和貢獻技術，藉由長期管理框架，建立Delta Lake社群生態系，並發展資料湖中資料儲存的開放標準，確保Delta Lake的資料保持開放且可存取。（詳全文）

Deepfake   臉書     AWS  
臉書、微軟打擊Deepfake影片活動啟動，AWS加盟贊助
臉書、微軟發起Deepfake影片辨識技術創新大賽將於12月正式啟動，近日雲端大廠AWS也表態加盟並贊助運算資源給參賽隊伍。這場Deepfakes Detection Challenge比賽，旨在邀集各方好手來開發能辨識AI技術造假影片的技術。臉書和合作廠商發布數萬個包含真實未處理和利用AI產出的Deepfake影片、音訊及其他檔案，讓參賽者用這批資料集，來設計能辨識資料真偽的演算法，這些演算法會再以另一批祕密測試資料集來評估，最後再評選出最優秀的模型。
AWS也將釋出自家平臺資源來贊助這項活動。AWS S3雲端服務將代管估計超過4 petabytes的所有比賽影音資料集，未來2年也預計提供100萬美元等值的AWS點數，供參賽者開發、測試演算法。每一隊最初都能要求最少1000美元的AWS點數，表現優異的計畫之後還能申請高達1萬美元的點數。該公司將派出Amazon機器學習解決方案實驗室專家，在參賽隊伍競賽期間提供協助。（詳全文）
圖片來源／Linux、Ubuntu
 AI趨勢近期新聞 
1. GoShare共享機車進駐臺北，能用AI分析用戶行為來推薦用車、找停車位
2. Adobe發表新AI演算法，可修復受損照片或影片
3. Alphabet Wing推出全美首個無人機快遞服務
4. Google將更新Pixel 4人臉解鎖功能，可設定只在睜眼時解鎖
資料來源：iThome整理，2019年10月

 

",https://www.ithome.com.tw/news/133810,"新聞,AI,IT周報,微軟,NLG,Ubuntu,SOTA,Sotabench,Nvidia,5G,Aerial,K8s,國網中心,醫療AI"
133789,8,2019-10-23,Fintech周報第118期：國泰金控建立DevOps文化加速數位產品開發，每周能完成破100項服務需求,設立在國泰金控底下的數位數據暨科技發展中心（數數發），作為推動集團數位轉型創新引擎，近期揭露內部已建立DevOps文化，也協同國泰金控旗下子公司導入DevOps文化與敏捷式專案管理，來開發數位金融產品。以國泰世華銀行在導入DevOps文化為例，現在每周可將100多個服務需求完成上線。," 1019-1025
 國泰金控   數數發   DevOps文化  國泰金控建立DevOps文化加速數位產品開發，每周能完成破100項服務需求國泰金控2016年設立的數位數據暨科技發展中心（簡稱數數發）作為國泰金控推動集團數位轉型的創新引擎，目前團隊人數在9月底達到了近500人的規模。數數發近期更揭露，內部已建立DevOps文化，包括產品敏捷開發、使用者易用性檢測、軟體測試工程、CI/CD（持續整合/持續交付）、維運監控，加上先前已建立的AI大數據平臺架構，要以客戶為中心的思維，應用創新技術，來壯大數位數據生態圈。
國泰數數發中心數位體驗科技部協理陳明泉指出，導入DevOps文化最大的好處，是讓軟體開發人員（Development）跟IT維運人員（Operations）更緊密溝通及合作，消除過往兩者間可能產生的鴻溝，進一步強化協作關係，加速軟體的開發、測試、部署、發布、監控。 
設立在金控端的數數發，協同國泰金控旗下子公司導入DevOps文化與敏捷式專案管理，來開發數位金融產品。目前，已應用在KOKO數位銀行、國泰優惠（My Rewards）App、國泰智能投資、國泰世華行動銀行等多項數位金融產品。
比如國泰世華銀行在導入DevOps文化後，可大幅去除複雜的開發框架、簡化上版部署申請流程、繁瑣測試工程及監控部署，透過網路、架構、交易、資安、客服等IT相關部門組成審議會議，現在每周可將100多個服務需求完成上線，並落實集中版控、集中編譯、隔離部署，落實DevOps文化。 
 花旗銀行   系統出包   金管會  花旗銀行年初系統出包，遭金管會開罰500萬

今年初花旗(台灣)銀行爆發系統大當機，導致超過萬名客戶的存款交易當天未能過帳。為此，金管會在10月17日宣布，開罰花旗銀行500萬元。金管會指出，花旗銀行執行批次作業部分交易檔案，未完整過帳到主機系統，導致客戶新臺幣帳戶餘額不正確，顯示其資訊系統的穩定性、可靠性與安全性控管不足。
此外，在委外作業上，金管會認定，花旗銀行未建立有效內部控制與稽核制度，監督受委託機構亞太資訊中心，在系統軟硬體、人員、測試、檢核等相關內控機制的執行，欠缺有效性。
原因是，花旗銀行未考量由委託機構的測試環境，轉換到受託機構的正式環境，可能產生的作業風險，金管會認定，花旗未針對此作業流程，建立有效檢核或監控機制，導致未能及時發現亞太資訊中心人員執行排程設定發生錯誤，或是覆核人員未檢查出錯誤，而造成系統異常。 
此外，金管會還指出，花旗銀行對於臺灣BAFES系統與新加坡主機系統間檔案傳輸作業，未有效建立檢核機制。金管會提到，花旗銀行雖然新增了系統自動在檔案傳輸完成時，啟動檢查作業。只是，未就檔案未傳輸的情況建立有效的檢核機制，或異常緊急處理作業流程，導致發生連線異常時，除這項新增的監控機制未發揮作用之外，也未能恢復檔案傳輸。 
 金管會   資訊系統   銀行公會  金管會要求公會訂定自律規範，強化銀行資訊系統作業風險抵禦能力

銀行系統頻頻出狀況，花旗銀行年初系統出包事件，才在上周遭金管會開罰；中華郵政也在今年7月底發生全臺當機事件，全臺近1,300間郵局的儲匯營業窗口與3,000多臺ATM（自動櫃員機）及網路交易服務全部無法運作。
根據聯合報報導，為了強化銀行資訊系統的作業風險抵禦能力，金管會已要求銀行公會，對銀行資訊系統出包時的衝擊容忍度訂定自律規範，並要求銀行應建置備援系統與制定恢復計畫。尤其是跟客戶密切相關的存款、匯款及ATM等核心系統，希望在2小時之內恢復中斷的服務。此外，純網銀的要求可能會更高，而此新規定預計明年上路。 
金管會也要求銀行公會，在研擬此自律規範有兩大項重點。一是將銀行資訊系統區分為核心與非核心系統，分別訂定衝擊容忍度。銀行公會需明訂核心及非核心業務的範圍，比如存款、匯款、ATM、網銀等跟客戶密切相關的業務，屬核心業務。二是，核心業務部分的容忍度，應比非核心業務嚴格。 
 LINE   野村控股   區塊鏈聯盟  LINE攜手日本最大投行野村控股，共組區塊鏈聯盟發展商業機會
通訊軟體LINE旗下負責加密貨幣與區塊鏈相關業務的子公司 LVC，繼今年9月獲得日本金融廳(FSA)的許可證，正式在日本開始營運加密貨幣交易所BITMAX，LINE日本每月8,100萬活躍用戶，可直接用LINE通訊軟體登入此交易所，除了連接銀行帳戶外，用戶也可以用LINE Pay帳戶買賣加密貨幣。 
LINE更在10月初揭露區塊鏈最新布局，宣布與旗下LVC，共同和日本最大投資銀行野村控股Nomura達成聯盟協議，要共同探索區塊鏈產業中的商業機會。目標是長期合作來用區塊鏈技術建構新的金融服務。 
 開放銀行   TSP   中華徵信所   徵信科技  搭上開放銀行風潮，新型態TSP業者出現

臺灣金融圈在今年初正式吹起開放銀行（Open Banking）風潮，在各家銀行積極參與之下，也有階段性成果。然而，在TSP業者之中，除了有幾家FinTech的新創在前期備受關注之外，現在，開始有一些新形態的金融創新服務出現了。 
在2017年被義大利商收購的中華徵信所（現為CRIF中華徵信所），CRIF中華徵信所總經理郭曉薇表示，近年中華徵信所結合了原有的徵信業務外，以及CRIF集團的金融徵信技術，推動全面的數位轉型，今年開始將全力發展「徵信科技」（CredTech），要協助臺灣金融機構在數位化轉型的道路上提升效率、獲利和提升客戶體驗。 
在開放銀行浪潮下，郭曉薇表示，CRIF中華徵信所在未來將進入個人信貸領域，成為TSP業者之一，在徵信生態圈中扮演著更重要的中介角色，並以自身徵信實力，為金融業者提供消費者的個人信用評估服務，推動大數據徵信服務。CRIF集團開放金融暨市場調查總監Silvia Cotta Ramusino也表示，CRIF集團近年來在歐洲，透過企業收購以取得31個國家的開放銀行信用評分執照（AISP），將在歐洲國家提供開放銀行相關服務。 
 MediaLab   Kik Messenger   Kik加密貨幣  MediaLab買下Kik Messenger傳訊程式，期待未來整合Kin加密貨幣

提供許多網路服務的MediaLab宣布將買下北美傳訊程式Kik Messenger。Kik Interactive在日前宣布將結束已發展9年的傳訊程式Kik Messenger，以專注於新興的加密貨幣Kin，MediaLab的出現則讓Kik再現生機。MediaLab表示，未來該公司將持續開發Kik，但會著重於改善程式的速度及可靠性，也會致力於減少程式臭蟲與機器人訊息，並期待在未來整合Kin加密貨幣。
至於仍與美國證券交易委員會（SEC）纏訟中的Kik Interactive則會繼續與SEC抗戰，並投入Kin的發展。 
 台新銀行   全家   刷臉支付  台新銀行攜手全家便利商店，將推出刷臉支付服務台新銀行繼ATM刷臉提款服務後，在10月17日宣布與全家便利商店合作，導入刷臉支付服務。台新銀行數位金融處副總經理包國儀表示，將刷臉支付功能結合到全家自助結帳機，民眾未來在全家便利商店自助結帳時，透過刷臉就能快速完成交易。
圖片來源：Citi、LINE、 CRIF中華徵信所、Kik Messenger責任編輯／李靜宜
",https://www.ithome.com.tw/news/133789,"新聞,FinTech周報,國泰金控,數數發,DevOps,花旗銀行,系統出包,金管會,資訊系統,Line,野村控股,區塊鏈,開放銀行,台新銀行刷臉支付,全家,IT周報"
133736,8,2019-10-21,Container周報第113期：德國快時尚商大談如何管140座雲端K8s叢集，而Google的Knative決定引起兩位K8s創辦人不滿,Google最近決定，Knative專案將不會捐給任何基金會，如CNCF，仍會繼續開源，但將由指導委員會繼續負責管理，兩位K8s創辦人Brendan Burns和Joe Beda紛紛大表失望！," 10/4~10/16精選容器新聞
#大規模K8s管理 #KaaS #企業實例德國快時尚網站Zalando如何管理140個K8s叢集？
德國快時尚網站Zalando內部有200個開發團隊，為了支援上千名內部開發者所需的基礎架構資源調度，他們的K8s團隊自行打造了一套KaaS服務（Kubernetes as a Service），來管理目前部署在AWS上的140多個K8s叢集。
Zalando建置這套KaaS有幾個目標，全面自動化維運、不養寵物叢集、高可靠度、自動縮放。在架構上，Zalando採取了成對調度策略（provision in pairs），一次都會同時部署線上環境和非線上環境的叢集。每個叢集都有一個專屬、獨立的AWS帳號（意味著目前有140多個帳號），可建立獨立網路環境的K8s叢集，但是所有帳號的配置工作，都統一由一套客製化Python工具來執行。Zalando也將整套線上環境的叢集配置放上GitHub來進行版本控管，並盡量使用AWS提供的CloufFormation範本快速建立應用程式建置架構。
另外，不論Master節點或Worker節點都用同一套自製AMI映像檔，採用Ubuntu和一套內建了Zalando所有在K8s需要的Docker映像檔。預先定義AMI有助於縮短開機時間來加快叢集擴充工作。另有一個利用PostgreSQL來基礎所建立的集中式Cluster Registry，所有工具都可以透過這個Registry的REST API來查詢。
＃CNCF #Knative #開源專案經營Google決定不將Knative專案捐給CNCF或任何基金會，引起K8s創辦人不滿！
由Google發起的開源無伺服器專案Knative將不會捐給CNCF基金會。Google Cloud Run產品經理Donna Malayeri在十月初時，在Knative社群宣布了這項消息。她指出，Knative專案成立之初，就一直在討論是否將專案捐出去給基金會，例如像是負責管理K8s的CNCF。不過，Google最近決定，Knative專案將不會捐給任何基金會，仍會繼續開源，但將由指導委員會繼續負責管理。這也意味著，Google將繼續主導Knative未來的發展大權。目前Knative指導委員會成員有7人，其中4人來自Google，另有來自Pivotal、IBM和紅帽各一人。
不過，Google這項宣布後續也引起其他科技業者或社群領袖的批評。例如任職於微軟Azure的Kubernetes專案創辦人Brendan Burns和任職於VMware的K8s另一位創辦人Joe Beda都跳出來大表失望，質疑此舉將有損於Knative的開放性。Joe Beda甚至直指，Istio也有同樣的情況。Donna Malayeri表示，未來幾周將會公布指導委員會的參加辦法，讓更多社群和業者可以參與，另外也會公布更詳細的指導委員會職務和分工。

#CI/CD #K8s導入經驗 #GitLabGitLab經驗：導入K8s前最好先做CI/CD，釐清自家應用程式的架構
GitLab派送工程經理Marin Jankovski最近一場演講中，分享了他們剛把Registry服務搬上K8s平臺上，過程中體會的經驗。他認為，擁抱K8s時，不只需要調整線上正式系統，也需要改變工程師的思維。他建議，擁抱K8s之前，工程師必須要具備CI/CD觀念，更聚焦程式碼的品質管理和更嚴格的功能規畫，甚至，他認為，與其花時間導入一套完善的CI/CD平臺，不如先利用現成簡單的工具，快速建立一個CD系統，快速找出現有應用程式的基礎架構。他解釋，CI自動化會讓應用程式的任何弱點都更凸顯，若先改善應用程式的架構體質，有助系統全套遷移到K8s。
而在GitLab的經驗上，Marin指出，擁抱K8s前先導入CI/CD，可以帶來另一個好處是，開發者對「完成」的定義改變了，過去開發人員只要通過程式碼審查就是完成，但這沒有考慮到程式碼部署到不同環境中隨時間變化的情況。「既然現在可以快速完成部署，就沒有理由忽視新異動在測試和正式環境的運作。」所以，像GitLab開發團隊每次部署後，會多等一天觀察，程式碼合併後的影響。
#HANA #K8s #SAPSAP要讓HANA資料庫未來能原生支援K8s叢集，年底前推出
SAP在年度TechED技術大會上宣布，SAP HANA記憶體式資料庫將可以原生支援K8s叢集，預計最快今年聖誕節年正式推出。SAP技術長Juergen Mueller表示，SAP的HANA雲已經演化成微服務架構的服務，這也讓SAP HANA更容易縮放規模，下一步就是在HANA資料庫上也採用微服務來強化擴充性。為了讓SAP產品更容易跨多雲部署，SAP宣布，當HANA資料庫原生支援K8s之後，企業將可以在這個基礎上來部署SAP所有的軟體。不過，因為另外，SAP也表示，將繼續強化對Cloud Foundry的PaaS框架的支援和貢獻。

#應用程式部署 #雲端原生 #CI/CDPuppet推出Nebula專案簡化雲端原生應用程式部署工作流程
老牌自動化組態管理軟體供應商Puppet推出了新專案Nebula，用來簡化雲端應用程式的部署工作，其提供了一個工作流程建置器，可以讓管理員定義部署應用程式的每個步驟，管理軟體元件的載入順序到硬體的配置等工作。Nebula提供了建置、配置和部署雲端原生應用程式的單一平臺，目前在公開測試的階段，專注可改善生產力的功能，內建範例工作流程，可以幫助開發者開始部署工作，並支援超過20種熱門的雲端部署工具，包括Terraform、CloudFormation、Helm以及Kubectl等。Puppet強調，使用Nebula可以簡單地編寫部署工作流程，Nebula與原始碼控制儲存庫深度整合在一起，開發者不再需要編寫混亂的bash腳本。
#EKS #Windows容器 #KubernetesAmazon EKS現在正式支援Windows容器
AWS在其Kubernetes服務正式推出支援Windows容器功能，使用者現在可以在Windows伺服器上安裝應用程式，並且與其他Linux應用程式一同部署在Kubernetes上，這項功能同時提供系統日誌、效能監控以及程式碼部署工作管線。Kubernetes在今年3月底發布1.14版本時，開始支援Windows容器，讓使用者可以將Windows節點加入工作節點（Worker Node）或是進行Windows容器調度。AWS提到，目前在叢集中至少需要有一個Linux節點來支援Windows節點和Pod網路，AWS建議用戶可以使用兩個Linux節點來實現高可用性。另外，Windows容器通常比Linux容器大，因此下載和啟動的時間都會更久。
#容器管理平臺 #Rancher #IstioRancher釋出2.3新版，也開始支援Windows容器
隨著Kubernetes 1.14版支援Windows容器格式後，越來越多通用型容器管理平臺正式支援1.14版，也同時支援了Windows容器。例如容器管理平臺業者Rancher Labs最近宣布旗下K8s管理平臺也開始支援Windows容器，而也可整合到服務網格軟體Istio，新版更提供了更多K8s叢集建置範本，例如可重複使用的Kubernetes配置範本。目前Rancher 2.3版可支援到Kubernetes 1.15版和Docker 19.03版。
責任編輯：王宏仁
更多容器新聞
搶攻企業DevOps小團隊，HashiCorp推出5人免費版
Carbon Relay推出靠K8s跑AI應用的優化工具Red Sky Ops
",https://www.ithome.com.tw/news/133736,"新聞,容器周報,Container,Knative,CNCF,google,SAP,GitLab,IT報告"
133649,8,2019-10-16,凌羣發表第四代Ayuda機器人主攻零售市場，月底要先導入美麗華、大潤發與義大,凌羣電腦今天在2019 AIoT展上發表第四代Ayuda，要搶進零售業市場。不僅整合了類似多媒體事務機kiosk的功能，能掃描電子發票QR code來顯示停車優惠、甚至繳費，也建置更完善的雲平臺來進行大數據分析，投放個人化廣告達到精準行銷的目的。," 繼2017年推出服務型機器人Ayuda後，凌羣電腦今天在2019 AIoT展上發表第四代Ayuda，強調從零組件、軟體、到系統整合100%國產製造。不同於第三代Ayuda多應用於警政、醫療等場域，第四代Ayuda主攻零售業，不僅整合了商場常用的QR code、NFC、RFID感應及晶片卡讀取功能，來掃描電子發票顯示停車優惠，也整合了熱感應紙列印功能，來發放號碼牌或優惠券。
Ayuda原先就有五大基本功能，應用在各式場合服務群眾。一是藉由移動式的頭部、手部來主動迎賓；二是採用訊連的人臉辨識AI引擎來識別訪客身分，並整合大數據分析進行個人化推薦；三是運用自行開發的語音辨識與回覆技術，來初步解答訪客問題；四是當訪客需求較為複雜時，透過遠端連線提供專人服務；五是裝設激光雷達來自建場域地圖，能自動帶位或避障。
而第四代Ayuda，則是凌羣透過資通所牽線，與大潤發、美麗華、高雄義大世界合作，由三家零售業者提交應用場域的需求，凌羣開發整合後，再導入實際場域測試。該公司軟體事業群第二專案總處長邵成武表示，美麗華是傳統百貨公司，大潤發為複合型量販店，義大世界則包含娛樂及零售、腹地大且複雜，針對三種場域，Ayuda也能提供不同形式的應用。

第四代Ayuda整合kiosk功能與雲端平臺，要主攻零售業市場
因應零售業者的需求，第四代Ayuda逐漸整合了類似多媒體事務機kiosk的功能，在外型及應用上，新增了QR code、NFC、RFID感應及晶片卡讀取的設計，能掃描電子發票QR code來顯示停車優惠，未來甚至要結合繳費功能，讓民眾感應卡片來繳納停車費；此外，也新增了熱感應紙列印功能，來列印號碼牌、優惠券或繳費收據。
另一個改變，則是後臺雲平臺的建置更加完整。後臺的雲端服務，能讓業者上傳各類廣告、宣導影片，再派送到各臺機器人來播送，不必再用USB傳輸資訊到機器人中；而雲端也能整合各個機器人即時上傳的資訊（如人臉資料），再同步派送給其他機器人更新，維持多臺機器人資料的一致性。
邵成武也提到，建置雲端平臺的最大優勢，是能串接業者的後臺系統，來整合各類產品與消費者行為資訊，即時進行大數據分析，並投放個人化廣告達到精準行銷的目的，「如果迎賓的時候只講：『XXX你好』沒有意義，一定要跟消費者在賣場的消費行為整合才更重要。」
其他硬體功能的轉變，還包括收音麥克風從指向型轉變為陣列型，接收來自不同角度的語音訊息，也新增自動充電功能，偵測到快沒電時會回到充電處充電；而下盤也裝設LED燈，不同顏色燈光能進行情緒表達、錯誤警示、顯示電力狀況等，且整體機械結構改進的更強壯耐用，耗損率高的馬達也更換為使用時數更持久的品項。
此外，邵成武強調，Ayuda解決方案不是單純賣「機器人」這項產品，而是會根據客戶需求來整合系統，並且依照實際場域的情況來調整機器人的功能。比如說，百貨公司裡的桌椅上寬下窄，這會導致機器人底盤的激光雷達感應錯誤，以為前方沒有障礙物而撞上。為此，機器人上新增了超聲波與機器人胸上的錄影機，來更精準地偵測路況，防止碰撞的情形。
第四代Ayuda預計在10月底會導入美麗華、大潤發以及義大世界商場中，總共將陸續部署12臺機器人（每個場域4臺），其應用包括：櫃位及公共設施查詢帶位、餐廳/影城訂位、現場招呼、商品查價、發放號碼牌、掃電子發票QR code顯示停車收費資訊、停車位查詢、商品促銷、語音詢答等功能。透過Ayuda在各場域進行實證，凌羣也會持續蒐集客戶回饋與新需求，再來修正服務內容。

頭部的攝影機用於人臉辨識。


Ayuda在講話的同時也會顯示文字於螢幕。


左邊能夠感應悠遊卡、晶片卡與QR code，右邊則能列印出優惠券或號碼牌。


上方間隙為激光雷達感測處，下方藍色處能夠進行充電。

",https://www.ithome.com.tw/news/133649,"新聞,AI,機器人,凌群電腦,Ayuda,智慧零售,Kiosk,Cloud"
133493,8,2019-10-08,Container周報第112期：Kubernetes 1.16新版的擴充力再升級,新版還多了一項端點切片（Endpoint Slices）Alpha版，可以為Kubernetes服務帶來更大的伸縮彈性，每個端點切片都被限制最多包含100個端點，使單一節點更新作業變得更有效率," 精選9/1~10/3重要Container新聞
#K8s、#端點切片Kubernetes 1.16來了擴充力再升級，也新增端點切片功能
Kubernetes現在釋出了1.16版本，這是今年的第3個版本，被用來作為Kubernetes擴充機制的CRD（Custom Resource Definition）現在成為正式功能，部分之前選用的防護功能會成為必要或是預設，像是結構架構（Structural Schema）、刪減未知欄位、驗證以及保護*.k8s.io群組等，目的是要確保API的穩定性，更不容易因為意外而故障。在Kubernetes API也有一些修改，也為Windows增加了新的增強功能。
另外，這個版本還加入了一個新的Alpha功能端點切片（Endpoint Slices），這可以為Kubernetes服務帶來更大的伸縮彈性，目前的端點資源，單個資源包括所有和服務相對應Pod的網路端點，但隨著服務越來越大，可能需要使用上萬個Pod，這使得端點資源變得非常龐大。預設情況下，每個端點切片都被限制最多包含100個端點，這樣的機制會使單一節點更新作業變得更有效率，因為每個端點都僅是整個網路端點的一小部分。

#Etcd、#分散式資料庫Kubernetes發布分散式鍵值資料庫Etcd 3.4，強化後端儲存與客戶端平衡器功能
Kubernetes團隊發布了分散式鍵值資料庫Etcd 3.4，這個版本強化了儲存後端的效能，並改進Raft投票程序，還加入了全新的客戶端平衡器（Client Balancer）。Etcd是一個分散式具高可靠性的鍵值儲存，可用來儲存分散式系統的重要資料，在去年底，CoreOS團隊將Etcd專案捐贈給CNCF。
新版Etcd對大規模Kubernetes工作負載進行了最佳化，大幅提升了執行效能，其最重要的更新，便是提供更好的存儲後端。3.4版的資料吞吐量大增70％，長時間進行讀取操作的情況下，P99寫入延遲減少了90％。租約儲存（Lease Storage）進行了許多改進，以提高整體操作效能，新版本還新增實驗性的租約檢查點功能，能透過共識機制，保存租約物件的剩餘生存時間值。
#作業系統、#GPULinux 5.3核心釋出，首度支援AMD Navi GPU
在經過8個RC（release candidates）版及比預定時間晚了一個星期後，Linux之父Linus Torvalds正式釋出了Linux 5.3核心。Linux 5.3版是繼7月的5.2版後釋出的最新版本，加入多項硬體、硬體功能的支援，其中包括首度支援AMD Navi GPU系列及中國x86兆芯處理器、對英特爾Icelake Gen 11繪圖晶片HDR、Speed Select及UMWAIT技術的支援、以及支援MacBook、MacBook Pro鍵盤、並強化對Nvidia Jetson Nano的支援。此外也支援ACRN guest hypervisor及加入1600萬個IPv4 位址等等。Linux 5.3版的釋出，也意謂5.4版進入整併階段。預定11月釋出穩定版的Linux 5.4，將加入exFAT 驅動程式及支援AMD Renoir APU、Intel Tigerlake Gen 12 Xe 繪圖晶片，及Intel Icelake Thunderbolt等多項重要更新。
#負載平衡、#GKEGoogle在GKE服務正式推出原生容器負載平衡功能
Google推出GKE上的原生容器負載平衡功能正式版本，原生容器負載平衡可以讓用戶創建使用網路端點群組（Network Endpoint Groups，NEGs）的服務，因此外來對服務的請求，可以直接經負載平衡發送給服務請求的容器。
NEG抽象層使得原生容器負載平衡，可以與GCP上的Kubernetes Ingress控制器良好地整合在一起，當使用者使用多層的網路部署，要對外公開一個或多個服務，也能夠創建Ingress物件，而這將會使用HTTP和HTTPS負載平衡，並且讓使用者設定以路徑或是主機的方法，路由後端的服務。

#容器安全、#GKE開放測試安全力度，GCP推出Shielded GKE節點測試版
Google在其雲端平臺推出Shielded GKE節點Beta測試版，提供強健且可驗證的節點完整性（Integrity），增加GKE節點的安全防護。而Shielded GKE節點則是建立於去年7月所發布的Shielded虛擬機器之上。這類GKE節點強化了底層，增加抵抗各種Rootkit和Bootkit的攻擊，確保使用者的節點不被任意竄改，同時也能保護工作負載免於遠端攻擊或是特權提升等威脅。在Shielded GKE節點中，會對節點作業系統的出處進行確認，透過加密驗證檢查，確保節點作業系統正在Google資料中心的虛擬機器上運作。目前Shielded GKE節點服務已經在所有區域提供。
#微服務管理、#服務網格Kong推出開源服務網路控制平臺Kuma，可用來調度服務網格流量
開源API管理平臺Kong服務供應商釋出新的開源專案Kuma，Kuma是能用於管理服務網路（Service Mesh）的通用控制平臺，透過無縫管理第四層與第七層網路流量、微服務與API，以解決第一代服務網路的技術限制。Kuma採用軟體定義安全性，為所有第四層流量啟用mTLS，並提供高精細度的流量控制功能，強化第四層路由功能，而Kuma也能夠快速實作追蹤與日誌記錄功能，讓用戶分析指標進行除錯。Kuma可在任意的平臺上執行，包括Kubernetes、虛擬機器、容器、裸機和傳統環境，使整個企業組織都能實踐原生雲端應用。
#服務網格、#K8s叢集網路管理Containous開源微服務網狀網路Maesh，用於管理K8s叢集內部網路流量
雲端服務業者Containous開源了新服務網狀網路（Service Mesh），這個專案的目的，是要讓Kubernetes應用程式的各個部分，更容易互相溝通，讓使用者能管理Kubernetes叢集內部流量。這個專為微服務設計的服務網狀網路Maesh，就是建立在反向代理Traefik之上，讓使用者能查看並管理在K8s叢集內流動的流量，Containous表示，管理叢集內部流量跟管理流入流出叢集的流量一樣重要，而Maesh是一個操作簡單功能齊全的服務網格，其基於原生容器的設計，能適用於用戶的K8s叢集，且支援最新的服務網狀網路介面規範（Service Mesh Interface，SMI）。
#AWS、#雲端監控、#容器應用安全Amazon CloudWatch正式為用戶提供容器應用程式監控功能
由於容器程式壽命短，過去用戶難以取得完整的監控資料，而現在Amazon CloudWatch針對容器應用程式，推出專門的監控功能。AWS正式發布Amazon CloudWatch中的Container Insights功能，讓用戶能夠監控Amazon ECS以及AWS Fargate新舊叢集中的容器，掌握包括容器利用率以及故障機率等詳細資訊。這項容器分析功能，可以監控叢集中所有正在執行的容器，並收集容器堆疊每一層的效能以及運作資料，監控Kubernetes、支援Kubernetes的Amazon Elastic Container Service、Amazon ECS以及AWS Fargate中容器的使用率以及故障機率等資訊，以進行即時分析。

責任編輯／王宏仁
更多Container動態
Visual Studio更新Azure IoT工具，可遠端進行Linux Docker容器除錯
甲骨文發布Java 13，而Eclipse基金會則釋出Jakarta EE 8
＠資料來源：iThome整理，2019年10月
",https://www.ithome.com.tw/news/133493,"新聞,Container,K8s,容器周報,IT報告,Kubernetes"
133300,8,2019-10-02,【K8s臺灣企業實戰經驗談：露天拍賣】K8s解決機器學習複雜的工作流程痛點，撐起電商AI服務,近年來，國內老牌電商平臺露天拍賣也積極邁向產業AI化，不只建造了任務型客服機器人，也進行點擊轉換率指標AI專案，目前也正打造以圖搜圖的AI模型。而撐起這些專案的利器，就是Kubernetes," 「機器學習工作流程不只是清理資料、訓練模型，還包括模型部署、轉換為線上服務、維持服務不中斷，甚至還有GPU資源調度等問題。」露天拍賣研發創新部主任張家棠指出，能解決機器學習（ML）工作流程痛點的幫手，就是容器管理平臺Kubernetes（K8s）。
K8s三大特點優化ML工作流程
Kubernetes擁有三大特點，分別是組合性（Composability）、可攜性（Portability）和擴展性（Scalability）。就第一點來說，機器學習工作流程包括資料前處理、模型訓練、部署和維運等數十個階段。而Kubernetes提供了可組合的控制流程，讓使用者依其需求，透過模組化來完成這些步驟，也不須要集中式控制流程。
再來，可攜性能解決模型訓練問題，比如開發環境。舉例來說，相同的程式碼由不同工程師執行，可不一定每次都成功，「這就是環境問題。」張家棠指出，Kubernetes微服務可將環境內容標準化，解決開發環境問題，而且「不管是透過筆電還是本機開發，只要將內容封裝好，就能輕鬆在正式環境執行。」
接下來則是擴展性。Kubernetes擴展性優點包括對CPU、GPU和記憶體資源的調度，但在張家棠眼中，擴展性真正的價值，在於能應付企業中不同團隊所需的作業環境要求。
專屬套件降低K8s與ML工作流程執行門檻
不過，要真正駕馭Kubernetes，並非易事。為了讓開發者更快上手，張家棠點名Kubeflow，也就是一套開源機器學習工具，「有如一個組合包，內含許多機器學習套件，供使用者安裝，」簡化了在Kubernetes上執行機器學習任務的流程。再加上Kubeflow以Kubernetes為基礎，因此只要在Kubernetes環境中，就能執行Kubeflow，達到簡單、可攜且可擴充的目的。
然而，Kubeflow並非適用於所有機器學習工作，它的強項在於模型建置、訓練，以及平行處理和模型部署（Serving）等流程。
其中，就平行處理來說，由於機器學習工作並非只是資料搜集、訓練模型、模型部署等如此直線進行的流程，而是由多個任務（Task）組成，有些任務必須要按照事先定義的順序來執行，有些任務則會依賴其他任務，還有些任務則是要同時執行。這個現象，就有如點狀發散的有向無環圖（DAG）般複雜，需要平行處理才能應付。
而Kubernetes CRD原生套件Argo Workflow，能夠解決這個問題。Argo Workflow是一套工作流程任務調度工具，可針對多步驟（Step）的工作流程來建模，使之成為一序列任務，也能利用DAG來找出不同任務間的相依性。它的特點包括跨程式語言、能即時更新日誌（Log），方便工程師隨時掌握工作流程狀態，此外還提供視覺化的使用者介面，方便監控作業動態。
在Argo Workflow提供的多種工作流程功能中，張家棠最推薦Loop、DAG-Diamond-step和Daemon-nginx。他指出，有別於一次只能執行一個步驟的傳統程式化腳本（Shell script），Loop可一次平行執行兩個以上的步驟，而DAG-Diamond-step則更進一步，專門鎖定如DAG般複雜的流程，使用者可根據自身需求，來彈性設計任務執行的架構。再來，Daemon-nginx讓使用者在執行批次工作排程時，先設置一個Daemon，之後排程的內容照著Daemon即可。

露天研發創新部主任張家棠推薦Kubernetes CRD原生機器學習任務調度工具Argo Workflow中的DAG-Diamond-step功能，可以處理如DAG般複雜的機器學習工作流程，讓使用者自行設計任務執行的架構。（圖片來源／張家棠）
事件管理器彈性觸發和執行工作流程，露天靠它打造Chabot服務
設計完工作流程後，開發者還需要觸發（Trigger）和執行這些事件（Event），而Kubernetes事件管理器Argo Event則能彈性完成這兩項動作。
這個管理器主要由3個元素構成，分別是Event Source、Gateway和Sensor。Event Source是用來定義事件內容，再透過Gateway來處理事件，之後由Sensor定義事件相依性，並觸發Argo Workflow或Kubernetes資源，來執行事件。此外，Argo Event還擁有多項功能，像是網站訂閱通知（Webhook）、排程（Schedule）等。
露天也實際利用這些工具，來開發自家的客服機器人。張家棠指出，露天參考許多坊間聊天機器人，特別是Google的Chabot平臺Dialogflow，並以此為藍圖，開發出自家的客服機器人熊咩。
熊咩為任務型聊天機器人，只針對露天平臺提供問題選項與回答，而非由顧客輸入字句來進行開放式對話。也因此，模型訓練原理就像訓練分類器，目的是要將問題對應到正確解答。
於是，露天先建置了一個後臺，讓客服人員來處理資料前置工作，比如分類問題等。之後，團隊再設置一個按鈕，當客服人員處理完前置工作後，就可點擊來觸發重新訓練聊天機器人。「這個觸發就是Argo Event中的Webhook功能，可以連結Argo Workflow來取得資料、重新訓練模型。」
但是，機器學習模型經過不斷重新訓練、YAML設定檔不斷更新時，Argo Workflow也就變得複雜了。為解決這個問題，Kubeflow Pipline釋出一款軟體開發套件，不只大幅簡化撰寫複雜度，還附加了Metadata的設定，方便開發者在工作執行完後，來檢視工作內容。張家棠表示，這一點，對機器學習開發者來說特別有幫助，因為有利於比較兩套模型的差異和表現。
善用模型部署利器，露天以此建置點擊轉換率指標
模型訓練完成後，接下來，就是要將模型轉換為服務（Serving）。張家棠指出，這時有兩個工具可選擇，一個是TensorFlow Serving，另一個是Seldon。
首先，如果開發者利用TensorFlow開發模型，就可直接透過TensorFlow Serving來部署模型。TensorFlow Serving有幾個優點，包括只要將新訓練好的模型檔，存放於舊模型檔的資料夾，就能直接切換為新模型；再來則是加速機器學習模型訓練效果，透過批次功能，可一次輸入數百個樣本給機器，有效利用GPU資源。這一點，也能用來提高AI推論效率，也就是透過累積請求（Request）數量，到達設定時間後，再全部送往GPU處理。
另一方面，除了TensorFlow Serving，如果開發者使用TensorFlow以外的框架來開發模型，比如PyTorch、MLflow、XGBoost等，就可透過Seldon平臺來部署模型。
而露天的商品點擊轉換率指標，就是透過TensorFlow Serving來運行。張家棠解釋，點擊轉換率指標，是要來了解不同消費者對哪些產品有興趣；要做到這一點，首先要收集露天平臺上所有使用者的Log，將這些資料整理、標註之後來訓練模型，並利用每天更新的Log來重複訓練。最後，再透過TensorFlow Serving整合這些結果，交給後端API來呈現點擊率與轉換率的效果。
另一個應用案例則是商品個人化搜尋，露天透過個別使用者的搜尋歷史，來訓練AI模型、預測商品搜尋結果的排名。張家棠舉例，比如用關鍵字搜尋「三國」，就可能出現電視劇、遊戲等不同類型的商品，但根據使用者搜尋歷史，就能找出使用者的興趣領域，進而提升相關商品的搜尋排名。
張家棠也揭露，露天目前也正利用K8s進行以圖搜圖的AI專案，目標是要「跟上國際電商的腳步。」
 相關報導  企業K8s實戰在臺灣 
",https://www.ithome.com.tw/news/133300,"新聞,雲端服務,伺服器虛擬化,容器,微服務,Kubernetes,K8s,露天拍賣,機器學習,GPU,Kubernetes Summit"
133298,8,2019-10-02,【K8s臺灣企業實戰經驗談：遠傳電信】告別單體架構，以多個微服務協同合作，更易擴展規模,採用微服務是當代IT應用系統發展的大勢所趨，在去年電信業面臨499之亂的業務衝擊後，遠傳電信也已經投入推動相關的IT架構轉型工程," 經歷過伺服器虛擬化、雲端服務，以及容器（Container）等浪潮的洗禮，如今我們已開始邁入多雲、混合雲的環境，然而，為何應用系統平臺的發展必須持續追逐這樣的趨勢，而且，每隔幾年就可能需要轉進新的架構？在遠傳電信IT基礎架構轉型的過程當中，我們看到了答案。

而在今年的Kubernetes Summit大會當中，遠傳電信也首度對外透露，他們如何從三層式（3-tier）架構、服務導向架構（SOA）架構，一路轉換到微服務（Microservices）架構。原來，一切的決策考量，都源於「擴展（Expansion）」，尤其對於臺灣的電信業者而言，從逢年過節的車票搶訂、知名品牌智慧型手機的大量預購，到2018年的行動網路499元吃到飽之亂，都造成極大的業務營運挑戰，他們也持續思考IT架構該如何配置，才能因應時間短暫、負載龐大的系統執行需求。
快速、大規模、簡便的擴展，成為企業應用系統架構變革關鍵
​
關於微服務，以及容器、Kubernetes等新興IT技術的導入，今年，臺灣終於有大型企業公開實際應用的經驗，例如，遠傳電信經理謝逸凡在9月的Kubernetes Summit大會，首度揭露他們IT架構轉型的歷程。
近年來，IT基礎架構的轉型，主要聚焦的部份，在於擴展、可用性、敏捷，而遠傳電信的IT環境，從原有的大型主機，陸續開始採用x86運算架構、伺服器虛擬化、私有雲、容器、公有雲，如今走向混合雲、多雲、雲端原生的架構。
在此同時，他們對於採用雲端服務的態度，也更為積極。因為在這樣大型的業務活動期間，原本資料中心預留10％到20％的系統資源，在那時幾乎全部都用上了，卻仍不夠用，導致許多消費者在申請時，還是得不到門號，他們必須要在一兩天之內，將系統資源擴增到原有的5、6倍之多，才能因應暴增的需求，所以，他們積極評估採用雲端服務的可行性，並且認知到每一朵雲各自的特色，於是，遠傳電信今年開始有混合雲、多雲的解決方案。接著，他們在2012年開始採用伺服器虛擬化的架構，而隨著虛擬機器（VM）部署規模的日益龐大，之後也導入一些自動化管理的機制。到了2017年，遠傳電信開始採用容器架構，原本他們想透過這樣的方式來取代伺服器虛擬化，節省伺服器虛擬化授權，但後來發現容器並不能取代虛擬機器，而在去年499行動通訊方案席捲市場之際，他們也試著用容器架構來支撐暴增的工作負載，雖然當時並沒有成功，但也讓他們意識到需要同時注意其他的環節，例如資料處理的方式（資料庫的分割、資料讀寫負載的分流、快取的配置），才能充分發揮容器架構的特性。在這段期間，他們首先面臨的挑戰，在於大型主機建置成本昂貴，而且只能縱向擴展（Scale up），若要擴展底層IT基礎架構的規模，也需要長時間的預算規畫、提案，後來，隨著x86架構的盛行，改用大量x86伺服器來擴充資源。
回顧這段轉型的歷程，遠傳電信經理謝逸凡表示，這一路走來，他們每天都在做的事情，就是擴展（Expansion），每遇到一個資源瓶頸點，就必須要設法跨到下一步，一關關突破。換言之，IT人員面臨的挑戰在於，如何擴展既有資源，讓上層的應用程式和服務，能夠快速而順利執行，保持可用性與穩定度。
因此，他們持續投入IT基礎架構底層的建置、系統平臺的建置，都是為了承載上層應用程式或服務，做到執行規模的瞬間放大或縮小。
然而，在不同時期所採行的IT基礎架構，皆有其相對的優勢。例如，在採用專屬伺服器架構的時期，從提案到實際部署完成，可能長達幾週，甚至幾個月，而且需同時考量的因素，最為複雜，包含硬體、作業系統、執行時期環境，以及程式碼；到了伺服器虛擬化、私有雲的環境，部署時間可縮短至幾天、幾小時，甚至幾分鐘，而且，不需考量硬體的相依性；而在容器的應用架構裡面，程式碼寫好之後，最快能在幾秒鐘的瞬間，完成應用程式的部署，又進一步擺脫作業系統的影響。

遠傳電信的應用系統架構，經歷了幾次變革，先從大型主機／主從式架構，換到三層式架構，之後，改用服務導向架構，近年來，他們也已經開始導入微服務架構。在這三種架構之下，應用系統的元件有不同的粒度與耦合度，在規模擴展與管理的難度上，都有不同的挑戰。（圖片來源／謝逸凡）
為了擴展規模，將應用程式拆成多個微服務也成考量點
導入伺服器虛擬化、雲端服務的環境，雖然為用戶提供快速擴展IT基礎架構資源規模的方式，再加上虛擬機器、容器的採用，也能帶來快速部署應用程式的成效，但就整體服務而言，若要穩定擴展規模，應用系統架構仍需調整。
以三層式架構而言，應用程式本身是緊密耦合的，以一套系統適用所有需求，程式碼修改較為困難，在應用程式發行、測試的步驟，會耗費許多力氣，若要擴展系統規模，作法也相對複雜。以遠傳電信而言，他們的應用系統在這段期間，已陸續經歷了幾次轉型，從過往的大型主機主從式架構、三層式架構、服務導向架構，如今則是繼續朝微服務架構邁進，而之所以改弦易張的關鍵，仍在於擴展能力的優劣。
到了服務導向架構、企業服務匯流排（ESB），應用程式是鬆散耦合的，拆分為多個元件，粒度較適當，利於服務重複使用，快速支援業務需求。然而，這類架構採用的協定，像是WSDL或是SOAP，效能不太理想。此外，應用程式存取資料來源，仍是同個資料庫。
在近幾年盛行的微服務架構，應用程式拆分粒度更細緻，且是鬆散解耦的（Loosely decoupled），不單將系統拆分、重新安裝多份、重新部署，還要有獨立運作、無狀態（stateless）、自我管理、去中心化（decentralized）等特性。
然而，相較於既有應用系統的單體式架構（Monolithic），雖然體型龐大，不易擴展，但好處是只需要考量單一實體，若把應用系統拆開成多個微服務，因為需要彼此相互呼叫，對於狀態與資料存取的需求也不一樣，將導致管理複雜性和維運難度變高的狀況。
因此，若要將應用系統拆分為多個微服務，該如何切割，執行起來才會順暢、理想，是許多開發人員面臨的重大挑戰。遠傳電信採取的作法，是先針對應用程式的運算部分，接著是處理資料層，此時會遭遇到非同步模式與狀態不一致，或是狀態、功能切分得不夠精細，因此也會涉及事件的處理。
等到應用系統開始建立之後，他們開始處理開發與維運的流程（Pipeline），因為系統完成開發好、進入穩定執行的狀態，接下來，該如何持續修改、調整，使其保持妥善運作，又是個挑戰。
而在上述的工作階段當中，如何擴展需要的資源也很重要，因為當本地端資源不足時，我們要懂得運用多個資料中心的資源，並在這樣的環境布建服務。
建構微服務的要點
要該如何切分微服務？因為資源有限，很難把應用系統的所有功能拆掉，基本上，還是回到原點：我們需要的是擴展性？快速？穩定？可用？謝逸凡以他們本身需求來說明，以門市運作而言，像是確認消費者能否購買、決定用戶是否有續約資格，都是最常使用的核心功能，若將這些改為微服務，效果最為顯著，至於其他功能不一定要在第一時間改成微服務，因為需求量相對少。
基本上，應用系統若切得越細、分割得越多，雖然可以擁有越好的彈性，但是，管理複雜度也會越來越高，導致管理成本可能超過開發成本的狀況。因此，面對微服務的粒度該如何取決的考量，謝逸凡表示，應該要在自身的管理能力與切割程度，找到平衡點，因為，相關的監控機制如果沒有到位，卻硬是切割出來，一旦運作上出問題，就很難復原，等於陷入另一個風險。
所以，他也認為，建構微服務不能想要一步到位，這麼做耗費的資源太大，後來會無法執行下去，應該要謹慎為之、逐漸轉換，可先從應用系統著手切割，再處理資料，再處理後面的事件。
之所以會有這樣考量，謝逸凡坦言，這是他們內部討論出來的作法，因為既有系統太多，需要逐步轉換，但這還是需要很多額外的資源，而且，還要從底層去調整架構。所以，他建議，可以各個擊破，「先建後拆」，把關鍵服務慢慢抽出來，等到看到成效之後，大家才會去想要修改舊的部分；而且，有些舊服務並沒有高速擴展的需求，在原來的架構還是可以執行，因此，企業不用花太多資源去改成微服務。
當應用系統改成微服務架構，執行方式會有哪些改變？會有API呼叫的請求，啟動幾個微服務，由API Gateway做服務管理，進行Service Discovery的程序，了解微服務的狀態與服務等級；而在微服務之間，是透過RESTful API呼叫來互動，也可能有推送或訂閱（Push and Subscribe）的非同步作業，將記錄發布至事件佇列（Event Queue），或從這裡取得記錄，然而各自執行各自的服務；而在資料存取的部分，也可能會用到資料庫或資料庫加上快取的作法。而在這樣的架構下，我們要把應用系統拆成好幾個，當中有執行狀態的轉換（有狀態改為無狀態）、API呼叫、資料流切割的程序。
在實際維運時，原本每個應用系統服務由一個開發單位負責的狀況，如今也可能會有改變。因為，採用微服務架構之後，會面對的是多個開發單位，該如何協調彼此，促進共同的控管、障礙排除、開發，所以，這也會是考驗之一。

微服務架構的組成，不光是容器技術的應用，以及應用系統的切割，在上層還有API管理、Service Discovery，以及應用程式框架，其底層則有Kubernetes平臺、網路、硬體設備的區分。同時，這樣的架構也需要搭配完備的系統監控、事件記錄，以及管理機制。（圖片來源／謝逸凡）
打破單體執行藩籬，轉為彼此協同運作的生態系統
微服務應用系統若由Kubernetes平臺來支撐，謝逸凡認為，從架構來看，最上層是應用程式的管理員，透過API來呼叫服務；接著是Service Discovery，探尋合適的微服務；下層是Spring Cloud這類應用程式框架， 再下層是Container，而Container底下會是Kubernetes平臺；到了最底層，則是網路與硬體設備。
而橫跨上述所有堆疊的功能，則是監控、記錄中心、管理，它們也扮演很重要的角色，因為當應用系統架構拆得如此分散，若要確保系統運作正常，要有很強大的監控、很詳盡的事件記錄，支撐整體架構的維運，如此也能做到集中化管理。謝逸凡表示，如果沒有這些機制，很難同時管理眾多微服務，以及持續更新軟體版本，提供穩定運作環境。
而經歷過這樣的變革，謝逸凡體認到，微服務的運作體系，並非一套獨立的應用系統，而是依靠好幾個部分一起協同運作，轉為生態系統的概念，因此，在這樣的架構之下，一個應用系統無法單獨存在，一定要互相合作。
相對地，若要維運和管理這樣的環境，也會變得很複雜。謝逸凡說，微服務化的應用系統可以執行得很順暢，一旦出問題，恐怕很難快速找到根本原因，因為它不是單一的軟體，若有影響，就會是全面的，所以，我們必須設法觀察資源的瓶頸所在，關注如何建立監控機制及整個維運體系。
當微服務結合K8s平臺
應用系統經過容器化、微服務化，實際運作在Kubernetes平臺，整體架構會變得如何？謝逸凡介紹遠傳電信的作法，他們用社群維護的Kubernetes版本，並在Intranet和DMZ兩個網路區域，建立叢集，共用容器映像登錄。
除了運用Kubernetes本身的API，他們也撰寫工具，協助部署與資源的管理。面對檔案交換的需求，他們也設置了共用儲存池。而在監控的部份，他們用了Kafka來接收事件記錄，然後交給ELK（Elasticsearch, Logstash, Kibana）處理，同時，這裡也運用Prometheus軟體來接收Kubernetes平臺，以及上層系統的重要資訊。
對於容器映像的管理，遠傳電信採取比較嚴謹的作法，他們不允許開發人員隨意到網際網路下載，須使用公司驗證過的容器映像，而他們也將列管的容器映像，根據用途的差異，區分兩大類型——維運（Operation），以及生產（Production），並且檢查當中的安全性，做好存取控制，例如，確認是否潛藏惡意程式，以及開放哪些作業系統層級的使用者存取通道。
此外，為了提升容器映像的適用性，符合開發、維運、測試人員的需求，遠傳電信也對環境變數的設定做了一些處理，當中運用ConfigMap的組態資訊來對應，達到參數化的設計，讓容器映像執行起來更順暢。
在資料處理的部份，也要特別注意，遠傳電信的經驗值得借鏡。他們在因應499行動上網吃到飽的業務暴增需求時，就曾使用微服務與Kubernetes，當時，應用系統已妥當分割為微服務，部署到Kubernetes平臺，Kubernetes系統規模的擴展很順利，容器也順利建立起來，最後卻因資料庫存取方式的限制，而無法承擔負載，還是敗下陣來。
對此，他們採取了3種作法來改善，分別是資料庫分割（Database Partition）、讀寫分流（Read/Write Splitting），以及快取（Cache），以便分散存取的I/O。
結合容器與K8s的開發與維運流程
當應用系統的整體架構建立起來，資料庫的分散存取也導入適合的作法，接著要考量的部分，是規畫可持續運作的DevOps流程，能夠整合、更新應用系統，並且維持系統的穩定運作，協助用戶執行持續交付、持續整合、持續測試、持續維運的所有工作。
遠傳電信DevOps流程是怎麼做的？以部署應用系統的作業為例，他們提供兩種作法，一是將程式碼打包在容器映像當中，一是將程式碼和容器映像分開，程式碼會放在共用的儲存空間，直接掛載到容器，再執行應用系統。
而在應用系統開發過程當中，若要進行持續整合、持續交付，遠傳電信也區隔出系統整合測試（SIT）環境，以及生產環境，分別設立對應的容器映像登錄，以及Kuberenetes叢集，位於系統整合測試階段的應用系統（容器映像），必須經過一定的預先部署、測試、更版等程序，才能將同步到生產環境，進行部署與上線切換的動作。

在容器映像的部署方式上，遠傳電信Kubernetes平臺提供兩種選擇：一種是包含程式碼，另一種是不含程式碼，可用於開發、測試、生產等不同階段的環境當中。（圖片來源／謝逸凡）
 相關報導  企業K8s實戰在臺灣 
",https://www.ithome.com.tw/news/133298,"新聞,遠傳電信,雲端服務,伺服器虛擬化,容器,微服務,Kubernetes,K8s,Kubernetes Summit"
133297,8,2019-10-02,【K8s臺灣企業實戰經驗談：中華電信】因應短暫而量大的預購壓力，以微服務實現彈性部署與標準化維運,針對搶票、預購的極端工作負載，臺灣的電信業者持續苦思應變之道，而在容器、微服務、K8s的技術應用之下，中華電信也開始著手預購系統的搬遷與改造," 雲端服務當道，接連掀起了伺服器虛擬化、容器化、微服務化的風潮，應用系統的開發、整合、測試、上線的速度有了劇烈的提升，承載應用系統的平臺發生量變與質變，在企業IT環境裡面的工作負載，除了支撐日常關鍵應用系統的穩定運作，也面臨更多極端的需求，像是持續時間不長、負載量卻超高的應用服務，越來越常出現，該如何因應這樣的挑戰？
在iThome主辦的Kubernetes Summit大會當中，今年就有兩家臺灣電信業者談到他們導入容器服務平臺的經驗，中華電信就是其中之一，他們目前是將這樣的架構用在既有的預購系統上，而且，建置的平臺是企業級軟體──紅帽的OpenShift Container Platform，不過，即便如此，他們在系統搬遷過程中，仍經歷了預期以外的狀況，有意採用這類環境的企業，若能及早掌握可能影響搬遷作業的各種細節，應能減少出錯機會。
先拿預購系統開刀，因其服務特性很適合移植到雲端環境
身為成立時間最久的臺灣電信業者，中華電信所經營的各種通訊、網路與加值服務，背後都由資訊系統支撐，當中有許多都是十年以上的老舊系統，因此，他們近期開始思考把這些系統搬到雲端服務的環境，而預購系統的搬遷就是率先進行的工程。
為什麼是這套系統先行？中華電信資訊處工程師黃昭文表示，傳統預購系統最大問題就是瞬間的搶訂壓力，許多網站往往承受不住，為了解決問題，業界提出的作法是運用分散式架構，但同時也須面對一些問題，像是網路管理、多臺設備管理、資料庫系統負荷能力、儲存管理，建置這些環境的成本也很高。
第二個考量是預購系統的另一個特性：使用時間很短。一般而言，電信業者的預購系統，運作時間並不長，可能上線為期三天、一週，之後就會下架，若要建置專屬環境，不敷成本效益。

這是一般電信業者預購系統的運作架構，在設計上，是以分散負載的方式來考量，希望能夠妥善消化瞬間搶購的壓力，但需要針對網路管理、設備管理、儲存管理、高可用性的需求，來配置IT資源，搭建成本相當高，而且這類系統服務時間並不長，之後又需要撤下、回收，想要以更經濟的方式快速擴展（縮回）應用系統規模，相當不容易。（圖片來源／黃昭文）

這是中華電信建置的容器服務平臺，他們採用的是Red Hat OpenShit Container Platform，在Kubernetes Summit大會上，他們首度揭露目前系統的架構。（圖片來源／黃昭文）
歷經容器化、解構，進入微服務
在系統搬遷的作業時程上，中華電信規畫了下列3個階段。
第一階段：原貌搬遷
系統搬遷初期，他們對應用系統的調整幅度不大，優先考量服務正常運作。此時主要的工作，是將應用程式的執行環境，從實體伺服器、虛擬機器，搬到OpenShift。過程當中，他們先把虛擬機器當中的應用程式，放到Docker container，再將容器搬到OpenShift。以耗費時間而言，從VM轉到Docker較短，從Docker到OpenShift較久。
關於這階段的搬遷，黃昭文列出7大工作重點。首先是盤點程式行為，因為當應用程式改到OpenShift執行之後，開始會有一些橫向擴充（Scale out）的活動，可能就會相互衝突；其次是參數需重新設計，若能用對參數、改變參數餵送的方式，對於K8s的操作比較友善。
第二階段：系統解構
此時，中華電信開始執行預購系統的解構，提高邏輯的清晰度。相較之下，前一個階段，他們是把整個應用系統包進容器當中，但在這個階段，則是開始進行合理拆解，導入微服務的概念，讓系統上下游之間可透過RESTful API去串接，應用程式當中的不同部分，可以橫向擴充規模。同時，他們也選用輕量的Web應用程式框架，像是Spring Boot來進行改寫，而不再採用WebLogic這類應用程式伺服器。
關於Kubernetes平臺的使用上，黃昭文也特別提醒，要注意Pod的串接數量。他們發現，串連路徑越長，效能折損越大。所謂的Pod是指一群容器的代稱，對於K8s環境而言，是最小的物件模型單位。
他也秀出效能測試的圖表，當Pod串接到兩個站點時，網路呼叫的效能就會瞬間降至低點。若要增加效率，他提出以下幾個建議：我們可以在應用系統上游的呼叫端，導入共用連線（Connection Pool），或是運用非同步作業的機制，也可以在應用系統下游的服務端，採用高效能的應用程式框架。若需要非常高的效能，我們可以多個相關的容器封裝在同一個Pod裡面，如此可以大幅減輕網路流量的負擔。
第三階段：微服務、DevOps
在預購系統的搬遷進入最終階段之際，中華電信期望可以跨入微服務、DevOps的應用。
在此之前，黃昭文呼籲企業應評估自身體質是否適合，確認應用系統架構的調整，究竟是想要還是必要。同時，也要注意單位組織分工的變化，如果是橫向切割，未來在DevOps的流程當中，彼此合作會更為密切，在系統維運的慣性上，IT人員也要有心理準備，因為複雜度可能會提升。
在資料處理的結構與流程，這時也可能需要重新設計。例如，應用程式連接的資料庫系統可能需要拆解，才能支應微服務的存取需求，而拆解之後的資料內容同步，也需要注意。
事實上，這個階段的目標更為宏觀，希望達到獨立開發、高效率部署、維運標準化的要求。黃昭文坦言，其實在中華電信內部有太多系統，每一套系統都有不同維運的方式，對於經驗傳承、未來招募新人而言，都是困難的地方，於是，他們希望應用系統的開發與維運，從需求管理延伸到交付部署，都有一模一樣的流程，對於企業而言，不論是成本或管理考量，都會比較簡單、穩定。
掌握不同環境差異，可少走冤枉路
除了規畫三大階段，黃昭文也列出多項過程當中需注意的技術細節。首先是底層環境，有些商用軟體的登錄機碼或組態授權，會綑綁處理器或伺服器的型號，如果沒有處理好，系統搬移到另一個環境時，可能無法啟動。
軟硬體的相依性上，由於部分軟體授權有處理器核心數量授權限制，因此，若搬遷到新環境，提供的處理器核心數量很多時，也可能無法啟動系統。
系統軟體本身也有一些相依性的議題，那就是與作業系統核心（Kernel）版本之間的捆綁。舉例來說，若底層伺服器的作業系統更新核心，應用系統可能就會受到影響而停擺。
在容器的部份，黃昭文建議，每個容器裡面不要放置太多處理程序，否則當多個容器同時執行，可能會相互干擾。
接著要注意的部份，在於容器的執行權限，以及K8s或OpenShift本身的環境變數，在配置上，應避免與其衝突，因為若發生這樣的狀況，原本自定的部份，將會被系統覆蓋。
容器的Volume設定也要關照一下，當我們包好容器或採用他人的容器之後，請記得打開裡面的組態，例如，查看Dockerfile，確認儲存Volume掛載的位置，以防出現資訊遺漏的狀況。
在Kubernetes的部份，我們要注意ConfigMap的唯讀限制，有些應用程式需要修改設定時，若沒有考慮到這個因素的影響，可能就無法啟動。對於實體儲存配置上，也要關注可用空間的多寡，因為若出現容量不足的狀況，Kubernetes系統會停用Pod。
 相關報導  企業K8s實戰在臺灣 
",https://www.ithome.com.tw/news/133297,"新聞,雲端服務,伺服器虛擬化,容器,微服務,Kubernetes,K8s,中華電信,電信業,數位轉型,Kubernetes Summit"
133294,9,2019-10-02,擁抱微服務不需一步到位，找對目標比全面重構更重要,未來企業IT不會只需管理微服務架構，而是微服務和傳統架構並行管理，不要問如何擁抱微服務架構？而要思考，你有什麼問題，需要靠微服務才能解決？這是來自美國零售巨頭Best Buy前電商架構總監13年經驗的建議," 「容器、微服務試了才知道！」大半生投入銀行IT的彰化銀行資訊處處長陳顯龍，談起最新的容器技術，衝勁滿滿。
這家百年老店正在思考銀行架構的大改造，不只要展開銀行核心系統大升級，為了更快速反應市場變化，陳顯龍還計畫，引進最夯的微服務架構、容器技術、商用Kubernetes產品等，來優化現有的系統。他希望改用「服務」來取代過去以業務為導向的功能模組，打造一套可以彈性組合和擴充的新一代分行端末系統。
陳顯龍早在多年前就推動過一波彰銀IT集中化架構的改造，可以做到全球全行一日結帳。相比自己過去熟悉的VM、SOA架構，他認為，容器和微服務架構的核心概念其實也很類似，開始導入這些技術時，銀行IT團隊仍然大概可以知道該如何進行。
但是，「沒有踩進去，就無法知道前置作業得準備到什麼程度才夠，做過一次就知道。」他坦言：「第一次不見得能做好，就算這次失敗，下次就可以調校得更棒。」所以，趁著核心系統升級之際，他打算先從分行端末系統開始擁抱容器技術和微服務，讓IT團隊練手。
彰化銀行不是唯一一家想要擁抱當紅微服務和容器架構的臺灣企業，除了網路公司、新創公司早就積極擁抱之外，這兩年如第一金人壽、國泰世華銀行、遠傳電信、中華電信等也開始嘗試用於特定領域或應用上，更有不少機器學習或深度學習分析團隊背後所用的運算環境，就是靠K8s和容器來調度，例如臺灣最新款的超級電腦台灣杉2號上就部署了一套K8s環境。
傳統企業擁抱微服務的挑戰，遠比新創公司、網路原生服務業者或行動應用業者，來得更困難，最大的挑戰就是大量單體式既有應用的包袱。如何踏出第一步，一步到位全面採用？還是分批進行？該從何下手？這都是CIO的困擾。

Gartner資深研究總監Kevin Matheny建議，導入微服務要先找對目標，可從面對顧客、需要快速改變的AP入手，一步到位全面重構的成本太高。（攝影／洪政偉）
Gartner資深研究總監Kevin Matheny建議，擁抱微服務最好不要一步到位，更不要趕流行，「導入微服務要先找對目標，可從面對顧客、需要快速改變的AP入手，一步到位全面重構的成本太高。」
他從兩個角度來看微服務架構，微服務的內部架構是容器技術和應用程式的程式碼，大多是企業IT開發團隊熟悉的領域。「微服務的精神是將大型應用打破成小單位，來實現最小變動，做到每次改變，都剛好是需要的最小調整。」
不過，解構了大型應用程式之後，將內部元件移到應用程式外來運作時，為了控制這些元件之間的存取，「微服務架構的外部環境，需要有一套支持系統和管理系統。」
這些讓微服務順運作的機制，除了用來管理容器的Kubernetes之外，還需要CI/CD自動化機制、用於服務互通管理用的服務網格（Service Mesh）機制、確保微服務運作的監控機制、面對不同前端應用的對外應用閘道器，以及其他後端服務機制等。
「擁抱微服務的代價是，複雜的維運和痛苦的導入過程。」Kevin Matheny指出。後者正是高度e化傳統企業的第一個挑戰，他認為，若有應用程式需要經常改變，就很適合改用微服務架構，否則不需要。
「若企業的應用程式一個月才需要異動一次，就不需要這樣的架構，太浪費了。」例如現有銀行核心系統，他就不建議先套用微服務架構。
他解釋，微服務架構是一種專供持續變革用的架構，企業可以進行最小幅度的修改，又能同時了解這些修改的影響，作為日後變動的回饋，「通常是面對顧客的系統，例如Web應用，才需要尋求持續不斷的變動。」

【微服務設計架構】Gartner提供了一套微服務設計架構，不同的微服務透過容器封裝，部署在容器管理平臺（如K8s）上，還需搭配CI/CD自動化工具，Service Mesh機制、後端服務、監測機制和對外Gateway。（圖片來源／Gartner）
三階段導入微服務，選對目標是第一步
Kevin Matheny也提供了一套企業三階段導入微服務的作法。「第一步要選對目標！」先辨識出需要經常改變的應用或服務，而且要從業務利益角度來挑選，同時還要評估企業對於微服務架構的準備度。
第二步則是要強化開發能力。包括要提升IT團隊的能力，同時要從產品或應用程式生命週期來思考，並大力擁抱自動化的開發流程和工具，例如CI/CD。
完成了第一、第二步之後，開始從小地方入手，梳理出可從單體式應用中剝離出來的功能API，再從中抽出最小單位的微服務，作為打造微服務的目標和起點。
就算是IT資源較充沛的銀行，他認為，最好也先從顧客系統開始擁抱微服務，累積足夠的人才和經驗後，評估真有需要經常變動的效益，才需要將微服務延伸到核心系統上。
「微服務架構不應該是企業的目標，」Kevin Matheny再三強調這件事，他觀察，未來企業IT不會只需管理微服務架構，而是微服務和傳統架構並行管理，所以，不要問如何擁抱微服務架構？而要思考，你有什麼問題，需要靠微服務才能解決？儘管IT要有大架構和藍圖策略，「先從小服務，開始感受到微服務的好處，遠比IT架構大躍進更為可行。」曾在年營收4百億美元的美國零售巨頭Best Buy擔任過電商架構總監13年的Kevin Matheny，這是他對有意擁抱微服務的臺灣企業，最重要的建議。
 相關報導  企業K8s實戰在臺灣 
",https://www.ithome.com.tw/news/133294,"新聞,微服務,IT集中化,Kubernetes,K8s,數位轉型,Kubernetes Summit"
133268,9,2019-09-26,NetApp亞太區CTO：多雲容器儲存將成為新常態，如何達到跨雲資料管理的一致性是關鍵,現在容器仍以應用端為主，就儲存廠商來說，NetApp亞太區系統工程部副總裁暨技術長Matthew Hurford指出，他們更關注的是在應用層之下的儲存層，如何讓底層的儲存架構能夠支援上層應用的容器是關鍵。," 近兩年，因為火紅的容器（Container）技術掀起雲端應用新浪潮，不只是AWS、Google、Azure等雲端巨頭紛紛押寶，就連儲存廠商也都看好容器應用市場，要讓自家儲存產品可以支援容器應用。儲存廠商NetApp也是其中一家。NetApp亞太區系統工程部副總裁暨技術長Matthew Hurford近日來臺也提出了他對於火紅的容器與K8s的出現，將會如何影響未來儲存架構發展與技術演進的最新觀察。
由於容器先天獨厚的特性， Matthew Hurford表示，現在有越來越多企業，開始走向容器架構，來逐步取代以VMware虛擬化技術為主力的傳統VM架構，甚至很多企業都希望透過建立以容器為主的微服務架構，來加快應用開發和服務更新。
Matthew Hurford也大方分享自己訪查經驗，就他觀察有採用容器的NetApp企業用戶，直到1年前比例還不到1/4，僅有25%有用，但是如今，他說，幾乎所有接觸到的企業用戶，不是已經將容器部署到生產環境，就是考慮未來要用，他說，容器已經成為企業翻新IT架構的新主流。
當容器進到正式環境之後，大量容器管理也成為新挑戰，他表示，在容器叢集調度和管理工具Kubernetes加入之後，很快就解決了這個棘手問題，更進一步加速企業應用容器化的腳步，甚至就他觀察，距今一年前，企業採用Kubernetes管理容器叢集的比例，只有2到3成，如今一舉爆增提高到6成以上，很多用於大規模部署和管理容器化應用程式，「K8s儼然已是企業容器管理平臺的首選。」他說。

Matthew Hurford直言： 多雲容器（multi-cloud container）儲存將會是新常態，如何透過簡化底層儲存到上層容器應用的一系列過程，來達到不同雲端環境的資料儲存管理的一致性，將是一大挑戰。

只不過，現在容器仍以應用端為主，就儲存廠商來說，Matthew Hurford指出，他們更關注的是在應用層之下的儲存層，如何讓底層的儲存架構能夠支援上層應用的容器是關鍵。
尤其，容器化應用雖然爆紅，他坦言，目前還是很難用在需要處理Key-Value類型資料庫為主的有態（Stateful）應用上，而是比較適合用於無關資料儲存的無態（Stateless）應用，也就是將持續性資料儲存於容器外部，但他強調，目前面向企業用戶的應用或後臺應用，多半是有態應用，由於容器本身並不保存資料，等於是說，一出生就注定死亡（They were born.They died），所以，如何打造支援容器化環境的持續性儲存環境，成為儲存廠商切入的一大重點。
而在雲端發展進入到了多雲（Multi Cloud）競爭時代，Matthew Hurford也直言：「 多雲容器（multi-cloud container）儲存將會是新常態，」他認為，不同於過去的容器應用，多部署在企業自己資料中心或單一朵雲，未來，企業不會只把所有應用都放在同一朵雲，而是會有很多朵，連帶也將衝擊到現有的儲存架構的發展，這也意謂著，以後越來越多儲存設計，將搭建在混合雲或多雲架構，在這樣個前提下，如何在不同多雲、跨雲環境來管理數據，將成為一個棘手難題。
面對多雲、混合雲的趨勢，他認為，未來儲存層將會與容器應用層更加緊密的整合，而不會只單獨看儲存發展本身，勢必也得考慮到搭建在容器上的應用程式與微服務，「如何透過簡化底層儲存到上層容器應用的一系列過程，來達到不同雲端環境的資料儲存管理的一致性，將是一大挑戰。」他說，這也為何NetApp開始整合各種雲端開發、部署與自動化管理工具，包含容器Docker、K8s、Ansible與 Jenkins等，目的就是要通過API串接這些平臺以建立一個解耦合（Decouple）的IT架構，提供可以橫跨多雲環境的單一管理方式。

以NetApp為例，他表示，近幾年，也逐步將許多現行儲存服務中提供的儲存功能，緊密整合到容器中，甚至還進一步引進開源Kubernetes容器叢集管理平臺，推出自己的K8s版本，稱為NetApp Kubernetes Service（NKS），可以讓企業用更簡易的方式來管理雲端上的容器，只要幾個步驟，就能在不同雲端環境完成叢集的容器部署，並在同一個環境來管理，還可以透過它來管理這些容器叢集中的不同應用程式。例如透過NKS建立一個更高效率的數據層，可以自動配置內容，以通過API對其進行寫入，來提供有更效率的雲端環境管理方式。
Matthew Hurford指出，NKS已經是一個相當成熟平臺，迄今已有多達6千個K8s叢集部署在NKS環境，他也提到，該平臺最大特色就是延展性（scalability），即使可以採用他們的K8s版本，但仍保留自由選擇的彈性，讓企業用戶能自行決定要將K8s叢集放在哪一個雲端環境，使用上也更容易；再者，因為NKS的核心是基於開源K8s，對於企業用戶來說，只要一有新版釋出，很快可以獲得升級來取得新版的功能。並可以支撐超大規模雲端或其他Kubernetes平臺架構，但目前還未支援紅帽OpenShift容器平臺。

在多雲、混合雲儲存方面，NetApp現階段也有不少支援的雲端儲存產品推出，他說明，目前企業資料在公有雲上運作有兩種方式，前者是以在公有雲硬體上執行NetApp儲存軟體的Cloud Volumes ONTAP，後者則是能在合作的公有雲平臺提供資料儲存方案的Cloud Volumes Services，來提供企業級原生雲端儲存服務，使用上也更具靈活彈性，可以依使用量來部署，他舉例，若想要在雲端配置100TB以上的儲存容量，3秒內就能完成。
該服務除了支援AWS外，NetApp也與Azure合作推出Azure NetApp Files服務，使用NetApp的ONTAP儲存OS，來提供雲端檔案儲存服務，目前已在新加坡推出上線。另外，與GCP也有合推Cloud Volumes Services試用版。另外，他也預告，Cloud Volumes ONTAP服務很快也將在臺上線。除此之外，他說，現在也跟微軟合作要把SAP的資料相關服務搬上雲端。
甚至NetApp在公有雲提供的儲存服務，現在也更進一步延伸到了HCI（超融合架構產品），不論是K8s或CVS服務都可以在公有雲版的HCI環境來使用。並且可以用同一套管理工具來管不同雲上的資料。在雲端分析也有推出如Cloud insights、Active IQ，以及雲端控制的Cloud Manager等產品。
但是如何確保不同朵雲的儲存資料是可以互通移轉？Matthew Hurford點出背後關鍵，靠的正是整合API，「對我們來說，就是在做數據服務層操作，」他表示，透過建立更靈活的API，除了可以簡化管理，也能幫助我們整合不同家雲端廠商的K8s引擎，如Amazon EKS、Google GKE或Azure AKS等，讓不論是本地端部署，或是採用其他公有雲，都可以在同一容器管理平臺下進行管理K8s叢集，橫跨不同雲端環境。
他表示，目前有提供4種Rest API，還可搭配Ansible自動化管理工具，來提供協助整個雲端環境運作的簡化，除了加快應用與容器的部署，也可以自動化的方式來部署這些key-value store 的NoSQL 資料庫。除此之外，在資料管理上，NetApp也新推出Fabric Orchestrator資料管理與調度產品，可以自動偵測資料，並根據資料類型自動設計保護規則，裡面也結合AI技術用於自動化監測，可以隨時掌握資料使用狀態，也能通過它來迅速刪除不必要的資料，如因應GDPR施行對使用者個資的要求等。
 
",https://www.ithome.com.tw/news/133268,"新聞,容器,K8s,儲存,NetApp"
133189,9,2019-09-21,施耐德微型資料中心第四季將在臺上市，內部設計搶先公開,施耐德設計了3款微型資料中心，都是一櫃就能提供UPS、散熱系統、環境監控等IT基礎架構所需的功能，42U全高款可適用各種工廠環境，18U半高款的外觀則像是一個尋常的櫥櫃，還有隔音設計，可藏身於商場或辦公室中," 施耐德電機（Schneider Electric）近兩年來因應邊緣運算興起的趨勢，陸續推出微型資料中心（micro data center）解決方案，其中三個系列R-Series、C-Series與S-Series已經在今年亮相，將在第四季於臺灣上市。而位於新加坡的施耐德亞太區總部，也在創新中心（Innovation Hub）展示了微型資料中心的實際應用情形，要讓企業能一窺其內部構造，根據需求來選用合適的產品。
施耐德對微型資料中心的定義，是在一個獨立機櫃中，就可以部署完整IT基礎架構。微型資料中心採取模組化設計，讓企業能根據部署環境與需求，來選擇軟硬體設備與系統。


依據部署環境的不同，微型資料中心也區分為三種類型。首先，FX-1是是採用封閉式設計架構，整合不斷電系統（UPS）、冷卻系統、環境監控系統，能透過硬體設備的溫度變化自動調整空調風量，進而節省能源消耗。施耐德表示，這套解決方案適合部署於較不安全的環境中，如倉庫、工廠、偏遠地區、閣樓等場域，能克服環境中有大量微塵、可能遇水、雜放多種機臺、溫濕度不可調節等問題。

取封閉式架構的FX-1，機櫃高度42U。單一機櫃上就設置了刷卡、密碼驗證功能，通過身份驗證者才能開門。


環境監控系統的儀表板，可以用來即時監測溫度、空氣流動、噪音，以及硬體設備健康狀況、電池壽命、用電量等。


開啟機櫃後，最下方的設備是冷卻系統，會有空調維持冷空氣的循環，而上面一層則為不斷電系統，也能直向放置在側邊，省下來的空間就能放置更多機架與設備。


而C-Series微型資料中心，其外型設計像一般傢俱櫃，大約是半個人的身高（18U），是專為商業場所設計，能放置於零售業店面、辦公室、機場、銀行等中度安全性的環境中，且因放置處更貼近人群，櫃門內部還有厚厚一層隔音材質，避免機器運轉噪音影響他人作業。

截圖自官網，外型像一般家具櫃。


櫃門內部有一層來隔音的材質，確保機櫃不會發出任何聲音，櫃子後面也設有多排風扇來散熱。

S-Series則是設計成非密封式的機櫃，適合部署在溫度可控、人員進出需要權限等安全性高的環境中，比如一般企業IT機房等。由於這個機櫃並非密閉式空間，環境溫濕度的偵測與就更顯重要，因此，機櫃經身份驗證開啟後，上層機架有一臺蒐集環境數據資料的遠端機架監控設備（NetBotz Rack Monitor），搭配兩個無線的小型感測器去蒐集數據，感測器也能移動到內外部機架的任意位置。

機櫃的外部有兩個感測器，能夠蒐集溫濕度資訊並反饋給機櫃內的設備來分析。


由上往下數第二個設備，就是用來蒐集環境數據資料的遠端機架監控設備。 

這三種微型資料中心解決方案，與一般大型資料中心不斷電系統中，所使用的電池種類也不同。大型資料中心所使用的電池多為碳鋅電池，部署成本較低、但電池壽命也僅有3-5年；施耐德表示，鋰電池才能滿足微型資料中心需要體積較小電池的需求，在有限空間內部署數量更多，不僅有效節省空間運用，電池壽命更長達10年，儘管部署成本較高，但長久來看卻更環保節能，且維運成本更低。因此，施耐德也特別改採用鋰電池取代碳鋅電池作為微型資料中心的發電設備。
目前採用微型資料中心的許多客戶，大多是在應用邊緣運算的前提下，有使用VM、超融合架構硬體設備的需求，因為這些設備的耗電量更高，且硬體機臺的溫度升降較不可控，需要更即時的機櫃冷卻系統來協助控溫，才能維持機器正常運作。

鋰電池的部署成本較高，但長期來看卻能帶來更大效益。

而微型資料中心三種解決方案中，透過IoT感測器即時蒐集到的設備數據，能透過部署在Azure雲端的EcoStruxre平臺來管理，如果偵測到異常情形將直接在儀表板上反饋。比如某企業在全球各地共50處設置微型資料中心，地圖上即可清楚看到每個資料中心的運作情況，如果臺灣的資料中心出現報警，如設備通訊有問題、電力未輸出、供給設備的電壓或頻率不能支持運作等，都能即時回報到中央儀表板，並能迅速查閱當地的維運人員，通知對方去解決問題。

從儀表板上可以去監測每個地點的資料中心設備是否發生問題，若發生問題能即時查閱可聯絡的在地維運人員前往處理。


運用Azure雲端來執行數據分析，能夠檢測出設備的健康分數。比如透過不斷電系統電池的壽命、溫度、零組件使用等數據，就能得到一個分數（圖右邊紅色數據），也能進一步檢視導致這個分數的原因，再由人力判斷是否有需要進一步維修的需求。


這是分別就電池溫度、壽命，UPS總負載量、壽命而製成的圖表。


這是較大型資料中心的溫度分佈圖，能做到即時的監控，當給定指令改變冷卻系統的風量與風向時，溫度分佈圖會隨之改變，且能一目了然的檢視是否有溫度過高，甚至顏色上升至橘紅色的位置，並盡快做出調整。


",https://www.ithome.com.tw/news/133189,"新聞,資料中心,UPS,施耐德電機,EcoStruxre,IoT,邊緣運算,Cloud"
133160,9,2019-09-20,搶攻邊緣運算市場，施耐德10月將推出全球最小的微型資料中心,施耐德電機根據企業導入邊緣運算技術的趨勢，近兩年也聯手生態系合作夥伴，推出微型資料中心的解決方案。," 【新加坡直擊】邊緣運算（Edge Computing）興起後，為了達到更低延遲的資料傳輸與分析，許多企業開始在本地端部署運算資源，追求在有限的空間裡，如零售店面、商辦、銀行、醫院、學校等場所，隔離出一小區塊來部署伺服器設備。為了滿足客戶需求，施耐德電機（Schneider Electric）近兩年來推出微型資料中心（micro data center）解決方案，今年10月，更預計要推出全世界最小的微型資料中心產品，達到更有效率的空間運用。

施耐德雲端資訊科技事業處資深副總裁暨CTO Kevin Brown說明資料中心的架構：Centralized Data Center是指一般傳統式集中式大型資料中心，如公有雲機房；Regional Edge Data Center是指地區性的資料中心，例如Netflix在全球每個地區都有建置資料中心，讓影片傳輸更低延遲；Local Edge Data Center是指為了邊緣運算而興建的機房，在邊緣端即時分析數據。

施耐德的微型資料中心解決方案，是在一個42U、24U或更矮的機櫃中，整合不斷電系統（UPS）、冷卻系統，並搭配自家EcoStruxure軟體平臺，來實現環境監控及預測維護，克服在環境因素不可控的場域中也能持續運作；同時，搭配生態系合作夥伴的資源，讓企業選擇伺服器廠商如HP、Dell、Lenovo等的設備，由系統整合商（SI）整合機櫃、伺服器與不同感應器，來打造一整套客製化的解決方案，讓客戶導入後能快速部署。
也就是說，微型資料中心除了有基本的網路、伺服器、儲存空間的硬體設備，也具備核心的不斷電系統、冷卻系統、機架配電遠端監測系統，搭配部署在Azure公有雲上的遠端維運軟體，來即時對設備進行健康診斷；而開啟機櫃時也設有身份認證裝置，外部更能裝設安全監控系統如CCTV、溫濕度、煙霧、漏水偵測感應器來報警，儼然就是個迷你版資料中心。
而施耐德目前已經推出的解決方案，能依據部署環境分為三種類型，分別是R-Series、C-Series與S-Series。R-Series適合部署於較不安全的環境中，如倉庫、工廠、偏遠地區、閣樓等場域，能克服環境中有大量微塵、可能遇水、雜放多種機臺、溫濕度不可調節等問題；C-Series則是專為商業場所設計，外型就像一般傢俱櫃，能放置於零售業店面、辦公室、機場、銀行等中度安全性的環境中，也具備活動式移動的功能；S-Series則適合部署在安全性高的環境中，比如一般企業IT機房等。
不過，要把所有的系統與設備整合到更小的空間，也是開發過程的一大挑戰。施耐德雲端資訊科技事業處執行副總裁Dave Johnson表示：「在一個小空間裡要保持產品架構的彈性、維護網絡安全性，且必須易於維護和管理，是非常複雜的事。」施耐德雲端資訊科技事業處資深副總裁暨CTO Kevin Brown則表示，微型資料中心的產品設計上選擇用鋰電池來供電，除了體積小的優勢，同時也是減少耗能的關鍵，此外，也參考客戶意見以體積更小的超融合架構來整合產品，「我們透過設計來決定物件擺放優先次序，並想辦法提高成效。」
而納入更多客戶意見的管道，則是透過施耐德在近期設立的施耐德電機夥伴社群平臺（Schneider Electric Exchange Community），讓全球合作夥伴共同討論如何解決能源管理和自動化等問題，目前已有超過10,000篇知識庫文章以及1,000常見問題的解答。
另外，談到如何與競爭對手做出差異化，施耐德雲端資訊科技事業處國際業務部資深副總裁Natalya Makarochkina表示，EcoStruxure軟體平臺是其中一個關鍵。這個平臺自10年前推出，近三年來發展成熟，目前部署在Azure公有雲上，走開放式數據傳輸的架構，舉凡符合網路傳輸協議（Communications Protocol）的硬體設備，其數據資料都能被加密並傳上雲端，運用Azure機器學習工具來分析，以此監控設備的健康分數。比如透過不斷電系統電池的壽命、溫度、零組件使用等數據，能用來分析目前的健康分數，再由人力判斷是否有需要進一步更換或維修的需求。
Natalya Makarochkina也指出，擁有尺寸齊全的機櫃設備也是做出差異化的指標，尤其十月份即將推出全球最小機櫃，是由客戶反饋驅動而設計的產品，且施耐德也曾提供國際大廠超過15公頃資料中心的解決方案。最後一個優勢，則是擁有龐大生態系的合作夥伴，能加快產品從設計到落地部署的時間，且滿足客戶多元的需求，「軟體的預測性維修服務、微型資料中心的發表、以及策略聯盟的生態系夥伴，是讓我們與眾不同的三大關鍵。」
",https://www.ithome.com.tw/news/133160,"新聞,AI,施耐德,資料中心,Cloud,UPS,邊緣運算,機櫃"
132996,9,2019-09-12,GCP用戶現可在GKE上執行Cloud Dataproc的Spark工作負載,Google讓Cloud Dataproc可在Kubernetes上執行，並提供用戶統一控制平臺，操作K8s和YARN兩個叢集管理系統," Google宣布用戶可在Kubernetes上執行Cloud Dataproc，也就是說，現在使用者可以利用GKE叢集執行Apache Spark工作負載，而這項更新將為企業簡化管理基礎設施的複雜性。
Cloud Dataproc是Google雲端上全託管的Apache Hadoop與Spark服務，Google提到，資料科學家可以使用Cloud Dataproc大規模地分析資料或是訓練模型，不過隨著企業基礎架構變得複雜，許多問題慢慢產生，像是部分機器可能處於閒置，但是某個工作負載叢集可能持續擴大，而開源軟體與函式庫也隨著時間過時且與堆疊不相容。
為了解決這些問題，Google現在讓Cloud Dataproc得以在K8s上運作，並為其提供了一個控制平臺，讓企業可以同時在公有雲和企業內環境，部署與管理在GKE上的Apache Spark工作負載。使用Cloud Dataproc的新功能，用戶就能以統一的集中檢視工具，跨K8s和YARN兩個叢集管理系統，操作混合工作負載。
而且新功能還隔離了開源軟體，消除傳統大資料技術對版本以及函式庫的相依性，讓使用者可以將模型和新的ETL工作管線，從開發階段直接轉移到生產階段，而不需要考量相容性，Google提到，使用K8s這樣的敏捷基礎架構，讓開源軟體升級更簡單。
Apache Spark是第一個放到K8s上Cloud Dataproc的開源資料處理引擎，而這項工作還會繼續擴及更多的開源專案，Google提到，Cloud Dataproc搬遷到K8s上，改變了他們將Cloud Dataproc和開源軟體作為託管服務的方式，他們會持續與其他開源社群合作，並為更多的開源專案啟用K8s上執行Cloud Dataproc功能。
",https://www.ithome.com.tw/news/132996,"新聞,GCP,GKE,Cloud Dataproc,Apache Spark,K8s,Kubernetes"
132902,9,2019-09-10,下一代vSphere全新K8s管理畫面搶先看,VMware揭露了新的Tanzu產品線，其中包括了以K8s重構，代號太平洋計畫的新版vSphere，以及可用來管理各種K8s叢集的關鍵機制Tanzu Mission Control，最新管理畫面首度公開," 「太平洋計畫就是下一代的vSphere。」VMware研發副總裁也是K8s專案創辦人Craig McLuckie直言，這就是vSphere的未來發展。VMware決定全力擁抱K8s，而且直接改以K8s為底層，重新打造了新版vSphere。在太平洋計畫中，VMware將vSphere的核心ESXi，換成了一個超級K8s叢集，將K8s API整合到vSphere的API中，讓企業維運團隊，可以像ESXi管理VM那樣，來運用K8S的能力，而vSphere也將變成了一款K8s原生產品。
現有的vSphere需搭配Pivotal的PKS來建置K8s叢集，但未來，新版vSphere能直接建置和部署K8s叢集。這個整合的另一個新特色是，同時將K8s的宣告式基礎架構管理能力，帶進了VM世界，K8s慣用的YAML配置檔，現在也可以用來配置VM。不只容器，連VM的基礎架構資源都可以程式碼化了。
新發表的Tanzu Mission Control則是VMware在K8s布局的另一個關鍵，這是大規模管理不同環境下K8s叢集的關鍵技術。VMware宣稱，可以支援任何環境中部署的標準K8s，包括主流公有雲AWS的EKS、Azure的AKS、GCP的GKE、IBM雲的IKS，也可支援企業內部部署的K8s環境，如紅帽的OpenShift。目前Tanzu Mission Control仍是SaaS服務，已釋出第一個測試版，但VMware預告，未來將推出企業內部部署版。而太平洋計畫成果，也就是內建K8s的新版vSphere，則將於今年底前釋出Beta測試版。
不過，在今年VMworld上，VMware也展示了新版vSphere和Tanzu Mission Control最新的管理畫面，例如新增加了新的管理單位Namespaces，可對K8s和VM套用同一個政策。
從這些展示畫面中，可以看到vSphere如何整合K8s叢集的管理介面，一窺VMwarer心目中，未來橫跨VM世界和K8s世界的新管理方式。

工作量管理單位Namesapce
新版vSphere將增加Namespaces（目前暫訂名稱）的管理單位，例如圖中的work-auth，可建立統一政策來管理K8s叢集、VM和原生Pod。（圖片來源／VMware）

K8s可套用原有SSO驗證
在新版vSphere中，可用現有的vSphere SSO身分驗證機制，來設定K8s群組權限，針對不同團隊、角色，來設定Namespaces的可用權限。（圖片來源／VMware）

統一管理VM和K8s資源
不論是VM或是K8s，都將套用同一份Namespaces的資源管理政策，可限定一個Namespaces能使用的CPU資源、記憶體、儲存容量上限等。（圖片來源／VMware）

內建K8s叢集管理功能
在新版vSphere中，可以直接檢視一個K8s叢集的詳細資料，例如資源池中有多少Pod，使用了多少VM等，甚至可以直接修改配置、權限等。（圖片來源／VMware）

直接檢視K8s事件資訊
在新版vSphere中，不只可以檢視K8s叢集資訊，在Namespaces監控頁面下，能直接瀏覽每一個K8s叢集的Log事件，來了解K8s叢集最新的運作狀態。（圖片來源／VMware）

自助式K8s部署包
在新版vSphere中建立K8s叢集時，會自動產生一個自助式K8s部署網頁，提供K8s CLI工具包下載，方便開發者在vSphere中部署K8s叢集。（圖片來源／VMware）

可用YAML來部署K8s和VM
新版vSphere內建了完整K8s API，不只可以用YAML來部署K8s叢集，甚至連VM的部署，現在也可以用YAML來宣告，提供基礎架構程式碼化的能力。（圖片來源／VMware）

遠端配置K8s叢集
新版vSphere搭配另一個Tanzu Mission Control工具，可以用來建立和配置不同公有雲上的K8s叢集，也可指定是開發環境用或正式環境用。（圖片來源／VMware）

可調度公雲和私雲K8s叢集
Tanzu Mission Control是大規模管理K8s叢集的關鍵，可支援主流公雲如EKS、GKE、AKS，也可調度企業內部私雲，如vSphere或OpenShift的K8s叢集。（圖片來源／VMware）
 相關報導  VMware的K8s逆襲 
",https://www.ithome.com.tw/news/132902,"新聞,vSphere,K8s,Craig McLuckie,VMware,Kubernetes"
132901,9,2019-09-10,【觀點：Kubernetes共同創辦人Craig McLuckie】VMware為何要用K8s重新打造vSphere？,儘管已有不少方法可以強化容器的安全，但VMware研發副總裁Craig McLuckie認為，目前沒有其他資安隔離方式，可以做得比VM更好。而VMware將K8s內建到vSphere的太平洋計畫，目的就是要提供隔離，利用VM來隔離容器實例，讓企業重度倚賴的現有系統，能直接使用K8s," 5年前，當時在Google任職的Craig McLuckie，仿照Google自家管理全球資料中心運算資源的Borg系統，和兩位同事Joe Beda和Brendan Burns，一起打造了這個現在影響全球雲端和IT基礎架構技術的Kubernetes專案。
「當年打造K8s專案的野心是，打通雲和雲之間的壁壘，建立一套一致的管理能力。」現為VMware研發副總裁的Craig McLuckie這麼說。
他和另一位創辦人合開的公司Heptio，被VMware買下後，兩人也跟著進入了VMware，開始負責重新改造VMware關鍵產品的任務。而另一名創辦人Brendan Burns也早就離開Google，成了微軟Azure的產品開發大將。
Craig McLuckie指出，回顧容器發展，容器是一個令人印象深刻的資源隔離框架，可以將實體資源切成非常微小的一份，也能提供了豐富的控制機制。可是，他話鋒一轉，「從安全角度來看則不佳，使用容器時，單靠Linux作業系統來提供使用者和Linux核心的抽象隔離，還缺少了一個更好的資安隔離框架設計。」
儘管已有不少方法可以強化容器的安全，但Craig McLuckie認為，目前沒有其他資安隔離方式，可以做得比VM更好。「VM的邊界，仍是最穩固的資安邊界。」所以，他解釋：「將K8s內建到vSphere的太平洋計畫，目的就是要提供隔離，利用VM來隔離容器實例。」另一個好處則是，可以讓擁有大量「當代應用」的企業，直接使用K8s。「我不喜歡用老舊應用這個詞，來形容企業重度倚賴的現有系統。」他說。
事實上，太平洋計畫的願景，第一是提供最好的環境，來執行現代化雲端應用工作量（Workload），「一旦把K8s帶vSphere，不是提供K8s服務，而是提供了新的維運選擇」，可以將傳統工作量和雲端原生工作的管理合而為一，不用分別管理；而該計畫的第二個目的，是要徹底改變vSphere的操作體驗，整合vSphere和K8s的介面，讓維運團隊也能運用到更敏捷、宣告式的IT管理經驗。
除此之外，Craig McLuckie指出，K8s利用分散式系統架構，成功建立了這一套管理機制，但也帶來了新的挑戰。「基礎架構維運應該越單純、越無聊越好。可是，不論是上雲或在企業內部使用K8s，仍需要執行很多管理任務。」
目前，多數企業使用K8s的方式，是，先建立叢集，再來部署應用程式。也因此，「企業須依叢集管理需求，來組織他們的工作，而非按應用程式的需求，來管理叢集。」他觀察。
「這就產生了全然不同的管理挑戰，」Craig McLuckie指出，管1個K8s叢集容易，但要管到十個、百個K8s叢集時，就變得非常困難。目前已有大型企業，例如，電信，製造或零售業者，實際要管理到上千個K8s叢集。因此，許多團隊開始研究多雲、多叢集的關鍵應用需求。
「對我而言，K8s不只基礎架構的技術問題，還需要考慮使用技術的人，讓打造和執行應用程式的人，都容易取用這些技術。」而Tanzu Mission Control的機制，就是Craig認為，可以用來管理數十、數百個叢集的關鍵，它能夠讓ISV產業將自家應用帶進雲上，也能夠用來定義各種可能的未來雲端應用的模樣。
未來，這個機制，還可以延伸到無伺服器、函數化應用的發展上。
 相關報導  VMware的K8s逆襲 
",https://www.ithome.com.tw/news/132901,"新聞,K8s,vSphere,Craig McLuckie,Kubernetes,容器安全"
132900,9,2019-09-10,VMware全面擁抱K8s，三大策略打造全新Tanzu產品線,早在2014年，VMware就開始擁抱Docker，將容器和VM技術整合，甚至3年前開始投入K8s技術開發，然而，不管是企業顧客或市場氛圍，仍覺得VMware對K8s的態度不夠明朗，所以，VMware決定徹底改造vSphere，推出全新的K8s產品線Tanzu," 【舊金山直擊】
終於，虛擬化技術龍頭VMware，正式發布了自己的Kubernetes（簡稱K8s）戰略。甚至，VMware執行長Pat Gelsinger在2019年度大會VMworld開場時就強調，K8s是一個能改變產業遊戲規格的技術，就像當年Java和VM技術問世一樣。
VMware年度大會第一天開場影片，就秀出「全面啟動」電影中不斷旋轉的陀螺，暗示未來的企業管理挑戰是，沒有人知道雲端應用真正在哪一臺機器上執行，以及執行到什麼程度，要等到出錯或當機時，才會意識到自己應用程式的存在。
但是，雲太深了，想要在多雲、混合雲中，尋找藏在其中的錯誤配置或程式碼，就像電影「全面啟動」中，須翻開一層又一層的潛意識來追溯軌跡，才能找到解決問題的下手處，對IT來說，這幾乎是無止盡的挑戰。
Pat Gelsinger一上場就指出，數位科技已將人們日常生活變成了數位生活，而撐起各式各樣應用場景的大量App。「2019年，全世界的App數量估計達到了3.35億個，」但是，他指出，到了2024年，預估將會達到7.92億個App。尤其，關鍵技術將是AI、5G和Edge相關技術，更會加速更多App的出現。
而且，這正是為何VMware決定，全力搶攻大規模應用部署，以及維運市場的重要因素。
K8s是整合開發和維運的關鍵技術
VMworld原有發展策略就是「任何應用，可在任何雲和任何裝置上安全的執行。」但是，隨著各種現代應用型態的出現，傳統應用、雲端原生應用、SaaS應用等類型越來越多元化，基礎架構的維運挑戰也更加複雜了，IT得要面臨私有雲、各種公有雲，再加上近兩年新興的邊緣運算環境的複合式維運考驗。
應用程式的建置，是開發者的課題，而執行和部署則是IT維運者的挑戰，「只有K8s能連結兩個世界，這是整合開發和維運的關鍵技術，K8s已經是現在的主流技術。」他坦言。

VMware決定把K8s內建到vSphere中，宣布了太平洋計畫（Project Pacific），甚至，重新架構了vSphere，來整合vSphere和K8s兩大平臺。（攝影／王宏仁）
5年前開始擁抱容器技術Docker
對VMware來說，K8s和容器技術，並不是全新的領域。2014年8月，同樣在舊金山的VMworld大會上，Pat Gelsinger就當眾宣布，VMware開始擁抱容器技術Docker。當時，VMware才剛完成了軟體定義資料中心產品布局，完成涵蓋了運算虛擬化vSphere、儲存虛擬化vSAN和網路虛擬化NSX產品線。
當時Docker才剛問世一年多，2014年6月，Docker公司剛發表了Docker 1.0正式版，8月時，VMware就宣布要在vSphere內支援Docker，還找來Docker執行長Ben Golub，到VMworld大會上站臺。那一刻我就在臺下目睹，VM龍頭CEO和容器浪潮先鋒CEO聯手宣布，VMware、Docker、Pivotal要聯手打造一個通用平臺，讓企業更容易管理和執行部署於Container內的應用程式。而這麼做的目標是：「透過這個單一平臺，企業可以管理傳統的虛擬機器、軟體貨櫃或者是安裝於虛擬機器內的容器。」Pat Gelsinger當時這樣說。
2015年自行研發容器OS
2015年，VMware更是大動作擁抱容器技術的應用，並且推出容器整合架構VIC（VMware-Integrated Container），甚至還自行打造了一套容器作業系統Photon OS，以及容器管理平臺Photon Platform，證明他們沒有在容器技術浪潮當中落後。
但是，市場一直有個質疑，容器看起來就像是VM的競爭對手，VMware要如何兼顧兩者？隔年5月，趁著Pat Gelsinger來臺之際，我在新竹往臺北的車上，對他提出了這個重大問題。
Pat Gelsinger回答，IT架構從專屬主從式伺服器世代，邁向行動－雲端（Mobile/Cloud）世代，至少需要20年才能完成這樣的轉型。「Container不會取代VM，因為我們仍然需要一個運作Container的環境，能夠提供管理、確保安全、建立網路連結，而這正是VM可以帶給Container的價值。」
VMware在2015年的容器策略是，在VM之中運作Container，同時開發新的VMware軟體層（VMware Stack），專為Container優化，也就是VIC（VMware-Integrated Container），目標是「讓企業在今日的基礎架構上運作Container。」同時VMware的Photon計畫，則是要打造一個特別為Container優化的環境，提供網路、安全性、管理性和相容性。
整合容器、用VM強化和優化容器，聽起來很熟悉，對吧？VMware的K8s策略也採取了同樣的作法，只是，容器技術換成了K8s。2017年，VMware正式投入Kubernetes市場，與Pivotal及Google聯手推出Pivotal容器服務（Pivotal Container Service，簡稱PKS）
可是，虛擬化龍頭的名聲和包袱過於巨大，儘管，VMware很早就開始卡位K8s市場，但其K8s策略和Pivotal自行開發的K8s相關產品，一直沒有獲得太多企業的青睞。
改透過併購手段布局K8s市場
VMware決定轉變策略，透過併購手段，來加速K8s市場的布局。從去年開始，先是大砸5.5億美元，買下了K8s專案兩位創辦人Joe Beda和Craig McLuckie創立的Heptio，不只取得一套跨雲K8s平臺，也擁有了K8s社群意見領袖。今年5月，則併購以K8s和容器用封裝技術著稱的Bitnami公司，尤其取得了提供130多款熱門軟體通用套件的雲端市集，以及Bitnami的自動化工具，能快速將更多軟體打包發布到雲端市集中。
同時，VMware也透過併購強化跨雲管理和雲端安全產品線。這兩年來，他們先後併購Cloud Health、Wavefront及BitFusion.io這三家廠商，取得跨雲管理和監控優化工具，同時，還拿下三家安全產品，包括無伺服器安全新創Intrinsic和網路安全新創Veriflow，以及剛大砸21億美元買下的網路安全公司Carbon Black。而就在今年VMworld舉辦前夕，VMware更突然宣布，以27億美元買回Pivotal，將3千名K8s和熟諳雲端原生開發技術的團隊，納入自家產品部門。
2019年揭露新產品線Tanzu，宣示全力擁抱K8s
即使有一連串併購行動，Pat Gelsinger表示，市場對VMware的K8s策略仍舊不甚清楚，因此，VMware決定推出全新的產品線VMware Tanzu產品線，從建置、執行和管理這三大面向，來布局K8s市場。
Tanzu這個產品名稱源於兩處，一是來自日文，意思是可移動的模組化櫥櫃（Tansu，簞笥），另一個則是出於斯瓦希裡語，具有不斷分叉的樹枝之意。
Tanzu產品線包括了三個部分，建置面（Build）、執行面（Run）和管理面的產品。執行工具主要是提供一套可用於內部、公有雲和邊緣環境的企業級K8s，而建置工具以現代化應用為主，涵蓋了傳統應用、開源應用和雲端原生應用。而管理工具的目標則要能跨多雲、多叢集和多團隊，支援開發者和IT所需的K8s。
現任VMware首席工程師也是K8s專案共同創辦人Joe Beda，正是Tanzu產品線開發團隊的負責人之一，他解釋，在建置面產品策略上，主要以Bitnami和Pivotal的技術為主，Bitnami提供了一套打包（packaging）和部署（deployment）技術，可用來打造出一個能到處部署的標準化K8s應用包，而Pivotal則有一套雲端原生開發經驗，「使用這兩家技術的開發者社群超過了500萬人，可以建立起一個龐大的ISV生態系。」
引進Pivotal團隊強化K8s開發力
為何現在決定將Pivotal買回來？Pat Gelsinger解釋，5年前，早在K8s問世之前，Pivotal團隊就開始解決雲端原生應用的問題，也經歷過重新改造自家產品來支援K8s的經驗，已經建立了一整套的雲端原生開發文化和經驗，VMware希望借鏡這個團隊的K8s轉型經驗，來加速VMware整合各項新併購的產品。「Pivotal團隊將成為Tanzu的開發主力之一。」他表示。
舉例來說，Pivotal過去持續力推的PaaS軟體Cloud Foundry，已釋出了Alpha測試版，去年也和Google、IBM、紅帽和SAP等廠商合作，開發了一個能夠跨多雲的無伺服器管理平臺Knative，「未來，這也將成為VMware發展無伺服器應用產品的關鍵。

VMware發表了一款Tanzu Mission Control工具，可用來管理私有雲、各家公有雲或邊緣運算環境中的任何K8s叢集，提供可視化、控制和各種政策管理工具。（攝影／王宏仁）
以K8s重新打造vSphere
在執行面產品策略上，VMware決定把K8s內建到vSphere中，宣布了太平洋計畫（Project Pacific）。Joe Beda指出：「VMware因此重新架構了vSphere，目標是整合vSphere和K8s兩大平臺，將vSphere經驗延伸到現代化App，也可以提供開發和維運的協作。」VMware營運長Raghu Raghuram指出。
「這不是表面上的整合而已，而是真的內建到核心，讓vSphere成為更容易執行K8s的平臺。」Joe Beda解釋，不只控制層和UI層，連虛擬化層都因此高度整合，做到ESXi可以原生執行K8s。未來，維運團隊可以透過單一介面來管理VM和K8s資源，而開發者也可以自助運用各種K8s API樣版。
整合之後，Joe Beda宣稱，初步測試顯示，在太平洋計畫的新版ESXi上執行K8s工作量的效能，可以比在傳統Linux虛擬機器上執行還要高30％。甚至，在新版ESXi上執行K8s叢集的效能，比在裸機上執行K8s叢集的效能高出一點，約8％。
透過太平洋計畫的整合，Pat Gelsinger預估，還可以將VMware現有VM生態系帶進K8s，包括了2萬家經銷商、1,100家技術夥伴和4千家服務供應商，以及50萬家VMware企業顧客。他透露，太平洋計畫的成果，也就是內建K8s的vSphere新版，將於今年底前釋出Beta測試版，先提供給現有企業用戶測試。
Tanzu產品線的第三類工具，是推出新的跨雲管理工具。對此，VMware發表了名為Tanzu Mission Control的工具，可用來管理大規模K8s叢集，提供可視化和控制功能。
這套產品的目標，是要能支援多團隊、多雲和多叢集，Joe Beda強調，可以管理任何環境中的K8s，包括AWS、Azure、GCP、IBM雲，以及VMware自家雲端服務，都可以支援。
維運人員可以直接使用Mission Control來調度K8s叢集，可以建立關於存取、備份、安全等政策。目前，Tanzu Mission Control已經釋出第一個測試版，提供給少數顧客試用。
Tanzu產品線可以提供K8s叢集的全生命週期管理機制，也將能整合到Bitnami應用程式市集，快速部署預先打包的K8s應用，並且透過Sonobuoy來驗證和控制所部署的K8s配置，確保部署的正確性。而VMware的跨雲管理產品vRealize，也可以透過Tanzu來管理到多雲上的K8s叢集。
透過Tanzu Mission Control，還可整合VMware自家跨雲效能監控平臺，也就是CloudHealth，來進行優化，能將K8s叢集資訊，結合VMware雲端監控服務Wavefront，提供一站式的視覺化監控管理。目前，這套系統也可搭配Heptio的備份或備援工具Velero，或結合Heptio的ingress控制器contour，來進行大規模K8s叢集的存取控制。
「VMware真的很認真要擁抱K8s。」Pat Gelsinger強調，過去半年來，不少大型企業告訴他，例如FedEx，想要一套K8s發展策略，而這也更加強了VMware整合K8s的決心，「未來幾季，就會看到Tanzu等新產品線的整體樣貌。VMware希望成為K8s的領導廠商。」Pat Gelsinger喊出了給自己的新目標。
 相關報導  VMware的K8s逆襲 
",https://www.ithome.com.tw/news/132900,"新聞,VMware,K8s,Tanzu,Kubernetes,VMworld,邊緣運算,雲端"
132884,9,2019-09-05,DevOps服務CircleCI資料外洩事件調查，攻擊者未取得任何用戶機密資料,Circleci強調，所有用戶的身份驗證憑證以及產品原始碼都未外洩，也沒有身份遭盜用的疑慮，但要小心針對性的電子郵件釣魚攻擊," 知名DevOps服務供應商Circleci在8月31日的時候，發現其合作廠商的帳號出現異常行為，並隨即終止了該帳戶的存取權限，現在經過調查發布了安全調查報告，Circleci表示，用戶的原始碼以及授權憑證都沒有外洩，因此用戶不需要更新密碼。
受影響的範圍，涵蓋了2019年6月30日和2019年8月31日之間，存取過Circleci平臺的所有用戶，Circleci已經主動以電子信件通知這些用戶，並提供必要採取的行動建議。
CircleCI在8月31日時候收到了來自第三方分析廠商的通知電子郵件，發現這個廠商的帳戶正進行異常活動，CircleCI立刻禁用了受到影響的帳戶，CircleCI工程團隊還偵測到系統增加了異常的資料庫，經確認該資料庫非CircleCI的資源後，便立即刪除了該資料庫。
CircleCI表示，根據他們的調查，部分用戶的使用者名稱、與GitHub和Bitbucket關聯的電子郵件信箱，以及用戶IP位置與用戶代理字串被洩漏，另外，組織名稱、儲存庫URL、儲存庫名稱、分支名稱以及儲存庫擁有者等訊息也可能被非法取用。
但CircleCI強調，在這個事件中，沒有任何的CircleCI用戶秘密、建置物件、建置日誌、原始碼以及生產資料被存取或是洩漏，所有用於CircleCI進行身份驗證的資料，像是身份驗證令牌和密碼雜湊都是安全的，也沒有任何信用卡以及金融訊息被盜走，而且由於CircleCI不收集社會安全碼以及信用卡資訊，因此用戶也沒有身份被盜用的風險。
除了加強安全防護之外，CircleCI正在與第三方數位取證公司合作，執行進一步的調查以及補救工作。CircleCI也仍持續與第三方供應商合作，找出切確的漏洞，雖然調查仍在進行，但他們認為目前攻擊者無法造成更多的威脅。
CircleCI提到，他們正在重新檢視第三方帳戶啟用雙因素驗證的政策，繼續推動單點登入的整合，並且呼籲使用者，應該檢查敏感商業資訊，此外，由於電子郵件遭到外洩，因此用戶也應該小心受到針對性的釣魚攻擊。
",https://www.ithome.com.tw/news/132884,"新聞,DevOps,Circleci,攻擊,資料外洩"
132646,9,2019-08-26,【舊金山直擊】VMware揭露K8s戰略布局，搶攻大規模K8s管理的第一個新產品Tanzu登場,Tanzu可以透過單一控制機制，來管理部署在各地的K8s叢集，包括了vSphere、公有雲，代管式K8s服務，甚至是企業自行建置的客製的Kubernetes都能統一管理," 虛擬化龍頭VMware過去20個月大力併購了多家K8s新創或產品線，甚至在年度大會前夕，宣布以27億美元買下了Pivotal，在VMworld第一天，VMware終於發表了第一款K8s新產品Tanzu，可以用來管理多雲跨雲架構下的K8s叢集。
VMware去年大砸5.5億美元下了K8s專案兩位創辦人Joe Beda和Craig McLuckie創立的Heptio新創，不只買下了一套跨雲K8s平臺，也擁有了K8s社群意見領袖。今年7月則收購了AI跨雲部署管理工具BitFusion.io，以及行動AI引擎新創Uhana，來強化對企業AI應用市場的布局。 8月更是大採購，除了買下無伺服器安全新創Intrinsic和網路安全新創Veriflow之外，又花了21億美元買下另一家網路安全公司Carbon Black，以及今年最大宗併購，以27億美元買下Pivotal。 這幾起併購，可以看出VMware快速從跨雲大規模部署、安全管理與治理、新興AI應用需求，來搶攻K8s市場的企圖。 
就在VMworld第一天，VMware終於揭露了第一個新的K8s產品線Tanzu，第一個產品就是VMware Tanzu Mission Control（Tanzu任務控制器）預覽版，可以透過單一控制機制，來管理部署在各地的K8s叢集，包括了vSphere、公有雲，代管式K8s服務或甚至是企業自行建置的客製的Kubernetes。不只可以直接瀏覽這些叢集，也可檢視叢集的容量，來進行備份和安全性配置等管理。
VMware強調，Tanzu將利用開源軟體來打造，尤其關鍵技術是利用K8s的Cluster API來串連K8s平臺，提供K8s叢集的全生命週期管理機制。另外，Tanzu可以整合到Bitnami應用程式市集，快速部署預先打包的K8s應用。可透過Sonobuoy來驗證和控制所部署的K8s配置，確保部署的正確性。可透過VMware自家跨雲效能監控平臺CloudHealth來進行優化，或是改將K8s叢集的資訊整合到VMware雲端監控服務VMware Wavefront上，提供一站式的視覺化監控管理。目前也可搭配Heptio的備份或備援工具Velero，或結合Heptio的ingress控制器contour來進行大規模K8s叢集的存取控制。
Tanzu任務控制器管理畫面也正式公開了



",https://www.ithome.com.tw/news/132646,"新聞,VMware,K8s,VMworld,Tanzu,Kubernetes"
132624,9,2019-08-26,Google：全球DevOps菁英績效企業數量從7％上升到了20％,"DevOps達到菁英績效的企業，比例已達20％，其程式碼部署次數比起低績效企業，多了208倍，故障恢復速度快2,604倍"," Google對採用DevOps企業進行分析，發布了最新的2019年報告Accelerate State of DevOps，調查自全球超過31,000名專業人士，並且已經進行超過6年的研究，這是目前最具規模且執行時間最長的DevOps報告。
比較2018年與2019年的報告顯示，DevOps已經跨過了發展鴻溝，各行各業中的DevOps菁英績效企業（Elite Performer）數量是去年的3倍，也就是說，表現良好的組織，仍然持續提升他們所擁有的DevOps專業知識，使其DevOps績效達到卓越。整體來說，低績效企業（Low Performer）的比例降低，中績效企業（Medium Performer）的比例則是上升，Google表示，中績效企業有部分來自低績效企業，而有另一部分則是從高績效企業（High Performer）降級。

事實上，Google在2018年，先定義了菁英績效企業這個詞，作為高績效企業中的一個子群，而今年將其獨立出來。菁英績效企業比起低績效企業，在生產方面，平均程式碼部署次數多了208倍，從程式碼交付到軟體部署的速度快了106倍，而在穩定性上，從意外故障事件復原的時間，菁英績效企業比低績效企業快了2,604倍，而且其程式碼變更失敗率為七分之一。

在Google調查的這些企業，其中有80％，主要的應用程式或是服務架構在雲端平臺上，菁英績效企業有更高的比例使用雲端技術，以獲取快速縮放規模及可靠性等優勢，而且DevOps績效最好的團隊，其在NIST所定義的5項雲端運算能力的表現，是DevOps績效最差團隊的24倍。
基本上，NIST定出的5項標準，包括：按需自助服務、網路存取、資源池、快速彈性，以及可測量的服務，Google提到，只有29％的雲端使用者符合NIST的5項標準，而這解釋了為何不少企業組織雖然使用雲端技術，卻沒有享受到雲端技術所帶來速度與穩定性優勢的原因。
Google還進行了額外的研究，分析DevOps績效在產業類別與規模的關係。結果顯示，雖然DevOps表現最好的產業是零售業，但沒有證據顯示是因為產業特性造成的，實際來看，所有的產業，包括金融服務和政府等受高度監管的組織，都可以實現良好的DevOps成果。
不過，企業的規模的確會影響DevOps的效能，因為，在組織人數超過5,000人的時候，DevOps成效會比員工數少於5,000人的企業組織還低。Google推論，這樣的結果，可能來自於重型處理程序（Heavyweight Process），以及緊耦合基礎架構（Tightly Coupled Architecture），所造成的延遲與不穩定性。然而，Google表示，企業不要以此當作DevOps績效不好的藉口，應該著手尋找可持續改進效能的方法。
",https://www.ithome.com.tw/news/132624,"新聞,google,DevOps,雲端"
132623,9,2019-08-25,Container周報第111期：如何撐起2千億次貼圖，Pinterest公開關鍵K8s平臺自建經驗,Pinterest開發了數千個各種服務機制，包括了需要單一CPU的微服務，也有靠大型VM執行的大型應用，另外還有跨不同框架的多種批次作業處理，可以打造一套通吃這些環境的K8s平臺，正是他們最大的挑戰," 精選8/15~8/21重要Container新聞，非看不可
#CRD、#部署自動化、#基礎架構設計支撐2千億次貼圖的關鍵，Pinterest公開K8s平臺自建經驗
3億用戶在圖片分享平臺Pinterest上標記了2千億次圖片。為了支撐龐大用量，Pinterest開發了數千個各種服務機制，包括了需要單一CPU的微服務，也有靠大型VM執行的大型應用，另外還有跨不同框架的多種批次作業處理。這些運作需要大量CPU、記憶體和I/O。
為了兼顧開發生產力、基礎架構效率和服務可靠性，Pinterest決定採用K8s來打造自家的基礎架構。不過，為了讓K8s平臺可以滿足上述的複雜需求，Pinterest維運團隊決定大量利用K8s的CRD（Custom Resource Definitions，客製化資源定義）功能。他們解釋，CRD有三大好處，一是可將不同類型的原生K8s資源打包成一組，方便再利用。二是可內建應用程式必要元件和基礎配置，開箱立即可用，讓應用程式工程師更專注於業務邏輯。最後一點是，透過CRD控制器，可以進行原生資源生命周期管理，讓資源利用情況更佳透明化。
另外，Pinterest還設計了一套AP自動部署流程，再依據不同的自動化任務的類型，來設計了一套自己的CRD（客製化資源定義），例如有用來管理批次作業任務的PinterestJobSet CRD，或是用於TensorFlow和Pytorch任務的PinterestTrainingJob CRD，或像適用來建立無態應用的PinterestService CRD。如此一來，就可以在呼叫一項AP任務時，就可以自動套用對應的CRD來完成K8s的配置。
#Istio、#服務網格Google接露開源服務網格平臺Istio下一步API方向
用於大規模微服務管理的服務網格平臺Istio是Google打造混合雲產品Anthos的核心元件之一，最近兩位Google工程師最近在Istio官網接露了新的API設計方向。Istio專案目標是打造一套穩固又強大的服務對服務網路元件，目前已有一套機制，方便開發團隊來對應架構、工作負載和服務運作限制之間的關係。過去，Istio的API設計，是從整體維運架構上的方便組合性、抽象化和彈性來設計，未來要轉而以使用者導向的抽象化方式來設計，也就是讓不同使用者可以用簡單的方法，做到複雜的管理和配置。因此，下一步，Istio的API將聚焦在不同權限角色的功能。例如資安管理者可以簡單地將資安命令套用在一組服務網格上，或者維運人員可以方便地套運流量管理命令等。
#叢集管理、#工作負載視覺化K8s叢集管理新工具，VMware開源了Web版K8s應用儀表板
從VMware今年開始加速布局K8s，最近開源釋出了一款Web版K8s叢集管理儀表版Octant，可以從開發者角度，來檢視單一K8s叢集中所有應用程式的執行情況。Octant提供了一個Web儀表板，可以透過視覺化的方式，來呈現應用程式所用的資源和物件之間的關連。不過，不同於K8s原有儀表板功能，Octant可以在主機本地端執行，而且直接使用自家K8s憑證來存取K8s的叢集，來降低安全風險。另外，Octant特色之一是即時監控CRD（Custom Resource Definitions）物件的狀態，也可自訂不同的CRD資源檢視方式，方便管理。另一個特色是，Octant設計了一套外掛系統，未來可以提供給第三方廠商開發擴充工具，將更多資訊整合到Octant儀表板上。目前Octant在GitHub上釋出了0.6版。

#Pivotal、#VMwareVMware正式收購Pivotal
先前VMware才傳出要收購Pivotal，已經展開了對外部流通普通股的股權收購計畫。就在VMworld舉辦前幾天，VMware也正式宣布併購了Pivotal。VMware指出，Pivotal 是VMware長期合作夥伴，雙方經常合作為企業提供應用開發和基礎架構的技術。VMware董事會將持續評估此事，但不保證收購案一定會發生。VMware目前力推的K8s產品，就是來自Pivotal打造的PKS，先前VMware營運長Sanjay Poonen更預告，會將K8s內建到自家vSphere產品中，今年8月底就會公布細節。近年VMware積極透過併購來搶進K8s市場，趁勢將Pivotal團隊納入，也是一種快速強化K8s產品整合的作法。
#Anthos、#Jenkins老牌CI/CD工具Jenkins將整合到Google混合雲軟體Anthos
最近Jenkins開發商CloudBees宣布，將與Google結盟，將Jenkins和Jenkins X的持續整合和持續派送機制，整合到Google的混合雲產品Anthos中。Jenkins X本來就是專門鎖定Kubernetes應用的CI/CD平臺，而Anthos也是以K8s為核心，可以跨公有雲和企業內部環境的跨雲平臺。
#容器持久儲存、#NetAppNetApp跨足容器服務應用，可橫跨多種雲端服務部署K8s叢集
最近，NetApp在臺舉辦的INSIGHT 2019 Taipei大會上，揭露了更多NetApp Kubernetes Service（NKS）的現況。NKS是一套SaaS雲端服務，並且是針對混合雲與多雲部署環境的Kubernetes上游服務（upstream K8s），能讓用戶透過NetApp Cloud Central的網頁入口介面，在指定的雲端服務環境裡面，直接建立具延展性且支援生產環境使用的Kubernetes叢集，並享有集中管理的機制，可在此控管Kubernetes生命周期。NKS可支援AWS的EKS、微軟AKS，以及GCP的GKE，以及從今年6月開始支援NetApp自家的超融合基礎架構系統，也就是NetApp HCI。NKS也預裝了NetApp發展的開放原始碼軟體Trident，可以針對容器環境，提供動態調度持續性儲存（persistent storage）的功能。

 
#AirShip、#雲端自動部署、#K8sAT&T找來戴爾科技聯手，加速發展新版跨雲自動部署平臺AirShip
去年初，AT&T、韓國SK電信和Intel聯手發起了一個雲端自動部署平臺計畫AirShip，要打造一個可以通吃傳統虛擬化、雲端環境、容器環境的框架，今年4月推出了1.0正式版。但是，這個框架未獲得重視，只在電信圈流傳。AT&T最近決定，找來戴爾科技，聯手打造下一版AirShip，還要整合Kubernetes到AirShip中，成為可自動部署和管理的支援環境。另外，也會強化AirShip在戴爾基礎架構的支援。雙方開發團隊初步將聚焦於開發Metal3-io、OpenStack Ironic套件和Kubernetes Cluster API的整合工作上。
責任編輯／王宏仁
更多Container動態
整合K8s、HCI與SDN，思科推出企業級容器應用平臺
微軟買下Java效能最佳化工具jClarity
Sylabs正式推出容器加密安全工具Singularity Enterprise

＠資料來源：iThome整理，2019年8月
",https://www.ithome.com.tw/news/132623,"新聞,Pinterest,K8s,CRD,Istio,VMware,Pivotal,IT報告"
132540,10,2019-08-21,被HTTP/2漏洞拖累，Kubernetes釋出安全更新,因為K8s採用的Go語言受到HTTP/2漏洞波及，K8s官方在Go完成修補更新後，同步釋出新版K8s," Netflix、Google及CERT/CC在日前揭露了攸關HTTP/2實現的8個安全漏洞，本周容器管理專案Kubernetes指出，用來打造Kubernetes的Go語言，受到其中兩個漏洞的波及，也讓Kubernetes遭蒙池魚之殃，導致所有版本都受到相關漏洞的影響，可能造成服務阻斷。
HTTP/2為新一代的HTTP傳輸協定標準，它是該協定自1999年發布HTTP 1.1之後的首個更新，但近日卻被發現含有從CVE-2019-9511～CVE-2019-9518的8個安全漏洞，所有的漏洞都可能導致服務阻斷（DoS），相關漏洞影響了部署HTTP/2的業者或服務，包括Go語言在內。
K8s貢獻者、亦為AWS系統開發工程師的Micah Hausler本周指出，Go語言的net/http函式庫存在著CVE-2019-9512與CVE-2019-9514兩個安全漏洞，造成任何基於HTTP或HTTPS接聽器的程序發生服務阻斷，而且波及K8s的所有版本及元件。
Go已經釋出Go1.12.9與Go1.11.13來修補這兩個漏洞，而K8s則是基於Go的修補釋出K8s v1.15.3、K8s v1.14.6與K8s v1.13.10，Hausler建議K8s 用戶應儘快升級到最新版本。
",https://www.ithome.com.tw/news/132540,"新聞,Go,HTTP/2,漏洞,Kubernetes,K8s"
132505,10,2019-08-20,Container周報第110期:第一個Mac平臺的Kubernetes容器調度軟體來了,Orka基於Docker和Kubernetes技術在Mac上的虛擬層，用戶可以在macOS上的虛擬機器，使用原生Kubernetes指令管理容器," 8/9~8/15精選容器新聞
#MAC平臺、#Docker、#Kubernetes第一個Mac的Kubernetes容器調度解決方案Orka亮相
企業級Mac雲端基礎設施供應商MacStadium推出了Orka（Orchestration with Kubernetes on Apple），這是基於Docker和Kubernetes技術在Mac上的虛擬層，用戶可以在macOS上的虛擬機器，使用原生Kubernetes指令管理容器，MacStadium提到，Orka是第一個Mac的Kubernetes容器調度解決方案。Orka為Apple硬體建構新的虛擬化技術，並且使用標準雲端排程工具。官方提到，任何版本的macOS，都能在數秒鐘啟動虛擬機器，之後交由Kubernetes叢集調度這些Pod，讓Apple開發人員也可以應用，與其他平臺相同的容器管理方法。由於Orka基於Kubernetes技術，因此也支援KubeCTL、KubeDashboard和Autoscaling等標準工具的存取。
#Hyper-V、#VM安全微軟8月大修補93個漏洞，29個重大漏洞中有兩個專攻Hyper-V
微軟在今年8月的Patch Tuesday修補了93個安全漏洞，並有29個被列為重大（Critical）漏洞，包括微軟特別提出警告的CVE-2019-1181與CVE-2019-1182，以及最新剛被公開披露的HTTP/2漏洞。其中，有16個與Windows有關，12個與繪圖元件有關，9個與腳本引擎有關，7個與Hyper-V有關，7個與RDP有關，與Windows核心及Office有關的漏洞各有6個，另有5個與HTTP/2有關。尤其是，列為重大等級的安全漏洞中，有兩個與Hyper-V有關，它們分別是CVE-2019-0720與CVE-2019-0965，它們都允許駭客透過Guest OS於Host OS上執行任意程式。
資安專家推測，不久的將來應該就能看到各種開採RDP漏洞的攻擊程式在市場上流竄。上述4個RDP漏洞都可能發展成蠕蟲式攻擊，亦即它們能自行複製並散布至其它系統，其它的蠕蟲式漏洞還包括位於DHCP客戶端的CVE-2019-0736，存在於LNK的CVE-2019-1188，藏匿在Word中的CVE-2019-1201，或是Bluetooth Classic的加密金鑰協商漏洞CVE-2019-9506。

#RDP、#VM安全資安研究人員踢爆：微軟忽視RDP漏洞直至察覺它影響Hyper-V
Check Point的安全研究人員Eyal Itkin最近踢爆，他們在去年10月曾向微軟提交一個遠端桌面協定（Remote Desktop Protocol，RDP）漏洞，但當時微軟不以為意，一直到微軟察覺該漏洞危及Hyper-V，才申請了CVE-ID漏洞編號並於今年7月修補。Hyper-V中有一個增強工作階段（Enhanced Sessions）模式，啟用後可重新定向本地端的裝置與資源，還具備了剪貼簿同步功能。Itkin發現它此一同步功能的設定介面與RDP一模一樣，而且可用同樣的腳本程式開採，但這卻是一個因RDP漏洞而起的Hyper-V guest-to-host虛擬機器逃逸漏洞（Hyper-V guest-to-host VM escape）。


#無伺服器、#GCPGCP大數據分析整合無伺服器應用更容易，Cloud Functions可以直接整合BigQuery了
Google為即時分析Cloud Storage中的資料，提供了一個新的途徑，用戶除了可以使用Cloud Dataflow進行複雜的資料串流處理之外，現在還可以使用無伺服器服務Cloud Functions，以函式自動地將資料串流到BigQuery，進行快速分析。相較於能夠用來處理複雜ETL工作以及大型資料集的Cloud Dataflow，Cloud Functions相對來說更為簡單靈活，除了能適時縮放運算能力，適應需要處理的資料量外，用戶還能以Cloud Functions自定義功能，執行像是使用Cloud Firestore資料庫等其他任務。
#CI/CD、#GitHubGitHub Actions完整支援CI/CD，免費公開儲存庫也可用
GitHub更新工作流程自動化平臺Actions，現在進一步完整支援持續整合和持續交付功能，而GitHub Actions支援的作業系統也從Linux，擴展到了macOS和Windows，支援的語言和框架包括了Node.js、Python以及.NET等。新提供的矩陣建置（Matrix Builds）功能，讓軟體開發團隊可以同時測試專案中的多個版本，以實現工作平行化減少測試時間，而在測試任務的安排上，GitHub也可以自動從現成的CI/CD池中，挑選並建議相關的工作流程。正式版預計會在今年11月13日上線。
未來Actions的更新，將會提供給使用者自託管的執行程式（Runner），當開發者在自己的資料中心執行虛擬機器，或是在雲端上運作的實例，開發者可以自己安裝Actions執行程式，同樣也能以簡單的方法自動化工作流程。

#高效能運算、#AzureAzure推出高效能運算應用專用的HBv2虛擬機器系列，效能是前一代的4倍
微軟推出Azure第二代HB系列虛擬機器HBv2，專為高效能運算應用設計，提供高階的硬體設備，微軟也發布經最佳化的預建置的CentOS映像檔，讓開發者能以HBv2最佳效能執行工作負載。
HBv2虛擬機器搭載120個AMD EPYC 7002系列CPU核心，每個CPU核心搭配4GB記憶體，因此整體擁有480GB記憶體，而HBv2的記憶體頻寬高達50GB/sec，約是x86的150％。每個HBv2可以提供雙精度4 teraFLOPS的效能，單精度則能有8 teraFLOPS，而這樣的效能是第一代的4倍。
API管理、微服務安全、ApigeeApigee API新增安全報告功能，助企業評估API服務安全性
Google在Apigee API管理平臺新增了API安全報告功能測試版，除了讓企業可以確保API服務符合安全法規之外，還能透過分析用戶行為，即時保護用戶敏感資料，而當API發生安全事件時，也能快速地診斷問題發生位置。
不少企業使用API作為連接關鍵應用程式的標準，營運團隊需要隨時監控並維護API服務的運作狀況，避免在內部或是外部遭到濫用，而現在Apigee API管理平臺加入的安全報告功能，其主要具有3項核心功能，包括安全法遵、資料保護以及診斷功能。

責任編輯／王宏仁
更多Container動態
台灣大哥大和VMware、數位通聯手推出運算雲Plus，搶攻企業上雲需求
Google擴充Compute Engine虛擬機器類型，推出N2、C2和M2系列測試版
AWS獨立各服務PowerShell模組，以減少模組載入時間
Slack釋出新的企業管理功能

＠資料來源：iThome整理，2019年8月
",https://www.ithome.com.tw/news/132505,"新聞,容器周報,Orka,Docker,K8s,Hyper-V,VM安全,IT周報"
132407,10,2019-08-13,Container周報第109期：K8s第一份第三方資安稽核報告出爐！Knative滿週年使用數據大公開,在第一次K8s稽核報告中發現，仍有不少部署政策安全性不足，甚至直接預設使用不安全的TLS傳輸，有些命令列參數或變數容易外洩憑證、機密元件命名缺乏Log記錄、沒有預設開啟Linux核心的seccomp安全機制等。最後，稽核小組公布了一份Kubrnetes資安白皮書和威脅模型," 精選7/26~8/8重要Container新聞
#CNCF、#資安稽核
找第三方來查！CNCF公布第一次K8s資安稽核報告
為了強化Kubernetes核心元件的安全性，CNCF從一年前組成了資安稽核小組，主要負責人來自Google、Salesforce、紅帽和Inguardians。他們開始規畫用第三方資安稽核工具，來檢查K8s核心工具或重要相關專案的安全性，並計畫定期公布檢查結果，作為專案維護團隊的改進參考。第一批完成資安稽核的專案包括了CoreDNS、Envoy和Prometheus。
資安稽核小組從6個項目來檢查這些專案的安全性，包括網路、架構拓樸、授權機制、驗證機制、機密控管、多租戶管理。在第一次稽核報告中發現，仍有不少部署政策安全性不足，甚至直接預設使用不安全的TLS傳輸，有些命令列參數或變數容易外洩憑證、機密元件命名缺乏Log記錄、沒有預設開啟Linux核心的seccomp安全機制等。最後，稽核小組公布了一份Kubrnetes資安白皮書和威脅模型，涵蓋對Kubernetes資安架構分析、威脅潛在來源，也提供了一套強化K8s資安管理的推薦作法。
#持續交付、#容器漏洞
GCP可以支援跨雲持續交付平臺Spinnaker，還可串聯容器漏洞掃描
現在GCP用戶能以更簡單的方法，開始使用由Google與Netflix聯合開發的跨雲連續交付平臺Spinnaker，Google直接在GCP整合中了Spinnaker，讓用戶可以擴充CI/CD工作管線，並在過程中彈性的客製化安全與法遵規範流程。Spinnaker整合了Container Registry的漏洞掃描功能，能盡早發現映像檔存在的安全威脅，另外，還加入Binary Authorization，以確保用戶最終部署的是受信任的容器映像檔，用戶也可以結合使用Stackdriver監控混合部署，掌握效能、應用程式健康度以及Spinnaker本身的狀態。
#服務網格、#Linkerd
服務網格框架Linkerd釋出2.4版，新增K8s服務網格介面標準的支援
CNCF旗下知名的服務網格框架Linkerd釋出2.4新版，這是比Istio更早推出的微服務管理框架。新版開始支援Kubernetes Service Mesh Interface服務網格標準介面（SMI）。SMI是微軟、VMware、紅帽、Docker等公司合推的服務網格標準，連Ubuntu作業系統官方Canonical都力拱的K8s服務網格標準，用來定義微服務在K8s上執行上，彼此溝通和交換資訊的共通標準。不過，Google力推的Istio尚未支援SMI標準。
#Serverless、#Knative
無伺服器框架Knative推出滿1年，最新使用數據大公開
Google發起的無伺服器框架Knative釋出一年了，這是Kubernetes專用的無伺服器框架，可將K8s上部署的容器轉換成標準的無伺服器服務，也是Google混合雲產品Anthos中的核心元件之一。Google也公布了釋出一年來的各項使用數據，目前包括GKE之外、Google Cloud Run、紅帽OpenShift、SAP Kyma、Pivotal的Function服務、IBM的ICK服務，以及其他共80家廠商，都正式支援Knative，來提供無伺服器功能或服務。目前版本只達到0.5，貢獻者超過400人，過去一年提出了3,700個程式碼異動請求，也反映出眾人對這個開源無伺服器框架的熱絡需求。
 
#開發工具、#Visual Studio
VS 2019釋出16.2正式版，揭露下一版支援容器應用更優化的.NET Core 3.0
微軟釋出Visual Studio 2019 16.2正式版，改進測試總管（Test Explorer），增加.NET開發功能，提升IDE可用性。16.2版中，MSBuild專案增加了預設Clang/LLVM支援，也為適用於Linux的Windows子系統支援增量建置（Incremental Build）。此外，也提升C++連結器的吞吐量，改善達最大輸入時的迭代建置時間，C++迭代建置時間可有數倍的提升。微軟同時揭露下一版的新特色，將支援對容器應用記憶體優化的.NET Core 3.0，改進Linux對Docker記憶體限制。
#D2iQ、#K8s自動部署
老牌容器作業系統Mesosphere大動作改名，跨大K8s和資料服務市場
微軟曾提議用1.5億美元併購遭拒的老牌容器平臺Mesosphere，最近大動作宣布重整品牌和策略，將公司名稱更改為D2iQ（發音為Day 2 IQ），並揭露未來戰略將聚焦在Kubernetes的支援和用K8s部署的資料分析工具市場，例如Cassandra、Kafka、Spark等大數據分析平臺的支援。
 
#容器部署、#IBM
IBM雲正式支援紅帽OpenShift
隨著IBM完成紅帽併購案，兩家產品整合腳步越來越快。最近，IBM宣布在IBM Cloud正式支援OpenShift，企業可以在IBM公有雲上運作OpenShift全託管服務，IBM提到，他們簡化了部署的程序，用戶只要點擊一個按鈕，系統就能自動開始部署工作，為企業提供混合雲端基礎設施。而現在OpenShift也能夠在IBM Z與LinuxONE企業平臺上執行，於用戶選擇的基礎架構上執行和管理原生雲端工作負載。相關的諮詢與技術服務，則繼續由紅帽認證的顧問團隊以及雲端應用程式服務團隊支援。
#容器安全、#AI
K8s資安工具Sysdig推出AI容器安全偵測技術
K8s資安工具Sysdig Secure在黑帽大會上推出2.4新版，增加了AI容器監控和安全政策新工具。2.4版新增Runtime即時剖析工具，另外可透過機器學習演算法來偵測有異常行為的K8s執行環境，以提早發現藏有惡意程式的K8s環境。另外，Sysdig也釋出新的安全政策工具Falco Rule Builder，可以快速建立不同Runtime的部署和管理政策和範本。

#GKE、#容器安全
Google App Engine雲端安全掃描工具，現在也能保護GKE
Google在2015年為增強App Engine弱點測試能力，所推出的雲端安全掃描工具，現在適用範圍擴展至GKE以及Compute Engine服務，當用戶使用Google雲端執行網頁應用程式，就能以雲端安全掃描工具分析其隱藏的弱點，偵測結果也會在雲端安全命令中心以及雲端安全狀態中顯示，供用戶以集中式儀表板監視漏洞狀態。雲端安全掃描工具預設關閉，用戶必需手動啟動這項功能，另外，Google還建議，可以搭配容器註冊表的漏洞掃描工具來掃描容器映像檔，以在部署至正式生產環境之前發現容器中的漏洞。
責任編輯／王宏仁
更多Container動態
Linus Torvalds親自廢除Linux軟碟機驅動程式
發行19年的微軟MSDN雜誌，將在今年11月停刊
Mac最新Visual Studio 2019版本8.2更新多種語言編輯器
＠資料來源：iThome整理，2019年8月
",https://www.ithome.com.tw/news/132407,"新聞,K8s,CNCF,Spinnaker,Knative,D2iQ,OpenShift,GKE,IT周報,Container周報"
132110,10,2019-07-30,香港第三方支付廠商AsiaPay進軍臺灣，要搶攻大型跨境電商交易市場,香港起家的AsiaPay，憑著客製化的第三方支付形式與多元服務，活躍於東南亞市場，近來，更要進軍臺灣、韓國與日本，目標大型跨境電商平臺推展服務。," AsiaPay是香港起家的支付服務平臺，自2000年成立以來，逐漸鎖定東南亞第三方支付的市場，為銀行提供支付網關服務（Payment Gateway），也為企業提供一站式支付平臺管理服務。近來，AsiaPay也開始佈局韓國、日本與臺灣，要憑著多元的服務型態進軍臺灣支付市場，已經合作的臺灣企業包括中國信託、台新銀行、OK超商等。
目前在亞太16國提供服務的AsiaPay，早期主要扮演第三方支付平臺的角色，提供支付網關服務來處理信用卡交易，提供相同服務的還有Paypal、Stripe、Braintree等跨境金流第三方支付商家。一般來說，當消費者向網路店家訂購商品時，會使用第三方支付平臺提供的帳戶，進行貨款支付，交易方式可包括信用卡支付或ATM匯款等；貨款支付後，再由第三方支付平臺通知賣家出貨，直到買方收到貨品及檢驗確認無誤後，第三方再將款項轉至賣家帳戶。。
後來，AsiaPay逐漸擴大業務，成為第三方支付解決方案、技術及服務供應商，提供企業客制化的一站式支付平臺管理服務。AsiaPay行政總裁陳永祥表示，企業要跨境運營，勢必會需要連結各國在地化的支付工具，但要在每個國家分析並串聯起支付工具的過程太繁瑣，所以企業可以將建立金流機制的整個業務打包，AsiaPay將提供客製化的解決方案，讓企業可以在一個平臺中管理收款、退款、管理風險，以及享有多元加值服務。
比如說，跨國企業要進軍臺灣，但不熟悉台灣在地的支付管道，這時，企業可以選擇要結算的收單銀行，以及支援的支付工具，AsiaPay就會建立起支付機制，串接從App到網站、手機到電腦、線上到線下的電子支付工具，甚至能開發前端交易網頁的頁面。而AsiaPay目前在臺灣合作的支付工具包括Line Pay，以及全家、7-11、OK、Hi-Life等超商的繳款功能，或以台新銀行作為第三方支付的網路轉帳服務，也在持續擴大合作夥伴。
其他平臺提供的多元功能，包括多種貨幣轉換的機制，能提供買家選擇不同種類的貨幣，並根據每日匯率即時轉換幣值，也支援多種語言的轉換；此外，也提供更多客製化選擇，如自訂分期付款的支付處理，也可促銷信用卡優惠、自訂優惠的條件和內容；甚至，支付網關前端更能與聊天機器人串接，直接從聊天機器人訂購商品也能跳轉付費頁面來繳款。

多元支付功能可分為六大類，包括區域覆蓋、反詐欺/安全性、交易處理、大數據、支付功能與渠道。

除了客製化功能，安全性的功能也至關重要，在支付網關服務中，AsiaPay提供信用卡資料代碼化（Tokenize），來避免交易風險，也提供防欺詐的交易偵測，當蒐集到的信用卡資訊不合常理，就會發出警示來提醒賣家。例如，有一筆訂單，從詐欺分析圖表中可以看見，線上刷卡的IP在臺灣，發卡銀行卻在菲律賓，手機網頁語言是泰語，送貨地址在馬來西亞，由此來評分得出這筆交易的風險較大，需要發送警訊給賣家來確認交易是否繼續進行。
陳永祥說明，早期的交易處裡分析報表，取得的數據可能包括交易時間、付款方式、卡號、付款貨幣、交易成功或失敗、IP位址等，但現在能取得的數據資料更精確，例如從IP位址可以得知下單裝置是手機或電腦、信用卡的種類是白金卡還是金卡、裝置上的語言設定等，有更多精確的資料可以納入分析，來找出具有詐欺風險的交易，但前提是在處理交易資訊時，並不觸碰消費者的個資訊息。
AsiaPay10月要推出數據分析工具，讓客戶能即時繪製市場分析報表
從去年開始，AsiaPay改採用雲端基礎架構，在確保資料在雲端傳輸或儲存均為加密狀態之下，將數據資料搬遷上雲，並應用其數據分析的功能來滿足即時繪製報表的需求，進而獲得管理上的洞察。陳永祥表示，採用雲端架構後，不再需要自行開發所有的報表，且長期來看能減少IT預算的投資，包括硬體基礎設施與維運人力的投入都會降低。
除了搬遷資料與改版後臺，接下來，AsiaPay還要整合雲端數據分析的功能，來提供客戶快速建置分析圖表的工具，讓非技術人員也能輕易上手，並以此作為產品來銷售，最晚10月底上線。陳永祥表示，這項工具會有權限管理的功能，讓跨國企業各個分公司能彙整各地數據上傳分析，總公司也能即時根據所有資料取得進一步的洞察，「讓企業理解每天、每個小時的交易，對比前一個禮拜的差異；還有線上線下、手機與互聯網的銷售分析；各國交易來源占比；成功率、失敗率多少，你可以很快的查出來，進而去擬定銷售戰略。」
此外，現有的交易風險評分的機制是AsiaPay自行開發的功能，未來，AsiaPay要進一步用雲端AI分析功能來偵測有風險的交易，包括詐欺與洗錢，將不同詐騙、洗錢等犯罪的態樣新增到AI分析功能，更即時的優化整個風控系統。
目前，AsiaPay的業務從線上的電商、旅遊為主，逐漸也擴大至線下零售與各種代收費的服務，並以東南亞為最大市場。陳永祥也表示，未來，也考慮跨足去中心化的區塊鏈場域，串接虛擬通貨電子錢包為付款工具，只是要等各國法規更完善，才能進一步的去開發應用。
",https://www.ithome.com.tw/news/132110,"新聞,第三方支付,AsiaPay,Oracle ADW,甲骨文,Cloud"
131903,10,2019-07-17,搶在VMworld前，VMware在臺預告下半年5大產品發表新方向,將推出一個多雲K8s叢集管理平臺，讓用戶通過單一控制介面，配置不同規格的K8s版本，於AWS、vSphere、GCP等不同的環境，且vSphere將可以管理容器。," VMware即將在8月底舉行年度大會VMworld，VMware營運長Sanjay Poonen上個月即在訪問中透露，VMware將會在大會上公布，自家vSphere產品的Kubernetes（簡稱K8s）新布局。近日，VMware也搶先在臺預告，更多未來產品發展的新方向。
在K8s布局慢了一步的VMware，過去一年，接續收購了容器技術廠商Heptio，及應用程式封裝公司Bitnami。例如VMware收購Heptio後，進而延攬了該新創的聯合創始人，也就是K8s專案3名創辦人中的2位，讓自身於K8s社群中的地位，急起直追競爭對手。VMware臺灣總經理陳學智表示，VMware目前在K8s社群的開源程式碼貢獻度上，僅次於Google，位居第二。這些併購瞄準的就是雲端原生應用市場，甚至，VMware自家新產品的開發已全面使用容器架構。
VMware 大中華區解決方案架構師淡成表示，微服務應用的崛起，帶來了基礎架構的挑戰，基礎架構希望更有彈性、更輕量級的部署，以及更快速的變更。K8s已經被視為是新的基礎架構標準。
其中，更有兩個值得關注的趨勢，淡成指出，第一個趨勢，基礎設施和應用層正在融合，不管是PaaS、DevOps、雲端原生架構等，可看到應用能驅動基礎設施來進行管理。另外，過去，基礎設施層僅提供基本的運算、儲存、網路等資源，現在，還需提供應用所依賴的服務，像是數據服務、訊息服務、行動業務等，隨著越來越多服務逐漸轉移到該層，PaaS層有越來越厚的趨勢。
不過，過去由應用團隊或開發團隊維運K8s叢集的作法，開始遇到挑戰。淡成解釋，K8s需要管理底層的實體資源、儲存、網路等，應用團隊雖然可快速建立一個K8s叢集，但因缺乏對安全、網路的部署經驗，所以無法擴大管理規模。隨著，不同業務團隊都需要各自的K8s叢集，他認為，遇到多叢集管理議題，應由基礎架構團隊統一管理，這也是目前業界主流觀點，將K8s視為基礎設施來維運。
淡成表示，多數用戶建置微服務平臺都採用K8s，但每個用戶的架構有不同情況。經過觀察，VMware將用戶劃分為兩類，有些用戶的應用雖已採用微服務架構，應用DevOps、CI／CD等工具或技術，但是，基礎設施仍停留在傳統的架構，像是中國的電信業者。對於處在這個階段的用戶，淡成建議，應先推動機房現代化，將雲算、儲存等進行軟體定義化的工程。
另一類用戶，不僅應用已採用新型態的架構，基礎設施也已採軟體定義資料中心， 而許多金融業用戶就屬此類。淡成建議這類用戶，打造自身的PaaS平臺，來讓業務服務化，以做更多元的應用。
因為這兩類K8s應用的差異，淡成表示，VMware也鎖定不同K8s應用階段的需求，推出3種K8s產品，可將K8s串連VMware架構的儲存、網路和安全功能的VMware Enterprise PKS，以及與開源K8s百分之百相容的VMware Essential PKS，還有由VMware維運的Kubernetes雲服務VMware Cloud PKS。
VMware下半年將聚焦雲原生，有5大產品新方向
到了下半年，VMware的K8s產品布局還會有大進展，淡成在臺先透露了5項產品新方向。首先，VMware會推出一個新的管理平臺，可管理多雲K8s叢集，讓用戶通過單一個控制介面，配置不同規格的K8s版本，於不同的環境，不管是AWS、vSphere、GCP等，並提供生命週期、認證、策略下發、監控等功能。
其次，VMware會推出多雲環境的服務網格治理平臺和工具，而新服務和工具將基於Istio開發，可用來管理跨雲端原生微服務的應用。
第三個，是早前Sanjay Poonen已揭露的產品布局，VMware將融合容器與虛擬平臺。未來，用戶通過vSphere，將可以管理容器，同時，也可管理VM，並且vSphere將提供儲存、網路和安全的統一管理模式。
再者，VMware將在vSphere的環境中，提供雲端原生的儲存環境，換句話說，用戶可在vCenter中，管理容器儲存的狀態，打破現階段只能管理虛擬機的限制。透過vCenter，用戶將可看到虛擬機或容器儲存的運作狀態，以及儲存隸屬的應用叢集。
最後，VMware會把5月收購的Bitami旗下逾150個已標準化打包的開源軟體，整合至VMware Cloud Services上，方便企業快速套用來部署。
「K8s已經開始變得無聊，」淡成提到，從去年底開始，CNCF基金會的領導人便在不同場合中，重複提及此概念。他指出，這是因為K8s已經非常成熟了，對企業用戶來說，K8s開源版本的功能就可滿足需求，但他提到，運行K8s於企業環境時，仍有許多事情需要考量，包含叢集生命週期管理，還有安全、網路、儲存如何與現有應用介接，這些都並非功能性需求，而是需要建構K8s工具。這也將成為是8月底VMworld大會的發布重點。
",https://www.ithome.com.tw/news/131903,"新聞,K8s,微服務,VMware,容器,PaaS,服務網格"
131819,10,2019-07-12,AWS正式支援基礎設施即程式碼，用戶可使用Python與TypeScript自動配置雲端資源,用戶現在可以使用Python與TypeScript兩種程式語言，以基礎設施即程式碼的方法配置AWS基礎設施," AWS供開發者以程式碼定義雲端基礎設施的雲端開發工具包CDK（AWS Cloud Development Kit），現在Python與TypeScript已經進入正式版本，另外，Java以及.NET版本則仍在開發者預覽階段。
AWS在去年釋出CDK預覽，而現在推出Python與TypeScript兩個正式版，CDK是一款可擴充的開源軟體開發框架，讓開發者使用熟悉的程式語言，來配置雲端基礎設施。這種基礎設施即程式碼（Infrastructure as Code，IaC）的方法是最近才興起的概念，AWS提到，IaC是企業發展成功的DevOps實踐一塊重要的墊腳石，因為管理員和開發人員，將可以使用配置檔案，自動配置應用程式所需要的計算、儲存和應用程式服務資源。

IaC有許多好處，包括基礎設施和應用程式的程式碼可以存放在同一個儲存庫，在不同的環境、AWS帳號以及區域，維持可重複且可預測的基礎設施變更，而且發布基礎設施變更，也能使用與程式碼變更相同的工具，因此部署的工作也可以同時包括基礎設施更新，IaC甚至讓基礎設施管理，還能應用軟體開發最佳實踐，進行程式碼審查以及經常性微小變更部署。
用戶使用CDK，可以根據自己的需求定義元件，建置像是自有標準的VPC，或是使用AWS CodeBuild和CodePipeline工具，為自家的微服務建置標準的CI/CD工作管線，並簡單地進行共享。AWS CDK可以提升端到端的開發體驗，讓用戶可以在IDE中編寫AWS基礎設施程式碼，並獲得程式語言開發的功能支援，像是自動完成以及參數建議等。
AWS CDK提供用戶豐富的建構模塊（Construct），用戶可以用這些模塊建構出任何複雜度的結構，從S3儲存桶等單個資源，或是跨多個AWS帳戶與區域的多堆疊應用程式都可以。AWS CDK包含了兩部分，AWS CDK Toolkit以及AWS Construct函式庫，AWS CDK Toolkit提供了命令列工具，供用戶管理CDK應用程式，而AWS Construct函式庫則內含每個AWS服務的模組，像是API等資源，以減少用戶在整合各種AWS服務時的複雜度。
",https://www.ithome.com.tw/news/131819,"新聞,AWS,IaC,CDK,開發,基礎設施即程式碼,DevOps"
131526,10,2019-06-28,Container周報第105期：K8s專用OS釋出測試版了，而kubectl老漏洞沒修好又爆新風險,Talos不是通用型OS，而是專門用來部署Kubernetes的作業系統，從機器角度來精簡功能，而非人如何管理的角度，甚至還移除了SSH、Telnet功能等維運人員慣用的機制。," 6/20~6/26精選Container新聞
＃Talos、#ARM
K8s叢集專用作業系統Talos釋出測試版了，超級精簡連SSH功能都移除
Talos作業系統不是一個通用型的作業系統，而是一款專門用來部署Kubernetes的作業系統，最近終於開源釋出了測試版，帶修正臭蟲後就會釋出1.0。Talos是一個API架構的Kubernetes專用作業系統，雖然也是Linux系列的作業系統，但是移除了大量執行K8s時不需要的功能來簡化作業系統的執行負載，特別是從機器角度來考慮功能的精簡，而不是人如何管理的角度，因此甚至還移除了Console功能、SSH、Telnet功能等維運人員慣用的機制。這個版本還可以支援ARM處理器，因此可用於邊緣運算設備或低功耗環境。Talos類似CoreOS、RancherOS或Linuxkit都是容器作業系統，但Talos更為精簡。
＃容器安全、#Kubernetes工具
kubectl工具老漏洞沒修好，cp複製指令出包恐讓駭客偷換惡意程式進系統
K8s管理者愛用的命令列工具kubectl又出包了，一年前曾發現了一個路徑瀏覽漏洞（path traversal），編號CVE-2019-1002101，kubectl的複製機制也就是cp指令有漏洞，當從Pod複製檔案到用戶端機器時，可以趁機換掉用戶端環境中其他目錄中的檔案，恐讓駭客用來偷偷植入惡意程式。儘管當時Kubernetes和OpenShfit已經釋出了修補程式，但最近K8s產品團隊發現，這個修補程式卻造成了另一個漏洞，但這次是發生在一種內有symlinks連結的tar壓縮檔案，同樣會導致路徑瀏覽漏洞的出現（CVE-2019-11246），目前也釋出更新。

#Istio、#服務網格
SAP跨雲整合工具Kyma釋出1.2新版，整合新版Istio來強化串接外部服務網格的安全
Kyma是傳統企業商軟巨頭SAP開源釋出的跨雲整合工具，可以讓企業內部的K8s應用，更容易和雲端服務串接。Kyma採取事件導向架構設計，三大元件包括了應用程式連結器，可提供安全連線，也可監控和追蹤內部應用和外部服務的呼叫情況，第二個Serverless元件，可讓外部系統也能透過API呼叫內部應用。第三項功能則是服務目錄，可串接公有雲業者的雲端服務或部署在上面的應用。新釋出的1.2版中，讓應用程式連結器元件改用Istio來取原有的Ingress Gateway，可用來強化與外部服務網格（Service Mesh）的連線安全性。
#Istio、#服務網格
VMware買下雲端容器應用派送平臺，繼續跨大混合雲布局
今年VMware接連併購，尤其鎖定混合雲架構和容器應用市場的布局，最新一起併購是宣布買下了可提供跨雲容器應用派送的新創公司Avi Networks，預計在VMware第二個財季也就是8月時完成併購案。Avi Networks主要產品是可以提供AP跨雲自動化派送，可支援AWS、Azure和GCP三大公雲，私有雲則可支援VMware和OpenStack。特別的是，Avi Networks另一個主力產品是容器應用的管理功能Universal Service Mesh，透過開源的服務網格平臺Istio，同時可管理微服務架構上的傳統應用程式和容器化應用，也可調度和管理Kubernetes和紅帽OpenShift上的容器應用。這兩大特性都是VMware今年持續強化的重點，混合雲和容器應用層管理。

#容器持續部署、#IoT部署
DevOps工具商JFrog企業版正式推出自家自動化部署引擎了
專攻IoT應用領域的DevOps工具商JFrog最近宣布自家企業版多了一項CI/CD自動化工具JFrog
JFrog今年2併購的Shippable，現在終於整合到自家產品線中，成為一個集中式的CI/CD部署服務，可用來調度從開發建置到正式上線的所有自動化部署任務。JFrog的DevOps工具不只可以部署原始程式碼，可支援如Docker容器映像檔、npm套件應用等，尤其可以透過網際網路來部署遠端IoT裝置上的程式，甚至最近還推出了可遠端持續部署自駕車系統的CI/CD工具。
#K8s App、#Prometheus
雲端供應商Platform9推新型K8s託管服務，直接託管常用K8s應用
雲端供應商Platform9推出不一樣的K8s託管服務，不是提供Kubernetes代管平臺，而是直接提供特定應用軟體的K8s託管服務，稱為Kubernetes Managed App服務（K8s應用託管服務）。目前可提供3種應用，包括Prometheus託管服務、EFK託管服務（也就是Elastic、Kibana和Fluentd三者一組的套裝應用）和MySQL的K8s託管服務。Platform9表示，可以提供到99.9％的SLA服務水準。
#深度學習、#容器部署
Google推深度學習容器，用戶能在本地和雲端建立一致的開發環境
Google推出深度學習專用的容器測試版，這是一個預先打包的容器，經過效能最佳化以及相容性測試，供開發者開箱即用，深度學習容器內含資料科學常用的工具包含Python 3環境，以及GPU用的Nvidia堆疊。深度學習容器提供多種版本，Google也為硬體最佳化了內含的TensorFlow，能用戶在GPU進行訓練，也可以在CPU上部署。深度學習容器可以自由地部署在GKE、AI Platform、Cloud Run、Compute Engine，甚至是Docker Swarm上。目前在深度學習容器初始版本，提供了TensorFlow 1.13、TensorFlow 2.0、PyTorch和R語言容器，Google接下來會補齊所有深度學習虛擬機器有提供的類型。
#版本控管、#JupyterHub
GitLab 12.0大改版，強化審核體驗以及相依項目管理
GitLab新版12.0有兩大特色，分別是視覺審核（Visual Reviews）以及相依項目列表。視覺審核透過自動搜集元資料，可以讓用戶快速提供高品質合併請求回饋，而相依項目列表，則會統一列出所有專案元件的相依項目，以方便進行漏洞管理。GitLab使用Kubernetes部署JupyterHub，以提供Jupyter Notebooks功能，讓用戶可以創建並共享包含即時程式碼以及視覺化圖形的文件，12.0版強化了與JupyterHub整合，，JupyterHub安裝到Kubernetes叢集的時候，會自動進行JupyterLab的Git擴充套件的配置，可以提供用戶完整的Notebooks版本控制，並能發送Git命令。
#GKE、#授權驗證
GKE應用程式存取其他雲端服務的驗證新方法
為了解決GKE應用程式連接到其他GCP服務，現行授權驗證方法存在的安全問題，Google為GKE用戶推出Workload Identity功能，透過建立Kubernetes服務帳戶和Cloud IAM服務帳戶之間的關聯，用戶能夠定義工作負載的身份，不需要管理Kubernetes機密資訊或是IAM帳戶金鑰，GKE應用程式就能自動地存取其他雲端服務。Workload Identity除了可以實施最小權限原則，讓所有工作負載僅具有需要的對低權限，當發生安全問題時，也能限制受到影響的範圍。
責任編輯／王宏仁
更多Container動態
Knative釋出0.7.0版，釋出序列API來強化事件功能
K8s管理者認證CKA現在可以提供3年認證了
螞蟻金服加入CNCF基金會成為金級會員
＠資料來源：iThome整理，2019年6月
",https://www.ithome.com.tw/news/131526,"新聞,服務網格,Talos,K8s,Istio,VMware,GKE,IT周報"
131441,10,2019-06-24,Google在臺揭露AutoML新功能，今年底還將正式推出BigQuery BI Engine,Google計畫於AutoML推出損失函數（Loss function）設定功能，也計畫將其大數據分析服務BigQuery BI Engine整合試算表，並提供進階BI功能和API功能，更計畫於明年初整合SQL介面。," Google上周五在臺舉辦Next 2019大會回顧，揭露數項AI和大數據分析產品的新進程，包括AutoML將推出損失函數（Loss function）設定功能，以及BigQuery BI Engine將整合試算表、提供進階BI功能和API，更計畫於明年初整合SQL介面。
AutoML為Google Cloud上的機器學習服務，目的是要減少開發機器學習模型時，使用者所面臨的資料詮釋困難，比如資料準備、特徵工程、架構選擇、調參數、模型評估等。
進一步來說，AutoML可自動化處理上述問題，包括建模前的資料和預期目標定義、分析輸入特徵等，在模型訓練過程中，還可自動進行特徵工程、模型選擇、調整超參數；模型訓練好之後，還會評估模型表現，並部署模型。在訓練階段時，AutoML會自動從Google的模型庫中尋找合適模型類型，比如線性模型、Feedforward DNN、Wide and Deep NN、GBDT、整合學習（Ensemble Learning）工具AdaNet等，其中，YouTube就是用Wide and Deep NN模型來進行使用者影片推薦。
雖然AutoML可自動訓練模型，但使用者仍無法手動進行細部的參數微調。Google Cloud雲端顧問Isaac Tsai表示，Google Cloud在與Google Brain的合作下，計畫將AutoML新增2大功能，第1是自動進行資料預處理，再來是Loss Function Selector，也就是說，將來使用者能進一步細部調整損失函數，可自行選擇損失函數或其型式。該功能的好處是，「當使用者做到98分，這個功能可幫助做到99分。」
然而，AutoML並非適合所有ML應用場域（如下圖，藍色為AutoML表現值），但AutoML好處是可以快速試錯。計價方式可分為3部分，在模型訓練（Training）部分以小時計算，預測部分（Prediction）則是以運算時數來計價，部署（Model Deployment）部分則是以使用的GB時數來計算。

此外，Google臺灣也於現場展示今年新推出的AutoML Tables。AutoML Tables是一套機器學習服務，特點是可用結構化資料，來簡單地建置客製化模型。AutoML Tables包括了6個步驟：輸入資料、選擇訓練目標、分析、訓練、評估、預測。其中，在分析階段，系統可顯示缺失的資料，以及資料間關聯性等；而預測階段則分為Batch Prediction和Online Prediction，皆能以API型式使用。
BigQuery BI Engine將發布正式版，也計畫整合試算表、提供API功能
BigQuery BI Engine是一套基於資料倉儲BigQuery的Google Cloud大數據分析引擎，特點包括了快速查詢、可橫向擴充，以及可即時串流寫入資料。BI Engine的架構簡單，因為建於BigQuery之上，只要使用現有儲存即可；不須管理BI伺服器、ETL工作流程等。
BigQuery BI Engine目前為Beta版，可免費使用至7月。Google Cloud客戶工程師Edward Chuang表示，BigQuery BI Engine將於今年第四季發布正式版（GA），也將整合試算表、提供進階BI功能和API功能，更計畫於明年初整合SQL介面。至於計費方式，他指出，Google預計今年第三季開始計費，計費方式分為隨選（On-demand）和定額（Flat-rate）。隨選最小記憶體使用單位為1GB，最大為10GB，每小時以美金0.0416/GB來計算；定額的計算金額則未揭露。
BigQuery ML新功能
BigQuery ML為Google今年5月發布正式版的機器學習服務，特點包括了不須搬移BigQuery中的資料，就能執行機器學習任務，此外，使用者只要透過SQL語法，就能完成機器學習任務，可加速開發過程。另一方面，BigQuery ML還能自動執行常見的模型訓練任務，比如整合特徵前處理和超參數調整等。
隨著今年5月GA後，BigQuery ML也新增了一系列測試中的功能，包括k-平均演算法（K-means clustering）、矩陣分解（Matrix factorization）、TensorFlow深度神經網路、特徵預處理，以及可匯入TensorFlow模型至BigQuery來進行預測任務等。
其中，TensorFlow深度神經網路為Alpha版，該功能可讓使用者選擇要用多少隱藏層或隱藏單元（Hidden units），或是dropout和batch_size參數的設定等。不過，Alpha版尚未提供自動調超參數的功能。至於匯入TensorFlow至BigQuery的功能，一樣為Alpha版，目的是要讓使用者用TensorFlow打造出非結構化資料的模型後，可至BigQuery進行預測。不過，Alpha版有2項限制：模型大小須為250MB，以及不支援RNN和LSTM。文◎王若樸
",https://www.ithome.com.tw/news/131441,"新聞,google,Cloud,AutoML,AutoML Tables,BigQuery,BigQuery BI Engine,BigQuery ML,機器學習,AI"
131315,10,2019-06-18,Container周報第103期:誤刪50節點K8s叢集為何3小時才能復原？Spotify揭自家事故幕後經驗,眼看著刪除指令關閉了一個又一個節點，問遍同事如何緊急停止這個刪除指令，「完全沒辦法阻止，只能重建叢集。」他坦言，後來Spotify足足花了3.25小時才重建了這個叢集。," 5/30~6/12重要Container新聞精選
#失敗經驗 #Spotify
誤刪50節點K8s叢集為何3小時才能復原？Spotify揭自家事故幕後經驗
線上音樂串流服務Spotify一位基礎架構工程師David Xia，在今年歐洲KubeCon大會上分享了自家Kubernetes叢集一次意外事件。擁有上億用戶的Spotify，旗下開發者高達1千人，經常要在上萬臺VM上部署程式碼。Spotify主要使用了GCP雲端服務，在雲端容器服務GKE上擁有3套生產叢集，分別負責歐洲、亞洲和美國，每小時會自動備份一次。
2018年11月時，有一次工程師為了測試GKE的新功能，新增了一個測試用的叢集，完成測試後，工程師要刪除這個測試叢集來節省資源，卻不小心刪除了負責美國區用戶的一個50節點的叢集。David眼看著刪除指令關閉了一個又一個節點，問遍同事如何緊急停止這個刪除指令，「完全沒辦法阻止，只能重建叢集。」他坦言，後來Spotify足足花了3.25小時才重建了這個叢集。
為何這麼久？重建過程中，他才發現，叢集建立Scrips有臭蟲，參考文件的內容不完整也不盡正確，導致他們設計的叢集建立程式，無法反覆使用。一個月，Spotify試圖將防止誤刪叢集的做法，列入自家的開發管理規範中，並採用了基礎架構管理工具Terraform來避免叢集部署的意外，但是，這又引發了另一起事故。這次是要將兩個現成叢集合併成一個新的叢集時，建立新叢集時因為權限不夠而失敗，工程師後來擴充了權限後才能執行。儘管合併工作順利完成後，卻導致Terraform誤判叢集需要異動，而刪除了整個亞洲區叢集，甚至連美國區叢集也一起刪除。
David表示，出錯難免，但失敗也要有因應計畫。後來，Spotify採取了3個因應對策，第一是執行K8s服務合併時，分批進行。第二是改變在K8s上登錄服務的作法，第三是建立K8s實例出錯時，可以快速由非K8s實例接手的備援機制。
#失敗經驗 #Datadog
SRE注意，要小心Kubernetes常見十大類問題
監控工具服務商Datadog兩位工程師Laurent Bernaille和Robert Boll在今年歐洲KubeCon分享了自家經驗中，管理Kubernetes常遇到的十種問題。Datadog投入Kubernetes專案超過2年多，自家服務也大力擁抱，最大規模的一個K8s叢集高達2千個節點，平均K8s叢集節點數也多有1,000～1,500之多。第一類問題是DNS管理問題，而且最常造成K8s事故的問題也多半是DNS問題。第二類常見問題則是任務啟動失敗而導致映像檔抓取失效。第三是kubectl命令列工具操作出錯。再者，應用程式Pod排程沒有考慮到新節點，Log檔10倍速度暴增塞滿儲存空間、大量副本和重製導致Pod失蹤、Cassandra叢集內有鬼（未預期的操作）、部署程序越來越慢、容器化過程出包、關超慢的Pod關閉過程（Termination）。他們提醒，要避免出錯得特別留意4件事，使用管理Pod的DaemonSet要小心，認清DNS管理向來很難，雲端基礎架構不見得很透明，最後則是容器不一定真的順利容器化了。

#GKE #雲端排程
Google正式推出雲端排程工作服務，GKE也能自動派工
Google正式推出其雲端託管的排程工作（Cron Job）服務Cloud Scheduler，使用者可以用Cloud Scheduler來觸發任何批次、大資料或是雲端基礎設施操作，而且這個功能不只可以在GCP上使用，還能從用戶本地端或是第三方資料中心來觸發目標工作。包括GCP容器服務GKE、Compute Engine、Cloud Run以及Cloud Functions等多項GCP服務，甚至可以是在本機端應用程式，都可以透過Cloud Scheduler來自動派工。更多報導
#Fargate #基礎架構管理
Pulumi開源基礎架構即程式碼框架Crosswalk，能簡化AWS各類部署工作
基礎架構即程式碼供應商Pulumi開源了一個可用於部署AWS工作負載的框架Pulumi Crosswalk for AWS，提供基礎架構即程式碼元件，並內建AWS最佳實踐，幫助用戶根據需求，將應用程式部署到AWS上。可支援多種AWS服務，包括無伺服器服務Lambda和API Gateway，還有容器服務ECS以及Fargate，以及像是熱門的Kubernetes服務EKS、跨網路的VPC和SecurityGroups，而監控服務Cloudwatch Dashboards與Alarms等都有支援。由於Crosswalk的模塊建構在AWS的原生功能模組之上，用戶可以自由地使用高階元件，或是使用低階平臺原語，也能根據需求混合使用。更多報導

#DevOps #Git
強化Azure DevOps程式碼提交機制，微軟釋出Multi-Cherry-Pick擴充套件
為了讓Azure DevOps開發者，可以更簡單地同時對多分支的應用提交，微軟釋出了PR Multi-Cherry-Pick擴充套件，該套件是使用git Cherry-Pick指令，能夠自動應用程式碼變更到多個分支上。擴充套件Multi-Cherry-Pick的名稱來自git指令Cherry-Pick，這是用來接受一個或多個現有的提交（Commit），並將每個提交的更改當作新的提交，應用到不同的分支上的操作。更多報導
#架構重構 #Kubernetes #IBM
IBM花2年改用K8s重新打造自家雲端平臺，部署上萬內部應用的現代化IT新架構首度公開
2年前，IBM展開了旗下雲端平臺產品的大整頓，不光只是重整品牌，還找來了20年前開發出IBM第一代SOA和Web產品的IBM Watson和雲端平臺首席架構師Andrew Hately，大力採用Docker、Kubernetes、Linux和Cloud Foundry，設計出全新的現代化IT架構。3年前，IBM開始研究跨雲管理架構，決定大力投入Kubernetes開源專案，2年前，IBM悄悄地展開了自家內部平臺的架構改造任務，甚至不惜重構自家雲端平臺，要將大部分的IBM軟體和雲端平臺，都搬上Kubernetes。IBM先從資料庫平臺開始著手改造，例如將天氣預測應用改部署到IBM雲上的Kubernetes環境中，後來更進一步擴大到所有的分析和AI產品，都轉而部署到Kubernetes環境上。Andrew Hately表示，去年終於完成了這個龐大的平臺重構計畫，除了用來管理基礎架構上運算、儲存和網路的控制臺程式，以及基礎架構的虛擬機器（VM）不是採用Kubernetes，IBM其餘的雲端服務，甚至內部所用的上萬支應用程式，幾乎全都搬上了Kubernetes。完整報導

責任編輯／王宏仁
更多Container動態
紅帽和容器儲存新創聯盟，要打造K8s上的HCI平臺
Information Builders分析軟體開始提供Docker映像檔安裝版本，方便用戶部署到公雲

＠資料來源：iThome整理，2019年5月
",https://www.ithome.com.tw/news/131315,"新聞,Container,失敗經驗,Spotify,Datadog,IT周報"
131210,10,2019-06-12,微軟為Azure DevOps釋出Multi-Cherry-Pick擴充套件,這個擴充套件可以簡化需要對多個目標應用提交的工作流程," 為了讓Azure DevOps開發者，可以更簡單地同時對多分支的應用提交，微軟釋出了PR Multi-Cherry-Pick擴充套件，該套件是使用git Cherry-Pick指令，能夠自動應用程式碼變更到多個分支上。擴充套件Multi-Cherry-Pick的名稱來自git指令Cherry-Pick，這是用來接受一個或多個現有的提交（Commit），並將每個提交的更改當作新的提交，應用到不同的分支上的操作。
Cherry-Pick指令使用時機很常發生，像是當某個開發人員提交並創建發布分支（Release Branch），而這個發布分支存在臭蟲，另一位開發人員為其創建修補程式分支，並提交了必要的更新，而為了確保其他分支不受這個臭蟲影響，就能使用Cherry-Pick指令，複製修補臭蟲的提交到其它分支上。
Cherry-Pick的指令並不是剪下貼上，而是複製的概念，因此要Cherry-Pick到其他分支的提交，會經過計算，為目標分支產生一個新的提交，原本修補程式分支上的提交，會依然存在。微軟提到，Azure DevOps本來就有內建Cherry-Pick功能，用戶可以直接從瀏覽器中，選擇拉取請求提交到新的功能分支（Topic Branch）上，但是當同時要應用多個提交到多個分支上，同時還要開啟新的拉取請求，則這個過程會相當麻煩。
因此微軟釋出了Multi-Cherry-Pick擴充套件，要來簡化這個過程， 用戶可以一次Cherry-Pick拉取請求的提交到多個分支上，而對於用戶選擇的每個分支，系統都會創建應用更新後的功能分支，當用戶在功能介面中勾選拉取請求選項，則會對目標分支（Target Branch）開啟拉取請求。
用戶安裝PR Multi-Cherry-Pick擴充套件之後，在上下文選單中現有的Cherry-Pick選項下，便會看到Multi-Cherry-Pick的選項。現在用戶從市集，就能安裝PR Multi-Cherry-Pick擴充套件，微軟提到，這個擴充套件是開源的，因此開發者可以在GitHub回饋或是提交功能請求。

",https://www.ithome.com.tw/news/131210,"新聞,微軟,Azure,DevOps,Git,開發"
130947,10,2019-05-29,收發232萬紅包最大挑戰是突發爆量，北富銀CIO揭露如何靠既有IT架構也能支撐新應用,台北富邦銀行資訊長蕭明輝揭露北富銀如何在舊有IT架構上，建構新的應用與平臺，並能讓基礎架構的資源保持快速且彈性的調整，同時還能保持後臺系統的穩定。," 台北富邦銀行（以下簡稱北富銀）2017年底與台灣大哥大攜手推出富邦M+旺紅包行銷活動，結合了通訊軟體M+ messenger，透過綁定北富銀帳戶，讓用戶使用手機收發紅包的服務。截至今年農曆年前，富邦M+旺紅包發送超過232萬個旺紅包，總金額達新臺幣12.1億元。
在面對FinTech的應用，北富銀舊有IT架構要如何建構新的應用與平臺，還能保持其彈性與穩定性，是一項挑戰。台北富邦銀行資訊長蕭明輝在一場活動中，揭露了自家作法。
蕭明輝解釋，銀行傳統架構有三層式，分別是前臺、中臺、後臺。前臺主要處理顯示給客戶的使用者介面（UI），後臺是產品系統，中臺是作為彼此之間的串接。過去，銀行這樣的傳統系統架構不易輕易變動，而得分析交易量成長，來決定何時啟動採購作業來擴充系統。例如CPU使用量超過80％時，才會啟動採購。
但，面臨FinTech的應用，尤其要推展新服務，過去靠採購來擴充的作法就遠遠來不及因應。蕭明輝指出，如北富銀旺紅包的行銷活動，有點類似電銷活動，會出現交易量突然爆衝的情況，風頭過了又回到原來的穩定交易量。
「IT在配合新服務時面臨的衝擊是，不能像過去那樣評估交易量。」他坦言，即便業務面已有預定的交易量目標，傳統IT不可能為了一場行銷活動，事先規劃採購量。
透過虛擬化讓資源能動態調整，充分運用
北富銀的作法有2點，一是基礎架構的資源，得保持快速且彈性的調整。比如說大型主機容量不足時，可以提升它的容量；而在非主機的形態，除非有特殊規格，否則都是走虛擬化。蕭明輝提到，虛擬化的好處是可以調整使用量，北富銀推虛擬化，主要就是為了充分運用它的資源。他也透露，北富銀目前在虛擬化的正式環境已達60％，測試環境則達85％。
對於現行架構未上雲的前提之下，要能夠符合FinTech交易形態的改變，整個資源要能夠動態調整，變得至關重要。蕭明輝舉例，北富銀在推展旺紅包時，一度有1萬人同時衝進來，這時前端進來的量越大，後端也要能調整資源，才不會發生爆量的問題。
二是如何保留後臺的穩定。蕭明輝提到，以銀行業來講，後臺的產品服務經過十幾年的淬鍊，交易功能穩定，但如何跟前臺的線上線下通路結合也是一大課題。為了因應新的服務形態，北富銀的策略是把後臺產品功能變更最小化，除了必要性的產品功能變更之外，他們把需要配合的彈性推往前臺去處理，讓IT能快速配合前臺調整使用者介面與客戶體驗，但後臺不會有大幅度的改變，以確保其穩定性。
而前臺與後臺的介接則是靠中臺，蕭明輝指出，北富銀在中臺建立ESB（Enterprise Service Bus，企業服務匯流排）進行串接。讓前臺不同通路進來的部分，用後臺同樣的服務來管，這樣一來後臺不用大幅度改變，便能維持穩定的服務。這就是北富銀在面對Fintech，採取的因應方式。
北富銀雲端策略
蕭明輝也進一步揭露北富銀在雲端的策略。他指出，銀行業相較於其他產業來說，在個人資料保護上相對嚴格許多，所以在雲端的應用上，也會有較多需要考慮的地方。但，他觀察到，在面臨未來生態圈概念的形成，銀行業非得走上雲端不可。
除了公有雲上有許多服務可以使用，蕭明輝提到私有雲的好處，主要是平臺化，加上資源能自動彈性調配。私有雲是在虛擬化的概念上，進一步把硬體轉換成資源池（Resource Pool），是一種IaaS（Infrastructure as a Service，基礎設施即服務）的模式。他表示，傳統的IT架構，未來可以走資源池的概念。
而以整個趨勢來看，蕭明輝也認為，銀行的基礎架構應該是要公有雲、私有雲與傳統架構並存，未來的銀行架構也會是多雲（Multi-Cloud）的時代。
他建議，在評估採用公有雲、私有雲時，重點是要評估後續如何維運，尤其是在金融業。第一，企業要把雲定位在哪，是IaaS、SaaS還是PaaS？又會應用在什麼地方。第二，維運的管理在評估時也要納入考量，例如資安的議題。
他舉例，採用外部的公有雲，得評估是否符合金融業內部資安的要求。此外，也要注重的是監控管理，外部公有雲如何與銀行的監控系統做結合，也是需要考量的部分。
「銀行評估怎麼運用雲之外，最重要是後面的維運。」蕭明輝強調，得把現行銀行本身的內部管理機制、資安要求、監控要求等，比照到公有雲上，包括他們可以提供的資安服務，能否與銀行的監控系統結合，都是企業在評估在公有雲上後續維運能否順暢的關鍵。然而，他也坦言，北富銀尚未導入公有雲，只是先行評估，目前在導入的部分是私有雲。
他也認為，銀行面對新型態的轉變，對內部組織會有很大改變。舉例來說，北富銀在3年前看到AI的運用，便把通路與使用者介面的人員整併成同一部門，也把數據的部分獨立成一個單位，布建大數據。另一個是，過去被動配合前端業務需求做事的IT人員，在未來的新型態，IT可能也要變成主動式，但這同時也是資訊部門與IT人員的挑戰。
",https://www.ithome.com.tw/news/130947,"新聞,台北富邦銀行,CIO蕭明輝,Cloud"
130763,10,2019-05-21,k8sBot讓使用者用Slack掌握Kubernetes狀態,k8sBot直接在Slack裡，為使用者提供Kubernetes中pod的狀態與日誌資訊," DevOps工具供應商ManagedKube在GCP市集推出了名為k8sBot的應用程式，使用者只要安裝對應的Slack小工具，就能從Slack監控雲端Kubernetes的狀態，透過k8sBot可以方便地讓所有團隊成員，快速地掌握Kubernetes的執行狀態。
k8sBot不只能提供類Kubectl工具能獲得的資訊，更重要的是k8sBot在Slack上提供簡單的介面，用戶只要使用滑鼠就可以取得pod狀態、日誌，以及故障排除建議，不需要記憶Kubernetes命令或是pod的名稱，ManagedKube提到，k8sBot代理會在使用者的Kubernetes叢集內執行，為使用者收集即時相關資訊，並透過Slack通知使用者。
k8sBot能夠以對話訊息的方式顯示Kubernetes中正在執行的每一個pod，使用者只要點擊pod右方的選項，就能取得需要的資訊，而DevOps團隊可以簡單地透過k8sBot產生的訊息進行討論，ManagedKube營運長Christie Lee表示，他們與Google雲端合作消除了存取障礙，才得以在k8sBot中提供Kubernetes的狀態。
",https://www.ithome.com.tw/news/130763,"新聞,Slack,Kubernetes,pod,DevOps,開發"
130158,11,2019-04-23,【舊金山Next直擊】122項Google雲端最新發布大整理（下）：AI、機器學習、生產力、生態系經營,Google今年在Next大會的發布涵蓋了基礎架構、混合雲、Serverless、DevOps、API管理、資料管理、網通、資安與驗證、聰明分析、Windows工作量上GCP、生產力與協作、顧客、夥伴關係，下半篇就從聰明分析、AI和機器學習新服務開始介紹起," 前半篇，請瀏覽【舊金山Next直擊】122項Google雲端最新發布大整理（上）：混合雲、無伺服器、資安三大重點
聰明分析
資料分析
48. Data Fusion雲端資料整合服務（Beta版），利用開源CDAP資料整合工具所打造的服務，是一款可將資料快速匯入BigQuery的雲端ETL前處理服務，支援上百種資料來源，包括Oracle、AWS和Azure資料源。不過，AWS和Azure也有提供類似的CDAP資料整合服務。
49. BigQuery DTS的SaaS應用連結器（Beta版），快速串接上百款SaaS服務的資料，不用寫任何程式碼。
50. Cloud Dataflow SQL服務（Alpha公測版），可用標準SQL建立批次或串流資料的通用分析流程。
51. Dataflow彈性排程服務FlexRS（Beta版），可排程執行Dataflow的批次資料處理任務。
52. Cloud Dataproc雲端服務支援自動擴充，可依據預先定義的擴充政策，自動增減在GCP上Hadoop和Spark叢集的節點規模。
53. Dataproc任務API新增Presto任務支援（Beta版），更容易用Dataproc API來進行不同資料源的Presto查詢任務。
54. Dataproc Kerberos TLC釋出Beta版，可在Dataproc服務上啟用 支援Kerberos驗證的Hadoop安全模式。
55. 推出BigQuery的BI引擎（Beta版），這是一個可即時分析BigQuery上資料的BI引擎，也能整合到第三方服務中產生互動式BI報表。
56. Google試算表服務增加新的「連結型試算表」（Connected Sheets），可以在試算表中連結BigQuery上的數據，將BigQuery上的限定資料，透過試算表分享給其他人。
57. BigQuery ML正式推出。用標準SQL語法就能在BigQuery內建立機器學習模型。可支援線性回歸、二元邏輯回歸、多重類別邏輯迴歸等。
58. BigQuery新增K-means集群分析ML功能（Beta版），同樣可用標準SQL來進行資料分群。
59. BigQuery新增TensorFlow模型匯入功能（Alpha測試版），可直接將現有TensorFlow模型匯入BigQuery，再用來快速建立新分類模型或預測模型。
60. BigQuery新增TensorFlow的DNN分類器功能（Alpha測試版），用標準SQL語法，就能來訓練或部署一個DNN模型，以便分類BigQuery上的資料。
61. BigQuery新增TensorFlow的DNN回歸器功能，可在TensorFlow中設計回歸模型後，再於BigQuery中用來產生資料的趨勢線。
62. Cloud Data Catalog服務（即將Beta版），這是一個資料集的集中管理和查詢平臺，可用來管理所有儲存在Google Cloud的資料集，或套用特定資料規範或資安政策。也可說是一款資料治理工具。
63. Cloud Composer資料流程自動化服務正式上線，這是一個Apache Airflow託管服務，可用來調度和排程分散於多雲或企業本地端的資料處理與分析任務。
AI與機器學習
64. AI Platform服務（Beta版），這是一個ML專案管理平臺，涵蓋ML專案從資料準備、模型建置、執行到維運管理等階段，支援群組角色控管。可將ML專案部署到GCP或本地端環境。
65. AutoML NL(自然語言)服務（仍是Beta版）新增特定產業分析模型（如生醫），強化其實體抽取和語意分析能力。
66. 新推出AutoML Tables（Beta版），可用分析結構化資料，自動建立ML預測模型。
67. AutoML Vision（仍是Beta版）強化物件辨識能力，可偵測影像中的多個物件，再以方框來定位。
68. 推出AutoML Vision Edge（Beta版），可在邊緣設備中部署AutoML Vision模型，進行即時處理。可支援Android與iOS裝置（ARM處理器皆支援）、Edge TPU和容器執行環境，可自動產生能在不同環境下執行的ML模型或容器應用。
69. 新推出AutoML Video Intelligence服務（Beta版），可自動建立客製化的影片特徵抽取模型，支援自動下標籤、自動辨識鏡頭型態等。
70. 推出文件理解AI（Beta版），可自動分析紙本文件的數位化圖檔，進行自動分類、抽取文件內容或轉換成結構化資料。
71. 影像產品搜尋API正式上線，可供企業在自家App中提供以圖找產品的功能，顧客拍攝或上傳圖片即可找出相似產品。
72. 大幅強化Cloud Vision API服務（Beta版），新增線上立即抽取PDF檔案、TIFF和GIF影像中的文字或提供註解描述，每次最多5頁。另提供離線（在雲端背景執行）批次註解大量影像，每次最多2千張。
73. 大幅強化Cloud NL API服務，新增俄文支援以及日文情感分析機制，也大幅強化了發票識別能力，可辨識電話、地址、日期、價格和數字。
74. 新推出第三代翻譯API（第三代仍是Beta版），可自訂字彙、專業術語來修正翻譯，也可非同步批次翻譯大量文字。可以匯入AutoML Translation訓練好的模型。
75. 大幅強化Video Intelligence API，上傳影片的物件追蹤功能、文字OCR功能正式上線，另外新增串流影片追蹤功能（Beta版），例如可追蹤影片中的物件、偵測特定內容、自動下標籤、偵測鏡頭切換等。
76. 發布推薦AI（Beta版）服務，只需提供產品目錄和使用者網站瀏覽行為資訊，即可自動建立個人化推薦功能，甚至可進行A/B測試。
77. 客服中心AI服務進入Beta版，可利用Google Cloud AI快速建立互動式客服中心，新增虛擬客服、真人客服小助手（自動提供參考資料）、自動判斷主題等，也和更多客服或視訊業者合作，如Avaya、Salesforce等。
Windows工作負載上GCP
78. 支援自帶微軟授權轉移上GCP使用，不用向GCP購買。
79. 日前併購了Velostrata串流遷移工具，已經可支援將VM搬上GCP的功能，幾周後會改版，可將指定實體主機上的Windows工作負載，自動遷移到GCP的單一用戶群節點上，還能自動套用現有微軟授權。
80. 即將推出微軟AD託管服務。將可在GCP執行AD，來管理雲端AD工作負載，自動維護AD伺服器，也能將企業內部的私有AD網域延伸到雲端環境。
81. Cloud SQL將推出微軟SQL Server託管服務，可支援到SQL Server 2017企業版，也可將現有授權轉移到雲端使用。未來會支援更多微軟環境，例如GCP將擴充Anthos混合雲部署能力到微軟環境上。
生產力與協作
G Suite
82. Google助理新增行事曆整合（Beta版），例如語音助理可以提醒下一場會議的時間和地點等。
83. G Suite擴充功能進入Beta版階段，在側邊欄新增最愛App存取清單，不用像過去得切換頁面才能打開不同App。
84. Google Search新增第三方軟體內資料搜尋（正式版但限定使用資格）。可以用Google Search來搜尋第三方軟體內的資料庫內容，如SAP產品、Sharepoint等。
85. 雲端磁碟新增後設資料功能（Beta版），管理員可對雲端硬碟中的檔案，增加更多類型或分類的後設資料，來強化搜尋。
86. Hangout Meet更新，增加即時自動字幕功能（正式版），即時串流影音將可公開釋出變成直播，單一視訊會議人數上限將提高到250人
87. 正式推出了G Suite的Google Voice網路電話服務。可透過AI技術來過濾垃圾來電或騷擾電話，也能自動將語音留言轉換成文字。
88. Gmail現在也能使用G Suite的Hangouts Chat功能了（Beta版），也可讓外部非Gmail用戶加入聊天對話中。
89. 可在G Suite直接編輯Office文件（正式版），包括Word、Excel和PowerPoint檔皆可線上編輯。
90. Google雲端硬碟新增了訪客共享功能（Beta版），可以提供一組密碼驗證機制，讓訪客也能共同編輯G Suite上的指定檔案。
91. Google+企業版改名為Currents（Beta版），類似Slack的群組討論和協作平臺。
92. G Suite企業版正式推出資料存取透明化控管機制（Access Transparency），可更進一步檢視雲端供應商存取企業資料的行為，如會列出Google員工在合約授權下，何時存取了哪些資料的記錄。包括因為維修需求、法遵規定，或是用戶提出的支援需求下，該員工採取了哪些操作。
93. G Suite資料區域功能強化，現在也可以指定備份資料的儲存區域，或是當特定人員轉移工作地點時，自動將其資料轉移到新工作地點的區域雲端中心中儲存。
94. 推出進階版釣魚和惡意程式防護服務（Beta版），新增加了可疑郵件隔離區、郵件附檔異常警示、可疑詐欺郵件警告。
95. 更新了G Suite的資安中心和通報中心功能，提供更多整合資訊。
企業級Chrome
96. GCP管理平臺新增了Chrome瀏覽器雲端管理功能，可以管理同一地點的所有Windows、Mac和Linux環境下的Chrome瀏覽器，來訂定和套用統一的政策。
顧客
97. 發行用戶案例書，涵蓋7大產業的40家GCP企業用戶。
98~108. ，新顧客應用案例，包括了澳洲郵政、貝克休斯油田、高露潔棕欖、柯爾百貨、麥卡遜醫藥公司、P&G、聯合利華、UPS、Viacom傳媒、惠而浦、Wix網站平臺。
夥伴關係
109~111. 新增加了4家將提供Anthos超融合設備的供應商：Cisco、Dell EMC、HPE和聯想。Intel也宣布支援硬體產品將支援Anthos。VMware的SD-WAN和服務網格功能也承諾將支援Anthos。
112. 公布開源策略合作夥伴，7大開源資料庫可在GCP內直接訂閱租用，提供單一帳單以及單一的支援窗口。
113~119. 與多家顧問公司、軟體公司、雲端供應商策略結盟，包括Accenture、Deloitte、DevOps產品整合（Atos和CloudBees）、Salesforce（整合客服中心AI）、Dropbox（整合G Suite）、Docusign（整合G Suite）、AI產品夥伴（Avaya、Genesys、Mitel、Nvidia、Taulia和UiPath）
120~122. 新增了3類合作夥伴（行銷分析專業、IoT專業、資安訓練專業），目前這3纇共有21家。另外，GCP將推出認證經銷商（MSP）的識別勳章，可供合格經銷商使用。GCP也照例在每年Next大會期間，公布了2018年合作夥伴大獎得獎名單，包括技術類、全球經銷類和區域經銷類的得主，今年有不少日本經銷商得獎，也反應出日本企業市場熱烈擁抱GCP的情況。
",https://www.ithome.com.tw/news/130158,"新聞,GCP,NEXT,google,Cloud,AutoML,AI,Machine Learning"
130154,11,2019-04-23,【舊金山Next直擊】122項Google雲端最新發布大整理（上）：混合雲、無伺服器、資安三大重點,Google今年在Next大會的發布涵蓋了基礎架構、混合雲、Serverless、DevOps、API管理、資料管理、網通、資安與驗證、聰明分析、Windows工作量上GCP、生產力與協作、顧客、夥伴關係," 每年Google雲端行銷副總裁Alison Wagonfeld都會總結今年Next大會中最重要的百項發表，今年也不例外，她一口氣彙整了122項重點發布，這也是一窺Google雲端今年戰略布局的捷徑。
去年Next大會有105項發布，涵蓋了顧客、夥伴、行動裝置與Chrome、AI和機器學習、基礎架構服務、應用系統開發、資料分析、資料庫、IoT、資安、企業協作與生產力、社會影響等，偏重產品導向的分類架構，也刻意將17家大型企業顧客放在最前面，來凸顯GCP真有大型企業採用。
今年GCP反而在大分類上刻意拿掉了熱門的AI和機器學習，改為聰明分析（Smart Analytics）這類更像傳統企業IT的用語。今年另一特色是更強調管理面向，而非產品面的發布。
GCP今年Next大會發布重點涵蓋了基礎架構、混合雲、Serverless（無伺服器）、DevOps/SRE、API管理、資料管理、網通、資安與驗證、聰明分析、Windows工作量上GCP、生產力與協作、顧客、夥伴關係。
順序安排上，雖然，顧客和夥伴關係放到最後兩項，但是，不像去年強調個別合作夥伴，GCP今年轉而強調夥伴關係和生態系。值得注意的，今年有幾項格外低調或沒有登場的產品，包括了去年引起話題的硬體產品Cloud TPU和Edge TPU（去年IoT戰略特色）和區塊鏈應用dApp，凸顯出GCP回頭聚焦軟體和服務。以下是今年122項新發布：
基礎架構
1.GCP再添2座新雲端營運中心，一座落腳韓國首爾（明年初啟用），另一座位於美國鹽湖城（明年上半年啟用）。GCP全球現有19座雲端營運中心，未來即將啟用的中心包括了日本大阪、印尼雅加達，以及剛公布的首爾和鹽湖城。
混合雲
2 .正式推出Anthos混合雲軟體產品（前身是Cloud Services Platform換新名）。可部署於雲端GKE服務或企業內部GKE On-Prem主機，未來也可部署於AWS和Azure等第三方雲端服務上。雖然Anthos已經是正式版，但GKE On-Prem仍是測試版。GCP也公布了30家軟硬體合作廠商，包括5家伺服器平臺業者Cisco、Dell、HPE、Lenovo和Intel。
3. Anthos Migrate自動遷移工具測試版。以GCP新併購的Velostrata技術為基礎，要來提供將VM自動轉換成Kubernetes容器化應用能力，等於是VM轉容器的遷移工具，再部署於Anthos上執行。不過，仍無法支援高負載或Windows環境的應用。
4. Anthos Config Management跨叢集管理工具。可透過集中式Git，來建立跨本地端和雲端的K8s多叢集管理政策，如RBAC角色管理、資源容量管理，配置檔可支援版本控管。
Serverless無伺服器
5. Cloud Run託管服務（Beta版）。可將無態的容器應用，部署到Cloud Run上自動變成雲端Serverless無伺服器服務，可支援任何語言，但僅支援單一核心vCPU和最多1GB記憶體，自動採用HTTPS，不支援VPC。
6. Cloud Run on GKE託管服務（Beta版）。GKE也將提供Cloud Run無伺服器託管服務的功能（相同API），但可擴大運用到GKE所支援的標準硬體，例如GPU。可支援VPC網路存取或GCE網路。
7. Knative無伺服器中介管理平臺發布。可用於管理部署在Kubernetes上的無伺服器應用，等於是無伺服器應用的中介軟體，也是Cloud Run的關鍵中介層。由Google和Pivotal、IBM、紅帽、SAP聯合開發，意味著這幾家的產品都會支援Knative，可將無伺服器應用部署到其他雲端平臺上。
8. 開源釋出FaaS框架Functions Framework。可將Node.js程式部署於Google Cloud Functions、本地端開發環境、Cloud Run或任何Knative環境中，等於可打造出一個通吃多雲混合雲架構的無伺服器架構（共同API），來強化既有Cloud Functions無伺服器服務，另外App Engine平臺也推第二代新版。
DevOps/SRE
9. 新推出Cloud Code開發外掛工具（測試版）。可讓常見開發工具直接部署、除錯Kubernetes上的雲端原生應用，甚至是管理Kubernetes叢集，也可將Cloud Build的DevOps流程串接到本地端IDE。目前支援微軟VS Code和IntelliJ。
API管理
10. Apigee hybrid混合雲API管理（Beta版）。可將Apigee API管理平臺部署到本地端或任何第三方公有雲上。
11. Apigee安全報表（Beta版），可提供API資安狀態的視覺化報表。
12. Apigee終於可以整合大量GCP服務，透過外掛可監控或存取如Cloud Function、Cloud DLP、Cloud ML引擎、BigQuery、Cloud Spanner、Cloud Pub/Sub等服務的API。
資料管理
資料庫
13. GCP將提供SQL Server託管服務（預覽版），Cloud SQL服務將可託管企業內部的微軟SQL Server工作負載，可支援到最新版SQL Server 2017。
14. Cloud SQL的PostgreSQL託管服務正式支援PostgreSQL去年底推出的11新版。
15. Cloud Bigtable的跨地區（region）副本功能正式上線，可以建立跨國的PB級NoSQL資料庫。
儲存
16. 新的低價歸檔雲端儲存服務，每GB每月價格僅0.0012美元，但資料存取速度仍可達毫秒級水準。
17. 雲端NAS檔案式儲存服務Cloud Filestore正式上線，支援NFSv3，最大IOPS為30,000。可支援GCE和GKE。
18. 地區永久磁碟服務4月底正式推出，可在同一雲端營運中心（Regional）中建立跨區域（Zone）的雙活磁碟副本。
19. GCP雲端儲存推出整套式資安政策（Beta版），可以建立共用的雲端儲存權限政策。
20. GCP雲端儲存支援Signature V4（Beta版）協定，可以讓同一支應用透過簽署過的網址，來存取不同的儲存資源。
21. 雲端IAM角色功能正式支援交易型服務。IAM權限可套用到交易任務的新增、存取、更新和刪除行為。
網通
22. 流量總管（Traffic Director）（Beta版），可用於大量微服務架構、服務網格架構的流量控管和SLA監控。
23. 高可用VPN即將推出Beta版，從企業內部到VPC的連線可靠度將達到99.99%服務水準。
24. 100Gbps等級的Cloud Interconnect服務，可直接從企業機房或和合作供應商機房的私有IP，提供高速網路直連。
25. 私人Google存取權正式上線，可指定私有IP來存取Google服務，支援大多數GCP服務。
26. 網通服務分級制。企業可選擇兩種不同等級的網通服務，便宜慢速的標準版（Standard），或高價高速的進階版（Premium ）。
資安與驗證
資安
27. 存取同意功能（測試版），可要求在存取GCP服務的資料或配置檔前，要先取得同意。
28. DLP資料外洩防護用戶端介面（Beta版），可透過簡單點擊，不用撰寫腳本程式，就能快速進行DLP掃描。
29. VPC服務控制功能正式推出，使用者可自訂GCP服務上機密資料的範圍，來限制這些敏感區域的資料存取行為。
30. 雲端資安中心（Cloud Security Command Center）正式上線，可以用來監控和管理GCP服務的各種安全狀態和事件。
31. 雲端資安中心新增「威脅事件偵測」（Event Threat Detection）計畫（Beta版），可偵測惡意程式、挖礦程式、外部DDoS攻擊等。
32. 雲端資安中心新增「資安健康分析」（Security Health Analytics）計畫（Alpha版），可自動掃描GCP基礎架構的配置安全問題，如儲存設定出錯、通訊埠曝光等
33. 可自動掃描漏洞的雲端安全掃描工具，正式支援App Engine服務，GKE和GCE支援則進入Beta版。
34. 八家資安夥伴提供更多GCP整合，包括Capsule8、Cavirin、Chef（法遵失效報表）、McAfee、Redlock、Stackrox、Tenable.io和Twistlock。
35. 雲端資安中心將支援Stackdriver事件回應和管理機制（即將Beta版）。
36. 容器儲存庫弱點掃描功能正式上線。
37. 二進位授權（Binary Authorization）功能正式上線，可在CI/CD系統的自動部署階段，確保部署的是正確的映像檔。
38. GKE沙盒功能進入Beta版。可利用開源gVisor建立容器的沙盒環境，避免容器跳脫（Container Escapes）攻擊。
39. GKE推出SSL加密憑證託管服務（Beta版），可管理GKE的ingress憑證。
40. 庇護式VM（Shielded VM）正式上線，可驗證GCE虛擬機器的完整性。
41. 智慧型政策功能（Alpha測試版），利用機器學習技術來自動管理資安政策。
42. 推出釣魚防護服務（Beta版），自動偵測可疑URL，確保網頁瀏覽安全性，可整合雲端資安中心。
43. 推出企業級reCAPTCHA驗證服務（Beta版），企業可用於防止可疑的網站登入行為，如程式自動登入。
驗證和存取管理
44. 脈絡式存取管理（Context-aware access）功能強化，目前為Beta版。新增BeyondCorp聯盟，加入的端點安全業者可將產品資訊整合到脈絡偵測引擎中。
45. Android手機內建軟體金鑰。Android 7.0版手機更新後可成為FIDO 2/WebAuthn標準的安全金鑰，不用額外購買金鑰硬體。
46. 雲端驗證服務功能強化，增加上千款App的單一登入機制（SSO），也可整合人資系統。
47. 身分驗證平臺正式上線。企業可在自製App中提供Google等級的驗證機制，做到類似Google服務的驗證機制。
 未完，請瀏覽【舊金山Next直擊】122項Google雲端最新發布大整理（下）
",https://www.ithome.com.tw/news/130154,"新聞,GCP,NEXT,google,Cloud,Anthos,Kubernetes"
130082,11,2019-04-19,【臺灣資安大會直擊】企業應用系統開發流程轉型更要納入資安，從系統管理、程式碼、政策框架做好DevOps安全,在強調開發與維運部門合作無間的開發流程進化過程中，資訊安全在其中占有重要的地位，中國文化大學推廣教育部資訊長陳仁偉認為，企業應該從DevOps系統管理和程式碼，做到架構層級的防禦，進而讓相關資安工作執行更為徹底。," 近年來應用系統開發的流程，可說是大幅變化，訴求整併開發與維運的DevOps，已經是大勢所趨，但在此同時，企業也面臨嚴峻的資安環境，因此，將資訊安全納入這樣的開發流程，相形變得更加重要。
如今，企業不光只是保護系統免於資安威脅，而是要將資安擴及DevOps的所有環節，從底層開始做起。在2019臺灣資安大會上，中國文化大學推廣教育部資訊長陳仁偉認為，企業在落實DevOps的過程中，資訊安全不只是要從系統層避免出錯（DevOpsSec），還要進一步透過程式碼編寫的過程就做好防範（DevSecOps），甚至更終極的目標，則是要由架構層面進行防呆（SecDevOps），讓資安深入到研發環境的底層。
因此，他表示，DevOps的資訊安全總共有3種層面，首先是強調要落實管理，其次則是近期廣泛受到討論的程式碼安全；而如今，更進一步強調，資安要貫徹整體開發的策略。乍看之下，兼顧資安考量的DevOps通盤開發流程，企業不只要將系統開發與維運部門統整，建立團隊合作的文化，還要做到各式的資安檢測，並且培養所有相關人員的資安意識，使得工作量大幅增加，但隨著將資安提升到開發策略的層級，陳仁偉說，企業從政策層面著手後，能使得前述管理和程式碼安全檢測的工作量，大幅減少，使得企業DevOps資安越做越輕鬆。因此，整體而言，要達到這樣的目標，其實是「知難行易」。

隨著Sec與DevOps排列的不同，代表資安層面上的差異。在DevOps之後直接加上Sec，意指系統安全驗證，若Sec介於Dev和Ops之間，為程式碼安全，至於將Sec放在DevOps之前，則是代表架構層級的資訊安全。

過往看待DevOps的角度上，企業大都是著眼於管理上的難題，也就是要求開發部門與維運部門合作，在兼顧產出的軟體品質的前題下，改善應用程式的開發流程，使得企業可能會認為「知易行難」，光是兩個部門之間如何併肩作戰，就傷透了腦筋，更不要說還要納入資安工作。導入DevOps確實存在相當程度的門檻，然而如今企業應用系統的開發，已經面臨許多挑戰，陳仁偉認為，透過DevOps改善現況有其必要性。
尋求外部單位監督，是落實開發安全的積極作為
對於如何落實應用程式的資安防護，陳仁偉舉出自身曾經擔任過大學入學考試中心處長的經驗為例說明，重點在於監管機制。他說，承辦考試的業務與確保資安有許多的共通之處，包含了涉及利害關係人眾多，且面臨各界近乎苛刻要求，主事者必須推動一套可行的作業程序，達到零缺失。因此，想要達成上述的目標，陳仁偉甚至認為，最好應該像國家安全會議諮詢委員李德財所提倡的方式，由獨立外部單位執行監管和驗證（Independent Verification and Validation，IV&V）。

在DevOps納入資訊安全後，合作模式便有所變化，在既有的開發、維運，以及品保（QA與QC）之外，也要將外部單位監管及驗證（Independent Verification and Validation，IV&V），納入其中。

在所有DevOps資安做法的規畫上，陳仁偉總共拆解成下列3種要素，分別是：規定、做法，以及監管。
首先，制定明文規範，遵循相關法令，這是基本要求的底限，也是較為偏向消極作為的層次；再者，則是具體的運作機制；至於想要做到前述的零缺失，就要從監管著手，這是在管理層面上，較為積極的態度。
陳仁偉也將這樣的概念，放到DevOps資安管理。在基本層面的部分，他認為，原則上依據ISO 27001等標準，而在運作機制的規畫上，則是提出具體管理作為；至於積極面部分，就是由品質保證部門（QA）進一步落實監督。
落實管理是DevOps資安的基礎環節
想要做好DevOps的資訊安全，陳仁偉說，企業要先從系統安全不出錯開始做起，也就是DevOpsSec的部分。針對系統安全運作的管理，他認為，需做好下列工作，例如開發環境的組態管理、程式碼簽章憑證、程式碼的版本控管、人員的職責要確實畫分、事件管理、使用者測試、弱點掃描、應用程式配置管理，以及行動版應用程式的安全管理等。
其中，人員的職責區分，是陳仁偉特強調的部分，舉例來說，系統設計師（SD）要依照操作人員（OP）提出的需求，開發出相關程式，且在獨立測試區通過測試後，由專人上線，操作人員再依照工單執行程式。而且，無論是系統設計師還是操作人員，都不應該直接接觸到公司的機敏資料。
DevOpsSec的另一個重點是事件的管理，陳仁偉提出的例子，是他曾在大考中心建置的iSEC系統（IT Service and Security Enabling Capacity），裡面整合IT服務管理、資訊安全，以及個資保護管理等業務流程，並能追蹤進度和權責分派。

資安事件處理流程也採用IT維修中，常見的事件通報和指派機制，陳仁偉建置的iSEC系統（IT Service and Security Enabling Capacity）裡，就是以這樣的方式列管資安事件，以圖中的個資外洩事件為例，過程之間便有專責人員負責釐清、調查，再交由相關部門後續處置。

最後要注意的是行動版應用程式，也是陳仁偉認為特別需要防範的部分，尤其管理又比PC軟體困難，因此在實務上，他的單位會限制員工只能在內部環境的特定網段使用行動App，或者是透過VPN連線存取，進而掌握員工的使用者流量。
而如何考核上述各種管理工作的成效？監管的部分同樣不可或缺，陳仁偉表示，須定期由外部單位執行使用者測試、弱點掃描，以及滲透測試等。
從程式碼檢核著手強化安全
在做好DevOps管理的環節之後，陳仁偉認為，企業應該邁入DevSecOps的階段，針對程式碼安全進行改良。管理的方向包含了開發環境的管制、程式碼的單元與整合測試，以及上線管理等。而在品保的層面，則是要針對程式碼與有關的元件，進行審核。
首先是開發環境的管理。雖然可區分成連線與離線環境等兩種型態，但管理上的共同點，都是須使用研發部門專屬的AD網域、程式碼的版本管理系統（如GitHub和Git），而且，工作用和開發用的電腦必須有所區隔等。
在程式碼審核流程的部分，陳仁偉引用了《Hands-On Security in DevOps》一書中，所列的各種措施，包含要審查整合式開發環境（IDE）附加元件的程式碼，還有針對系統設計師產出的程式碼，執行靜態審核與最終的目標程式碼審核等。
其中的靜態審核，可區分成4種：靜態應用系統安全測試（SAST）、動態應用系統安全測試（DAST）、互動式應用系統安全測試（IAST），以及執行期間應用系統自我防護（RASP）等。
不只做好還要防呆，從架構層級預防潛在的資安風險
有了程式碼檢測與審核機制之後，陳仁偉認為，接下來，企業就該從架構層面著手，採取保守主義，做到SecDevOps。具體來說，像是程式開發過程中，只採用經過資安驗證的函式庫（Library）和開發模式（Pattern），若是有新的函式庫與開發模式，則要通過雛型（Prototyping）資安驗證，才能納為可使用的模組。再者，則是對於開發人員採用的函式庫及指令樣式庫，也透過監管系統，定期稽核。
陳仁偉強調，SecDevOps如果能夠落實，前述DevSecOps檢核流程裡，程式碼存在的弱點數量也會大幅降低，大部分只會剩下與組合、規則邏輯，以及流程有關的資安問題。
除此之外，安全架構還包含了使用者端的軟硬體規畫，以及應用系統的軟體設計安全檢核，並且進一步納入主動偵防機制等。
例如，在架設電商平臺時，許多網頁開發者偏好採用動態網頁，導致網頁很容易成為駭客攻擊的目標，而為了減少企業資料對外曝露，陳仁偉採用了兩種作法，一是在建置產品清單的網頁時，採取靜態網頁，而網頁的內容則是每天半夜批次更新，雖然靜態網頁的內容容易遭到複製，卻比較不會成為攻擊目標；另一種確保網頁安全的作法，則是在客戶下單之後，針對電商網站交易網頁的部分，僅回傳顧客的ID與產品ID，有心人士較難從中得知交易的明細。而這些都是落實前述的保守策略後，所帶來由減少攻擊面的規畫，形成架構上防禦的優點。

時下許多網頁設計師偏好採用的動態網頁，雖然使得開發更便利，但陳仁偉認為，這種做法在電商網站中，很容易成為駭客下手的目標，而且也會因為在使用者存取產品清單網頁時，即時透過網站伺服器向資料庫查詢，導致執行效率大幅降低。

因此，在DevOps的資安防護上，陳仁偉認為，SecDevOps、DevSecOps，以及DevOpsSec三種防護策略，其實是相輔相成，陳仁偉也指出，為了避免相同的錯誤反覆出現，企業應該針對DevSecOps與DevOpsSec的部分，建立標準作業程序，同時也要納入稽核管理的範圍。
舉例來說，面對經滲透測試後已修改上線的新版應用系統，若是因為沒有標準作業程序可遵循，遭到其他網管人員操作錯誤，以舊版本覆蓋，那麼，這套系統實際上形同沒有修補相關的弱點，因此，從標準作業程序著手，才能防範這種可能會出現的情況。
維護DevOps資安的實用軟體
針對DevOps的資訊安全，陳仁偉提出了11款軟體，其中2款是提供應用系統的組態程式化管理，其餘大部分則是對應程式碼的審查，涵蓋4種檢核方式（SAST、DAST、IAST、RASP）。
應用系統組態程式化管理
01.Puppethttps://puppet.com/
02.Chefhttps://www.chef.io/
靜態程式碼檢測（SAST）
03.Find Security Bugshttps://find-sec-bugs.github.io/
04.Fortify Static Code Analyzerhttps://www.microfocus.com/products/static-code-analysis-sast/
05.Converity Scanhttps://scan.coverity.com
06.Klocworkhttps://www.roguewave.com/products-services/klocwork
動態程式碼檢測（DAST）
07.OWASP Zed Attack Proxy（ZAP）https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project
08.Burphttps://portswigger.net/burp
互動式程式碼檢測（IAST）
09.Checkmarxhttps://www.checkmarx.com/
10.Veracodehttps://www.veracode.com/
執行期間自我防護（RASP）
11.Open­source Run­time Ap­pli­ca­tion Self-Pro­tec­tion（OpenRASP）https://rasp.baidu.com/
",https://www.ithome.com.tw/news/130082,"新聞,DevOps,DevOpsSec,2019臺灣資安大會,RASP"
129392,11,2019-03-18,微軟AI研發中心CEO：臺灣企業現在的AI應用有7大問題,張仁炯指出，臺灣企業要做數位轉型，除了要先了解自身定位，還要有長期投資的決心，才能為產品與服務加值。," 微軟AI研發中心執行長張仁炯最近在一場研討會中，揭露了1年多來在臺觀察企業AI發展的七大問題。
這些問題包括了，企業對數位轉型有錯誤的認知，仍維持傳統硬體思維，也缺乏了對資料、數位轉型和AI的戰略，尤其組織內部資料不流通，再加上對既有AI欠缺長期投資，甚至沒有長期研發規畫，也沒有妥善保護資料和善用雲端。
2018年1月10日微軟宣布在臺成立「人工智慧研發中心」，張仁炯正是這個中心主要負責人，目標在5年內培育超過200人的AI研發團隊，微軟看中臺灣學術界的研發能量，以及世界第一的資訊硬體製造業等。
儘管，臺灣的AI實力大獲國際廠商看好，但張仁炯觀察，第一個問題是，仍有許多本地企業缺乏數位轉型思維，仍以降低成本為主要思考方向。
張仁炯直言，軟體才是改變未來的主要力量，臺灣的製造業硬體非常強，卻也因此限制了企業家的想像。他指出，數位轉型的第一步，就從資料的流通開始。「你要先接受雲端化、意識到資料的重要性。」
張仁炯舉例，許多大型企業至今未整合ERP，人事與會計系統個別獨立，或像政府組織各局處的資料不流通，更別提還有許多中小型企業沒上雲。換句話說，部分企業與政府並沒有妥善應用資料、善用雲端運算，也無長期規劃投資與研發方向，反而把AI或軟體的應用當成標案，以短期採購案方式購入，「這是對數位轉型的錯誤認知。」
企業想要尋找AI創新方向，張仁炯建議：「創新式思考不見得是新的問題，多數是已知的問題，用新的方式做。」如光學字元辨識（OCR）已經問世超過20年，應用於文件處理、車牌辨識等，但現今以ML、NLP的技術，能增加文句辨識的效率與準確度，降低人工校正的時間，也使AI-based OCR在商業上的應用更廣泛。因此，用新技術解決舊問題，讓產品或服務獲得更高的商業價值，是企業引入AI時應思考的方向。
然而，要讓AI落地，他他提醒，人才的訓練很重要。臺灣科技類博士生人數從2010至2017年下降近5000人，占總博士生比例也從69.2%下降至59.8%，均呈現逐年下降的趨勢，導致科技業的研發人才短缺。為此，微軟AI研發中心向人才拋出橄欖枝，要與交大建立合作關係，讓博士生直接到微軟實習，除了吸引學生攻博，也希望起到拋磚引玉的作用。
張仁炯更要企業放眼國際，不要將眼光侷限臺灣，他解釋，本地企業轉型時面臨的問題，在其他國家也會發生，「我們先有好的東西，未來才能往別的地方走。」
",https://www.ithome.com.tw/news/129392,"新聞,AI,微軟,張仁炯,Cloud,數位轉型"
129146,11,2019-03-07,微軟Team Foundation Server改名釋出Azure DevOps Server 2019,Azure DevOps Server 2019與Team Foundation Server功能大致相同，微軟為其大幅度更新使用者介面，加入回應性更好的導覽功能。," 微軟正式發布Azure DevOps Server 2019。Azure DevOps Server 2019以前被稱為Team Foundation Server（TFS），能夠將Azure DevOps功能放進企業的專有環境中。Azure DevOps包含了一系列開發人員協作工具，包括Azure Boards、Azure Repos、Azure Pipelines、Azure Test Plans以及Azure Artifacts。
這些工具支援所有熱門的開發語言，也能在macOS、Linux和Windows，或是雲端等平臺運作。和TFS一樣，使用者可以選擇將Azure DevOps Server 2019安裝到任何的資料中心，並決定應用更新的時機。
微軟為Azure DevOps Server 2019加入更具回應性的新導覽功能，可以讓使用者在服務間簡單的來回瀏覽切換，微軟提到，這是這是近年來最大的一次使用者體驗更新。

而在Azure Pipelines方面，微軟加入了新的建置以及發布頁面，並增加了對YAML建置的支援。另外，在早期版本的TFS中，微軟整合了GitHub Enterprise和Azure Pipelines，在Azure DevOps Server 2019版本，還進一步整合GitHub Enterprise提交和拉取請求，以及Azure Board中的工作項目。
",https://www.ithome.com.tw/news/129146,"新聞,微軟,Azure DevOps,DevOps,開發"
128614,11,2019-02-03,Cloud Pub/Sub現提供重播功能，能回退Backlog到特定時間點,過去經確認過的Pub/Sub訊息便會被丟棄，只要使用者先在訂閱啟用retain_acked_messages屬性，往後經確認的訊息也能進行回退。," Google現在為其GCP資料串流擷取服務Cloud Pub/Sub增加重播（Replay）功能，快速簡單地批次處理Backlog中訊息，即便資料訂閱者收到一連串有問題的串流資料，也能利用重播功能，丟棄某個事件的有問題訊息，或是回復到過去某個時間點的訂閱狀態，安全地修復程式錯誤。
Cloud Pub/Sub是Google可擴展的資料串流服務，提供將資料從發布者串流至訂閱者客戶端的訊息服務，而現在新增了重播功能，使用者可以重播舊事件或是訊息，為資料訂閱者提供一個額外處理訊息的機會。
正常的使用狀態，Cloud Pub/Sub發布者客戶端持續發布事件到Pub/Sub主題中作為訊息，而資料訂閱者則會平行地處理和消耗這些事件。在不少時候，訂閱者端可能發生故障而無法確認正在處理的訊息，抑或是發布者端產生了訂閱者不支援的資料，而這代表Backlog中可能存在部分訂閱者永遠不會確認的訊息。這時候新的重播功能就能發生作用，簡單的清除Backlog未被確認的訊息，或是回退Backlog狀態，幫助修復發布者或是訂閱者程式碼的錯誤。
Backlog訊息狀態發生問題有不少可能性，問題或許發生在資料發布者端，產生的訊息不符合訂閱者預期的格式，即便開發者對於資料發布者作出修改，但是之前未確認的訊息仍然存在，訂閱者也無法確認這些訊息，此時Cloud Pub/Sub增使用者可以使用Seek API批次確認某個特定時間點之前發布的所有訊息。
而且在過去，一旦被確認過的訊息，Pub/Sub便會丟棄該訊息，以至於使用者完全無法復原，Cloud Pub/Sub強大的重播功能，讓即便確認過的訊息也能往前回退。這個功能可以用於修復資料訂閱者發生的錯誤，當訂閱者確認了部分訊息後仍沒有完成預期的工作，使用者可以使用重播功能，一樣使用Seek API以倒帶取消確認之前的訊息，並修復訂閱者後接續之前的工作階段。Google表示，這個功能必須要在訂閱功能上，事先啟用retain_acked_messages屬性。
另外，重播還提供快照功能，使用者可以創建訂閱者Backlog的當前切確狀態，這個功能同樣可以應用在修復訂閱者錯誤上，當使用者想要迭代訂閱者程式之前，可以先使用CreateSnapshot API創建訂閱快照，一旦新的訂閱者程式發生問題，錯誤確認了訊息，使用者只要簡單的使用之前創建的訂閱快照，就能快速地使用Seek API，將訂閱Backlog恢復到創建快照時的狀態。
使用者可以重複這些重播功能，直到修復發布者或是訂閱者程式的錯誤，並正確的處理Backlog中的訊息。Cloud Pub/Sub重播功能提供開發者靈活的手段，在不需要冒著丟失訊息的風險，安全地修復錯誤。
",https://www.ithome.com.tw/news/128614,"新聞,google,Cloud,Pub/Sub"
128601,11,2019-02-01,軟體建置與測試平臺ElectricAccelerator 11.0釋出，強化雲端服務暴量應對能力,ElectricAccelerator對AWS EC2和Kubernetes環境，強化雲端服務暴量應對能力，當需求超過靜態配置的容量時，系統將會動態擴展資源。," Electric Cloud釋出軟體建置與測試平臺ElectricAccelerator 11.0，這個版本加入了諸多改進，以幫助企業縮短開發周期，現在為AWS和Kubernetes環境，以不影響效能的情況解決雲端服務暴量（Cloud Bursting），還新增基於Yocto的嵌入式Linux建置和Android平臺隨插即用的支援。
ElectricAccelerator是軟體建置加速器，透過在伺服器叢集上進行分散式建置工作，以大幅度降低軟體建置時間，加速器插件可以無縫的與現有軟體開發環境整合，並提供網頁報告和管理工具。加速器包含了eMake、檔案系統、叢集管理器以及Electrify元件。
ElectricAccelerator 11.0支援最新Android Pie版本以及LineageOS的，並加入了buildroot以及基於Yocto的嵌入式Linux建置支援。Bitbake使用者現在可以使用ElectricInsight分析buildstats檔案，以預測改進建置時間，也能以增強的ebitbake命令，加速Yocto建置工作。這個功能將原本的GNU Make（gmake）以eMake do_compile替換。
這個新的ebitbake命令，為BitBake do_configure工作提供快取和加速建置，用法則和BitBake本身完全相同。而為了改進Yocto編譯JobCache的命中率，這個命令替換了原本在ElectricAccelerator 10.1使用的Wrapper公用程式。
另外，這個ElectricAccelerator版本還加入了bb2anno公用程式，這個工具會為每個BitBake套件以及使用加速器的任務轉換註釋檔案，並將註釋檔案與其他buildstats資料組合在一起。對Android的改進部分，主要是提升其效能以及相容性，當使用者使用Android整合工具時，預設新增了常見的Android環境變數到列表中，以避免發生錯誤，使用者不再需要明確指定這些變數。
Electric Cloud還為AWS EC2和Kubernetes環境，增加了對雲端服務暴量的開箱即用支援，現在使用者可以啟用雲端服務暴量功能，當需求超過靜態配置的容量時，系統將會動態擴展資源，以應付突發的流量高峰。如此，使用者可以在需要的時候再啟用這些資源，而不需要預先準備備用，將有助於企業控制成本。
ElectricAccelerator 11.0增強了叢集資源管理，透過簡化並整合叢集管理器資源概念，以提升可用性，資源現在是叢集管理器不可缺少的一部分，因此不再提供啟用或是禁用選項，只有永遠在上線的狀態，會在需求超過容量時，以每個資源為基礎實現雲端服務暴量功能。
",https://www.ithome.com.tw/news/128601,"新聞,Electric Cloud,建置,DevOps,CI,開發"
128187,11,2019-01-14,臺北市前資訊局長李維斌轉戰產業界，正式加入北富銀，將負責金融科技、大數據和雲端建設,未來，李維斌將負責臺北富邦銀行的金融科技、大數據以及雲端系統的設計與建置，北富銀總經理則期待他能在大數據、雲端運算、區塊鏈、Open Banking等金融科技幫助北富銀再升級," 前臺北市資訊局長李維斌走入金融圈，加入臺北富邦銀行，擔任數位金融顧問，也兼任富邦金控創新科技辦公室的執行秘書。富邦銀於上週五(1/11)晚上宣布此消息，並透露未來李維斌將負責臺北富邦銀行的金融科技、大數據以及雲端系統的設計與建置。臺北富邦銀行總經理程耀輝則期待李維斌可以強化北富銀在大數據、雲端運算、區塊鏈、Open Banking 等金融科技領域的發展。
李維斌也在1月11日下午，首次以業界身分，參加一場立委江永昌和余宛如召開的資料權與開放銀行政策公聽會，會中不改劍及履及的本色，他直言，不論開放銀行政策走向如何，都要盡快決策，如果遲遲不跨出第一步，趕快訂立規則，再多的討論都沒意義。
李維斌解釋，政府要盡快界定清楚政府、銀行和第三方服務業者（TSP），每個角色所要承擔的責任和義務，以及要遵守的規範，更要訂立出各方可承受風險的力度範圍，以降低風險發生時的影響。他還建議金管會，應成立一個專責單位才能快速因應變化，可補足行政機關所缺少的彈性要素，以滿足創新的需求。
原本是大學資工教授的李維斌，後來成為逢甲大學資訊處資訊長，成功帶領逢甲資訊處轉型成服務型SI，成了學校的重要營收單位，2015年1月進入臺北市政府，擔任資訊局長，在任內除了大力推動臺北市數位服務的變革，也致力於讓臺北成為各種數位創新的實驗場域，應用領域涵蓋了多項新興科技趨勢智慧城市、物聯網、資安、區塊鏈等試驗場，讓城市可以成為業界練兵的場域，也能帶動城市數位化的發展。
他也大力推動開放資料，支援公民科技應用發展，並積極與開源社群聯手，建立了公私協力的新合作模式。不過，在2018年底，臺北市長柯文哲連任成功之後，李維斌轉而卸下公職，走入業界，於2019年1月進入臺北富邦銀行任職。
",https://www.ithome.com.tw/news/128187,"新聞,臺北富邦銀行,李維斌,開放銀行,大數據,Cloud"
127948,11,2019-01-03,【2019年關鍵趨勢5】Kubernetes成企業應用平臺新標準，下一步還要能通吃多雲混合架構,越來越火紅的Kubernetes平臺，正在發展一項重要新功能Federation，目的是讓應用程式，可以部署到多雲或跨雲上的Kubernetes叢集上，Kubernetes正逐漸成為一個可以支援多雲、跨雲架構的通用應用平臺," 2018年3月初，Kubernetes正式進入了新的發展階段。原本Kubernetes專案由CNCF（雲端原生運算基金會）管理，但從3月開始，正式畢業了，也代表了Kubernetes專案已經打造出可以長期穩定發展的技術生態圈。
Kubernetes在2018年依舊火紅，各大雲端平臺從2016、2017年開始紛紛支援，甚至將自家以「容器」為名的服務，改成「Kubernetes」為名的託管服務，例如Azure的ACS早在2017年就換成了AKS，或像IBM則是2018年5月將Cloud Container Service更名為Cloud Kubernetes Service，簡稱IKS。Kubernetes取代了Container，成了容器服務的新代名詞。
在2018年，Kubernetes更成了雲端巨頭進軍企業內部市場的關鍵武器。例如Google宣布GCP雲端Kubernetes託管服務GKE，將推出軟體版本GKE On-Prem，可安裝於企業內部機房伺服器。
而AWS年底發表的AWS Outposts軟體，同樣可部署於企業機房內部，也預告了會提供EKS，也就是AWS的Kubernetes服務的軟體版。
不同於Docker等容器技術以開發者為主，AWS雲端架構策略副總裁的Adrian Cockcroft指出，Kubernetes要解決的是容器技術的維運問題，這句話也點出了Kubernetes比起Docker，更適合成為以應用程式為中心的容器管理平臺。Kubernetes可以提供應用程式需要的資源調度，如自動擴充、大規模部署管理，甚至可以將一個應用程式所需的容器叢集部署和擴充配置都打包起來變成一套，方便重複使用或快速部署。
紅帽也從2018年中開始鼓吹，Kubernetes將成為新一代的應用程式伺服器（Application Server），未來，企業應用的部署底層將會都是Kubernetes，而紅帽力推的OpenShift就是專攻這個一層需求的主力產品。
不過，只靠Kubernetes來管理和部署應用程式還不夠，雲端原生應用的另一個新特性，就是微服務架構，一支應用系統，由多個不同功能或用途的微服務組成。
K8s搭配服務網格更適合管理微服務架構
在Kubernetes內雖然可以快速部署微服務類型的應用系統，然而，一旦微服務數量越來越多之後，如何管理這些微服務成了新的挑戰。這正是Google、IBM和Lyft聯手打造另一套開源微服務管理平臺Istio的目的，可以透過服務網格的架構（Service Mesh），來管理龐大的微服務群。
Istio可以將多個Kubernetes叢集，集中到單一套服務網格中來管理，並能支援跨Kubernetes叢集連線，也能確保每個叢集都套用一致的管理政策。不只Google，連紅帽後來也讓自家OpenShift支援Istio。Kubernetes加上Istio，可以從應用程式的調度管理，進一步擴大到企業內部整體雲端基礎架構的管理。
雖然各雲端業者或軟體商，都推出了各自的Kubernetes服務或平臺，但這些Kubernetes之間的資源調度，仍舊少了一個共通的標準作法。
開源社群也意識到這個問題和需求，所以，Kubernetes社群正在發展其中一項重要功能Federation服務，目的要讓Kubernetes上的應用程式，可以輕易地部署到多雲，或是跨雲上的Kubernetes叢集上，當然也包括了橫跨公有雲和私有雲的混合雲架構，目前仍是開發版本。未來，這個功能成熟之後，企業就可以有一套真正通吃雲上雲下各種平臺的Kubernetes了。
",https://www.ithome.com.tw/news/127948,"新聞,Kubernetes,K8s"
127941,11,2018-12-28,Twilio聊天機器人平臺Autopilot開始支援臉書，加速企業打造Chatbot應用,Twilio Autopilot現在擴大支援臉書Messenger，為了加快應用落地速度，該工具透過統一API，一次搞定智慧助理、通訊平臺的聊天機器人應用部署工作," 提供雲端通訊服務的Twilio，在今年10月時釋出了人工智慧平臺Autopilot，加速企業用戶開發客製化的聊天機器人服務。而近日該公司進一步擴大Autopilot的產品布局，現在開始支援臉書Messenger，方便使用者打造Chatbot應用。不過，目前此產品支援還位於Beta階段。
Twilio表示，Gartner的研究報告指出，到了2019年時，消費者透過行動通訊軟體尋求客服的需求，將會超越透過傳統管道。而臉書Messenger是用戶數量非常可觀的通訊平臺，每日約有20億個活躍用戶數，透過臉書聊天機器人，可以提供用戶更為快速、方便的服務。
以AI為驅動力的聊天機器人，可以應付更為複雜的問題。而Twilio Autopilot透過單一API，存取多個通訊管道，將Chatbot應用部署至多平臺執行，囊括簡訊、語音，或者智慧助理如Alexa、Google Assistant。該公司認為，藉此能提高終端用戶的一致性體驗。
",https://www.ithome.com.tw/news/127941,"新聞,Twilio,DevOps,Chatbot,聊天機器人"
127858,11,2018-12-25,開發者的聖誕禮物! GitLab 11.8版將開源ChatOps功能,目前GitLab ChatOps所支援的平臺包含Slack跟Mattermost。," 正逢西方聖誕節，GitLab執行長Sid Sijbrandij也要送給開發者聖誕禮物，「未來GitLab內的ChatOps功能，將要開源釋出。」目前，GitLab的規畫是在GitLab 11.8版推出時，將ChatOps功能開源。
GitLab ChatOps的主要功能，就是讓開發者透過通訊平臺發送程式指令，目前此功能所支援的平臺包含Slack跟Mattermost。Sid Sijbrandij表示，自家公司也在正式環境導入GitLab ChatOps功能，藉此部署GitLab或者執行資料庫Query查詢。
Sid Sijbrandij認為，實用的ChatOps服務，往往包含了5大特點。第一是提供監控功能，並且搭配監控圖表，讓維運人員方便進行故障排除。第二則是支援Query指令操作，讓開發者可以輸入簡單的SQL指令。第三是整合角色存取控制機制，每個使用者分別有不同操作權限。再者，不需要預先進行組態設定工作，只要開發者登入即可開始存取服務。最後，ChatOps平臺在組織內，必須有一致的運作規則。
",https://www.ithome.com.tw/news/127858,"新聞,GitLab,DevOps,開源"
127708,11,2018-12-17,GitLab整合Knative，無伺服器服務GitLab Serverless即將登場,GitLab Serverless整合無伺服器管理平臺Knative，讓開發者可透過GitLab在Kubernetes叢集部署Knative，藉此在Kubernetes環境執行無伺服器應用," 自從AWS在2014年率先釋出無伺服器運算架構，一波新IT架構革命慢慢發酵，各大雲端廠商紛紛釋出自家雲端無伺服器服務，而開源專案如Fn、OpenFaaS等也逐漸興起。而近期GitLab也宣布要加入這場戰局，與無伺服器新創TriggerMesh合作，預計在12月22日時，釋出自家無伺服器服務GitLab Serverless。
GitLab表示，無伺服器功能預計與GitLab 11.6版一同釋出，讓企業用戶可以在相同的使用環境，直接建置、管理無伺服器應用。因應搭配無伺服器及容器技術的潮流，GitLab表示，該服務也整合無伺服器管理平臺Knative，讓開發者可透過GitLab在Kubernetes叢集部署Knative，藉此在Kubernetes環境執行無伺服器應用。除了搞定應用程式的隨需擴充需求，Knative本身相容多異質雲端平臺的特性，也降低企業用戶被特定廠商綁定的壓力。
而這次GitLab產品新發布，無伺服器新創TriggerMesh也是背後的重要推手。GitLab表示，TriggerMesh共同創辦人Sebastien Goasguen早期就開始投入開發K8s無伺服器框架Kubeless。在今年11月時，TriggerMesh也釋出了自家無伺服器管理平臺，支援開發者利用GitHub、GitLab、Bitbucket這些儲存庫內的Function，作為事件驅動來源。

在12月底預計發布的GitLab Serverless，屆時使用者就會在左側選單看見「Serverless」選項，不過是以Alpha版釋出。如要了解該函式的更多資訊，只需滑鼠點擊，在選單便會看見Kubernetes Pods資源的使用量，以及該函式被觸發的頻率。圖片來源：GitLab

",https://www.ithome.com.tw/news/127708,"新聞,GitLab,無伺服器應用,DevOps,Serverless"
127665,12,2018-12-13,微軟Azure Monitor開始正式支援容器監控服務,現在開發者更可以進行即時除錯（Live debugging），透過Azure Monitor容器監控功能的即時串流處理，可以將容器內的Log資料匯入使用者的Azure Potral," 今年5月Build大會上推出公開預覽版的Azure Monitor容器監控服務，近日微軟終於宣布，該服務已經正式上線，企業用戶可以透過該服務，監控部署於Azure環境上Kubernetes叢集的健康狀況、效能。微軟表示，導入該服務的企業用戶可以不仰賴第三方工具或是登入容器，就能在Azure環境進行遙測工作。
而邁向正式版本的Azure Monitor容器監控服務，功能自然也比5月釋出的技術預覽版豐富。首先，現在該服務新增了多叢集瀏覽模式（Mulit-cluster view），系統自動會探查所有部署在雲端的Kubernetes叢集，包含資源群組、工作空間等環境，並且提供管理員相關的叢集資訊，如名稱、節點數目、健康狀況等訊息。而
再者，該服務也加強叢集監控的顆粒度，除提供較為巨觀的叢集觀察角度，Auzre Monitor容器監控功能也提供更微觀的視角，讓使用者可以更往下鑽，探查各節點、Pod的健康狀況、即時運作效能等。
此外，現在開發者更可以進行即時除錯（Live debugging），透過Azure Monitor容器監控功能的即時串流處理，可以將容器內的Log資料匯入使用者的Azure Potral。而使用者也能隨時暫停該串流處理，開始著手分析Log檔案中，是否出現異常狀況，以利使用者進行除錯。

在多叢集瀏覽模式內，系統會提供叢集當前狀況的總結資訊，如果使用者當前未有納入監控範圍的Kubernetes叢集，只需要滑鼠點擊，便可以將其納入Azure Monitor容器監控的守備範圍。圖片來源：微軟


除了叢集此項度，Azure Monitor容器監控功能，現在也往下提供節點、Controllers、Pod、容器等。例如，叢集內的各節點的狀態、容器數量、以及當前開啟時間，如使用者發現異常，還可繼續往下延伸，更進一步探查。圖片來源：微軟


現在Azure Monitor容器監控功能也搭配了即時除錯服務，系統可自動執行串流工作，將容器內的Log資料匯回使用者的Azure Portal，接著對照Log紀錄，檢視是否有異常之處。圖片來源：微軟

",https://www.ithome.com.tw/news/127665,"新聞,微軟,容器,Container,Azure,公有雲"
127823,12,2018-12-10,Container周報第92期：Kubernetes 1.13來了，正式納入容器儲存介面,11/29~12/05必看Container新聞," 11/29~12/05必看Container新聞
#Docker、#桌面版容器
Docker桌面版推出企業級服務，開發裝置管理、正式環境組態設定一把抓
近140萬人使用的桌面版Docker最近也推出了企業版本Docker Desktop Enterprise，IT管理員可以通管端點開發環境，讓開發者可以在桌面環境下，快速建置、交付容器化應用程式。針對IT維運人員，新版有兩大特色，首先是提供MSI、PKG檔案格式的發布檔，同時企業還可以利用Policy Files，關閉部分系統設定選項，進行終端裝置管理。第二項則是提供開發者經認證後的客製化應用程式模板，可隨即進行開發工作。在Docker Desktop Enterprise內，企業內部架構師可利用產品內建的應用程式設計介面（Application Designer interface），提供開發者一致的應用程式模板。同時，系統管理員還能在整條軟體開發鏈中，提高安全、開發守則的一致性。
針對容器應用的開發者，新版也有兩項新功能。第一項，開發者可以將正式環境的組態設定，製作成打包檔，原封不同地搬回桌面開發環境，包含Docker API、Kubernetes版本，過往因為不相容API版本，導致應用程式無法執行的痛點也可以解決。同時，如果企業內部正式環境有多組版本API的組態設定，使用者也可以直接在選單上切換，調整成相容該版本的環境設置。第二項功能，則是利用應用程式設計介面，讓開發者可以不透過Docker命令程式列，直接建立容器化應用。此外，Docker Desktop Enterprise還供開發者使用偏好的IDE、文字編輯器或命令程式列工具。
#容器安全、#Kubernetes漏洞
Kubernetes爆重大漏洞！不法人士可取得管理員權限，竊取機敏資料、癱瘓企業應用
近期Kubernetes爆出資安漏洞，Kubernetes產品安全團隊表示，近日在Kubernetes API Server內存在權限擴張漏洞，發現此漏洞的開發者為Rancher共同創辦人兼首席架構師Darren Shepherd。紅帽雲端平臺副總裁Ashesh Badani更強調，此權限擴張漏洞的影響非常重大，可讓不法人士在任何運算節點、Kubernetes Pod取得管理員權限。
此漏洞編號為CVE-2018-1002105，讓攻擊者可以發送特殊的系統請求，經由Kubernetes API Server，與企業內部後端伺服器進行連線，藉由取得Kubernetes API Server的認證，攻擊者就能利用既有連線，任意向後端伺服器發送請求。
目前Kubernetes開發團隊已經發布V1.10.11、V1.11.5及V1.12.3，以解決該漏洞帶來的風險。參與Kubernetes安全團隊的Google高級工程師Jordan Liggitt建議，在叢集內執行先前版本Kubernetes的企業用戶，得儘速擇一版本進行更新。
#容器儲存、#Kubeadm
Kubernetes 1.13來了! Kubeadm、容器儲存介面成為正式功能
近日Kubernetes釋出2018年第4次更新，也就是1.13版本，鎖定系統的穩定性、加強擴充性。先前為Alpha階段的功能，如支援容器儲存介面，或者透過Kubeadm簡化叢集管理等，在1.13版也成為了正式功能。兩個進入正式版的重要系統功能，首先是官方部署工具Kubeadm，維運人員可以用該工具處理叢集建置、設定Kubernetes核心元件組態，「可插拔性及組態設定的彈性，是該工具邁向GA版的重要特色。」Kubernetes官方團隊表示。第二項則是容器儲存介面，早在1.9版時就推出了Alpha版功能，經過一年，在1.13版中終於正式可用，搭配容器儲存介面，可讓第三方儲存廠商逕行開發套件，旗下產品可與Kubernetes介接，不需要另外修改Kubernetes的核心程式碼。此功能也讓儲存廠商可以更快切入容器儲存市場。

#雲端原生應用、#Docker
微軟與Docker攜手發表開源雲端專案Cloud Native Application Bundle
微軟與Docker共同發表了雲端原生程式包（Cloud Native Application Bundle，CNAB），這是一個用來包裝分散式程式的規格，Docker則將它稱為「各種容器的容器」（A container of containers），可用來包裝、安裝或管理容器程式及與之相關的服務。CNAB奠基於JSON、Docker容器及OpenPGP等技術上，定義包裝、安裝及管理分散式程式的格式，透過CNAB，開發人員只要利用單一的安裝檔就能管理各種分散式程式，確實地供應來自不同環境的應用程式資源，也方便管理應用程式生命周期。CNAB可適用於各種平臺，從雲端的Azure到就地部署的OpenStack，從Kubernetes到Swarm，或是從Ansible到Terraform，而且它能在工作站上、公有雲上、氣隙網路（air-gap network）上，或是資源受限的IoT環境中執行。

#Kata Container、#OpenStack
OpenStack容器專案Kata Container一次推2個新版，1.4版特別加強CPU資源管控
近期OpenStack基金會的容器專案Kata Container一口氣推出了兩個新版本：1.3及1.4版。1.3版為穩定發行版，而1.4版才推出了較多的新功能。1.4版有不少新功能。首先，主機端開始支援Linux內建的資源隔離機制cgroups，可限定主機端虛擬機器上的系統程序只能在特定CPU上執行，除了可以分配各個虛擬機存取CPU資源的額度，還能避免特定容器存取過多資源，導致服務中斷的狀況發生。其次則強化了雲端部署應用情境，支援更輕量型的虛擬機器類型NEMU，這是以QEMU為基礎修改的雲端Hypervisor，藉由縮小容量，降低虛擬機器的攻擊面積。再者也加強了Kata Container專案的網路功能。在1.4版新增了兩種網路使用模式，分別是none模式及tcfilter模式。

#微服務管理、#Mesh
AWS釋出App Mesh助企業監控微服務應用程式
AWS推出服務網狀網路App Mesh公開預覽版，供使用者輕鬆的監視與控制AWS上，構成應用程式微服務之間的通訊。使用者能以App Mesh監控在Amazon ECS、Amazon EKS，還有在Amazon EC2的Kubernetes上執行的微服務。App Mesh除了Amazon CloudWatch和AWS X-Ray，也整合了Prometheus和Datadog監控工具。開發者可以使用App Mesh構築微服務連接的方式，App Mesh會自動計算並且發送適當的配置，到每一個微服務代理伺服器，這將提供標準，易用的可見度和流量控制。App Mesh使用開源代理伺服器Envoy，相容於廣泛的AWS生態系與開源工具。另外，App Mesh也能讓使用者輸出可觀測資料到多個AWS或是第三方工具，包括Amazon CloudWatch、AWS X-Ray或是與Envoy整合的第三方監控與追蹤工具，像是Prometheus和Datadog。現在App Mesh目前是公開預覽版，只支援北弗吉尼亞州、俄亥俄州、奧勒岡州和愛爾蘭的AWS區域。

責任編輯／王宏仁
更多Container動態
緊接Kubernetes、Prometheus，Envoy也從CNCF基金會畢業了
Nutanix正式押寶Kubernetes，自家K8s解決方案Nutanix Karbon出爐
AWS再加強無伺服Lambda布局，使用者可自選Runtime，還原生支援Ruby
＠資料來源：iThome整理，2018年12月
 
 
 
",https://www.ithome.com.tw/news/127823,"新聞,Container,Kubernetes,AWS,容器,IT周報"
127503,12,2018-12-06,雲端小組工作討論版Azure Boards開始整合GitHub,除了整合Azure Boards、GitHub，雲端DevOps平臺Azure Pipelines也被拉入整合，連接軟體開發工作計畫階段、程式碼持續整合，以及最後持續交付工作，讓開發流程變得更為透明。," 今年微軟併購大筆GitHub後，也陸續開始整合雙方產品線，像是微軟雲端DevOps服務Azure Pipelines登上了GitHub市集，供開源專案免費使用，或者雲端資料整合服務亦開始支援GitHub。而近期微軟的整合工作，則是將雲端小組工作討論版Azure Boards與GitHub介接，使用GitHub代管程式碼的企業用戶，可使用敏捷管理常會用到的Kabnban boards服務、短期衝刺規畫等。

在開始使用前，開發者得先將GitHub上的提交項目、合併請求，與Azure Boards上的工作項目（work items）合併，如此其他團隊成員可以直接在看板中，追蹤當前專案的動態，成員也可以標注該工作的優先性、急迫性等資訊。圖片來源：微軟


當開發者準備要在GitHub提交程式碼，但同時得提醒該員該程式碼已經提交、需要注意之處時，可直接使用Azure Boards的工作ID，標註該成員。圖片來源：微軟


微軟這一次也加入整合雲端DevOps平臺Azure Pipelines，一次整合這三大服務，讓開發者從最初的軟體開發工作計畫階段、中間程式碼持續整合，以及最後持續交付流程串接起，讓開發流程變得更為透明。圖片來源：微軟


當使用者於GitHub完成提交程式碼工作後，Azure Boards會在工作看板產生新工作進度訊息，當負責人已完成該工作時，即可移動至「已解決」區域。而已經結案的工作，則可被移動至封存區。圖片來源：微軟

",https://www.ithome.com.tw/news/127503,"新聞,Azure,公有雲,GitHub,DevOps"
127385,12,2018-11-30,Container周報第91期：AWS開賣伺服器硬體，推出AWS雲外帶機櫃，未來EKS和SageMaker都可落地部署,AWS要變成一家伺服器公司，讓你把AWS這朵雲帶到企業機房中部署，目前可提供一朵自建的Amazon EC2私有雲，也可提供Amazon EBS區塊儲存，未來還會支援RDS、ECS、EKS、SageMaker和EMR。," 11/17~11/28一定要看的Container新聞
#AWS本地部署、#Outposts
AWS開賣伺服器硬體，推出AWS雲外帶機櫃，未來EKS和SageMaker都可落地部署
AWS執行長Anady Jessy在今年re:Invent年度大會開場演講最後，出人意料地宣布了一個重量級的消息，AWS要推出整櫃式的AWS主機，稱為AWS Outposts，可以讓企業在自家資料中心部署一套AWS原生基礎架構，或者是一套VMware Cloud on AWS平臺。等於是可以將AWS雲端服務外帶打包帶回家。這個機櫃硬體是由AWS自行設計的伺服器，和AWS資料中心所用的相同。這套產品可提供一個和雲端AWS一樣的配置畫面，可以用來管理一朵自家的Amazon EC2私有雲，也可提供Amazon EBS區塊儲存，未來還會支援RDS、ECS、EKS、SageMaker和EMR。等於不只是虛擬機器，未來也可以將AWS雲端容器服務和AI部署服務，打包帶出到自家機房裡安裝。
#虛擬化、#無伺服器
加強無伺服器應用，AWS釋出輕量虛擬化技術Firecracker
今年AWS年度大會中，AWS更進一步開源釋出用於無伺服器情境的輕量虛擬化技術Firecracker。AWS使用了開源的KVM虛擬化技術為基礎，再利用Rust語言，來開發了此虛擬化專案Firecracker。該公司表示，每一臺使用Firecracker開啟的虛擬機，只需要耗費5MiB的記憶體，在單一實例上，可以開啟數千臺虛擬機。透過此輕量虛擬化技術，使用者可以在非虛擬化環境中，開啟輕量級虛擬機（microVMs），同時保有虛擬機的隔離性、容器快速開啟的特性。據AWS測試，開啟一個輕量級虛擬機，所需時間只要125ms，「現在也已經用於AWS Labmda及AWS Fargate。」在其架構中，AWS除了減少其攻擊表面，也導入了多個系統隔離機制，改善Firecracker的安全性。

#容器、#Docker
Docker引擎18.09版釋出，採用平行建置新架構和快取，建置速度最多快9倍
近日，Docker也公開新的Docker引擎18.09版，同步支援企業版及社群版。Docker公司表示，此新版容器引擎導入新的建置架構外，也改善了容器執行的效能。
新版Docker引擎的設計架構，整合符合OCI標準容器Runtime runC，以及Docker的核心元件containerd 1.2版為基礎。在這些基礎元件之上，Docker社群版、企業版共同擁有的元件，包含調度元件SwarmKit、Docker API、命令列工具Docker CLI、網路元件Libnetwork、建置工具。Docker公司宣稱，新版導入新的並行（Concurrency ）運作架構及快取模式，部署速度可以快上2至9.5倍。再者是建置工作的安全性，整合SSH協定後，開發者可透過轉發既有SSH agent連線或金鑰，與私有容器儲存庫連線。最後是快取檔案的管理，現在Docker加入了新指令，可以以映像檔為區分，處理建置工作後的快取檔案。

#CI/CD、#持續交付
Atomist釋出開源雲端原生軟體交付平臺SDM 1.0
雲端DevOps工具新創Atomist釋出軟體交付機器（Software Delivery Machine，SDM）框架1.0，讓開發者使用工程化的交付方法，提高組織整體一致性。
Atomist遵循軟體定義交付的原則，使用開發應用程式的工具和方法，解決軟體交付的挑戰。Atomist提到，交付的程序應該以版本化和經測試的程式碼實作，而非大量的殼層腳本和數百行複製貼上的YAML定義。Atomist SDM主打使用者可以像軟體開發者一樣，自動執行部分日常的重複性工作，像是讓原始碼應用一致的格式、管理變更日誌，以及在產品臭蟲修復時將待處理問題上標記，在審核時自動合併PR並成功建置，也能更新企業中每個儲存庫中的授權許可檔案。
#持續整合、#Drone持續整合服務Drone Cloud上線，開源專案可免費用x86、Arm裸機運算資源
近年獲得不少開發者關注的DevOps工具Drone近期釋出免費持續整合服務Drone Cloud，可以支援開發者同時在x86、Arm架構下使用。雖然是免費服務，但Drone Cloud所提供的裸機伺服器硬體規格也相當不錯，此服務提供的x86伺服器，使用24核心的AMD 7401P EPYC處理器，搭配64GB記憶體、960GB的固態硬碟。至於Arm伺服器的硬體規格，Drone Cloud則是選用了Cavium ThunderX處理器，並選配128GB記憶體、250GB容量的固態硬碟。
#OpenShift、#容器PaaS
富士通內部開始導入容器平臺，也將用OpenShift部署自家AI風險系統
＠內文：日本老牌IT廠商富士通也擁抱容器技術，近期該公司內部的商業智慧競爭力中心（BICC），為了更快讓應用程式可以交付至富士通其他國家分部，同時減少維運人員負擔、提高系統可用性，開始擁抱容器技術及Kubernetes，採用紅帽OpenShift作為該儀表的底層系統，藉以提升系統的彈性、可用性及擴充力，藉此加速該公司內部應用程式的開發、交付速度。富士通也預計在2019年3月時，將自家建置的風險迴避AI系統，部署於OpenShift上運作。同時與擴大與紅帽合作，未來要在富士通公有雲服務上，提供代管OpenShift服務。
#Kubernetes管理、#Log追蹤
Log管理工具Scalyr新增Kubernetes叢集監控機制，還強化監控團隊協作討論機制
主打通用Log管理工具的Scalyr最近宣布推出Kubernetes叢集監控機制，可以提供一個集中式的監控平臺，來追蹤整套Kubernetes環境的運作，而可進一步細分成不同應用程式層級的角度來尋找容器環境的問題。另外也強化了多項協同追蹤的功能，例如提供了圖表註解，方便維運團隊彼此討論。發現問題事件後，還可直接連結到該事件所對應的程式碼儲存庫，例如在GitHub或GitLab上的專案連結，來減少開發團隊搜尋問題程式碼的動作。另外，現在也可以串接到AWS的雲端監控服務CloudWatch。Scalyr預計在第四季結束前正式推出這些新功能

#DevOps、#IDC
IDC預測：2021年，65％資訊長都會擁抱DevOps和敏捷來加速創新
調查公司IDC最近發布了未來10大科技預測，第一項預測就是，2021年時，7成資訊長要建立敏捷連結力，透過API和各種新興數位解決方案，來串連雲端平臺或新創服務。另一個趨勢則是，2021年時，65％的資訊長都將擴大引用DevOps和敏捷作法，來加快創新和執行的速度。
責任編輯／王宏仁
更多Container動態
現在ARM處理器也能租了，亞馬遜AWS推出自製CPU的全新EC2運算服務
微軟釋出Azure DevOps Server候選版本，提供本地Azure DevOps部署選項
紅帽釋出RHEL 8 Beta版本，提供原生容器開發包
＠資料來源：iThome整理，2018年11月
 
 
",https://www.ithome.com.tw/news/127385,"新聞,AWS,EKS,DevOps,Firecracker,Outposts,IT周報"
127363,12,2018-11-29,Cloud周報第4期：Pure Storage推出AWS雲端資料管理服務,Pure Storage的AWS雲端資料管理服務，可將企業資料中心內的Pure Storage儲存架構，延伸到雲端。未來更有機會看到，Pure Storage在其他公有雲上，也推出雲端資料管理服務。," 重點新聞（1122～1128）
Pure Storage    AWS  
Pure Storage在AWS上推出雲端資料管理服務
Pure Storage推出AWS雲端資料管理服務，包括了AWS版雲端區塊儲存、AWS版雲端快照（CloudSnap）和雲端重複資料壓縮服務StorReduce，可將企業資料中心內的Pure Storage儲存架構，延伸到雲端。雲端區塊儲存可供企業應用更容易轉移到雲端部署，而CloudSnap則可將企業機房內快閃陣列的快照，自動傳送到S3上儲存。StorReduce則是可以用來加快傳輸到S3上儲存的備份資料。Pure Storage也提到，不只AWS，之後會考慮在其他公有雲上也推出這些雲端資料管理服務。（詳全文）
  EC2     預測性擴充  
AWS自動擴充功能再進化，推出EC2預測性自動擴充功能
原有AWS自動擴充功能可依據所用的AWS服務用量變化，自動擴充運算力，以避免過度配置虛擬機器而導致成本大增。最近AWS進一步推出了EC2預測性擴充功能，利用機器學習技術，來預測用戶每日和每周的流量，自動建立每日和每周流量預期高峰的擴充計畫。
這項預測性擴充功能的演算法，會根據用戶所用EC2虛擬機器每日和每周的流量變化來修正預測結果，用戶不再需要手動調整自動擴充功能的參數，也讓自動擴充功能更易於配置。AWS表示，新功能會提供用戶更快、更簡單也更準確的EC2用量配置。新功能目前支援包括美國俄亥俄、維吉尼亞和奧勒岡洲機房、歐洲愛爾蘭以及亞太地區的新加坡機房。（詳全文）
  AWS    故障  
配置出錯導致南韓AWS斷線84分鐘，殃及當地電商和加密貨幣的交易
南韓AWS機房於11月22日因內部伺服器發生故障，網路中斷長達1個多小時之久，導致南韓最大網路商城Coupang、餐點外送服務平臺POOQ、飯店訂房網Yanolja，甚至加密貨幣交易所Coinone和Upbit等都受到牽連，在故障期間皆暫停提供服務和進行交易。 AWS也隨即展開緊急調查，發現是因為他們在韓國資料中心的DNS服務配置設定錯誤，導致EC2執行實例的DNS解析遭到阻擋，長達84分鐘後才修復。後來AWS也發布公告解釋事故原因，因為AWS在韓國企業用戶很多，尤其是多家韓國銀行、大型消費電子集團都採用，這次事故也引起當地高度討論。（詳全文）
  英航   資料中心 
資料中心供應商遭告，英國航空要他們為去年672班航班大取消事件負責

英國航空宣布，將控告管理其資料中心的美國外包公司CBRE。英航將去年5月在倫敦希斯洛機場遭遇的IT故障事件，歸咎於CBRE網路故障所導致。當時因位在西倫敦的資料中心事故導致系統中斷，不只乘客報到手續的操作系統受到影響，也導致通訊中斷，讓英航難以聯繫空服和地勤人員，進而造成大規模的航班停止營運。事發當時正值英國5月的銀行休假日，總計當時有672架班次被迫取消，7萬5千名乘客滯留於機場。英航母公司國際航空集團證實，該事件的賠償費和業務流失所造成的企業損失，大約有5800萬英鎊。CBRE表示，身為英航設備的管理員會全力支持調查，但目前事件的原因尚未判定。（詳全文）
微軟    FSLogix  
微軟收購FSLogix，要用來強化Office 365虛擬桌面
微軟收購了一家應用程式調度平臺FSLogix，計畫使用FSLogix的技術來改善Office 365的虛擬桌面體驗，不過，微軟並未公布收購金額。微軟在9月推出了Windows虛擬桌面，可在Azure雲端虛擬桌面上快速部署Windows和Office。微軟希望併購FSLogix，來加快Outlook和OneDrive載入用戶資料的速度。除此之外，也希望用來強化Office 365 ProPlus的多用戶虛擬環境效能，例如虛擬桌面能有更好的執行速度。（詳全文）
CloudWatch    自動儀表板 
Amazon CloudWatch推出自動儀表板，可用來監控所有AWS資源
近日，AWS的雲端資源和應用程式監控管理服務Amazon CloudWatch推出了自動儀表板功能，用戶可透過這個新工具來監控所有AWS資源的運作狀況和性能，以資源為基礎來建立各種指標和警報，以利分析出影響效能的原因。在AWS服務推薦的最佳實務配置建議中，也已經預設啟用自動儀表版功能，仍保留原有的資源預警機制，但大幅更新了關鍵效能矩陣的呈現，用戶也不需自己添加程式碼，就可以使用過濾機制來建立特定的監控視圖，以掌握最新AWS資源的情形。用戶可在所有AWS服務的區域使用，不需額外付費。（詳全文）
Python    IBM Cloud Functions 
IBM Cloud Functions無伺服器服務開始支援Python 3.7
IBM近期宣布，無伺服器服務IBM Cloud Functions現在開始支援Python 3.7。開發者只需在命令列啟用Python runtime時多輸入「–kind python:3.7」參數，或是在建立新的行動時選擇Python 3則可支援。支援Python 3.7後，Functions可支援Context變數、資料類別、數據階層、事後計算的類型註解、可客製模組屬性的存取方式，另外，時間模組也可支援到奈秒。（詳全文）
  DataSync    加速數據傳輸  
AWS推出新資料同步服務DataSync，傳輸速可加快10倍

AWS推出新的資料同步服務DataSync，可在企業本地端儲存系統、Amazon S3或Amazon EFS（Elastic File System）之間自動搬遷資料。AWS指出，這項服務使用了專用的傳輸協定來加快透過網際網路或是AWS Direct Connect專線傳輸資料的速度。官方宣稱，傳輸速度可比開源工具快10倍。
AWS表示，企業用戶有大量資料移動需求，像是資料搬移、上傳至公有雲、備份及災難復原等需求。企業使用DataSync服務時，得先安裝一個本地端軟體代理程式，來連接本地端儲存設備，再透過雲端服務自動進行傳輸，用戶不用自行撰寫控制用的腳本程式，也不需修改應用和資訊基礎架構。企業可以一次性用DataSync傳輸本地資料，或是隨時將本地端資料送到雲端分析，也能設定自動在AWS建立副本來保護資料或日後復原之用。這次推出的AWS DataSync，是一個按用量計價的資料傳輸服務，這項服務目前支援10個區域，在亞太地區，包含首爾、新加坡、雪梨和東京都可使用。
AWS DataSync同步支援上雲、下雲的功能，瞄準的是混合雲市場。儘管，不少企業已開始採用公有雲，但本地端環境內的工作負載仍占不少比例，因此，現在有許多廠商正朝著讓企業用戶的IT架構，能保有最大選擇彈性的方向來發展服務。（詳全文）
圖片來源／Pure Storage、英國航空、AWS
 更多Cloud動態 
1. 微軟Azure的多因素身分認證服務MFA再度發生故障，搶修花費近3小時
2. AWS宣布推出第一個自製CPU的EC2運算實例，以ARM架構設計
3. Cylance端點偵防系統上AWS，結合AI掃描外部威脅，確保AWS實例應用程式的執行安全
資料來源：iThome整理，2018年11月
",https://www.ithome.com.tw/news/127363,"新聞,Cloud,Pure Storage,EC2,AWS斷線,Office365,Python 3.7"
127261,12,2018-11-26,台灣大哥大率先推出Azure Stack公有雲服務，微軟Azure雲分身在臺落地,企業上雲又多了一個新選擇，台灣大哥大採用微軟Azure Stack平臺打造了一個公有雲服務，開始在臺提供與Azure雲端服務相容的本地端IaaS服務。," 企業上雲是趨勢所在，台灣大哥大今日（26日）宣布，推出全臺第一個Azure Stack落地公有雲服務。台灣大哥大商務服務營運長吳傳輝表示，此落地公有雲會部署在取得Tier III認證的台灣大哥大雲端IDC機房，並會結合台灣大哥大的網路寬頻優勢，讓臺灣企業能夠運用雲端的優勢，同時符合臺灣現行法規限制特定產業資料不可儲存於境外的規定。
目前，三大公有雲巨頭，只有Google Cloud先在臺建置資料中心，而AWS和微軟Azure在臺均無機房。台灣大哥大採用微軟Azure Stack平臺所建置的雲端IaaS服務，等於是為微軟Azure服務的分身，有類似的管理機制和服務介面，不過，所提供的服務則由負責營運的台灣大哥大決定，服務不一定會和微軟Azure相同。台灣大哥大指出，租用在地IaaS服務，可連線本地機房，藉高速電信頻寬達到低網路延遲，另外，台哥大也想搶攻那些受限於法律規範，不可將資料儲存於境外伺服器裡的產業，如金融業和政府機關。
不過，不只台哥大，遠傳也在稍早宣布，同樣採用了微軟Azure Stack平臺來提供混和雲服務，但從網站資訊可發現，相較台灣大哥大網站已經揭露了詳細的租用價格，也可提供試用申請等自助式服務入口，遠傳則沒有揭露所提供的IaaS服務類型，如VM規格、定價等，而是只提供了一個申請表單，企業如想要使用遠傳的服務，仍需與專人聯繫接洽，尚未達到雲端自助式公有雲服務的階段。
關於台哥大Azure Stack落地公有雲服務的計價方式，台灣大哥大企業產品暨營運管理處副處長魏政賢說明，企業用戶可按照運算資源的需求，以租用所需虛擬機器數量的方式，用多少付多少，按使用時間的小時數來付費，或如有使用合作軟體程式開發商所提供解決方案的需求，則可按繳納月租費的方式，租用打包好的解決方案。
企業用戶如遇特殊情節，在短時間內面對流量暴增，如電商在雙11時，面對暴增的流量需要擴充支援，對此魏政賢強調，台灣大哥大的Azure Stack落地公有雲可即時支援企業用戶擴充的申請，小則十位倍數，大則百位倍數的擴充需求都能因應。不過，他沒有透露，最大可擴充的VM機器數量規模，或台哥大已部署Azure Stack的伺服器數量。
台灣大哥大也自行建立一個技術支援團隊，來協助企業用戶，可提供7天24小時的安全監控與在地化客服。魏政賢透露，台灣大哥大與微軟接洽前後已歷時2年，期間技術人員一直不斷在測試系統服務的流暢性，團隊從中已建立一定的技術支援能力。
為了更進一步打造Azure Stack生態圈，台灣大哥大也與多家獨立軟體程式開發供應商合作，發展多項企業雲端垂直或水平的應用，與合作廠商推出的解決方案包括Critix的未來數位工作式、 Check Point的多層次防護混合雲資安服務、金財通商務科技金商物流的整合服務、天心資訊的企業EPR智慧互連運用解決方案、碩網資訊的人工智慧機器人平臺、芝麻開雲科技的混合雲遷移備援服務等。
Critix提供的虛擬桌面服務，因應企業用戶內部員工用個人裝置，處理工作事宜所產生的資安顧慮。Critix在台灣大哥大發布會現場展示了兩項獨家功能，透過QR Code掃描，可將前個裝置上正在進行但中斷的工作，投射在其他裝置上，以從暫停處繼續進行待完成的工作。此外，Critix在工作畫面上也提供浮水印的功能，以防止裝置畫面被翻拍，後續畫面外流的情況發生。
從現在開始，至明年6月30日前，台灣大哥大提供申請Azure Stack服務的企業用戶，每個帳號每月有500GB的免費網路流量，台灣大哥大表示，目前大部份企業用戶的網路使用流量不到100GB。
",https://www.ithome.com.tw/news/127261,"新聞,Cloud,落地公有雲,台灣大哥大,Azure Stack"
127224,12,2018-11-23,微軟釋出Azure DevOps Server候選版本，提供本地Azure DevOps部署選項,導入舊版產品Team Foundation Server的企業用戶，Azure DevOps Server可以支援Team Foundation 2012後的版本，直接進行更新。," 在今年9月時，微軟宣布將Visual Studio Team Services整合至雲端DevOps服務Azure DevOps，同時提供本地端部署的Team Foundation Server，也將更名為Azure DevOps Server。而近日，Azure DevOps Server終於釋出了第一個候選版本。微軟Azure DevOps產品管理總監Jamie Cool表示，必須在本地環境執行Azure DevOps服務的用戶，此產品可以提供隔離性的Azure DevOps實例。
在Azure DevOps Sever實際功能面，此候選版共推出了兩個新服務。第一個亮點是支援Azure SQL，讓企業用戶可以在本地環境內，整合Azure DevOps Server及自有的SQL Sever，或者在公有雲環境，自行架設Azure DevOps環境。微軟釋出此功能，便是瞄準了混合雲市場，一方面在公有雲上提供代管Azure DevOps服務，提供自動更新、自動水平擴充功能。另一方面，則是提供企業高度的管理自由，提供自建、自行部署選擇。
第二個新功能，則是改善維運效能，讓IT人員可以更密切掌握當前部署的狀況。微軟解釋，Azure DevOps Sever提供點對點追蹤功能，系統會觀察當前應用程式正進行部署，以及此應用的部署位置。
至於導入舊版產品Team Foundation Server的企業用戶，微軟表示，Azure DevOps Server可以支援Team Foundation 2012後的版本，直接進行更新。
",https://www.ithome.com.tw/news/127224,"新聞,Azure,DevOps,公有雲"
127223,12,2018-11-23,VMware在臺揭露明年將擴大VMware Cloud on AWS混合雲服務版圖，不只歐美，更要搶進亞太市場,VMware Cloud on AWS從原先只在歐美提供服務，今年開始將版圖延伸進亞太地區，除了東京已在稍早11月擁抱此服務，明年更有多個亞太據點可開始使用此服務。," 身為虛擬化平臺龍頭的VMware掌握企業私有雲平臺，從去年開始，與AWS聯手推出混合雲的解決方案VMware Cloud on AWS，打通私有雲與公有雲的經絡。不過原本這項服務只先提供歐美地區的企業用戶使用，直到VMware近期在臺北vFORUM2018會上宣布，自11月11日起，位於東京的AWS資料中心，也開始提供這項混合雲服務，這也意味著，臺灣企業想要將私有雲的虛擬化應用搬上AWS公有雲將變得更容易。
除了今年開始支援雪梨與東京，其他亞太地區包含新加坡、香港、首爾等，都將在明年迎來VMware Cloud on AWS，VMware大中華區策略發展副總裁李映更在臺揭露，VMware Cloud on AWS將在2020年加深中國市場的布局，顯現VMware要擴大進軍亞太地區的企圖。

VMware Cloud on AWS服務版圖，揭露明年度以及2020上半年度的版圖​拓展計畫。（攝影／黃郁芸）

今年是VMware成立的20周年，VMware全球副總裁暨大中華區總裁郭尊華回顧過去20年來VMware產品開發的歷程，皆與企業不同時期所面臨的IT挑戰息息相關。
從一開始，企業在購買特定品牌伺服器時，容易受到廠商綁定，迫使他們必須選邊站，無法根據自己所面對各種複雜的應用環境需求，彈性地來自由搭配選擇，後來，VMware因此而推出ESX虛擬化方案，讓企業著手於伺服器導入虛擬化架構，使得企業現在能在一臺臺通用x86伺服器上，以一個或多個VM（虛擬主機）方式來執行各種商業應用，讓他們可以自行選擇搭配的硬體，進而避免受到廠商所綁定，也提供了可以搭建不同伺服器間的連結方式。
接著，跨入行動化裝置的時代，企業面對到員工自帶裝置（BYOD）處理公事帶來的資安控管挑戰，VMware也開發產品因應此狀況，如推出VMware Workspace ONE的技術，提供跨裝置平臺的一致性管理，當企業員工的裝置連結到內網，以虛擬機器建立桌面虛擬化場景，來使用企業應用，讓企業的資料不外洩，保護商業機密。
而當企業走向現代化資料中心， 為了需要處理大量的網路流量，以及滿足不斷擴充硬體的迫切需求，而掀起一波軟體定義網路（SDN）與網路功能虛擬化（NFV）風潮。為此，VMware大舉併購虛擬網路新創公司Nicira來因應，提供企業用戶VMware NSX網路虛擬化技術，以解決硬體網路僵化的困境，實現網路水平的連結。VMware指出，他們會持續透過軟體定義的營運措施，幫助企業達成數位轉型。
目前，NSX有超過8千萬個以軟體定義網路的交換器連接埠，財富雜誌的百大企業有82%採用NSX。李映表示，NSX不僅幫助企業在資料中心實現軟體定義，管理東西向的流量，VMware也通過與公有雲合作，將軟體定義網路的模型架構拓展到公有雲，甚至在未來拓展到邊緣運算。從傳統資料中心的網路架構，發展成虛擬雲網路（ Virtual Cloud Network）。
網路虛擬化到虛擬雲網路的發展，也進而會影響電信環境。為搶攻電信市場，VMware推出軟體定義廣域網路解決方案NSX SD-WAN by VeloCloud，提供電信環境中的應用程式和資料，持續連線性和安全性的服務，建構具有端到端服務能力的網路平臺。VMware觀察到，現今電信網路不到10%完成網路虛擬化，5G的來臨將使電信業者的服務邁向多元化，不再只是增加容量和加快速度，VMware認為電信網路架構必須重新打造。李映進一步指出，5G將推動技術的融合，無論是有線和無線網路、私有雲和公有雲，以及電信業者與邊緣網段雲端之間的界線都將變為模糊，成為整合的資源池。
",https://www.ithome.com.tw/news/127223,"新聞,VMware,虛擬化,Cloud,5G,混合雲"
127175,12,2018-11-21,Cloud周報第3期：整合百家企業資料，經濟部工業局打造企業資料共享合作平臺DataMart,經濟部工業局局長呂政華分享，企業資料共享合作平臺DataMart創造了1千萬用戶服務規模，平台提供數據、API存取、分析模型和合作業者。," 重點新聞（1115～1121）
  經濟部     企業資料共享平臺  
工業局打造企業資料共享合作平臺
經濟部工業局局長呂政華日前在台灣雲端物聯網產業協會揭露，過去一年政府在雲端和巨量產業上推動的成果。為加速虛實整合新事業發展，經濟部打造了百家企業資料共享的合作平臺DataMart，創造了1千萬用戶服務規模。平臺首先收集了巨量資料，分別來自18種臺灣家電品牌裝置和1千1百萬筆生活型態數據，以及9大社群網站的數據，接著提供7項API串接，有消費數據API、社群觀測API、議題分析API等存取方式，再進而有預測分析的消費數據模型、社群偏好模型、議題分析模型等模型，最後，透過平臺可與國內裝置業者達成合作，包含東元、聲寶、大同、HTC等。
  IBM    自動化遷移工具  
IBM推自動化雲端遷移工具，簡化和加速企業應用遷移至混合雲
IBM針對混合雲市場布局再出招，推出一系列為加速雲端遷移和混合雲部署的技術和服務。主打雲端資料自動化遷移工具，使用IBM雲端遷移工廠裡的演算法，簡化和加速企業數位轉型時，將應用遷移至雲端或採用混合雲策略的複雜過程，減少移動和現代化企業基礎架構、數據、應用程式和工作負載的時間。新工具集裡含深入洞察的演算法，可在早期查看應用程式的關聯性、依賴關係和組件，以推薦遷移途徑，來提升遷移計畫的準確性和降低風險發生的機會。（詳全文）
  AWS    Redshift   
AWS強化Amazon Redshift的彈性，只要幾分鐘就可增減節點

AWS宣布可快速擴展的資料倉儲Amazon Redshift新增Elastic縮放尺寸的功能，現可在幾分鐘內增加和刪除節點，以便針對需求，增加節點以提高工作負載的性能和記憶體，而當作業完成時，也可以移除節點來節省成本。Elastic縮放尺寸功能在增減節點上，可大大減少過去Amazon Redshift使用Classic縮放尺寸功能所要花費的時間，也能降低干擾進行中的資料庫讀寫查詢。不過，如果需要改變節點的型式，用戶仍可透過Classic縮放尺寸功能來完成，而Elastic縮放尺寸並不支援DC1的節點型式。（詳全文）
  WorkSpaces    BYOL 
亞馬遜發布自帶授權自動化操作，能將Windows桌面快速移動到WorkSpaces
AWS雲端桌面託管服務WorkSpaces推出以自帶授權（bring your own license，BYOL）的自動化操作，可將Windows 7和Windows 10桌面操作系統帶入Amazon WorkSpaces。此自動化操作是把用戶已有的微軟桌面系統授權帶進Amazon WorkSpaces，能快速地將上百，甚至上千的微軟桌面移動到WorkSpaces。當用戶的帳號被賦予BYOL，只需要3個步驟就可完成操作，首先，使用VM Import API匯入現有Windows 7或Windows 10的圖像，然後，在WorkSpaces管理控制臺中，在「圖像」頁面上選擇「建立BYOL圖像」操作，以使用剛剛匯入的圖像，建構自訂的WorkSpaces圖像。最後，根據自訂的WorkSpaces圖像，在WorkSpaces管理控制臺中的「圖像」選項裡，建構自訂的WorkSpaces包裹。（詳全文）
開放架構高峰會    OpenStack  
OpenStack高峰會下屆將改名為Open Infrastructure高峰會

OpenStack Summit上周在柏林登場，OpenStack基金會宣布，因應開放基礎架構的重要性日漸加增，OpenStack社群的重要年度活動Open Stack Summit，將改名為Open Infrastructure Summit。會上OpenStack基金會也宣布，最新第20版的OpenStack將以Train命名，但基金會並無說明Train釋出的時程點，不過按照每年平均更新兩次OpenStack版本的頻率，Train可望在明年推出。而首次Open Infrastructure Summit明年4月底將會在美國丹佛舉行，明年下半年度的Open Infrastructure Summit則會移師中國舉行，但活動的城市尚未公布。（詳全文）
OpenStack    4大專案 
OpenStack基金會4大新孵育對象，開放基礎架構為特點
因應開源的浪潮，OpenStack基金會在上周的OpenStack Summit以開放式基礎架構為關鍵，提出4大先導專案扶持的對象。首先是雲端建置、管理工具Airship，該工具因採用宣告式框架的設計，讓使用者可以管理、定義基礎架構工具和底層硬體的生命周期。接著是容器專案Kata Containers，透過整合Intel輕量虛擬化技術Clear Containers、相容開放容器OCI標準的runV，讓基礎架構可兼具虛擬機器的安全性，以及容器技術的輕量化特性。還有OpenStack基金會釋出的邊緣雲專案StarlingX，以物聯網軟體廠商Wind River旗下的Titanium Cloud產品為基礎，開發者可以部署在邊緣環境，或選擇建置邊緣雲所需要的軟體服務。最後是也由該基金會所發展的CI/CD工具Zuul，現階段可以支援Python 3，並且利用Ansible作為驅動DevOps流程的執行工具。
OpenStack基金會表示，此項新決議將擴展基金會為開發人員、用戶和開放架構生態系提供服務的使命，通過共享一組資源來構建社群，促進用戶之間的協作，以及支持開源基礎架構技術的整合實現。基金會的目標是幫助這些新項目從試驗階段，發展至確立的階段。（詳全文）
Azure Monitor    支援開源資料庫 
Azure Monitor開始支援自家Azure雲端版開源MySQL、PostgreSQL資料庫
微軟近期宣布，Azure公有雲下的監控服務Azure Monitor，開始支援自家Azure雲端版開源MySQL、PostgreSQL資料庫，讓用戶除了第三方解決方案外，多了原廠解決方案可選擇。而用戶如已使用第三方廠商的解決方案，可利用合作夥伴的整合套件，也能整合Azure Monitor成為另一資料來源，以豐富企業內部監控儀表板的數據來源。Azure Monitor可以搜集雲端環境內的資料，協助企業了解基礎架構當前的運作情形。而利用Azure Monitor監控雲端資料庫運作的企業用戶，可以直接從Azure Portal掌握資料庫的運作情況，多個關鍵數據會呈現在儀表板上，包含資料庫吞吐量、儲存空間、延遲性，以及可用性等。（詳全文）
CIF    雲端基礎設施  
CIF調查研究：企業在雲端基礎設施的花費已超越本地端部署
英國非營利雲端產業論壇Cloud Industry Forum（CIF）針對英國的IT和業務決策者進行雲端使用的調查，研究發現雲端基礎設施花費已超越本地端部署，用於雲端基礎架構的支出占19％的IT預算，而本地端部署則占18％，雖僅是小小1%的差距，但這是第一次，雲端基礎架構支出首度的超越。儘管如此，雲端基礎設施和本地端部署花費上的差距，將在未來三年顯著的擴大，因企業和組織將把老式的IT系統除役，會大大拉高新一代技術的投資金額。（詳全文）
  物聯網通訊    SpaceX   
FCC核准SpaceX通訊衛星再部署及擴充計畫

美國聯邦通訊委員會（FCC）近日核准了SpaceX的非靜止軌道通訊衛星（NGSO）部署及擴充計畫，將使SpaceX於3月獲得4,425個通訊衛星之外，能夠再增加部署額外的7,518個通訊衛星。除了這7,518個通訊衛星被授權使用V頻段（37.5~42.0 GHz及47.2~50.2 GHz），FCC也同意讓前一波核准的衛星使用V頻段。而新一波衛星會運行在超低軌，高度大約是在海拔335公里至346公里。SpaceX計畫在2019年到2024年間部署前一波的4,425個通訊衛星，最快可在2020年提供全球性的寬頻網路服務。（詳全文）
圖片來源／AWS、SpaceX；攝影／蘇文彬、黃郁芸
 更多Cloud動態 
1. 8月初推出的Amazon Aurora Serverless，繼亞太區只支援東京，現在新增支援新加坡等4個亞太區據點
2. Sauce Labs發表首款雲端無頭瀏覽器測試解決方案Sauce Headless
資料來源：iThome整理，2018年11月
",https://www.ithome.com.tw/news/127175,"新聞,Cloud,IBM,AWS,OpenStack,SpaceX"
127130,12,2018-11-19,本土跟進搶攻邊緣運算市場，宏碁推出AIoT邊緣運算裝置aiSage,宏碁榮譽董事長施振榮表示，需靠分散式的邊緣運算，才可應付AIoT時代下的運算需求，宏碁將朝此方向努力。宏碁今發布AIoT邊緣運算裝置「aiSage」，透過AI加值，要為企業提供更有效率的客製化解決方案。," 看準AIoT的發展，宏碁今天（19日）宣布，自建雲智慧產品線推出了一款內建鏡頭的AI邊緣運算裝置aiSage，主打影像辨識能力，要來搶攻AI技術結合IoT裝置的邊緣運算市場。
aiSage外型簡約，長32公分、寬5.5公分，以及高度2.59公分，可直接裝置在螢幕上，外型就像是微軟已經停產的Xbox Kinect體感裝置，但具有商用級的硬體規格，內建6核心的（ARM Cortex A72雙核心+四核心Cortex-A53）處理器和4核心的Mali T-860MP4 GPU，內建2GB記憶體和32GB儲存空間，也提供有線和無線網路、USB、Com埠、HDMI等介面，而前置鏡頭可拍攝1080P解析度的影片，有70度以上的視野。
aiSage採用分散式運算架構，可用來安裝應用程式或進行資料初步數據，讓現場端的設備和裝置能即時反應。搭載Android 7.1作業系統或Debian Linux，支援TensorFlow Lite機器學習框架，Caffe框架以及神經網路加速器，另外在應用層則支援電腦視覺模型或邊緣運算應用。而aiSage採無風扇散熱設計，可用於攝氏50度到零下10度的環境。
aiSage目前也可支援AWS影片串流服務Amazon Kinesis，可將aiSage所錄製的影片傳上AWS雲端，再透過AWS機器學習服務來分析。另外，aiSage也可安裝訊連科技的FaceMe臉部辨識引擎Android版SDK，來提供臉部辨識功能，目前可辨識性別、年齡、情緒等特徵，可用於電子看板、資訊服務站、零售系統等應用的臉部辨識功能之用。

aiSage導入訊連科技FaceMe臉部辨識引擎SDK，可辨識畫面中，每一個人的性別、年齡甚至情緒。螢幕上方的裝置為aiSage實體。攝影／黃郁芸

宏碁目前也開始拓展aiSage的垂直應用，並與人工智慧解決方案供應商結盟，目前已有零售業先試用，如漢神百貨導入的智慧零售解決方案，而長照方面與緯創資通合作智慧型照護整合方案，以及資安方面，整合安碁資訊的資安妙管家，藉aiSage與內網連線，定期檢測主機及網站的資安程度，進而修補弱點。
其中，緯創資通的智慧型照護整合方案，可設定居家偵測區域的範圍和管制的時間，再透過aiSage來偵測區域內的人的行為，可偵測如跌倒或進入危險區域、徘徊等異常行為，並即時通報，讓醫護人員和子女掌握長者的行動。

緯創資通推出的智慧型照護整合方案，可支援aiSage，能標示出管制區和徘徊區的範圍，透過機器視覺偵測區域中跌倒、入侵、徘徊等異常行為，並立即通報。攝影／黃郁芸

",https://www.ithome.com.tw/news/127130,"新聞,AIoT,邊緣運算,Cloud,宏碁,臉部辨識"
127094,12,2018-11-16,Cloud趨勢周報第2期：MOMO購物網雙11流量創新高，一度大當機,雙11瘋購物，MOMO購物網流量暴增7倍，網站更一度進入網頁維護。另外，微軟近期在Office 365藍圖上，新增「Google G Suite搬遷工具」計畫，微軟要開發Google Suite的搬家工具，雲端服務客戶搶奪戰即將開打。," 重點新聞(1108～1114)
  MOMO購物網     塞爆當機  
流量暴增七倍撐不住，MOMO購物網雙11搶購日一度大當機
儘管為了因應一年一度的雙11購物節，MOMO購物網早就比去年準備了更高備援容量，但在10日晚上，MOMO購物網就開始出現塞爆的狀況，從9點20分左右陸續有消費者在MOMO購物網的臉書粉絲頁上抱怨，無法進入網頁或無法把屬意的商品加入購物車，甚至有網友購物車裡的商品全都不見。富邦媒總經理林啟峰向媒體解釋，10日晚上流量爆增7倍，導致網站不穩。根據MOMO購物網官方統計，當時的流量再創站方歷史新高，比去年雙11的高峰還要更大。MOMO也緊急在11日中午宣布暫時關站進行設備維護，一直到當日傍晚接近4點，MOMO購物網才在臉書貼文公告，網頁恢復全線通暢。儘管此次狀況凸顯事前再多準備也難以預料實際爆量的情況，不過，這波事件也引起開發圈的反思，對於技術架構如何調整才能快速因應的討論，可能有機會成為電商業者的轉機。
  網際網路傳輸協定    HTTP/3  
新一代網際網路傳輸協定將命名為HTTP/3，HTTP/QUIC取代TCP協定
標準組織網際網路工程任務組（Internet Engineering Task Force, IETF）近日商討下一代HTTP底層協定，可望將改用以UDP協定發展出的QUIC技術，不再使用沿用多年的TCP協定，同時新一代HTTP的名稱確立為HTTP/3。現今傳輸控制協定TCP有安全、流量穩定、講求封包的傳輸順序等優點，但缺點是效率低、連接耗時。為了提升資料在IP網路上的傳輸，Google提出了使用UDP為底層實驗性網路層協定，稱為QUIC，UDP雖然較不安全、可能有掉封包或封包後發先至的問題，但較簡單、傳輸效率更高，能大幅減低延遲性。雖Google有意將QUIC提交到IETF，以成為下一代網際網路規範，但IETF也提出了一個和Google QUIC分庭抗禮的QUIC。HTTP工作小組暨QUIC工作小組主席Mark Nottingham申明，HTTP/3並非HTTP/1.1或HTTP/2的後代，也不是QUIC上的HTTP/2協定，因為它是在QUIC協定上新開發出的HTTP。Litespeed的工程師宣布該公司和臉書已經完成HTTP/3實作的相容性測試。 （詳全文）
  微軟    Google Suite搬家工具   
眼紅Gmail破15億用戶市場，微軟正著手開發Google Suite轉移到Office 365的搬家工具

雲端服務客戶搶奪戰即將開火，微軟近期在Office 365藍圖上，新增「Google G Suite搬遷工具」計畫，透露出微軟要開發Google Suite的搬家工具，方便用戶從Google G Suite上，將郵件、行事曆和通訊錄上的資料能快速搬遷整合進Office 365服務上。此工具預計在2019年第二季度推出。不過，也有技術顧問分析，微軟此舉是為了穩固Office 365的成長幅度，因為從Exchange本地端安裝到Office 365的搬遷用戶越來越少，微軟得開拓新客源。微軟強調，他們會提供高度安全的解決方案，讓數據直接匯入Office 365，並且會增加可支援遷移批量的電子郵件帳號服務。（詳全文）
  Dropbox    擴充工具 
Dropbox開始支援第三方工具線上編輯功能，用戶能直接在站內完成各項編輯

Dropbox推出第三方擴充機制Extensions，可以讓第三方業者的App，嵌入Dropbox中來進行內容編輯等作業，以強化Dropbox整合使用經驗。目前可支援的App包括了PDF文件類的Nitro、airSlate和Smallpdf、圖檔編輯類的Pixlr、影片類的Vimeo，以及電子簽章類的Adobe Sign、DocuSign和HelloSign等，讓用戶可直接在Dropbox環境下，編輯PDF文件、圖檔和註解影片，或是完成簽章，和他人共享DWG或影片檔。Dropbox指出，企業用戶工作流程上，往往牽涉多個App，而必須在不同視窗來回切換，這個擴充機制將能解決此不便，可直接在Dropbox上編輯後，就分享給其他人，省去下載編輯再回傳上Dropbox的步驟。Extensions功能將在11月27日正式釋出給所有用戶。（詳全文）
微軟    雲端合約  
擠下AWS，微軟拿下美國服飾Gap集團五年雲端合約

公有雲企業市場競爭激烈，尤其是指標型的大型企業，更是雲端業者角力之地。微軟動作連連，繼拿下Walmart的雲端解決方案合作協議，最近還搶到了美國服飾Gap集團五年的雲端合約，將把它旗下品牌的企業生產力系統，搬到Microsoft Azure及Microsoft 365上。在這項協議中，Gap集團旗下所有品牌，包含Old Navy、Banana Republic、Athleta等的數百支應用搬遷到Microsoft Azure上，以提升店內、線上商店及行動裝置上的顧客使用體驗。微軟表示，Gap集團將可應用進階的分析技術和機器學習技術，來更全面的了解顧客，以找出各品牌個性化的行銷、服務和組合產品，提供給顧客。
利用Azure平臺即服務，將可加快Gap集團新式應用的上線時間，Azure支援Gap集團的DevOps開發模式，使工程、產品開發團隊可迅速開發、部署及測試新功能。此外，Gap集團還將部署Microsoft 365，為其員工提供雲端生產力、通訊及協同應用。微軟也提到，Gap集團正在使用​Microsoft Power BI，讓更多員工可以視覺化的掌握資訊來採取行動，以提供顧客最好的服務。（詳全文）
GCP    Nvidia Tesla T4 GPU 
GCP現提供Nvidia Tesla T4 GPU，支援混合精度機器學習運算
GCP在雲端開始提供Nvidia Tesla T4 GPU的Alpha測試版，Tesla T4 GPU為機器學習推理、分散式訓練模型以及電腦圖形優化而設計，因此可以大幅提升這些任務的效率，GCP提到，他們是第一個提供Tesla T4 GPU的雲端供應商。與其他人工智慧技術相比，機器學習的推理階段特別需要高效能和低延遲的運算能力，Google提到，Turing Tensor Core支援FP32、FP16和INT8的各種精度模式，Tesla T4還實現高達130 TFLOPS的機器學習推理運算效能，延遲最低可達1.1ms。另外，Tesla T4附帶的16GB高速GPU記憶體，能幫助大型或是多個機器學習模型同時進行推理。（詳全文）
SageMaker    新加坡  
SageMaker擴大亞太區服務範圍，開始支援新加坡
Amazon旗下AI應用部署工具SageMaker最近擴大了亞太服務區域的支援，除原先的東京和首爾外，AWS宣布，Amazon SageMaker增加支援新加坡，對於習慣將自家服務部署在AWS新加坡資料中心的臺灣企業，現在也可以使用SageMaker來串接AI應用的開發和部署。同時增加的支援區域另有美國北加州、加拿大蒙特婁、英國倫敦和印度孟買，此次服務區域拓展讓Amazon SageMaker的可用區域提升至14個。（詳全文）
  EC2    AMD EPYC   
AWS推出採用處理器AMD EPYC的新EC2執行實例
AWS宣布推出新的EC2執行實例類型，可支援2.5 GHz的AMD處理器EPYC 7000系列，是通用執行實例M5和T3及記憶體優化執行實例R5的變體。官方宣稱，新款執行實例可讓用戶節省EC2運算環境的成本，和當前M5、T3和R5執行實例相比，可減少10％的花費，來解決用戶面對工作負載沒有充分利用所選執行實例的運算資源，但仍需要為不需要的性能付費的情況。用戶可透過隨需執行實例、預留執行實例或 Spot執行實例的形式購買，不過，要將現有執行實例上的應用程式遷移到新的執行實例時，還得需要些微修改。採用AMD處理器的R5和M5執行實例可以通過AWS管理控制臺或AWS命令行介面啟動，目前亞太地區只有新加坡支援。（詳全文）
  SageMaker    多項更新   
AWS機器學習部署工具SageMaker大更新
AWS去年年度大會推出了機器學習開發部署工具SageMaker引起很大關注，AWS今年發布的2017年報中更強調，AWS機器學習的服務的活躍用戶推出幾個月內的成長率超過2.5倍。AWS近日一口氣宣布了多項SageMaker的更新。SageMaker可以支援的機器學習框架版本也有更新，如可以支援到最新版的Apache MXNet 1.3，以及TensorFlow 1.11，不過還沒支援到TensorFlow最新的1.12版。用戶可以直接執行MXNet和TensorFlow的指令碼，並同時利用Amazon SageMaker所提供的各項功能，包含高性能演算法函示庫、模型自動調整的管理、分散式訓練、一鍵部署和託管部署等。另外，Amazon SageMaker也支援增量學習，可提供圖像分類物體偵測的演算法，也新支援加密資料金鑰服務。用戶現還可透過SageMaker控制臺複製調校好超參數的任務，不需再為新任務重新建立相同的參數資訊。（詳全文）
 
圖片來源／Dropbox、GAP
 更多Cloud動態 
1. Dropbox和Google擴展合作關係，通過Cloud Identity增強安全生態系統
2. IBM開放區塊鏈開發平臺給AWS和其他雲端服務商
3. 紐時宣布將逾500萬張歷史照片搬上Google雲端
資料來源：iThome整理，2018年11月
",https://www.ithome.com.tw/news/127094,"新聞,Cloud,電商,雙11,Office 365,Google G Suite,Dropbox"
127071,12,2018-11-15,如何克服傳統行銷預測模型的痛點？玉山銀上雲AI實戰大公開！,玉山銀行在傳統行銷預測模型，遇上資料爆量的難題，使得過去建立的預測模型，3到6個月才能更新一次。為了讓預測模型的更新速度更為快速，玉山銀從信用貸款產品開始，運用顧客瀏覽行為，在Google雲端平臺上建立一套機器學習行銷預測模型，要找出消費者在網站上購買信貸產品的關鍵要素，並讓廣告投放等行銷行為更為精準。," 早在2013年玉山銀行就成立了資料科學團隊，從傳統的資料倉儲分析、BI分析，進一步開始投入資料科學分析、大數據應用，近年也開始引進機器學習、雲端運算等新興科技。最近，玉山銀行數位金融長暨副總經理李正國在Google Cloud Summit活動上，揭露了玉山銀行利用機器學習建立預測模型，來解決傳統行銷痛點的經驗。
「玉山銀行在傳統行銷預測模型，遇到了許多挑戰。」李正國指出，最大痛點就是，不斷擴增的巨量資料，而這些維護龐大資料以供內部分析之用，也考驗著玉山IT硬體的效能與系統效率。
這個資料爆量難題，也讓玉山過去建立行銷預測模型時，通常得經過3到6個月，才能更新一次模型。但，李正國坦言，這樣的更新速度，遠遠跟不上顧客對玉山銀行銷售服務的期待，只有預測模型不斷更新，才能夠讓顧客在瀏覽網路銀行時，推薦最新金融產品或服務來吸引顧客。
除了速度，玉山也希望可以進一步提高推薦的精細度，李正國解釋，過往玉山是從單一產品行銷角度來看，分析顧客在網頁上瀏覽特定產品的行為，來推測顧客是否對特定一款產品的興趣程度來進行推薦。
但現在，玉山希望改以顧客為導向，不只看單一產品的瀏覽行為，而是轉而分析顧客在整個官網上的各種瀏覽行為，試圖想更精準地判斷顧客想要的金融產品。「一旦找出顧客在瀏覽行為上的細微變化，就能提供更為客製化的服務。」李正國說。
在GCP上建構機器學習平臺，打造信貸行銷預測模型
這些想解決的痛點，讓玉山銀行開始考慮採用Google Cloud平臺。
李正國提到，玉山銀行從信用貸款開始嘗試，利用Google雲端平臺來建立一套機器學習行銷預測機制。玉山銀行在GCP上租用虛擬機器自行建置了一套TensorFlow機器學習系統。再將大筆不涉及個資的線上顧客行為資料，如Log檔和點擊數據等，儲存到GCP的BigQuery雲端資料分析倉儲服務上，再抽取出需要的數據，放入雲端這套TensorFlow系統上用Python語言開發的機器學習程式，來訓練預測模型。
不過，銀行這麼多金融產品，為何先選用信貸？李正國解釋，玉山銀行有很大量的信貸顧客，例如房屋貸款、汽車貸款等，都是透過 Google關鍵字搜尋而來。顧客從搜尋關鍵字結果進入玉山網站後，打開的第一個頁面，就是到達頁面（landing page）。他說，到達頁面包含了許多與顧客溝通的數位內容，從顧客在這一頁的行為，加上顧客在站上其他頁面的瀏覽行為，以及顧客過去的成交記錄，「可以找出最後讓顧客在網站上完成信貸送件的關鍵。」
但只有分析線上顧客行為的資料還不夠，李正國強調，後續資料和變數的處理才是一大重點，例如如何判斷顧客的活躍可能性、瀏覽深度、平均成交周期等。例如在顧客活躍性上，玉山分析團隊會思考，一位在短時間內進到網站頁面瀏覽7、8次的顧客，看似信貸需求很強，但也可能有其他意圖。
至於瀏覽深度面向，則是會從一系列複合的瀏覽行為來分析，例如若顧客只瀏覽信用貸款相關頁面，就可以輕易推斷他有信貸需求。但也有顧客不只瀏覽信用貸款網頁，又會接著瀏覽信用卡通信貸款，就可推測這名顧客很有可能還是玉山信用卡用戶，或像是顧客還會登入玉山網頁，檢查自己有無負擔保責任，就表示他名下可能有房屋等不動產，而不只需信貸服務就夠。
李正國表示，從顧客在銀行網站中往返不同產品網頁之間，進行價格、額度或分攤時間等瀏覽比較行為中，就可以串連出很多精彩的變數。但要進一步結合這些顧客瀏覽頁面的次數、看過的產品或方案數量，甚至前述的瀏覽深度等變數，找出能影響信貸成交的關鍵，就得靠機器學習平臺打造出來的預測模型，找出消費者購買信貸產品的關鍵要素。
玉山銀利用雲端自建的機器學習平臺，來建立信用貸款的推薦模型後，從廣告投放的轉換率來看，過往玉山會投放大量網路廣告，即便成功吸引消費者打開銀行網頁，甚至瀏覽了許多頁面後，最後往往難以讓顧客申請信貸送件，等於白費功夫。李正國說，現在改用機器學習訓練的新模型，能讓行銷變得更為精準，也等於降低了在信貸產品的廣告投放轉換成本。
不只如此，李正國更看重的是，可以根據顧客新的行為資料，不斷重新訓練出新的模型，所以，「預測模型可以維持新鮮，預測能力也維持恆定的水準，這也能解決了過去玉山3到6個月才能更新一次預測模型的痛點。」
李正國透露，玉山的投放廣告轉換率因此而提升了7.5倍。因此，不只信用貸款產品，未來還可延伸到更多相似的目標客群，如理財、外匯、信用卡、購物推薦都將是未來的應用方向。文⊙李靜宜
更正啟事：玉山銀行11/16下午來信，提及演講時中談到大筆不涉個資的「結構化與非結構化」線上顧客行為資料取自「網路銀行、官網」以及玉山銀行有「75％」的信貸顧客來自Google關鍵字搜尋，兩者括弧中的資訊有誤，內文已更正。
",https://www.ithome.com.tw/news/127071,"新聞,玉山銀行,GCP,Cloud,機器學習"
127036,13,2018-11-14,展望新一代高效能運算應用崛起，Nvidia彙整多種領域開源軟體，並提供新型雲端GPU加速卡，推動各產業應用,在高效能運算應用的領域，GPU角色越來越吃重，而且，隨著人工智慧當道，更增添了對於各種加速技術進展的渴望，Nvidia今年在美國超級電腦大會期間，發布了當前他們對於高效能運算的發展藍圖，當中揭示了近期陸續發表的各種軟硬體解決方案，以及拉攏企業跨入這個領域的企圖心," 【美國達拉斯現場報導】本週舉行的美國超級電腦大會剛好滿三十周年，Nvidia公司創辦人暨執行長黃仁勳在這場活動期間，以新一代高效能運算（New HPC）為題發表演講，探討他們對於現今HPC應用的最新看法，並介紹該公司今年針對機器學習加速而發展的開放原始碼軟體套件RAPIDS，以及去年發表的雲端加速容器登錄服務NGC（Nvidia GPU Cloud）最新進展，同時，也揭露他們在雲端GPU橫向擴展應用的最新產品Nvidia T4 Cloud GPU。

加速推動資料科學應用，不能單靠深度學習技術，Nvidia重申機器學習的重要性，並且持續擴充雲端容器登錄服務版圖
在加速運算的發展上，Nvidia最著名的是旗下的GPU加速技術，然而他們長期發展的統一運算架構CUDA，也隨著該公司GPU架構的進展而持續推出新版，並且保持各個世代架構的相容，以及針對整個技術堆疊進行全面的最佳化，因此，在高效能運算的應用領域，伺服器也能因為搭配多張GPU加速卡，而獲得大幅領先純CPU伺服器的運算效能。
不過，承擔大量高效能運算工作負載的資料中心，現今所需執行的相關應用程式類型越來越繁雜，根據統計，有數百種、甚至數千種之多，而且除了因應高效能運算的各種模擬、機器學習、深度學習，隨著人工智慧的應用崛起，超大規模環境與企業環境的機器學習與深度學習，也將是未來高效能運算技術發展的重點。
對於這樣的新局面，黃仁勳特別提到他們在GTC歐洲大會宣布推出的開源軟體套餐RAPIDS，希望透過當中整合的程式庫，提供一套支援CUDA加速的資料科學工作流程，目前已有多個開源軟體社群、新創公司、企業級資料科學平臺廠商、雲端服務業者，開始採用。



Nvidia另一個能夠協助資料科學應用開發的資源，則是他們去年發表的雲端容器登錄服務Nvidia GPU Cloud（NGC），在這次超級電腦大會期間，黃仁勳也談到目前這套服務的最新進展，像是：提供新的加速容器映像，以及多節點架構的容器部署，並且支援在高效能運算領域備受關注的容器Singularity；同時，NGC原本訴求的執行環境，主要是公有雲服務，如今也能用於獲得「NGC-Ready」認證的工作站、叢集系統、雲端服務等環境，應用情境更為寬廣。

根據Nvidia的新聞稿內容，目前在伺服器的部份，總共有6款機型拿到NGC-Ready認證，分別是ATOS BullSequana X1125、Cisco UCS C480ML、Cray CS Storm NX、Dell EMC PowerEdge C4140、HPE Apollo 6500、Supermicro SYS-4029GP-TVRT；工作站的部份，則有HP Z8、聯想ThinkStation P920；而在雲端服務的部份，原本就有Amazon EC2，後來，Google Cloud Platform、Microsoft Azure、Oracle Cloud Infrastructure等業者，陸續提供支援。當然，還有Nvidia自家的DGX Systems系列整合應用設備，以及特定的Titan與Quadro GPU，也支援NGC。

針對資料中心GPU橫向擴展需求，提供新的加速卡
在資料中心對於GPU的效能擴充作法上，以往大多只能採用縱向擴展（Scale Up）的方式，改用運算效能更強勁的GPU加速卡，或是在單臺伺服器安裝多張GPU加速卡的方式，而在Nvidia今年推出的DGX-2，他們開始展現了一機16張GPU的配置，到了9月舉行的GTC日本大會，他們宣布推出新的GPU加速卡Tesla T4，以及TensorRT Hyperscale Platform，支援超大規模的人工智慧推論應用。
於本週舉行的美國超級電腦大會期間，黃仁勳則是提到可以用這套新型GPU加速卡與橫向擴展（Scale Out）架構，來因應更大量的GPU使用，而根據Nvidia的新聞稿所公布的消息來看，每臺運算節點最多可搭配20張Tesla P4，延展性有重大突破。



",https://www.ithome.com.tw/news/127036,"新聞,Nvidia HPC,Tesla T4,RAPIDS,Nvidia GPU Cloud,Container"
126928,13,2018-11-09,Cloud趨勢周報第1期：AWS影像辨識服務大更新，增加資訊邊框標出圖中多個物體的位置,重點新聞(1031～1107)," 重點新聞(1031～1107)
  AWS     影像辨識  
AWS影像辨識服務再升級，現在可框出圖片中多個物體的位置
AWS影像辨識服務Amazon Rekognition有大更新，最近可以進一步辨識出影像中的物體，甚至是場景的功能，再加上對應的標籤。過去，Amazon Rekognition無法找到物體在影像中的所在位置，現在可以用資訊邊框來標示出圖片中常見的物體，如狗、人、汽車等的位置，辨識準確性也比過去更高了。此外，使用者也可以使用資訊邊框來推斷出現在圖片中的物體數量（如3隻狗），以及物體之間的關係（如沙發上的狗）。這個服務不只可用於圖片，也可用於影片中的分析，來辨識出影片中物體的位置。（詳全文）
  Amazon    RDS  
AWS監控服務現在可以追蹤Amazon RDS資料庫服務事件了
雲端龍頭AWS旗下CloudWatch Events監控服務開始支援自家關連式資料庫服務Amazon RDS了。CloudWatch Events可接收所有由RDS傳送出的服務事件，作為監控之用，方便企業用戶掌握RDS資源的變化，以利快速反應。Amazon Aurora也屬於可支援的RDS資料庫引擎。 CloudWatch Events可監控的資源類型包括了資料庫執行實例、資料庫叢集、參數群組和資料庫快照，甚至可以跨不同用戶帳號來監控各類事件，可以用來監控企業所擁有的RDS服務的事件。另外也可以利用CloudWatch Event規則來促發後續的動作，例如用來驅動無伺服器的AWS Lambda函數或用來呼叫ECS任務。 （詳全文）
  AWS    帳號登入管理   
AWS單一帳號登入服務小更新，可自訂AWS帳戶連線期限了
AWS最近優化了單一帳號登入服務（Single Sign-On，SSO）功能，讓用戶可自訂AWS 帳戶登入後的可用時間，範圍能從1小時到12小時都可自訂，不過企業可以再針對每一組工作階段（session）設定可用時間長度，以便優化不同AWS帳戶來存取AWS管理主控臺和AWS 命令列界面（CLI）的時間，例如當使用者需要執行較長時間的操作，可延長工作階段的時間長度，讓使用者在一個工作階段中，即可完成操作。另外，企業還可以透過SSO管理使用者對AWS Organizations中多個AWS帳戶和商業應用程式Salesforce、Office 365、Box等的存取。（詳全文）
  Azure HDInsight    Spark 
Azure提供HDInsight IO快取，提升9倍Spark作業速度

Azure旗下HDInsight推出IO快取功能，可以用來加速大數據分析平臺Apache Spark的任務，微軟官方網站宣稱，最大可以加快9倍的查詢效能。甚至，使用者只需啟用HDInsight IO快取後，不需更改任何原有任務配置，就能提升Spark任務的查詢執行速度。HDInsight IO快取功能採用了一個新的快取架構RubiX，不用先預留大量記憶體，而是搭配SSD快取來提高記憶體的利用率，讓多數記憶體可保留給Apache Spark任務計算所需的記憶體之用。微軟指出，這個架構尤其可用於從雲端儲存服務中讀取資料來進行分析的Spark任務。（詳全文）
Azure    運算服務  
Azure宣布超大記憶體容量的M系列VM開始支援東亞地區
微軟Azure的高效能運算服務M系列虛擬機器，開始支援東亞可用區域。M系列VM是Azure去年12月底推出的超大記憶體虛擬機器規格，採用 Xeon E7-8890 v3 2.5GHz （Haswell）的處理器，可支援最少64個，最多128個虛擬核心，記憶體則從最少192 Gib，最高可提供到3,892 GiB約4TB的記憶體。M系列也針對大型記憶體內部進行工作負載最佳化，目前已通過SAP HANA認證。除了SAP HANA之外，也可用於SAP S/4 HANA和SQL Hekaton應用的部署。（詳全文）
.com網域費用    Verisign 
.com網域名稱費用要漲價了，最快2020年調漲將影響全球上億個網站
美國國家電信暨資訊管理局宣布和網域名稱註冊管理機構Verisign續約，由Verisign繼續負責2019年到2024年.com註冊業務，並允許其在合約的後4年，可連年調漲最高7%的.com批發費用，鬆綁前朝政府對.com的價格控制，全球總計超過1.2億個以.com註冊的網址，都將受到影響。另外，續約內容更約定若無意外將自動再續約6年，亦將依循同樣的價格政策。.com為全球最普及的頂級網域名稱，根據Statista的調查顯示，它的市占率高達46.5%，遙遙領先居次.org的5.1%市占率。（詳全文）
CockroachDB    資料庫託管服務  
CockroachDB釋出全託管服務，可在不同雲端供應商間自由搬遷

開源關連式資料庫CockroachDB最近推出了雲端全託管服務。這是由三位Google工程師，依照Google Spanner資料庫白皮書打造的超強擴充力和強健性資料庫，今年三月推出了2.0版本，可以提供極大的擴展性，能部署到數千節點伺服器上運作。最近開發商進一步宣布，將推出由官方營運的全託管CockroachDB資料庫（Managed CockroachDB）服務，使用者將可以輕鬆的部署、擴展和管理CockroachDB。全託管CockroachDB與所有雲端相容，可在AWS和GCP上部署，讓開發者專注於建構高可擴展的應用程式，而無需分心於基礎架構的操作。（詳全文）
  Google雲端    儲存桶   
Google雲端儲存桶鎖定功能上線，鎖定資料防止遭刪除或竄改
Google持續增加雲端服務的可靠性，在雲端儲存中加入雲端儲存桶鎖定（Cloud Storage Bucket Lock），讓使用者控制儲存桶的內容，在指定的時間內無法刪除或是修改內容。對於需要一次性寫入多次讀取（Write Once Read Many）或是不可變的儲存應用尤其有用，特別是許多組織為符合法規要求，都需要保留資料一段時間，雲端儲存桶鎖定能夠為組織提供保留鎖定（Retention Lock）、暫時以及事件保留等功能。更進一步將雲端金鑰管理系統（KMS）與雲端儲存整合使用，KMS的金鑰可被用來保護使用者的雲端儲存資料，使用者也可管理並控制雲端儲存資料集的加密金鑰，執行金鑰輪換、撤銷和刪除等功能。（詳全文）
  Azure    即時通訊   
微軟Azure的SignalR服務正式上線，最大可支援到單一實例10萬個連線數

微軟今年5月發表的新服務Azure SignalR服務，最近正式上線了，從測試階段的單一實例支援1萬個連線，現在釋出正式版後，標準版單一實例最大可支援到10萬個連線數。SignalR服務可整合.NET函示庫以及Visual Studio開發工具，供開發者在應用程式中建立即時通訊功能，可用來設計多種即時通訊機制，如即時廣播、聊天、即時儀表板等。開發人員不需管理即時通訊的結構細節，如裝載、擴充能力、負載平衡或驗證等。微軟建議，適合用於4類應用，包括了需從伺服器進行高頻率更新的應用如遊戲，監控類應用如企業儀表板，協作類應用如小組會議軟體，或是需要傳送通知的應用如聊天室。（詳全文）
 
圖片來源／AWS、微軟、Cockroach Labs
 更多Cloud動態 
1. 搶攻企業應用市場，IBM Cloud VMware推出5個打造雲端應用的參考架構
2. Amazon RDS的Oracle版可用JVM支援Oracle Java，並新增績效詳情監控功能
3. 租用Spot虛擬機器省多少？AWS EC2 Spot主控臺現在可以查了
資料來源：iThome整理，2018年11月
",https://www.ithome.com.tw/news/126928,"新聞,Cloud,AWS,Azure,Google雲端"
126841,13,2018-11-05,SolarWinds升級基礎架構管理工具AppOptics，新增例外狀況追蹤功能,此次推出的新功能，是以AppOptics既有的工作功能為基礎，系統會列出例外狀況發生的時間、頻率，還能進一步追蹤發生異常的端點、源頭的應用程式為何。," 以IT環境、網路監控工具產品為主的SoloarWinds公司，在2017年時推出了IT管理工具AppOptics，融合了應用程式效能、基礎架構監控服務，並且讓使用者能在該解決方案中，自訂Metrics，更深度地了解基礎架構當前的運作情形。而在近日，SolarWinds近一步加強了AppOptics的功能，釋出例外狀況追蹤功能。
SolarWinds表示，此次推出的新功能，是以AppOptics既有的工作功能為基礎，讓開發者可以追蹤系統服務出現例外的情形。在進行故障排除時，系統會列出例外狀況發生的時間、頻率，還能進一步追蹤發生異常的端點、源頭的應用程式為何。
在操作功能面，當維運人員著手修復系統時，可以在選單中點擊「最近一次發生」的選項，系統便會列出最近一次發生故障的歷史紀錄，讓使用者參考例外狀況是否又再同一處發生。

當使用者要進行故障排除時，可以先點擊系統選項中的「最近一次發生」按鈕，參考過去例外狀況發生的情境，與新例外狀況比對下來，是否有類似之處。圖片來源：SolarWinds


當系統故障時，AppOptics可以鎖定某服務下的基礎架構，觀察此環境的健康程度，監測其CPU、記憶體、硬碟 I/O的數據是否正常。圖片來源：SolarWinds

",https://www.ithome.com.tw/news/126841,"新聞,SolarWinds,DevOps,IT維運,系統監控"
126730,13,2018-10-31,Cloudbees推新打包工具Custom WAR Packager，發布Docker映像檔更方便,使用者將所需套件、組態配置撰寫成YAML檔格式，接著交由Custom WAR Packager及Jenkinsfile Runner進行打包，輸出成Docker格式," 不少開發者選用的DevOps工具Jenkins，最近其開發商Cloudbees針對開發者，推出新客製打包工具Custom WAR Packager，使用者可以將自己專屬的Jenkins版本、套件及組態設定，打包成WAR檔、Docker映像檔，或者Jenkinsfile。
Cloudbees高級工程師Oleg Nenashev表示，利用Jenkins進行整合測試一直是個痛點，而主要用於進行測試的框架如Jenkins Test Harness、Acceptance Test Harness，都得利用Jenkins WAR檔案打包後，才能用於測試工作。而近年雲端爆發的趨勢下，除了面臨在公有雲環境使用Jenkins執行測試任務的問題，因應不同環境而生的Jenkins發行版，如雲端原生Jenkins、支援Kubernetes的Jenkins，都必須通過整合測試的考驗，才能用於持續交付流程
面對這些痛點，這也是CloudBees之所以推出Custom WAR Packager的原因。Oleg Nenashev表示，該工具可以Maven套件、Docker打包檔，或者CLI執行檔的格式取得。使用者將所需套件、組態配置撰寫成YAML檔格式，接著交由Custom WAR Packager及Jenkinsfile Runner進行打包，輸出成Docker格式。在實際運作流程中，每當儲存庫完成建置時，Custom WAR Packager就會開始運作，將開發者指定的輸入檔案，重新打包成WAR檔。
",https://www.ithome.com.tw/news/126730,"新聞,Jenkins,Docker,DevOps,持續整合"
126676,13,2018-10-27,強化DevOps與容器應用支援，NetApp祭出橫跨多雲環境的K8s管理服務，旗下超融合基礎架構可部署OpenShift容器平臺,看好企業IT的容器應用與持續儲存環境的動態建立需求，NetApp發展開放原始碼的儲存調度指揮軟體Trident，並且藉由併購新創公司，迅速推出可橫跨多種雲端服務的Kubernetes管理服務，為企業在混合雲、多雲環境的容器應用開創新的模式," 【美國拉斯維加斯現場報導】對於混合雲與多雲環境管理的強力支援，成為今年NetApp全球用戶大會Insight的一大重點，積極主推各項新的整合應用服務與軟體功能特色之餘，動作之大，就連該公司共同創辦人之一David Hitz都忍不住在大會主題演講尾聲爆料，表示他頻頻被客戶詢問，想確認NetApp是否之後不再銷售硬體設備。
過往，NetApp的業務範圍其實已經延伸到儲存系統以外的IT基礎架構，但多數企業對於他們的印象，仍停留在儲存系統的供應商，不過，近年來，他們藉著併購SolidFire，而開始跨入超融合基礎架構（HCI）解決方案的發展，外界還是以為他們所著眼的部份，只是提供另一種軟體定義儲存環境的選擇，然而，NetApp在此次全球用戶大會新發布的容器管理雲端服務，以及對於主要容器平臺、自家發展容器技術提供了軟體支援，則更突顯了他們對於整體IT環境管理應用的企圖心，希望能在IT基礎架構新興的調度指揮、整合與控制應用技術上，佔有一席之地。
而就在10月25日這一天，NetApp除了先前推出的各種資料服務之外，也正式發布了一系列與DevOps有關的解決方案。其中，最讓人關注的是，正式推出了NetApp Kubernetes Service，這是該公司甫於9月併購新創公司StackPointCloud之後的最新進展，而在一個月後的此刻，就將他們發展的Kubernetes即服務平臺，納入NetApp旗下的雲端服務系列解決方案。


在這套雲端服務之中，將提供一套通用的控制平面（Universal Control Plane），管理多種雲端服務當中的Kubernetes環境，藉以大幅簡化將Kubernetes叢集部署到雲端的作業，因應IT基礎架構與應用程式等兩種層面的調度指揮需求。目前可支援AWS、Azure、GCP等公有雲，未來也將涵蓋到NetApp HCI這套超融合架構。同時，NetApp Kubernetes Service對於容器應用系統的支援，也會擴及Istio、Trident等兩種開放原始碼的軟體。


值得一提的是，上述的Trident，其實是由NetApp所發展出來的，主要是針對容器環境提供自動建立持續儲存系統的功能，具備相關的動態調度指揮能力，在今年NetApp與Nvidia共同宣布推出的ONTAP AI當中，首度嶄露頭角，為這套主打快速建置企業深度學習訓練環境的融合式基礎架構解決方案，提供容器儲存環境的整合應用。
而且，Trident也陸續支援多種常見的容器應用平臺，例如：Docker、Kubernetes、Red Hat OpenShift Container Platform，以及NetApp旗下的多款儲存系統與雲端服務，像是ONTAP、SolidFire、NetAp HCI、NetApp Cloud Volumes。
到了10月底舉行的NetApp全球用戶大會上，他們也宣布Trident將同時支援NetApp Cloud Volumes ONTAP，便於運用其中內含的NetApp Snapshot快照複本技術，而能進一步整合資料備份與還原的功能。這套能夠協助容器環境自動建立持續儲存的軟體，未來也將支援多雲環境的使用。
NetApp不只是持續推動既有產品對於主流容器平臺的支援，令人訝異的是，他們更打算在自家的超融合基礎架構NetApp HCI之上，提供直接部署容器平臺的選項，並且藉由這樣的搭配，將原本同類型產品均側重的快速建置伺服器與儲存虛擬化環境，達到基礎架構即服務（IaaS）的資源整合目標，更進一步提升到以應用程式、容器、微服務的部署與提供為主的層次，邁向更高階的平臺即服務（PaaS）供應。
而關於這項突破性的作法，超融合基礎架構市占最高的兩大廠商──Nutanix和VMware，都在積極布局，發展適合他們架構的容器應用服務，而NetApp則是找上Red Hat合作，為該公司的OpenShift Container Platform提供NetApp HCI驗證架構，讓軟體開發團隊也能在公司內部的IT環境當中，運用容器來加速應用系統的建立、部署與管理，同時，也能以此容器平臺，橫向擴展使用規模，並且能夠延伸到公有雲環境，建構出混合雲的應用程式平臺架構。
除了與容器相關的多種支援與整合應用模式，NetApp也在此次大會期間發出的新聞稿當中，提及其他的DevOps所需的特色，例如，自動化，強化支援措施。
例如，他們最近針對旗下的三大儲存系統──ONTAP、SANtricity、Element，分別推出了系統自動化平臺Ansible專用的模組，便於用戶整合AFF與FAS系列儲存設備、E系列儲存設備，以及SolidFire和NetApp HCI等解決方案，來達成自動化作業的應用。
",https://www.ithome.com.tw/news/126676,"新聞,Kubernetes,Container,DevOps"
125920,13,2018-09-17,DevOps工具Drone開始原生支援Windows Server環境,原生整合Drone的Windows Server環境，開發者可以結合Drone與Windows Containers，將雲端環境執行建置、測試的流程，套用至Windows Server環境執行。," 近年竄起的持續整合（CI）、持續交付（CD）工具Drone，以Docker為基礎，並且結合Go語言開發。日前該工具背後的軟體開發商Drone才宣布要支援Arm架構，近日更進一步擴大布局，開始要支援Windows Server，對於後端環境仰賴Windows Server環境的企業，現在又多了一款新DevOps工具可用。
Drone創辦人Brad Rydzewski表示，除了企業用戶提出支援Windows Containers技術的需求，藉以加速程式碼開發、發布速度，Windows社群也開始積極擁抱容器、開源技術。
Drone表示，現在原生整合Drone的Windows Server環境，在微軟自家容器格式Windows Containers中，開發者可以透過Drone，將雲端環境執行建置、測試的流程，套用至Windows Server環境執行，「提供開發者組態配置自助式服務，同時讓測試環境建置工作也能自動化。」
目前Drone專案在GitHub有相當高的人氣，有超過1.5萬顆星星。此工具也一併支援市面上主流的程式碼儲存庫，包含GitHub、GitLab、Bitbucket。為了讓開發者能客製化自家的持續交付流程，Drone也有推出線上套件市集，讓使用者可以串接多種開發環境、DevOps工具，以及通訊軟體。現在Drone支援的開發環境，包含Cloud Foundry、Bluemix Cloud Foundry，而公有雲則是以AWS、Google為主。
",https://www.ithome.com.tw/news/125920,"新聞,Drone,Windows Server,DevOps"
125830,13,2018-09-12,Chef推出延伸套件，支援Azure DevOps,Chef今年不少產品布局都大力支援微軟，像是自動化建置工具Habitat支援Azure Kubernetes服務，或將法遵工具InSpec推上微軟公有雲。這一次在微軟推出Azure DevOps，Chef也隨即宣布支援。," 近日微軟才發布Azure DevOps，以取代舊有VSTS後，應用程式組態工具廠商Chef也跟上腳步，宣布該公司開始支援Azure DevOps平臺。
Chef表示，該公司這次釋出一款Azure DevOps專用套件，讓Azure企業用戶在軟體開發流程中的建置、發布步驟，可以整合Chef工具，「我們也使用Azure Pipelines開發這些延伸套件。」除釋出專用套件，Chef的自動化建置服務Habitat也推出專用延伸套件，目前已同步登上Azure DevOps服務。在具體功能面上，該整合套件使用自動化平臺Chef Automate，可以支援軟體開發的建置、發布工作。
今年Chef開始積極的擁抱微軟。今年5月時，Chef與微軟聯手，讓開發者可用Habitat Builder，在Azure環境部署應用程式，並且支援Azure容器儲存庫，利用一鍵持續部署機制，將應用程式部署於Azure Kubernetes服務中運作。
",https://www.ithome.com.tw/news/125830,"新聞,Chef,Azure,DevOps"
125388,13,2018-08-22,Container周報第78期：區塊鏈新創AMIS大方公開K8s部署經驗,AMIS為了建置區塊鏈平臺，利用了HashiCorp的基礎架構部署工具Terraform來建置K8s，透過命令列工具四個指令就能完成大部分的部署工作，再搭配宣告式的配置檔，內部開發人員只需要描述自己對基礎架構的需求，而不用知道如何取得這些基礎架構資源。," 08/08~08/14精選Container新聞
#AMIS #Kubernetes臺灣區塊鏈新創AMIS怎麼用K8s？架構師大方上網分享自建經驗
臺灣商用區塊鏈新創AMIS一位軟體架構師Alan Chen近日將自家公司部署K8s的經驗大方公開上網。AMIS為了建置區塊鏈平臺，積極導入各種新技術，Kubernetes也是其中之一。Alan Chen利用了HashiCorp的基礎架構部署工具Terraform來建置，之所以選擇這套工具的關鍵是，可以透過Terraform命令列工具提供的四個指令init、plan、apply和destroy，就能完成大部分的部署工作，再搭配宣告式的配置檔，內部開發人員只需要描述自己對基礎架構的需求，而不用知道如何取得這些基礎架構資源。AMIS還利用了Terraform上的一個開源模組ElastiKube，來建立K8s區塊。完整內容
#封包監控 #容器叢集效能量測大廠也要進軍容器和K8s監控，Ixia推出套裝容器叢集網路可視化服務
美國量測大廠Keysight旗下子公司Ixia近日推出一款容器和Kubernetes叢集的套裝檢測服務Cloudlens可視化平臺。可以提供24小時的監控服務，追蹤容器化應用的網路封包派送情況，將企業部署在雲端環境中的容器或是Kubernetes叢集的運作情況可視化。目前可以支援主流Kubernetes代管平臺，包括了AWS EKS、微軟AKS和Google的GKE。這套系統也可以用來追蹤實體設備網路流量，還能將資訊整合到企業的應用程式效能管理或網路效能管理機制。


#大數據預處理 #Paxata大數據預處理軟體也能用Kubernetes強化即時處理速度
美國一家自助式資料預先處理軟體商Paxata開始利用Kubernetes來強化自家產品的即時處理能力。Paxata的資料預處理引擎，主要部署於記憶體式大數據分析框架Spark上，現在Paxata在自家軟體增加了一個擴充runtime，可以將原本的批次預先處理作業，打包成Kubernetes的應用程式，發布到雲端Kubernetes服務來成為隨時執行的任務。這是Paxata一系列Kubernetes產品強化的第一項，Paxata也因此改採訂閱付費制，來取代過去的軟體授權銷售方式。

#VMware #Docker最新調查：更多企業改用容器取代VM來節省授權費
一家裸機容器基礎架構商調查576位中大型企業的資訊主管，了解企業基礎架構部署動向。這群作答者所屬企業，有34％每年VMware軟體授權費超過了25萬美元（臺幣750萬元），費用超過10萬美元（臺幣300萬元）者也有55％。因此，44％的作答企業決定改用正式上線系統改部署到容器環境來降低授權費。根據這份調查，對企業來說，採用Docker技術的比例仍舊高於Kubernetes，有52％作答者採用Docker，Kubernetes採用者只有3成。已經採用容器技術者，71％是在虛擬機器中執行容器化應用，尤其是部署在雲端虛擬機器中居多。
#Docker桌面版 #Windows 10Docker桌面版可以部署K8s了，在桌機部署K8s叢集更簡單了
Docker公司最近宣布Docker桌面版中的Kubernetes調度工具支援已經進入穩定版本了，Docker用戶，可以切換Kubernetes和Swarm以供容器調度引擎之用。這意味著，更容易在Windows 10或者是Mac OS上安裝Docker桌面版，來部署一套桌機上的Kubernetes叢集這套桌面上的Kubernetes也能整合到開發者的容器開發流程上，做為其中一項測試環境之用。目前Docker桌面版，可用來部署.NET、NodeJS和Java應用，只需要透過Compose檔案就能將這幾類應用部署到Kubernetes環境中。


#CNCF #PrometheusKubernetes後，Prometheus也從CNCF基金會畢業了
繼Kubernetes專案之後，近日，CNCF基金會宣布第二個畢業專案出爐，這次輪到受開發者喜愛的開源監控專案Prometheus，這也是容器開發者愛用的監控平臺。CNCF基金會營運長Chris Aniszczyk表示，從2012年起，Prometheus就已是頂尖的開源監控方案。第二個被納入CNCF基金會育成專案的Prometheus，在2012年開源釋出，並於2016年捐給該基金會後，已經發布了30個版本。現在該專案已經有近20個核心維護者，並且有超過1,000名開源貢獻者。而使用該監控專案的企業，包含Uber、DigitalOcean、ShowMax、ShuttleCloud等公司。

#Functions #ServerlessGoogle事件驅動無伺服器運算平臺Cloud Functions也正式上線了
相較於AWS和Azure，Google在無伺服器服務的腳步稍慢，儘管早在2017年就對外發布了Cloud Functions測試版服務，但直到近日，這項服務才正式上線，除了美洲，服務地區也增加了歐洲和亞洲地區。
Google將Cloud Functions作業系統升級到了Ubuntu 18.04 LTS，擴大了可用函式庫的範圍，除了Imagemagick一直都有外，還多了Ffmpeg和Libcairo2系統函式庫，連無頭Chrome也有，使用者不只可以在Cloud Functions中處理影片，甚至還能進行網頁截圖。另外，在Cloud Functions上也可以使用Python 3.7，用法與Node相同，透過HTTP請求由Cloud Functions為後端提供資料與上下文內容，且由於Python的HTTP功能基於Flask微框架，可以非常快速的啟動執行。


#Azure #Windows容器微軟Azure應用程式裝載服務開始支援自家Windows Server容器
Azure App Service是雲端應用程式裝載服務，可供企業快速選擇和安裝想要的雲端應用，現在此服務還處於公開預覽版階段。近日，Azure App Service終於支援微軟自家的容器技術Windows Server Containers，可以讓企業將網頁應用打包成Windows容器格式，部署至Azure App Service的環境上部署運作。不過，此服務還處於公開預覽版階段。使用者可以整合Docker Hub、Azure容器映像檔儲存庫或第三方私人儲存庫，將容器化應用部署到Azure App Service環境，微軟也支援開發者進行漸進增量部署（Incrementally deploy）。
#GAE #PythonGoogle App Engine更新Runtime，可支援Python 3.7版
使用Python的雲端應用開發者，現在公有雲開發環境又有新選擇，近日Google宣布，雲端PaaS平臺App Engine推出第二代標準Runtime，開始支援Python 3.7版，現在該服務已經開放公開測試。Google表示，這一次釋出的第二代標準Runtime，結合了自家的gVisor容器沙箱技術，消除過往App Engine許多使用上限制，讓開發者可以開發攜帶性更高的網頁應用、微服務，也能結合該服務的隨需擴充、按用計價機制。

責任編輯／王宏仁
更多Container動態
AWS雲端資料庫Aurora正式支援無伺服器MySQL應用
Kubernetes社群Slack上臺灣用戶討論區#tw-user開張了
＠資料來源：iThome整理，2018年8月
",https://www.ithome.com.tw/news/125388,"新聞,AMIS,K8s,區塊鏈,HashiCorp,IT周報"
125385,13,2018-08-02,Container周報第76期：微服務平臺Istio正式釋出1.0版，而Azure支援Ansible 2.6,"07/26~07/31精選Container新聞
#Istio #微服務"," 07/26~07/31精選Container新聞
#Istio #微服務微服務平臺Istio正式釋出1.0版，管理跨Kubernetes叢集的應用和服務更容易了
Google、IBM及Lyft共同研發的微服務平臺Istio，近日終於釋出了1.0版。距離第一個釋出的0.1版，已經超過一年。Istio團隊表示，也有大型企業於正式環境中採用，像eBay、汽車交易平臺Auto Trader、房產交易平臺Trulia等公司，開始使用Istio管理、串接內部的系統服務。
1.0版所有核心功能已經可以導入正式環境使用。當中幾個亮點功能，首先是多個Kubernetes叢集現在可統一整合到單一服務網格，而且Istio在支援Kubernetes進行跨叢集連線的同時，也能確保每個叢集都有套用一致的管理政策。而網路API管理功能也有改善，提供管理員顆粒度更細緻的網路流量管理。此外Istio表示，現在Mutual TLS功能，讓使用者可以逐步更新，不需要一次更新所有客戶端服務，有助於降低正式環境部署Istio的門檻。
#GitHub #GoogleGoogle與GitHub合作，讓DevOps部署工具Cloud Build登上GitHub市集
近日Google Cloud Next大會中，Google除了發布GCP原生的持續整合、持續交付服務Cloud Build外，也進一步與GitHub聯手，讓使用者在GitHub上的儲存庫可以串接Cloud Build，建立完整的開發流程，Cloud Build也在GitHub市集上線。而整合GtiHub後的Cloud Build，開發者完全不需要介入Docker build設定，每一次的合併請求（Pull Request），系統可以自動執行容器應用的建置、流程，並且將程式碼上傳至GitHub儲存庫。
在使用者執行建置工作時，GitHub平臺會掃描儲存庫內的Dockerfile，如果使用者未有使用自動化CI工具，平臺推薦使用者GitHub市集中適合的工具，GitHub表示，這個智慧化推薦功能預計在下個月上線。在CI流程中支援使用自定義的YAML文件，開發者便可以自行規畫建置流程，例如讀取Docker映像檔快取，藉此加速建置流程，或開發者可以選擇將容器應用部署在GKE、App Engine、本地環境，或者其他雲端環境。

 
#DevOps #AKS微軟Azure支援Ansible 2.6，管理AKS資源也能用
日前紅帽釋出Ansible 2.6版後，加強支援公有雲、私有雲環境。而近日微軟也宣布，Azure環境不只支援Ansible 2.6版，新增了4個模組，主要補強AKS服務、Azure資源的建立、管理，合計超過17項新功能或改善。微軟表示，搭配Ansible 2.6版，現在使用Azure的企業用戶，可以用來新增、更新、刪除雲端Kubernetes服務外，也能結合Azure REST API，管理Azure公有雲資源。微軟也推出三個新Ansible使用教學，包含利用Ansible設定AKS叢集、虛擬機擴充集（VMSS），以及如何靠Ansible，在Azure虛擬機環境部署Java應用程式。詳細教學已經公布在Ansilbe on Azure Developer Hub。

#容器儲存 #BlueData瞄準AI大量資料儲存需求，BlueData開源釋出Kubernetes儲存
雲端儲存服務供應商BlueData最近發起了一個打造一系列Kubernetes儲存專案的計畫稱為BlueK8s，其中第一個儲存專案就是KubeDirector。該公司架構長Tom Phelan表示，這項專案可用來加快用Kubernetes部署Hadoop和Apache Spark軟體所需的儲存環境。讓開發者更容易用Kubernetes管理有態的原生雲端應用。KubeDirector是一個利用Kubernetes的資源客製定義（CRD）框架來設計的客製化控制器，可用來管理複雜的有態應用程式。
#ServerlessServerless釋出自家無伺服器應用開發平臺
早在2015年就推出無伺服器框架Serverless Framework的無伺服器新創公司Serverless，近日推出自家無伺服器開發平臺Serverless Platform，目前還位處Beta版本階段，除了建置之外，特別新增了加入了維運、整合功能。在Serverless Platform提供了儀表板功能，替應用程式建立完整的架構圖，開發者也可以匯出Log紀錄、設定警報條件，即使企業用戶一次選用多個混合環境，還可以在單一介面，列出雲端環境當前的基礎架構資源等。另一個新功能就是Event Gateway，可以將事件資料與無伺服器應用、雲端服務串接。可以協助企業整合無伺服器應用及既有系統服務。而Event Gateway也可以與儀表板結合，直接提供即時的Log資訊。


#OpenStack #KataKata Containers登上Canonical軟體市集Snap Store
由OpenStack基金會主管的容器專案Kata Containers，結合Intel的輕量級虛擬化技術Clear Containers，以及相容開放容器OCI標準的runV技術，想要兼顧VM的安全性，及容器技術的輕量性。在近日，Kata Containers登上了Canonical軟體市集Snap Store。
參與Kata Containers專案的Intel Linux軟體工程師Julio Montes表示，利用Snap格式打包Kata Containers，系統可以自動更新或快速回復至舊版。此外，可以讓更多開發者接觸到該專案，並且將該應用程式部署於雲端環境執行。目前Kata Containers可以支援的Linux作業系統版本，包含Ubuntu、Linux Mint、Manjaro、Fedora、Debian、ArchLinux、OpenSUSE、Solus。現在軟體開發市集也是各家IT廠商要搶攻的市場，像三大公有雲廠商都有提供軟體市集，讓企業用戶可以更簡單取得商軟解決方案。在Kata Containers、PowerShell加入之後，Snap Store也變得越來越熱鬧。
#Datadog #容器監控容器開發者愛用的Datadog監控服務，開始支援Windows環境
近日Datadog也宣布，現在自家平臺的程序監控服務Datadog Process Monitoring也可以支援Windows環境了。只要是Windows Server 2008（包含）以後版本的作業系統，Datadog的程序監控服務都可以支援。
IT環境混合使用Linux、Windows的開發者，Datadog可以在同一儀表板上，同時呈現這兩個異質環境的概況，提高企業IT監控的整合度，單一平臺就可以通吃兩個環境。而在Windows環境的程序監控中，使用者可以利用Process owner作為過濾條件，隔離出每個使用者的資源空間。或者，以Process name、字串進行搜尋。而將應用程式部署在多主機環境的企業，該服務可以利用標籤、主機ID、服務區等資訊，作為分類條件，聚合不同來源的數據，讓系統管理員可以更簡單進行跨環境監控。除了即時監控，在整合Windows環境監控時，Datadog也提供使用者瀏覽過去Metrics的功能。Datadog企業用戶也可以將Windows程序監控加入既有的儀表板。
責任編輯／王宏仁
更多Container動態
Docker桌面版開始穩定支援Kubernetes
Azure管理群組功能正式上線，一步讓多帳號套用多種權限機制
結盟取代競爭，Slack買下Atlassian旗下HipChat與Stride
Google釋出透明SLIs，助GCP用戶更快找出原因除錯

＠資料來源：iThome整理，2018年8月
",https://www.ithome.com.tw/news/125385,"新聞,Datagod,IT周報,Container,Kubernetes,Ansible"
124979,13,2018-07-26,Container周報第75期:進軍企業混合雲架構，Google雲端GKE落地推出軟體版,GKE On-Prem的管理介面和雲端GKE服務完全相同，企業可以將雲端GKE上的服務，搬到自家機房，而不用改變管理維運作法。Google也推出Cloud Services Platform方案，搭配GKE On-Prem軟體，可以實現Google Cloud Platform（GCP）混合雲部署架構，來填補Google於混合雲服務的缺口," 07/19~07/25精選Container新聞
#GKE #Google進軍企業混合雲架構，Google雲端GKE落地推出軟體版，可部署於企業機房
Goolge開始用新策略搶攻企業混合雲需求，將GCP雲端的GKE服務（Google Kubernetes Engine），打包成可部署於企業機房的K8s軟體GKE On-Prem，目前是Alpha版本。GKE On-Prem的管理介面和雲端GKE服務完全相同，企業可以將雲端GKE上的服務，搬到自家機房，而不用改變管理維運作法。企業維運人員透過Google Cloud Console就可以同時管理雲端的GKE服務和部署於自家機房的GKE On-Prem環境。
另外，GKE On-Prem軟體也強化了多項混合雲整合機制，如企業可使用也可和雲端GKE整合，不用建立複雜VPN。另外也可通用雲端身分或自家身分驗證服務來登入GKE On-Prem。Google日前推出的Kubernetes應用市集，不只可部署於GCP，企業也可將Kubernetes應用部署到本地端的GKE On-Prem環境中。
 
#混合雲 #Cloud Services PlatformGoogle終於有混合雲解決方案了! Cloud Services Platform將於秋天問世
終於，Google在Google Cloud Next大會議上發表了全新的Cloud Services Platform，搭配GKE On-Prem軟體，可以實現Google Cloud Platform（GCP）混合雲部署架構，來填補Google於混合雲服務的缺口。兩大核心元件分別是就地部署版的Google Kubernetes Engine（GKE On-Prem），以及專門管理微服務的開源專案Istio。光有GKE On-Prem是不夠的，還需要藉由Istio來發現、連結與管理不同的Kubernetes環境。其它元件還包括了擔任監控與管理任務的Stackdriver、掌管Kubernetes任務的GKE Policy Management、支援無伺服器運算的GKE Serverless外掛及Knative開源框架，以及開發者工具Cloud Build。


#Docker #應用程式指南Docker釋出應用程式指南，助企業將傳統應用搬至容器環境
近日，Docker則釋出應用程式指南（Docker Application Guides），作為企業傳統應用程式容器化時的參考。這次釋出的指南，是該公司傳統應用程式現代化專案的一部分（Modernize Traditional Applications, MTA）。在2017年推出的MTA計畫，目標是要讓企業可以將老舊應用程式搬遷至現代容器化環境運作，免除開發者重寫、重構的工作。
在Docker應用程式指南文件中，該公司會結合螢幕截圖、程式指令，按部就班引導開發者，如何將應用程式部署至Docker企業版環境、Docker桌面環境。同時，在指南文件中，Docker也會提供部署架構，給使用者參考。再者，Docker也結合自家容器軟體商城Docker Store，提供企業用戶認證安全的容器映像檔。目前該指南內容有限，現階段主要瞄準Oracle WebLogic、IBM MQ這兩個企業級產品。


#CI/CD #DevOpsGoogle進軍雲端DevOps，推出Cloud Build提供CI/CD服務
雲端持續整合、持續交付有新工具。Google在近日推出了自家原生的雲端持續整合、持續交付服務Cloud Build。而用戶每天享有120分鐘額度的建置時間，可以免費將程式碼上傳至GCP平臺。
Cloud Build服務主要針對雲端容器應用程式，開發者可以自行選擇程式語言，完成開發工作後，利用Docker容器將程式碼封裝，部署至線上環境執行。而Cloud Build平臺也整合了GCP的Cloud SDK，使用者可以這套開發工具，存取雲端平臺上的運算、儲存等服務。
Cloud Build也包含版本控制，除了自家提供的程式碼儲存庫Google Cloud Source Repositories，開發者也可以選用GitHub、Bitbucket作為程式碼輸入來源，開發完畢後再將程式碼上傳至Google雲端儲存。而開發團隊每建立一個新版本，Cloud Build都會留下完整版本記錄，以便未來程式碼出現臭蟲時，開發者可以更快進行除錯任務。
#Go語言 #雲端原生應用誓成雲端應用程式語言首選，Go應用程式現在能輕易跨多雲環境部署
瞄準跨雲開發，Google的Go團隊也發布了一個新的Go專案Go Cloud，這個函式庫與工具可用於開放雲端開發，讓Go應用程式方便的在不同雲端平臺移植，目標是讓Go成為雲端應用開發人員的首選語言。現在全球約有一百萬個Go的開發者，Go在許多雲端基礎架構中扮演重要的角色，包括Kubernetes、Istio和Docker。也有不少企業大量的仰賴Go語言作為生產工具，像是Lyft，Capital One，Netflix等公司。不過，官方在與這些開發團隊接觸後，獲得其中一個共同的需求，便是應用程式跨雲端供應商的可移植性，這些開發團隊希望可以在多雲以及混合雲環境中部署Go應用程式。推出Go Coud之後，開發者現在已經可以在GCP和AWS這兩個雲端服務供應商上，使用通用API建立跨雲端的應用程式。
#Knative #Kubernetes持續強化無伺服器服務，進一步用Kubernetes達成跨雲單一平臺
Google與Pivotal、IBM、紅帽和SAP等企業共同合作，發布基於Kubernetes用來建立、部署與管理無伺服器工作負載的平臺Knative（發音為kay-nay-tiv），以達成跨雲單一平臺的目標。
Knative提供了一群可重複使用的組件，幫助開發人員解決日常瑣碎但必要任務，像是協調來源到部署容器的工作流、路由並管理部署時的流量、自動擴展工作負載或是綁定執行的服務到事件生態系中。開發人員能以慣用的開發語言與框架來部署功能（Functions）、應用程式與容器等任何工作負載。除此之外，Knative也支援常見的開發模式，如GitOps、DockerOps和ManualOps，以及Django、Ruby on Rails與Spring等工具框架。Knative也能與現有的持續整合與持續交付工作鏈良好協作。

#SUSE #CRI-OSUSE容器服務平臺第3版開始支援CRI-O
SUSE釋出自家容器服務平臺第三版（SUSE CaaS Platform 3），新版提供了更多容器叢集最佳化的配置選項，可以讓開發者對SUSE自家容器專用作業系統MicroOS，提供更精細的調整。而在近日該公司也宣布，現在SUSE CaaS平臺已開始將CRI-O列入開發者可選用的容器Runtime。CRI-O這個Runtime格式，同時相容Kubernetes Runtime Interface、開放容器標準（Open Container Initiative，OCI），SUSE也認為，相比其他容器Runtime，CRI-O是個更輕量的替代方案，還可以加強容器環境的安全性、穩定性。

#VMware #混合雲VMware與Google加強合作，讓企業靠vRealize就能管理混合雲
近日，VMware與Google擴大合作，推出GCP上的支援vRealize Automation及vRealize Orchestrator的外掛工具，要來加速企業用戶管理混合雲環境。這個GCP外掛工具件的功用，可以讓IT團隊在本地、GCP平臺都有一致的管理體驗，例如，系統管理員可以利用Google預先提供的GCP藍圖，布建公有雲環境。抑或是自行撰寫藍圖後，再使用vRealize建立GCP環境。而該工具使用的方法，就如系統管理員既有在本地VMware環境一樣。目前是預覽版。

責任編輯／王宏仁
更多Container動態
Google推出Container Registry弱點掃描工具
Docker桌面版開始穩定支援Kubernetes
微軟Azure市集容器映像檔更新，Bitnami多款容器映像檔上架
＠資料來源：iThome整理，2018年7月
",https://www.ithome.com.tw/news/124979,"新聞,google,GKE,混合雲,DevOps,Kubernetes,K8s,IT周報"
124700,13,2018-07-23,微軟Azure市集容器映像檔更新，Bitnami多款容器映像檔上架,而Bitnami在Azure平臺提供的企業級應用，一律採用容器技術打包，再交付至用戶。這一波上架的應用內容相當豐富，從搜尋平臺、深度學習、大數據串流工具、分散式資料庫、基礎架構管理應用、監控工具都包含。," 日前微軟與企業軟體市集廠商Bitnami合作，讓企業應用程式更容易上雲，在5月時，多款Bitnami提供的容器映像檔，已經登上Azure市集，包含WordPress、MySQL等熱門應用程式。而在近日，雙方又加強合作力道，在6月Bitnami總共將42款企業級軟體應用推上雲，提供企業用戶在Azure市集選購。
而Bitnami在Azure平臺提供的企業級應用，一律採用容器技術打包，再交付至用戶。這一波上架的應用內容相當豐富，囊括了搜尋平臺、深度學習、大數據串流工具、分散式資料庫、基礎架構管理應用、監控工具。

由Google所開源的機器學習工具TensorFlow，現在也登上Azure市集。這次Bitnami上架的是TensorFlow Inception容器映像檔，可讓開發者用於執行圖像辨識應用。圖片來源：微軟


Apache軟體基金會下的ZooKeeper，系統管理員可以靠此工具，確保分散式系統下各叢集的組態設定一致。  圖片來源：微軟


開源搜尋平臺Apache Solr，其核心功能包括全文檢索、分類搜尋、動態聚類、資料庫整合等。


雲端應用開發者愛用的Prometheus也登上了Azure市集，該工具可以提供系統服務監控，並且自行定義警報觸發條件，即時掌握IT環境。圖片來源：微軟

",https://www.ithome.com.tw/news/124700,"新聞,Azure,容器映像檔,Container"
124677,13,2018-07-20,紅帽釋出Ansible Engine 2.6版，強化支援混合雲環境,支援異質架構是近年紅帽的重點策略，從2017年高峰會先將OpenShift推上三大公有雲，今年則是繼續與其他雲廠商合作，擴張OpenShift。而這一次Ansible Engine開始加強支援多雲後，也讓紅帽往多雲發展的野望，更跨出一步。," 在2015年紅帽併購DevOps工具廠商Ansible後，開始與自家產品生態系如Red Hat OpenStack、OpenShift進行整合，讓使用者可以加快基礎架構環境部署工作。而近日該產品線下的Ansible Engine發布2.6版，開始加強支援多雲環境。支援異質架構是近年紅帽的重點策略，從2017年高峰會先將OpenShift推上三大公有雲，今年則是繼續與其他雲廠商合作，擴張OpenShift。而這一次Ansible Engine開始加強支援多雲後，也讓紅帽往多雲發展的野望，更跨出一步。
紅帽表示，這次推出Ansible Engine 2.6版，主要是讓企業以不增加人力為前提，可以更快速擴張其IT基礎架構。而達成此目標，主要推出了三大策略：支援多雲、強化網路功能，以及整合Windows環境。
第一個重點特色，就是簡化多雲基礎架構環境的建置工作。現在該產品所支援的公有雲環境，包含AWS、Azure及GCP，讓企業用戶只要利用單一工具，就可以通吃多雲的部署、管理、建置工作。而針對AWS環境，紅帽也有改善AWS EC2實例使用的Ansible模組。除了公有雲環境外，Ansible也有支援VMware虛擬化環境，包含私有雲vSphere及混合雲服務VMware Cloud on AWS。
紅帽表示，新的Ansible VMware模組，加了標籤、主機管理功能，並且讓自動化部署功能從作業系統層，延伸至上層的應用程式。除了外部廠商，自家產品生態系的OpenStack、Virtualization、Satellite，這次紅帽也有分別推出專用的Ansible套件，讓自家產品整合更為縝密。
再者是加強網路功能，紅帽表示，新版Ansible Engine採用Common Language的設計，使用步驟不因廠商而有所差異，解決網路管理員必須學習廠商自家專用指令的痛點。只要一套語言，就可以統管不同的網路設備，目前支援的廠商包含Juniper、思科。同時，Ansible也有支援Infoblox，包含DHCP、DNS、IPAM，利用紅帽新開發的Anisble Infoblox模組，可以將IP位址選擇、保留、指派等工作變得更加自動化。第三個特點，則是讓Windows工作負載更加自動化，包含Windows AD、Windows工作排程器。
目前紅帽Ansible產品下，總共有兩個分線。第一是Red Hat Ansible Engine。採用Agentless的設計，主要瞄準小型團隊、開發者使用，該公司也有提供許多現成模組，讓開發者可以加速IT環境的自動化。第二個則是Red Hat Ansible Tower，適用於多層部署情境，此工具也有提供視覺化儀表板、角色存取控制機制等功能，適合維運團隊使用。
",https://www.ithome.com.tw/news/124677,"新聞,紅帽,Ansible,DevOps"
124672,14,2018-07-20,SUSE容器服務平臺第3版開始支援CRI-O,現在SUSE CaaS平臺登入的組態設定選單中，開發者就可以自行選擇，使用CRI-O或者Docke開源引擎作為容器Runtime。在SUSE的未來布局中，計畫先透過此技術預覽功能，蒐集使用者回饋後，預計在下個新版本SUSE CaaS平臺第4版推出就正式支援CRI-O。," 日前SUSE釋出自家容器服務平臺第三版（SUSE CaaS Platform 3），新版提供了更多容器叢集最佳化的配置選項，可以讓開發者對SUSE自家容器專用作業系統MicroOS，提供更精細的調整。而在近日該公司也宣布，現在SUSE CaaS平臺已開始將CRI-O列入開發者可選用的容器Runtime。
SUSE表示，現在SUSE CaaS平臺登入的組態設定選單中，開發者就可以自行選擇，使用CRI-O或者Docke開源引擎作為容器Runtime。雖然當前系統仍然預設使用Docker，不過SUSE的未來布局，是計畫先透過此技術預覽功能，蒐集使用者回饋後，並且預計在下個新版本SUSE CaaS平臺第4版，正式支援CRI-O。
CRI-O這個Runtime格式，同時相容Kubernetes Runtime Interface、開放容器標準（Open Container Initiative，OCI），SUSE也認為，相比其他容器Runtime，CRI-O是個更輕量的替代方案，還可以加強容器環境的安全性、穩定性。身為CRI-O開發社群SUSE表示，最初Kubernetes快速改版革新、各家Container格式不一，讓此專案穩定性遭受挑戰，這也催生出Kubernetes專用的CRI-O，一舉減少程式碼數量，讓潛在攻擊面縮小，同時也更容易維護。除了設計理念不同，「Docker的目的是要支援多使用情境，反之，CRI-O則鎖定支援Kubernetes。」SUSE表示。
SUSE解釋，Kubelet透過gRPC遠端程序呼叫CRI-O，接著CRI-O便會開始建立Kubernetes CRI運作所需的元件、服務，像是建置系統服務，串接容器映像檔下載、上傳的工作，或者設定好容器網路，讓容器、Pod可以互相連線。相比功能豐富的Docker Daemon，「CRI-O的功能則輕薄了許多。」

開發者就可以自行選擇，使用CRI-O或者Docke開源引擎作為容器Runtime。目前SUSE CaaS平臺雖預設使用Docker，不過SUSE的未來布局，是計畫先透過此技術預覽功能，蒐集使用者回饋後，並且預計在下個新版本SUSE CaaS平臺第4版，正式支援CRI-O。圖片來源：SUSE


Kubelet透過gRPC遠端程序呼叫CRI-O，接著CRI-O便會開始建立Kubernetes CRI運作所需的元件、服務，像是建置系統服務，串接容器映像檔下載、上傳的工作，或者設定好容器網路，讓容器、Pod可以互相連線。圖片來源：SUSE

",https://www.ithome.com.tw/news/124672,"新聞,容器技術,SUSE,容器平臺,Container"
124653,14,2018-07-19,Docker 18.06社群版釋出，未來要放慢發布速度，延長專案維護時間,未來Docker社群版發布將有新規則。第一條新規則，未來Docker社群穩定版本，將要改為一年兩次的發布周期。原先開發者可以選用Edge選項，搶先測試Docker新功能。未來該公司不再支援Docker CE Edge。未來想要搶先用新功能的開發者，現在Docker CE Edge已經被整合至Docker社群版中的Nightly Build Channel。," 現今容器市場的焦點多半聚焦在Kubernetes生態系的發展，相較之下掀起容器熱潮的Docker，昔日光環已褪色不少。在6月DockerCon上，該公司的產品發布，主要以企業版Docker為核心，邁向多雲整合、異質IT環境架構整合。而在近日，該公司終於發布Docker社群版的消息，推出了Docker 18.06社群版（Community Edition，CE）。
除了發布新產品，該公司也公告，未來Docker社群版發布將有新規則。第一條新規則，未來Docker社群穩定版本，將要改為一年兩次的發布周期，此次釋出的Docker 18.06社群版，是最後一個維護生命周期為4個月之版本，未來版本如Docker 18.09、Docker 19.03社群版開始，就會開始適用新發布周期規則，並且將支援時間拉長至7個月。
Docker表示，將發布周期從每季發布，放慢至每半年發布，開發團隊可以針對不同作業系統，製作不同的打包檔案，「讓每個新版本作業系統上都可以執行Docker」，而未來釋出預先版本前，Docker也會推出公開測試版。
第二條規則，則是取消Docker社群版的Edge選項。原先Docker在2017年時，讓使用社群版的開發者可以選擇Edge選項，該版本每月都會釋出更新，可以搶先測試新功能。在社群版新規則發布後，該公司已經不再支援Docker CE Edge。未來想要搶先用新功能的開發者，現在Docker CE Edge已經被整合至Docker社群版中的Nightly Build Channel。不過Docker表示，桌面版Docker，如Docker for Mac、Docker for Windows，仍然保有Edge選項，該公司會持續每個月發布新功能。
",https://www.ithome.com.tw/news/124653,"新聞,Docker,容器技術,Container"
124617,14,2018-07-17,Azure DevOps專案功能正式上線，融合VSTS加速整合、建置及部署自動化,Azure DevOps專案服務也與自家其他雲服務結合，開發者可將App部署在VM環境、Azure Kubernetes環境，或者自家微服務平臺Azure Service Fabric。目前該服務所支援的開發環境，共有.NET、Node.js、Java、Python、Ruby，以及Go等熱門選擇。," 去年微軟在Connect();大會上，開始布局雲端DevOps服務，推出了Azure DevOps專案服務，讓企業用戶可以使用Azure App Service，發布應用程式，一併將開發、部署及監控等環節都搞定，當時該服務處於預覽版本狀態，現在該服務已經邁向正式版本，從Azure Portal登入後，開發者就可以開始建立CI、CD工作流程。
微軟表示，使用Azure DevOps專案服務，開發者可以存取所有必要的Azure資源。以Git儲存庫作為程式碼版本控制的樞紐，搭配自動化的CI、CD流程，加快軟體開發流程。在此新服務中，微軟也有提供即時監控儀表板功能，讓開發者可以從Azure Portal中，監控程式碼提交、建置以及部署的狀況。例如，Azure DevOps專案服務就跟微軟Visual Studio Team Service（VSTS）整合。微軟表示，在VSTS帳號內建立Git儲存庫後，未來新專案程式碼就可以提交至該儲存庫，每次整合就會驅動一次建置，而只要建置工作正確完成，服務就可以部署在任一Azure環境中執行。
Azure DevOps專案服務也與自家其他雲服務結合，開發者可以將App部署在VM環境、Azure Kubernetes環境、微服務平臺Azure Service Fabric，或者無伺服器平臺Azure Functions。目前該服務所支援的開發環境，共有.NET、Node.js、Java、Python、Ruby，以及Go等熱門選擇。
在DevOps工作流程中，監控也是個非常重要的環節。使用Azure DevOps專案服務的企業，也可以搭配微軟分析工具Azure Application Insights，遙測應用程式的運作效能、伺服器回應時間、請求次數及失敗次數，再一併回傳至Application Insights。系統管理員也可以設定條件，像是當回應時間超過某臨界值，系統可以透過郵件發布警報。

Azure DevOps專案與其他Azure資源整合，開發者可以選擇要將App部署在Linux或WindowsVM環境、Azure Kubernetes環境、微服務平臺Azure Service Fabric，或者無伺服器平臺Azure Functions。圖片來源：微軟


Azure DevOps專案服務跟微軟Visual Studio Team Service（VSTS）整合，使用者可以選擇要建立新VSTS帳號，或者沿用舊帳號。圖片來源：微軟

 
在此新服務中，微軟也有提供即時監控儀表板功能，讓開發者可以從Azure Portal中，監控程式碼提交、建置以及部署的狀況。在VSTS帳號內建立Git儲存庫後，每次程式碼整合就會驅動一次建置，而只要建置工作正確完成，服務就可以部署在任一Azure環境中執行。在儀表板內，微軟也有整合分析服務Azure Application Insights。圖片來源：微軟

",https://www.ithome.com.tw/news/124617,"新聞,Azure,DevOps"
124469,14,2018-07-17,Container周報第73期：Google釋出Java大型應用容器化工具，微軟則推出開發者新Azure測試空間,近日，Google開源釋出了一款Java容器化工具Jib，讓開發者可以將Java應用打包為符合開放容器標準（OCI）的容器映像檔，," 07/04~07/11精選Container新聞
#Java #容器化大型Java應用容器化更容易了，Google開源釋出Java容器化工具Jib
今年多家雲端廠商相繼推出代管容器服務，可支援Java、Python、Node.js等環境，但老舊大型Java應用如何支援最熱門的容器技術？近日，Google開源釋出了一款Java容器化工具Jib，讓開發者可以將Java應用打包為符合開放容器標準（OCI）的容器映像檔，而Java開發者常用的建置工具Maven、Gradle，只要安裝延伸套件就可以使用。
Google表示，Jib這款開源Java容器化工具，可以提供容器映像檔建置服務。原先使用者將Java應用程式容器化時，必須先建置JAR檔，並且與Dockerfile匯入Docker，利用Docker Daemon，完成容器映像檔建置後，再將映像檔上傳至儲存庫。
#容器 #DevOpsCloudFoundry最新調查：開發者想先擁抱容器，但超過6成CIO想先導入CI/CD
近日Cloud Foundry基金會（CFF）公布最新容器使用率調查結果，針對601位IT決策者的調查結果，其中已經採用容器技術的公司有32％，但有25％受訪者，決定在未來1年內採用容器。已經採用DevOps流程的比例也同樣是32％，但未來一年想要導入DevOps的比例只有17％。企業想要採用容器的力道比採用DevOps更為迫切。
另外也有針對Serverless的調查結果，目前已經採用者的比例也有19％，未來一年想要採用的比例也不低，達到19％。
若從不同職位的採用優先度來看，開發者最嚮導入容器，但維運人員或架構師則想先採用機器學習技術，而CIO和CTO或IT管理者則是將CI/CD視為優先導入的項目，超過6成比例，第二優先採用的技術則是Serverless，也都遠高於容器技術的採用排序。 

#容器部署 #Kubernetes在地部署容器平臺又新選擇，Nirmata推出自家K8s容器平臺軟體
儘管多家公有雲供應商的Kubernetes容器代管服務陸續上線正式服務，但企業不一定想把所有的服務都搬上雲端，仍有不小的企業在地部署需求（On-Premises），加州這家Kubernetes容器管理新創Nirmata就會推出了可自建的CaaS（Container-as-a-Service）平臺軟體，可供企業打造自家IT維運平臺之用，可支援多租戶架構，和高度CI/CD整合。因為利用Kubernetes為基礎來開發，也可串連到多家公有雲平臺如AWS或Azure。

#A10 #Kubernetes更多網通業者聚焦容器叢集管理，A10負載平衡產品支援Kubernetes
隨著Kubernetes容器管理平臺逐漸成為企業資訊基礎架構的部署選擇，網通業者也開始向容器叢集管理平臺靠攏，近日老牌網通業者A10 Networks就強化了自家產品負載平衡機制，能支援Kubernetes平臺。用來動態調整輕量級應用派送的A10 Harmony控制器，現在能分享資訊給Kubernetes的A10 Ingress控制器，讓開發者更容易管理容器叢集中應用程式的網路流量政策。

#AKS #命名空間容器開發測試有新選擇，微軟推出AKS開發者空間環境
微軟再次加強AKS的開發者功能，釋出線上開發人員空間（Dev Spaces）環境，讓雲端應用程式可以更快進行除錯、建置，現在此服務已經進入公開預覽版。
在今年Build大會中，微軟就已經預先展示此功能，以可以簡單、快速開發容器應用為訴求。微軟表示，開發者只需要準備好IDE及Azure CLI，隨即可在AKS環境中開發應用。鍵入所需指令後，此功能就會開始建置獨立Kubernetes命名空間，而使用者馬上就可以開始著手軟體開發。
除快速搞定開發環境的優點，AKS開發人員空間功能，也有搭配程式碼同步技術，「讓開發者IDE與AKS環境中執行的容器同步。」微軟表示，使用容器、Kubernetes，以往都避不了映像檔的建置、上傳至儲存庫，最後才部署於正式環境。現在使用者在IDE結束開發工作後，程式碼即時同步至AKS叢集。
#叢集管理 #Lighthouse容器新創Portworx推叢集管理工具Lighthouse
投入原生容器儲存市場的容器新創Portworx，在近日推出了叢集管理工具Lighthouse，提供視覺化監控介面，管理Portworx儲存叢集。Lighthouse以Docker容器格式打包執行，讓使用者可在筆電開發環境安裝此監控工具。Portworx也改善易用性，現在新增、移除叢集變得更方便，只需要點擊頁面中「新增/管理」選項就能完成。而開發者也能更近一步檢視叢集中各節點、快照，或者個別容器的資訊。而利用搜尋功能，使用者可以在叢集選單中鍵入標籤、姓名，引導開發者更快鎖定特定節點。
Portworx企業級儲存產品PX-Enterprise 1.4版也可以搭配Lighthouse，監控叢集的健康狀態、節點數量，以及整體儲存容量的使用量。

#自動更新 #Pharos自動更新Host的Kontena家K8s版本Pharos改版，支援Ubuntu 18.04和RHEL 7
容器微服務平臺新創公司Kontena推出了自家Kubernetes版本Pharos，以社群版本K8s為核心，同時也是經過認證的Kubernetes版本，而Kontena發行的版本，也能相容Arm 64位元架構處理器。近日Kontena再釋出Pharos 1.2.0版，已支援更多作業系統，包括CentOS 7、RHEL 7，以及Ubuntu 18.04 LTS等作業系統。1.2.0版這次所支援的Linux作業系統，也都可以搭配輕量級容器Runtime cri-o使用。另外，也可讓容器主機搭配的Host作業系統，可支援自動更新、滾動更新等功能。使用者可以根據維運需求，決定服務是否要暫時中止，或者在節點完成更新前，暫時拒絕回應新的系統請求。
#紅帽 #OpenStack紅帽OpenStack邁入第13版，大力擁抱容器化，強化與OpenShift整合
@內文：紅帽近日釋出的自家OpenStack新的13版，利用今年3月推出的新功能Fast foward upgrades，改善OpenStack過去較難升級的痛點。過去紅帽提供的更新周期，分別有半年或者18個月的選項。而利用Fast foward upgrades，企業就不受限在這兩個選項。該公司表示，利用容器技術，打包紅帽OpenStack並且進行部署，可以簡化OpenStack更新的手續。現在使用紅帽OpenStack第10版本的企業，即可透過Fast foward upgrades，將平臺更新至第13版。此外，紅帽新版OpenStack也大力擁抱容器技術，所有的系統服務都已經容器化，也加強與OpenShift、雲端超融合產品線整合，來提供容器式的開發、部署平臺，還具備可擴充混合雲的功能。紅帽提供標準3年支援，可選購延長2年支援。
責任編輯／王宏仁
更多Container產品動態
Canonical推迷你作業系統Minimal Ubuntu，映像檔只有29MB
Nutanix的AOS軟體推出5.8版，內建金鑰管理也支援SAML 2.0標準
ASP.NET Core 2.0版正式支援開放式資料通訊協定OData
＠資料來源：iThome整理，2018年6月
",https://www.ithome.com.tw/news/124469,"新聞,容器,DevOps,CI/CD,Serverless"
124389,14,2018-07-14,當年，雲端教父如何成功讓Netflix成為第一間完全上雲的大型企業,在2010年10月之前，幾乎沒有人相信，大型企業真的可以全靠雲端，徹底取代資料中心。當時擔任Netflix雲端架構長，而現在是AWS雲端架構策略副總裁的Adrian Cockcroft，他的一場演講，從此改變了許多人的想法。而且，那是他第一次完整揭露Netflix的上雲之旅," 關於這趟旅程，起點是2008年8月的一次SAN儲存設備故障事件，足足讓Netflix的關鍵資料庫系統當機2天，當時因為無法查詢訂單資料，一連3天，沒有寄出任何一片顧客租借的DVD影片。大家都在問Netflix怎麼了！Netflix是全美最大的DVD租片服務公司，顧客透過網站租片，過兩天就會在自家郵箱收到，看完再用回郵信封寄回。
這次事件讓Netflix開始反省，就算砸大錢，買來業界最高階的Oracle資料庫系統，搭配最頂級的硬體設備設備，為何還是會出錯？當時Adrian Cockcroft是網站工程團隊的總監，他開始意識到：「服務可用性的主角應該是應用程式，而不是硬體。」而順著這個思路進一步發現，其實，Netflix不見得需要昂貴的硬體，而是可以考慮租用便宜的雲端環境，也許就夠了。
這並不是Netflix獨到的經驗，很多企業資訊主管遇到當機事件時，都會有同樣的反省。但是，「得等到出現外在危機的壓力，企業才會真的願意採取行動，我們也是。」Adrian Cockcroft事後回憶。

Netflxi在2010年4月公開上雲計畫，所有人都不看好，直到年底公開了這張AWS架構圖後，才讓大家意識到，大型企業真的也可以上雲。
 
全球布局的外部壓力浮現，才下定決心上雲端
這個來自外部的壓力，出現在2009年。Netflix除了租片服務，從2007年也開始在美國提供線上影片串流服務，當年2月，Netflix宣布累計出借了10次億份DVD，但他們的串流服務人數，遲遲沒有突破1千萬用戶。
之後，Netflix在2010年進軍國際市場，而為了解決DVD全球寄送的問題，Netflix決定改變，開始主推線上串流服務。這也讓Adrian Cockcroft開始思考，新業務帶來的挑戰有多大。
原有的DVD出租生意，顧客大約每周使用一次Netflix網站來租片，須等到DVD寄到顧客手上看完後，顧客才會再次上站來租片，寄送的時間，往往決定了顧客下次何時再上線挑片的頻率，而這個頻率大約是每人每周一次。
但是，線上串流服務的挑戰完全不同，Netflix串流服務顧客每天大約可以可以觀賞5到6段影片，租片量是DVD租片的10倍以上，而影片還提供個人化瀏覽服務，顧客會花更多時間上站選片，甚至顧客看到一半停下來，網站還要記住他當時所看到的進度，下次再繼續播放。根據Adrian Cockcroft估計，串流顧客與Netflix官網的互動（瀏覽）頻率，大約是租片顧客的100倍。
換言之，租片量10倍成長，顧客互動次數增加100倍，兩者相乘，租片顧客改用串流服務後，每周帶來Netflix資料中心的流量成長，是過去的1千倍。只要有0.1%的用戶改用串流服務，Netflix資料中心承受的流量規模，就要翻倍。

轉移前端系統時，Netflix的策略是，先從最簡單的網頁開始轉移，一次只將網站上的一頁服務搬上雲端。這是Netflix第一個搬上AWS的網頁。（資料來源：Adrian Cockcroft）
 
IT未來要考慮全球顧客的參與度
從IT營運模式的改變來看，Adrian Cockcroft指出，過去IT只需考慮到，以員工人數來決定系統的擴充規模，但未來IT要考慮全球顧客的參與度，以此決定擴充規模。這個數位轉型壓力是根本性的變革，從服務數百、數千人，到服務全球顧客，而且要提供24小時服務。
2009年時，Netflix有兩個選擇，第一是雇用一個世界級資料中心維運團隊，未來需要多少用量，就預先建置多少資料中心。第二個選擇是使用Netflix競爭對手AWS提供的雲。當時的Amazon Prime影片串流服務，是Netflix最大的競爭者。「選擇自己蓋資料中心，還是租用競爭對手的服務，改把錢花在內容和開發者身上。」Adrian Cockcroft表示，這是當年經營高層最頭痛的抉擇。
還有一個難題，促使Netflix最後決定上雲端。那就是進軍全球市場後，Netflix串流服務也會整合到多種播放裝置上，不只是電腦，還增加了iPhone、Wii、PS3和Xbox的版本，未來的成長規模幾乎難以預測。如何滿足至少是1千倍的擴充需求？Netflix決定開始認真評估，了解搬上雲端的風險。
首先，考慮AWS業務和Amazon Prime服務的關連，後來Netflix高層也直接聯繫Amazon創辦人，確定兩者各自獨立運作。其次是要測試AWS的能耐，評估AWS的擴充能力，能否勝過自行建置資料中心的速度。後來，Netflix簽署AWS 第一個企業授權契約，直接上網用信用卡刷卡就完成這件事。
直到2010年4月，Netflix開始公開即將上雲的消息，Adrian Cockcroft表示，大家都覺得他們瘋了，因為他們是第一家這麼做的大企業。不過，早在2009年，Adrian Cockcroft率領的網站工程團隊，就展開上雲轉移的作業。而這個過程的第一步，是先檢視那些不會直接面對顧客的系統，決定先將影片編碼（Movie Encoding）伺服器放上AWS的EC2。因為，這類影片編碼服務需要大量機器來運算，但現有資料中心的空間並不足以擴充。
選定搬遷的目標後，下一步就是要測試EC2的擴充能力，Adrian Cockcroft表示，那次一口氣向AWS提出要求，想在一小時內要取得3千臺EC2虛擬機器，後來，真的拿到了，也才讓Netflix相信，雲端真的可行；接著，就真的把影片編碼的實體主機關了，全部搬上EC2。影片編碼的處理，租用了數千臺EC2實例來組成運算農場，當時還用了不少Windows環境的影片轉碼軟體，處理了上萬部影片，而為此而儲存在S3的資料量，已經高達PB級。
除了影片編碼，第二步則是改將大量的網站存取日誌放上雲端，尤其是所有串流服務的日誌。Netflix有太多想紀錄追蹤的資訊，都改用S3來儲存，這些日誌資料每天的成長量也是TB級。最後，利用Hadoop來分析，還和AWS合作整合Hive SQL來設計資料超市，再整合到Netflix內部資料中心的BI系統上。
2010年初，Netflix就決定不再蓋資料中心了，並且在年初開始也把串流服務的後端系統搬上雲，例如像是DRM金鑰管理、用戶重播書籤服務、高可用設計的「播放」按鈕服務等。
Netflix還決定要在2010年底前，要把前端系統和用戶端設備的API服務，也都搬上雲端。當時，多數後端系統仍部署在資料中心內，不過，前端上雲後，機房就可用於擴充後端系統。

過去IT只考慮服務員工數，來決定系統規模，但未來IT要考慮全球顧客的參與度，來決定擴充力道，這個數位轉型壓力，是根本性的變革。──雲端教父 Adrian Cockcroft
 
2010年底官網前端系統全面上雲
「我們沒有備案！一定要在年底前將網站前端搬上AWS。」那時，Netflix每次經營會議時，都會秀出一張圖，上面有一臺準備起飛的飛機，代表著Netflix，軌道盡頭就是樹林，「到了年底，沒有飛上雲端，就會撞上樹林。」Adrian Cockcroft強調。在2010年12月初，完成官網最後幾頁的轉移，過程沒有發生任何一次當機，Netflix順利飛上了雲端。
原本，Adrian Cockcroft一開始設計了一個漸進式轉移的作法，但他的老闆直接指示：「全部砍掉重練！頂多留下你覺得有用的10～20％，你不要的程式碼，一行都不要留。」他希望趁著重新設計的機會，要求Adrian Cockcroft設計可符合未來5年需求、兼顧效率和生產力的新架構。「因為，我們不想成為一味節省成本的公司，而要追求業務速度。」Adrian Cockcroft表示。
除了重新打造新架構，在轉移前端系統時，Adrian Cockcroft的策略是，先從最簡單的網頁開始轉移，逐次將網站上的一頁服務搬上雲端，並且先從最簡單的API服務開始轉移，其次是轉移對應的頁面，然後再進行下一個API和下一個頁面。同樣的作法，先套用到其他服務頁面，再來，才是轉移其他不同資料來源的頁面。
因為是一頁一頁地轉移上雲端，因此，他們也採取雙軌系統並行。用戶先登入位於資料中心的舊版官網網頁、後端系統和登入服務，再挑選合適網頁，切換成由雲端提供服務的版本給顧客。一旦出現問題，可以馬上切換回來，因為採取標準HTTP轉址來切換，因此，顧客不會察覺。
在資料轉移的策略上，原有系統資料都儲存在Oracle資料庫中，先利用Oracle遠端副本功能，在雲端建立一份副本資料庫，多數用戶只是需要查詢資料，就先由雲端資料庫來提供，只有用戶需要更新記錄時，才連回資料中心的Oracle資料庫來修改。
2011年決定全面上雲端後，新的挑戰是如何備份。過去，Netflix採用磁帶進行離線備份，來保存系統記錄。上了雲端後，Adrian Cockcroft不想把資料再運回本地端資料中心來備份，因此，改而不同的服務區域，建立不同的AWS帳號，利用不同帳號的S3服務，來提供另一個備份。
此外，所有系統記錄資料不會刪除，而是採取每90天自動執行清除程式，將資料壓縮備份到歸檔區的S3帳號，因為可預期這些資料存取頻率不高，壓縮資料的時候，也以縮小容量為主，而不用考慮解壓縮速度來節省空間。後來AWS推出了超便宜的歸檔服務Glacier，就有更彈性的備份策略可用。
後來，Netflix發現，上雲的決定是正確的作法。因為拓展到全球市場後，光是2009年第三季到2010年第三季，一年內串流服務就成長了145％，從原有的1千萬名用戶，增加到1,600萬人。更大的挑戰是，到了冬天，大家都待在家裡看電視，從感恩節到聖誕節期間的串流影片需求，將會大爆發。2011年時，Netflix就決定，全面上雲，連後端和全部資料都要搬上去，不過，仍有少數資料轉移不易，例如，當時有些支付法規遵循的要求，規定資料必須落地。結果，他們花了7年時間，直到2016年1月，Netflix才完成所有雲端轉移工作，並且關閉了資料中心的最後一臺機器。
 
數位轉型三階段：速度、規模，以及策略
從Netflix上雲的經驗，Adrian Cockcroft歸納，企業數位轉型的途徑可分成三階段。第一，是先追求速度，採用新架構，例如將所有JAR元件都微服務化，就不用每隔兩周得關機10分鐘來更新，或是統一服務設計模式，而不是共用一套標準程式碼，同時，還將複雜糾纏的服務API，改為功能分明的分層式架構。這些設計，後來讓Netflix的雲端架構，成為微服務架構的經典參考範本。
「有了速度，下一步才追求規模。」他解釋，例如，透過水平式擴充架構，滿足越來越多服務上雲後的運算需求，還要提高利用率。數位轉型的最後一個階段，就是策略性轉型，目標是徹底取代資料中心，將關鍵應用搬上雲端。
Netflix租用了超過10萬個EC2虛擬機器，來服務遍布全球130多國市場的上億名用戶。根據Netflix統計，從2007年12月到2015年12月為止，每月串流服務播放總時數，成長了1千倍以上。正是因為當年上雲端的決定，才能支撐起這樣的千倍的發展速度。
 
 Profile 
雲端教父 Adrian Cockcroft
1982年：進入劍橋顧問公司擔任軟體工程師，一待就是6年，專責開發即時嵌入式訊號處理和控制系統，後來還兼職擔任Unix系統首席管理員。

1988年：進入昇陽電腦，任職長達16年，直到2004年才離開昇陽，他不只熟諳雲端技術和軟體技術，更是高效能電腦技術的專家，最後成為昇陽高效能工業計算（HPTC）部門的首席架構師。在昇陽期間，也有多本高效能電腦的相關著作，例如他是《Sun Performance and Tuning：Java and Internet》第二版一書的第一作者，這是暢銷的HPC調校參考書之一。
2004年：離開昇陽後，9月轉而進入eBay工作，主要參與多項創新計畫，也是eBay Research Lab創始團隊成員之一。早在iPhone和Android問世之前，Adrian Cockcroft就開始研發自製手機和先進行動應用。
2007年：進入Netflix，擔任網站工程團隊總監，負責Netflix首頁開發，以及打造個人化選片服務，尤其是研發背後的演算法，也參與了Netflix Java系統重構計畫，也就是SOA架構的導入。
2008年8月：一場SAN儲存設備大當機，Netflix開始考慮採用雲端。Adrian Cockcroft是關鍵評估者之一。
2009年：Netflix開始展開雲端轉型之旅，先將內部系統搬上雲端AWS，例如影片編碼。
2010年：進一步將網站前端系統全部放上AWS。
2010年4月：Netflix開始宣布上雲端計畫。
2010年12月：正式完成官網上雲端轉移。
2011年：開始將後端系統搬上雲端。
2013年：Netflix也大方公開了這套轉型上雲端的經驗，甚至打包自己開發的工具和架構設計範本，開源推出了NetflixOSS平臺，這也成了設計雲端原生架構的最佳實務參考之一。
2014年：Adrian Cockcroft離開Netflix，轉而進入Battery Ventures創投擔任技術院士，從更宏觀的角度，來觀察科技產業、網路新創、創新技術的發展。
2016年1月：Netflix最後一批資料搬上雲端，完成了為期7年的雲端之路。
2016年10月：Adrian Cockcroft進入AWS擔任雲端架構策略副總裁，不只帶領AWS的開源推動工作，也開始到各國分享自己一路參與雲端架構發展的經驗。
2018年6月：Adrian Cockcroft首次來臺分享數位轉型經驗和雲端發展策略。

",https://www.ithome.com.tw/news/124389,"新聞,Cloud,Netflix,Adrian Cockcroft"
124502,14,2018-07-12,CloudBees生產工具DevOptics強化CI、CD監控功能,這次的新功能，可以協助開發者、Jenkins管理員確保企業內部的CI、CD平臺，能支撐產品團隊運作。利用DevOptics，系統可以監控軟體交付流程的各環節，提供即時訊息或歷史數據," 提供企業級Jenkins服務的CloudBees，近年積極擁抱雲端，大力支援AWS、Azure、GCP跟OpenShift等環境，而除了擴張企業級Jenkins的布局，近日也加強自家生產工具CloudBees DevOptics功能，讓它可以監控CI、CD平臺的運作狀況。
這次的新功能，可以協助開發者、Jenkins管理員確保企業內部的CI、CD平臺，能支撐產品團隊運作。利用DevOptics，系統可以監控軟體交付流程的各環節，提供即時訊息或歷史數據。CloudBees表示，不論企業用戶導入代管Jenkins服務CloudBees Core抑或社群版Jenkins，CloudBees也可同時支援兩者，讓開發人員可以串接多個Jenkins Master，整合企業內部CI、CD平臺的運作資料。
CloudBees認為，過往開發者不易即時掌握CI、CD平臺的資訊，像是當前有多少任務執行、哪些建置服務處於閒置狀態，或者追蹤任務從開始到完成所需時間。隨著企業組織擴大，要整合這些即時資訊就變得更為困難。而勤追蹤企業CI、CD平臺例行的執行情況，也有助管理員在平臺發生異常時，及早發現。此外，管理閒置建置資源也是團隊的重要工作。得避免資源閒置過久，開銷過多基礎架構成本，或者資源臨時不足，導致軟體開發流程塞車。
在CloudBees DevOptics的Run Insights介面中，將CI平臺的資訊視覺化，管理員可以觀察，當前有多少任務正在執行、閒置Build Executor的數量、平均任務啟動所需時間，以及整體閒置時間等資訊。
而今年2月時，CloudBees釋出的Value Stream Editor工具也是協助DevOptics視覺化的重要元件。利用此工具，使用者可以管理軟體生產鏈。將原先多個資料源頭，統一彙整為單一來源。除了減少人工、複雜數據來源的困擾，也讓團隊可以使用近乎即時蒐集的數據，了解當前軟體生產鏈的運作狀況。建立完軟體生產鏈之後，系統管理員就可開始監控CI、CD平臺的運作狀況。例如，CloudBees DevOptis指出整合測試出現了多次錯誤，而在選單則可以列出是哪些任務失敗、導致整合失敗的原因，以及相關負責人員等資訊。如此一來，當平臺故障，系統管理員可以更快判斷真正的事發原因為何。

在CloudBees DevOptics的Run Insights介面中，將CI平臺的資訊視覺化，管理員可以觀察，當前有多少任務正在執行、閒置Build Executor的數量、平均任務啟動所需時間，以及整體閒置時間等資訊。圖片來源：CloudBees


CloudBees認為，勤於追蹤企業CI、CD平臺例行的執行情況，也有助管理員在平臺發生異常時，及早發現。而CloudBees DevOptics可以列出當前任務，成功執行、不穩定，或者失敗的百分比。有利企業理解正常運作下，系統的表現數據為何。圖片來源：CloudBees


在今年2月時，CloudBees釋出的Value Stream Editor工具也是協助DevOptics視覺化的重要元件。利用此工具，使用者可以管理軟體生產鏈。將原先多個資料源頭，統一彙整為單一來源。除了減少人工、複雜數據來源的困擾，也讓團隊可以使用近乎即時蒐集的數據，了解當前軟體生產鏈的運作狀況。


建立完軟體生產鏈之後，系統管理員就可以馬上開始監控CI、CD平臺的運作狀況。像是圖表的範例，CloudBees DevOptis指出整合測試出現了多次錯誤，而在右邊選單則可以馬上列出是哪些任務失敗、導致整合失敗的原因，以及相關負責人員等資訊。如此一來，當平臺故障，系統管理員可以更快判斷真正的事發原因為何。圖片來源：CloudBees

",https://www.ithome.com.tw/news/124502,"新聞,Jenkins,DevOps,CloudBees,監控"
124483,14,2018-07-11,DevOps周報第1期：臺灣第一屆敏捷高峰會500人齊聚，連柯P都來開講快速變革思維,"DevOps國內外精選新聞
#臺灣敏捷社群 #Agile臺灣第一屆敏捷高峰會500人齊聚，連柯p都來分享快速變革的秘訣"," DevOps國內外精選新聞
#臺灣敏捷社群 #Agile臺灣第一屆敏捷高峰會500人齊聚，連柯p都來分享快速變革的秘訣 
在6月底，近500人齊聚在臺北參加臺灣第一屆敏捷高峰會，超過30多位講者，其中更有來自全球200多位認證Scrum訓練師（CST）中的三位，遠從瑞典、德國、中國來臺開講。開場是前行政院長張善政，他點出敏捷是企業實現AI應用的關鍵，臺北市長柯文哲也登臺分享，改造臺北市府團隊不斷求變追求創新的另一種思維。台灣敏捷協會理事長林裕丞也以「要幫臺灣長出敏捷的翅膀」為訴求，強調臺灣有多個敏捷社群和敏捷輔導機構，可以扮演敏捷之路上的老司機，希望將「快速迭代」和「高自主性」思維推廣到更多臺灣企業和開發者。簡報下載連結
#柯文哲 #團隊創新求變得先容忍失敗！柯P另類團隊創新秘訣：成功是失敗之母
企業想要導入敏捷開發方法，不只是光是採用新方法或新工具就夠，還得讓團隊具備敏捷開發的文化才能真正落實，但想要改變舊有風氣不是一件容易的事。臺北市長柯文哲日前也現身敏捷高峰會，分享他進入市政府後，如何再造台北市政府組織文化的經驗。
他更要求臺北市府團隊要謹記「成功為失敗之母。」不要緊抓著成功模式不放，而是更要不斷追求創新。這也是他想要賦予市政團隊的第二個使命，得為城市不斷尋求創新。不過，追求創新也得有配套，想要擁抱創新，他建議，主管還應該要創造一個不怕失敗的環境。他認為，容許失敗最好方法就是，採取小規模試辦，試辦失敗就收起來檢討，若成功就繼續推展，但要隨時修正，「因為環境會改變。」他說。這正是他上任後，不斷推動多項臺北試辦或實驗平臺的緣故。
#雲端高可用 #混沌工程LinkedIn公開混沌工程經驗，並開源部分異常注入框架LinkedOut
LinkedIn對外發表並部分開源其異常注入測試框架LinkedOut，這個框架可以在不影響會員使用經驗下，透過兩種機制引發分散式系統異常，其中包括錯誤、延遲以及超時3種情況。LinkedIn認為，該框架對內除了可以幫助工程師產出高品質程式碼，對外也能展示其系統的強健性。LinkedOut現在可以製造出3種類型的服務異常，分別是錯誤、延遲以及逾時。
在避免影響會員使用經驗的前提下，LinkedOut現在有兩個主要機制來觸發干擾器（Disruptor），其中一個是使用LiX，而這個本身是LinkedIn上進行A/B測試以及功能限制的框架，LiX可瞄準多個層級引發錯誤，測試範圍可從單一用戶進行個別請求，到下游叢集對一定比例的會員發出範圍請求。

#Slack #團隊協作Slack強化搜尋功能，更快找到聊天記錄、檔案文件
許多新創、小規模組織愛用的企業通訊軟體Slack，面對Google Hangouts、Microsoft Teams的競爭壓力，也得要加速腳步加強自家產品服務。在5月先加強整合第三方協作平臺，聊天內容也可直接加到工作清單，近日更宣布，改善自家通訊平臺搜尋功能，利用新釋出的搜尋過濾器，可以更快找到人特定對話記錄、傳送檔案。Slack預計在數禮拜後，上架這個新搜尋功能。
新的搜尋機制中，使用者可以選擇更多過濾條件，像是對話對象、頻道名稱，或者文件類型。Slack舉例，像是鍵入世界盃足球賽為關鍵字，如果使用者第一時間沒有在對話紀錄、檔案中看到搜尋目標，可以進一步，利用通聯對象、公司團隊頻道，以及檔案類型過濾，更快找到目標。


#臉書 #效能優化工具臉書釋出自動優化工具Spiral，數分鐘就能自動改善服務更新後的快取政策
臉書開發了一個小型的嵌入式C++函式庫Spiral，以機器學習為資源有限的即時服務，產生資料驅動或是反應式的啟發演算法，以最佳化服務。臉書提到，過去他們手動撰寫快取（Cache）、許可（Admission）與驅逐（Eviction）策略太過困難，而且也過分耗費時日，Spiral可以加速這個最佳化過程從數周到數分鐘。Spiral可以單純在本機端運作，進行輕量的模型訓練，或是也能用於回傳統計訊息或是回饋至後端，以視覺化呈現資訊用作除錯，或是以日誌資料記型長期儲存，供未來分析使用，也可以進行資源吃重的模型訓練。
#Jenkins、#AzureJenkins企業版正式登上微軟Azure Kubernetes代管服務
Jenkins開發商CloudBees近日宣布，自家企業版Jenkins服務CloudBees Core，正式與微軟Azure Kubernetes服務整合。該公司表示，當今企業開始擁抱微服務、容器技術，開發、部署雲端原生應用程式。目前Kubernetes成為最多人使用的容器調度工具，「不過要安裝、維護該工具，也需要相當程度的專業」，因此該公司的策略是與提供Kubernetes服務的Azure合作，讓企業用戶在代管環境執行Kubernetes，利用該環境原生的命令列介面，安裝CloudeBees Core，開發者隨時可以開發流程中導入CI/CD工作。


#Serverless #SQSAWS SQS現在可驅動AWS Lambda無伺服器事件了
AWS的無伺服器應用服務又加強了，現在旗下的雲端代管訊息佇列服務Amazon Simple Queue Service（SQS），也可以用來驅動AWS Lambda事件。使用者可以在AWS管理主控臺建立新訊息佇列。選用建立標準訊息佇列後，Lambda以後便不會因接收FIFO訊息佇列而觸發。而Lambda會根據接收到的系統訊息量，自動水平擴充、水平收縮。當Lambda平臺處理完該批訊息後，這些訊息就會從佇列中移除。反之，萬一處理失敗或是逾時，訊息就會被回傳至佇列。已經使用AWS SQS的企業用戶，AWS會根據既有SQS API呼叫的計價標準收費，但是此項整合AWS SQS及AWS Lambda的新功能，並不會收取額外費用。

#甲骨文 #Ansible加強雲端DevOps功能，甲骨文公有雲服務推出Ansible模組
甲骨文近日宣布，推出公有雲服務Ansible模組。現在開發者愛用的Terraform、Ansible等基礎架構自動化工具，都可以在甲骨文公有雲上使用了。甲骨文也將此Ansible模組，在GitHub上開源釋出。
甲骨文表示，利用Ansible進行雲端資源的組態設定、建置，可以提高任務的自動化，目前Ansible已經支援該平臺上的核心服務，「未來也會擴張支援。」而Ansible所包含的模組，例如雲端、資料庫、監控、網路以及儲存等，甲骨文雲端也全都支援，開發者可以更簡單串接公有雲及本地開發環境。

#雲端部署 #Ubuntu雲端大量部署優先! Canonical推迷你作業系統Minimal Ubuntu，映像檔只有29MB
Canonical近日推出了新的迷你作業系統Minimal Ubuntu，特別針對雲端大量部署而重新設計。這個新版本的Ubuntu，比起標準版的Ubuntu伺服器映像檔，容量縮小至50％以下，而啟動速度則快上40％，現在Minimal Ubuntu 16.04 LTS及18.04 LTS版本，已經可以在AWS EC2、Google Compute Engine或者OpenStack、KVM、LXD等虛擬化環境部署。針對不同虛擬化、公有雲環境，Minimal Ubuntu也有修改其作業系統核心，以加速其效能。Canonical表示，Minimal Ubuntu 18.04 LTS版打包成Docker映像檔，只須占用29MB的空間，讓開發者可以快速在跨雲環境下，部署容器化應用程式。

責任編輯／王宏仁
更多DevOps動態
紅帽Ansible釋出2.6新版，開始強化記憶體利用率
GitLab 11.0來了！主打高度自動化DevOps
Git 2.18正式釋出，Git協定第二版可用了
資料來源：iThome整理，2018年7月
",https://www.ithome.com.tw/news/124483,"新聞,Agile,柯文哲,混沌工程,IT周報,DevOps"
124465,14,2018-07-11,加強雲端DevOps功能，甲骨文公有雲服務推出Ansible模組,利用Ansible進行雲端資源的組態設定、建置，可以提高任務的自動化，目前Ansible已經支援甲骨文雲平臺上的核心服務。," 除資料庫、ERP產品，公有雲是甲骨文近年加強經營力道的事業，在今年陸續加強對Kubernetes、GPU的支援，也與Cloudera合作，讓企業用戶可以在該公有雲平臺使用Cloudera的資料倉儲、串流分析等服務。而除擴張平臺的大數據、運算力等功能，甲骨文在近日也宣布，推出公有雲服務Ansible模組。現在開發者愛用的Terraform、Ansible等基礎架構自動化工具，都可以在甲骨文公有雲上使用了。甲骨文也將此Ansible模組，在GitHub上開源釋出。
甲骨文表示，利用Ansible進行雲端資源的組態設定、建置，可以提高任務的自動化，目前Ansible已經支援該平臺上的核心服務，「未來也會擴張支援。」而Ansible所包含的模組，例如雲端、資料庫、監控、網路以及儲存等，甲骨文雲端也全都支援，開發者可以更簡單串接公有雲及本地開發環境。
Ansible的優點之一，就是其架構採用Agentless設計，不需要額外架設組態設定伺服器，因此管理節點不用預先安裝代理程式。使用甲骨文雲端Ansible模組，使用者同樣也必須使用該工具的腳本Ansible playbooks，宣告基礎架構的組成方式。設定完畢後，Ansible就會協助開發者，利用甲骨文雲端服務的各項資源，拼湊出符合腳本定義的基礎架構。在使用前，開發者必須先在其甲骨文公雲環境安裝Python SDK，並且從GitHub上複製一份Ansible模組儲存庫，安裝完畢後，就可開始撰寫Ansible playbooks。

而Ansible的內建模組，例如雲端、資料庫、監控、網路、打包、儲存、網頁基礎架構等，甲骨文雲端也全都支援，開發者可以更簡單串接公有雲及本地開發環境。

 
",https://www.ithome.com.tw/news/124465,"新聞,甲骨文,Ansible,DevOps"
124285,14,2018-07-03,Container周報第72期：5千人容器應用大調查，JavaScript和Python是容器應用主要語言,高達57％的開發者在容器中使用JavaScript語言，其次則是Python，使用比例也高達46％，這是容器應用的兩大主流語言，PHP則排名第三（36％）而Go語言（28％）排名第四," 06/27~07/03精選容器新聞
5千人容器應用大調查，JavaScript和Python是容器應用主要語言
根據DigitalOcean最新調查5千位開發者，使用容器技術的比例高達49％。吸引開發者採用容器技術的原因主要有5個，第一項就是擴充性（39％）、其次是簡化測試（24％）、加快測試工作（23％）和避免廠商綁定（10％）。而在調度工具的選擇上，Kubernetes一面倒為大宗，42％的開發者採用，不過，Docker Swarm的愛用者比例也不低，有35％的開發者採用，排名第三、第四的調度工具則是紅帽的OpenShift（5％）和Apache Mesos（3％）。
用來開發容器應用的程式語言，目前仍以JavaScript為大宗，比例甚至超過了一半，高達57％的開發者在容器中使用JavaScript語言，其次則是Python，使用比例也高達46％，這是容器應用的兩大主流語言，PHP則排名第三（36％）而Go語言（28％）排名第四，企業應用常見的Java語言則是排名第五（27％）。
Kubernetes發布1.11版，CoreDNS和IPVS進入正式功能
近日Kubernetes正式推出1.11版，第一項新特色是支援開發者用Linux虛擬伺服器內的IPVS功能，作為Kubernetes叢集內的負載平衡工具，可以改善網路吞吐量、延遲時間，以及加強水平擴充規模。在1.11版中，IPVS是正式版本，但預設未啟用。再者，現在使用者可在Kubernetes環境中，選用CoreDNS作為DNS外掛套件，如果使用Kubeadm部署Kubernetes叢集，此功能會預設開啟。
除了網路功能，新版Kubernetes繼續強化儲存功能。這次分別釋出了兩個Alpha功能。首先，現在開發者可以在線上直接調整持久儲存容量大小，使用者不需要將Pod關閉、拔除Volume，也能增加容量。第二個Alpha功能則是新推一個容量套件，讓使用者可指定各節點連結的儲存容量大小。Kubernetes表示，過去得設定環境變數，才能限制各節點的儲存容量。

Windows Server將增加第三款「Windows」容器映像檔，可支援老舊應用容器化
微軟又要加強容器技術開發力道，預告要推出新的Windows容器映像檔（Windows Container Image）。在今年度Build大會上，該公司就宣布，除了Nano Server、Windows Server Core，要推出這個容器基礎映像檔。現在如果開發者有參與Windows測試人員計畫，可以開始試用此款容器映象檔。
微軟早在2015年時釋出了Nano Server，這一款精簡精簡版本的Windows Server容量極小，開啟速度快之外，也能支援Docker容器。後來也還推出了Windows Server Core版映象檔本本，企業將應用程式容器化時，可選擇其中一種作為底層OS之用。不過，微軟表示，開發者和用戶中得知，這兩款OS版本還不足夠應付企業需求。許多老舊應用程式仍舊無法打包成容器映像檔，也因此，微軟這次想要推出的「Windows」容器映像檔，可以提供更多Windows Server的OS元件，讓企業用來打包老舊的應用程式。
Datadog也能監控微軟AKS代管服務，容器地圖也能用
雲端監控服務Datadog近日加強支援Azure環境，可監控超過60種Azure服務，而隨微軟Azure Kubernetes代管服務（AKS）在6月中正式上線後，近日Datadog也開始宣布支援AKS和Azure Monitor，讓企業用戶加強Azure環境的可視度。Datadog推出不久的容器地圖新功能也能在AKS環境使用。
Datadog表示，此解決方案會蒐集Azure、Kubernetes環境、容器基礎架構中的metrics、系統請求、Log紀錄等資料。該公司表示，想要使用該解決方案監控Azure環境的使用者，只需要設定整合AKS、Datadog，加強監控方案的易用性。此外，該公司也提供了YAML manifest檔案，讓開發者可以將Datadog Agent容器應用程式，部署至AKS叢集，確保每個叢集中的Pod，都有執行監控應用程式。


GitLab 11.0來了！主打高度自動化DevOps，可支援K8s
新版GitLab 11.0更新重點是簡化內建的持續交付流程，提供自動化的服務Auto DevOps。這一個完整持續整合與持續交付（CI/CD）功能，涵蓋了整個端到端的程式碼生命週期，從建置、測試、程式碼品質掃描、安全性掃描、授權掃描、封裝、效能測試、部署，一直到了應用程式上線後，Auto DevOps也會監控執行狀態。
四月時，GitLab就與Google雲端整合，可自動部署應用程式到Kubernetes，現在更全面強化了整合功能，Auto DevOps也可用來監控Kubernetes狀態，這是GitLab 11.0新功能之一，需要除錯與檢查pod的時候，能直接從GitLab部署儀表板中，瀏覽Kubernetes pod的日誌檔。

Jenkins企業版正式登上微軟AKS服務
持續整合工具Jenkins背後的開發商CloudBees近日宣布，自家企業版Jenkins服務CloudBees Core，正式與微軟Azure Kubernetes服務整合。當企業在AKS環境部署CloudBees Core後，該工具提供開發者自助式CD服務，「開發者能存取經認證合格的CI/CD工具」，該公司也宣稱，只要這一套解決方案，就能讓所有的老舊應用程式、雲端原生應用都整合到CD工作流程中。而Jenkins Master及Jenkins Agent也會自動水平擴充，調整至符合企業IT環境需求的規模。除了這次正式支援的不只AKS，Amazon EKS、GKE或者紅帽OpenShift也可支援CloudBees Core
VMware容器PaaS平臺PKS 1.1版釋出，深度整合自家產品生態系
近日VMware與Pivotal宣布PKS 1.1版正式上線，可支援到Kubernetes 1.10版的標準化儲存的Container儲存介面（CSI），讓儲存供應商可開發自家解決方案。
PKS也在此版本進行補強高可用性和監控機制。在高可用性功能上，PKS可以建立多個異地同步備份部署（Multi-AZ），在建置Kubernetes叢集時，系統管理員也能指定該服務區該叢級內管理政策、資料關聯（Data Affinity）等設定。萬一某叢集故障，其他異地叢集會立刻接手該叢集的工作負載，確保服務不中斷。
PKS 1.1版也整合了Pivotal雲端應用監控平臺Wavefront，提供Kubernetes環境的可視度。新版PKS也擴大與VMware自家工具生態系的整合。可支援混合雲管理平臺vRealize Log Insight，可搭配資料標籤功能，來追蹤容器平臺的運作。另外，也整合了VMware開源釋出的容器儲存庫Harbor。使用該容器儲存庫，上傳映像檔時，都會經過掃描、簽署等工作，確保儲存庫內的容器映像檔都安全。

責任編輯／王宏仁
更多Container產品動態
能自動更新Host的Kontena家K8s版本Pharos改版，支援Ubuntu 18.04和RHEL 7
遭Micro Focus出售，開源作業系統SUSE四度易主
＠資料來源：iThome整理，2018年6月
",https://www.ithome.com.tw/news/124285,"新聞,Container,Kubernetes,AutoDevOps,IT周報,GitLab"
124261,14,2018-07-03,容器新創Kontena自家Kubernetes版本Pharos 1.2.0版釋出,Kontena Pharos 1.2.0版這次所支援的Linux作業系統，也都可以搭配輕量級容器Runtime cri-o使用。不過，目前此版本在Arm 64位元架構處理器下還未能支援cri-o," 廣受各大廠商青睞的Kubernetes，不只大廠支援，也出現了不少容器新創來發展自己的Kubernetes版本。5月時，容器微服務平臺新創公司Kontena推出了自家Kubernetes版本Pharos，以社群版本K8s為核心，同時也是經過認證的Kubernetes版本，而Kontena發行的版本，也能相容Arm 64位元架構處理器。近日Kontena再進一步正式釋出Pharos 1.2.0版，現在該版本已經支援了CentOS 7、RHEL 7，以及Ubuntu 18.04 LTS等作業系統。
Kontena表示，Pharos 1.2.0版這次所支援的Linux作業系統，也都可以搭配輕量級容器Runtime cri-o使用。不過，目前此版本在Arm 64位元架構處理器下還未能支援cri-o，該公司會在下次新版釋出時整合此功能。 再者，容器主機搭配的Host作業系統，現在也支援自動更新、滾動更新等功能。使用者可以根據維運需求，決定服務是否要暫時中止，或者在節點完成更新前，暫時拒絕回應新的系統請求。
不過，由於Kubernetes社群已經不再投入資源維護Heapster專案，現在Kontena轉為整合現屬Kubernetes育成專案的Metrics Server，該元件會透過Kubernetes Summary API蒐集Metrics。Kontena建議，如果企業使用1.10版後的Pharos，如果未使用Heapster API，可以透過Kubectl，將Heapster元件移除。
",https://www.ithome.com.tw/news/124261,"新聞,Kubernetes,容器技術,Container"
124070,14,2018-06-25,GitLab 11.0來了！主打高度自動化DevOps、強化網頁IDE功能,在GitLab接住了不少從GitHub來的移民後，迎來第一個主要更新11.0版本，除了簡化並自動化內建的持續交付流程外，也強化了網頁IDE功能，在支援軟體安全性上，SAST還多支援Scala與.Net共5種語言。," 前些時日GitHub被微軟併購，GitLab順勢推出許多優惠方案，吸引了不少用戶。而現在釋出GitLab 11.0，新增了許多新功能，要來服務廣大的用戶，重點更新除了這次主打Auto DevOps正式可用外，還強化了安全性以及網頁IDE的功能，並持續強化對Kubernetes的整合。
GitLab把這次的更新重點放在簡化內建的持續交付流程，提供自動化的服務。這個稱為Auto DevOps的功能，在10.0測試版的時候開始提供，而在11.0已經正式可用，這是一個原本就建置在系統內服務，提供完整的持續整合與持續交付（CI/CD）功能，其涵蓋了整個端到端的程式碼生命週期，讓開發者只需要進行提交程式碼的動作，接下來的工作便由系統接手，包括建置、測試、程式碼品質掃描、安全性掃描、授權掃描、封裝、效能測試、部署，一直到了應用程式上線後，Auto DevOps也會監控執行狀態。
 
在GitLab 10.7就釋出的網頁版IDE，在11.0版本，主要新增了兩項功能，讓開發者可以直接在網頁處理更多工作。現在使用者可以直接在網頁IDE查看CI/CD工作管線，在介面的左下方有一個狀態欄顯示CI狀態，而且在右邊也能查看每項工作的狀態以及日誌，方便修復合併請求等CI錯誤。不同以往的是，過去想要修復錯誤，需要開啟多個標籤頁，並且互相切換，現在所有資訊都可以直接在網頁IDE開啟，未來還能在提交前進行預覽和測試。網頁版IDE的第二個重點更新，使用者現在能很方便的處理多個合併請求，只需要一次點擊就可以對管理的合併請求進行切換。
此外，GitLab 11.0新功能之一的授權管理（License Management），或是稱為軟體組合分析。由於應用程式通常包含多個函式庫和框架等外部組件，每個組件都擁有各自的授權與限制，開發者要確保這些外部組件與應用程式授權相容，以避免不需要的法律問題。而GitLab現在把授權管理整合進工作流程的一部分，系統會自動收集軟體中組件的相依關係，在新的改變進入主要分支前，會在合併請求的小工具中顯示新的授權供使用者確認。而使用Auto DevOps功能的使用者，系統會自動為專案啟用授權管理，不過這個新功能只提供給Ultimate與Gold級用戶使用。
在四月時，GitLab就與Google雲端整合，可自動部署應用程式到Kubernetes，現在更全面強化了整合功能，GitLab 11.0提供了幾項新功能，使用者可以用來管理與監控Kubernetes狀態外，需要除錯與檢查pod的時候，也能直接從GitLab部署儀表板中，瀏覽Kubernetes pod的日誌檔。過去當Auto DevOps用於私人或是內部專案的時候，部署作業完成後，Kubernetes便無法存取註冊表（Registry），現在已經能夠創建一個部署權杖，供註冊表後續存取，並且減少錯誤發生的可能性。
在提升使用者應用程式安全性上，GitLab透過整合靜態與動態應用程式安全性測試、相依性與容器掃描，讓使用者可以盡早發現軟體錯誤與漏洞。GitLab在10.7時提供了Go、C與C++靜態分析安全性測試（Static Analysis Security Testing，SAST），現在測試支援的語言擴增Scala與.Net。
",https://www.ithome.com.tw/news/124070,"新聞,Git,GitLab,DevOps"
123873,14,2018-06-14,容器技術在臺成顯學，臺北Kubernetes高峰會破5百人參加,今年臺北Kubernetes高峰會更是超過500名開發者、IT人員參加，涵蓋資訊產業、網路公司、金融圈、高科技公司、遊戲業和政府機關等," 容器技術不只在國外火紅，從5年前吹進臺灣開發圈至今，也逐漸成為企業數位轉型，擁抱新一代架構的關鍵技術，從2014年底的Container高峰會至今，今年臺北Kubernetes高峰會更是超過500名開發者、IT人員參加，涵蓋資訊產業、網路公司、金融圈、高科技公司、遊戲業和政府機關等。不只大型高科技巨頭、半導體大廠，在金融圈也是金控、大型銀行、壽險公司的開發人員齊聚，甚至有消費產品公司，直接派出17人團隊參加。由公司付費來參加的比例也高達77％。
十多位來自臺灣業界的專家，揭露第一手Kubernetes實戰經驗，如91APP技術總監劉峰全分享了91APP為了快速打造出新一代零售平臺，一路從Docker容器技術，到擁抱Kubernetes實現高彈性IT微服務架構的歷程，也有來自中國阿里巴巴阿里雲高級技術專家張維，來臺揭露了運用Kubernetes打造最新Serverless架構的經驗。
多家IT業者也擺攤展示自家容器平臺產品，如紅帽、IBM、VMware、微軟等

iThome也把今年CIO大調查中，臺灣企業新一代架構採用動向結果，輸出成大看板

",https://www.ithome.com.tw/news/123873,"新聞,Kubernetes,Docker,Container,Serverless"
123859,15,2018-06-13,6千名開發者大調查：最愛的持續整合工具是Jenkins,根據JetBrains釋出的調查，目前Jenkins是最多開發者常用的持續整合工具，總共占了62％，而依序排名下來，分別是Travis C、GitLab CI、TeamCity等工具," 位於捷克的軟體公司JetBrains，旗下除了有許多跨平臺IDE產品、程式語言套件工具外，該公司亦有開發DevOps工具，像是持續整合工具TeamCity、協作工具Upsource等。而近日，該公司釋出了一份調查報告，總共收集6,000名開發者的問卷，集結各種程式語言、資料庫、DevOps、團隊協作工具的使用偏好後，發布2018年開發者生態系統報告。
在該份報告中的團隊工具調查結果顯示，目前Jenkins是最多開發者常用的持續整合工具，總共占了62％，而依序排名下來，分別是Travis CI（21％）、GitLab CI（18％）、TeamCity（12％）、CircleCI（10%）等工具。不過，開發者可能同時使用多項持續整合工具，因此，該調查的百分比總和會高於100。
當進一步再劃分公有雲環境、本地開發環境時，兩者的使用者狀況也有些許排名差異。首先是公有雲環境，Jenkins依然是排名第一（57％），依序下來為Travis CI（33％）、GitLab CI（19％）、CircleCI（17％）跟TeamCity（11％）。而在本地環境，相較公有雲環境，Jenkins在本地環境拿下的使用比例更高（66％），而Travis CI（11％）則掉落至第四名，由GitLab CI取得第二名（16％）。
而除了持續整合工具的調查結果，JetBrains也列出開發者最喜歡使用的版本控制系統服務、議題追蹤工具（Issues Tracking）。不意外的，GitHub以56％的使用率，穩坐版控服務第一名。再來，依序是GitLab（26％）、Bitbucket（24％），以及微軟TFS/VSTS（7％）。
在議題追蹤工具中，GitHub也占有相當影響力，該平臺中的GitHub Issues、GitHub Issue Board功能，分別以29％、12％，占據第二、第四名。而第一名最多使用者愛用的議題追蹤工具為Jira（69％）。
",https://www.ithome.com.tw/news/123859,"新聞,持續整合,DevOps,CI/CD"
123693,15,2018-06-06,Container周報第68期：Google釋出Skaffold持續整合工具，K8s也有全新社群討論區,Google釋出了一款可用來快速建立CI/CD工作流程的Kubernetes自動化任務工具，可供DevOps建立自動化任務，來建置建立、發送和部署," 05/30~06/05容器精選新聞
9萬個正式環境容器使用數據大公開！Docker仍是大宗
雲端監控服務公司Sysdig近日發表了第二版容器使用年報，Sysdig蒐集了正式環境中9萬多個容器的使用數據，統計出這份報告。根據這次年報，Docker仍舊是正式環境中容器Rutime的主流，83％的容器使用Docker，其次是CoreOS的RKT，占了12％個容器，Mesos的Contanerizr則以4％比率，排名第三。在容器使用壽命上，27％的容器壽命介於5到10分鐘之間，容器壽命佈道10秒的比例也有近1成，但只有5％容器開啟時間超過1周。平均企業單一主機上啟用的容器數量（中位數），從去年10個，增加到今年的15個，最多有使用者在單一主機上啟用了154個容器。容器映象檔的更新頻率大約是每周一次，大約有三分之二的容器映象檔都是如此。
另外，在容器調度平臺採用率上，採用目前熱門的Kubernetes平臺來調度的容器占比，從去年的43％，在2018年提高到了51％，Kubernetes平臺已經成為調度平臺的主流，而採用Docker Swarm的比例只有11％，但也比去年的7％比例來得高，顯示採用Docker Swarm的企業也持續增加。而Mesos的採用率反而從去年的9％，在今年下滑到4％。

DevOps維運Kubernetes叢集有新工具，Google釋出Skaffold持續整合工具
當Kubernetes應用開發完成後上線後，開發者而言，後續部署、更新和維護是一件繁瑣的工作，也是DevOps工程師例行的工作。Google釋出了一款可用來快速建立CI/CD工作流程的Kubernetes自動化任務工具，可供DevOps建立自動化任務，來建置建立、發送和部署
全球跨區管理Kubernetes叢集流量也能全自動，GCP釋出內網負載配置新工具
越來越多企業在GCP雲端平臺上部署Kubernetes叢集，但要將多個叢集Kubernetes部署到全球機房，來支援同一個應用服務的運作，仍就不是一件容易的事。Google釋出了一個新的內網負載配置自動化工具kubemci，可讓Kubernetes原有的叢集內網流量管理機制Kubernetes ingress，透過規則訂定，就可以結合GCP上的雲端負載平衡服務GCLB（Google Cloud Load Balancer），來部署一個全球跨區運作的多Kubernetes叢集應用架構，讓鄰近機房的主機彼此更容易分擔要服務的流量。


容器原生應用也可用區塊儲存，儲存新創Linbit企業級儲存軟體能支援K8s叢集
軟體定義儲存新創Linbit推出了一款開源企業級區塊儲存軟體Linstor，可用來管理分散式Linux上的DRBD儲存資源，提供容器化應用的區塊儲存之用。甚至Lintor可跨大型儲存叢集，來提供多Volumes儲存空間，也可為Kubernetes配置儲存空間，另外也可支援紅帽OpenShift環境。目前Lintor先釋出Beta測試版。
因為太好用！K8s套件管理工具Helm要獨立成為CNCF新專案
Kubernetes旗下子套件管理工具Helm正式獨立，變成了CNCF基金會代管的新專案。這是一個用來將打包應用程式配置檔，以便可以重複採用同樣的配置，來加快部署到Kubernetes上的工具。因為太好用了，CNCF基金會表示，根據最近一次Kubernetes應用調查，64％容器應用開發者，都是用Helm來管理Kubernetes上的容器化應用。因此，CNCF決定把這個子專案獨立出來，成為一個代管專案。這也意味著Helm未來有機會成為不只是Kubernetes上的套件管理平臺，還可以進一步變成通用型的套件管理平臺。
IBM私有雲強化容器支援，能跑1千個Kubernetes節點
以Kubernetes為核心的私有容器雲平臺IBM Cloud Private近日釋出新的2.1.0.3版，除了增加GDPR法遵功能，也支援到Kubernetes最新的1.10版本。IBM Cloud Private現在單一叢集，也可以執行1,000個節點。在該架構中，可以搭配四種功能不同的節點，分別是Master、Management、Proxy、Worker節點，並且結合開源網路虛擬化專案Calico。。
另外Kubernetes Helm Charts儲存庫也開始支援角色存取權限機制（RBAC），系統管理員可以根據開發者身份，限制該員的存取、部署、更新，以及應用程式刪除的權限。而搭配服務ID、服務API金鑰，使用者可以根據各應用程式權限區分，客製化該程式能存取服務的權限。
Slack、GitHub不夠用，Kubernetes社群有全新交流討論區
使用人數最多的容器調度工具Kubernetes，光是GitHub上的已知貢獻者就超過1,600人，而要同時調度這麼多人，同時一起開發開源專案，也不是件簡單的事。Kubernetes社群仍有超過3.5萬人參與，雖然有Stack Overflow、GitHub、郵件清單以及Slack，但要追蹤Kubernetes社群的話題，仍然是一個大工程。因此，Kubernetes社群決定開始成立開源討論平臺Discourse，為社群成員多開一個新溝通管道。使用者可以點選分類清單，搜尋自己有興趣的議題。如果想追蹤特定議題，也可以直接訂閱，系統也會自動發送通知、電子郵件。
Docker公司推出Kubernetes自學教室，讓你自己動手學
Docker公司去年夏天就推出了「動手玩Kubernetes」網站，開發者透過瀏覽器就可以直接試用Kubernetes的功能，不用自己安裝環境。最近，Docker進一步升級了這個自學網站，推出了「動手玩Kubernetes教室」（Play with Kubernetes Classroom），提供了一套Kubernetes動手做實驗室的課程，還提供了一整套的Kubernetes教學課程，和Kubernetes線上試用環境，讓開發者可以自學，或企業IT人員舉辦小型工作坊練習之用。

管Docker不用全靠命令列，網頁版容器管理工具Portainer簡單夠用
Docker仍舊是不少開發者正式環境中使用的容器環境，但要管理越來越多的Docker容器，尤其是Docker容器叢集，只靠命令列工具仍舊是一件麻煩的工作。現在也有不少圖像化容器管理工具可用，可以透過網頁上的視覺化儀表版來管理複雜的容器叢集，開源的Portainer就是其中一款簡單夠用的Docker叢集管理平臺，可透過管理網頁，快速掌握Docker主機和Swarm叢集的運作。
 
責任編輯／王宏仁
更多Container產品動態
企業級K8s軟體Kublr推出1.9.2新版，能讓K8s環境更容易和外網隔離
紅帽發布Fuse 7版以及線上版Fuse Online，可提供整合式PaaS服務

＠資料來源：iThome整理，2018年6月
",https://www.ithome.com.tw/news/123693,"新聞,Docker,Kubernetes,IT報告,CI/CD,DevOps"
123439,15,2018-05-25,針對多種雲端平臺提供更多自動化，以及儲存服務整合應用，Pure Storage宣布支援VMware SDDC、Red Hat OpenShift，並提供開放式自動化工具集,提供Container支援驅動程式之餘，Pure Storage擴大支援更多私有雲的平臺服務，像是VMware SDDC與Red Hat OpenShift，同時，他們也發表了儲存服務調度指揮機制Service Orchestrator，讓Container應用程式存取儲存服務更為簡便," 今年Pure Storage在全球用戶大會Accelerate，首度倡議以資料為中心的架構（Data-Centric Architecture，DCA），而他們接下來在雲端服務平臺的策略布局走向，也是各方關切的重點。
在大會主題演講過程中，該公司雲端暨新架構解決方案資深總監Sandeep Singh也特別上場介紹了他們目前的解決方案。Pure Storage目前支援的平臺，涵蓋了VMware SDDC、Red Hat OpenShift，分別提供經過驗證的設計，以及因應基於Container的PaaS參考架構，可支援企業級應用系統的IT基礎架構，以及雲端原生型應用系統的執行需求。

 

同時，Pure Storage也積極支援開放式的自動化平臺，將提供一套支援全架構（Full Stack）的工具套件。
該公司的新架構技術總監Simon Dodsley，也走上大會主舞臺，展示在Red Hat OpenShift和Pure Storage全快閃陣列的整合下，在很短時間完成MangoDBy資料庫的建立與產生，相較於現行的作法，需要5天之久，而在兩套系統的整合下，可縮短到1分鐘。
而在Container的應用場景當中，Pure Storage先前已提供Docker Volume Plugin，以及Flex Driver & Plugin，讓FlashArray和FlashBlade作為Docker的區塊儲存與檔案儲存，並且能以API來支援Kubernetes。
到了今年，Pure Storage發表了Pure Service Orchestrator，在原本的兩層存取架構，添加了儲存服務調度指揮的機制。

",https://www.ithome.com.tw/news/123439,"新聞,Container,OpenShift,VMware SDDC,自動化,Kubernetes"
122982,15,2018-05-12,Container周報第64期：容器監控有視覺化監控地圖新幫手，Google則開源了沙盒容器Runtime gVisor能像VM那樣安全又輕巧,過去就耕耘雲端應用程式監控的Datadog，近日也釋出了新的監控工具容器地圖（Container  Map），讓開發者可以對容器應用程式即時進行監控、除錯," 05/06~05/12精選Container新聞
容器監控新幫手，Datadog推視覺化容器監控地圖
在正式環境導入容器的企業，如果想要監控容器基礎架構狀況，除公有雲廠商提供的原廠服務，或自用開源解決方案搭建，都是常見的做法。不過，過去就耕耘雲端應用程式監控的Datadog，近日也釋出了新的監控工具容器地圖（Container  Map），讓開發者可以對容器應用程式即時進行監控、除錯。 Datadog表示，這款容器監控地圖以過去的Autodiscovery為基礎，搭配新的視覺化呈現方式，企業可觀察容器基礎架構的整體運作狀況，根據需求，進行分組、過濾，或是進一步檢個別容器。另外也提供相當高彈性、互動式的操作，根據不同的中介資料，使用者可以對基礎架構的容器進行分類，像是服務的類別、提供服務的區域、容器任務角色，「或是任何企業所想要的觀察面向，都可以做為分類的標準。」Datadog舉例，利用每個容器中的標籤，系統可以將基礎架構執行特定Docker映像檔的容器，進行標色。
容器儲存新創StorageOS推出企業級容器持久儲存，Docker、Kubernetes及OpenShift都支援
容器儲存新創StorageOS近日正式推出企業級容器持久儲存解決方案，而儲存方案也原生支援Kubernetes、Docker及OpenShift等環境。目前該平臺所支援的調度工具，共為Docker Swarm及Kubernetes，相容的作業系統則是Ubuntu及RedHat Linux。使用者除了能利用命令程式介面操作外，StorageOS也提供視覺化介面的操作模式。StorageOS主打的就是能支援任何基礎架構，無論企業內部資料中心、VM環境、裸機或是其他公有雲中，都可以讓容器應用、Kubernetes應用建立持久儲存。
OpenFaaS也推出雲端版，結合Git流程自建無伺服器應用更容易了
可用來自建無伺服器平臺的開源OpenFaaS專案作者Jock Reed宣布，進一步推出OpenFaaS Cloud，這是一套利用Docker結合Git工作流程來建立無伺服器雲端服務平臺的軟體。可以將GitHub上的開發專案，透過JSON資料拋轉，就能快速建立和部署一個雲端Function as a Services服務平臺。這套OpenFaaS雲可以支援Docker的Swarm或Kubernetes調度平臺。也可串接到常見CI/CD工具或程式碼代管服務，如GitLab, Travis CI, CircleCI, Flux。目前支援 Go、Node.js、Python、Ruby和C#語言。
Windows Server容器套件有遠端執行漏洞，Windows容器用戶快更新
使用Windows環境執行容器的企業用戶要小心了，近日微軟公開了編號CVE-2018-8115的漏洞。在Windows Server容器套件hcsshim（Host Compute Service Shim）的函式庫中，隱含了遠端程式碼執行漏洞。微軟表示，該漏洞會讓系統無法正確認證使用者上傳的容器映像檔，因此，攻擊者可事先準備特殊設計的容器映像檔，裡頭打包著惡意程式碼。一旦握有系統權限的管理員，不慎將此映像檔上傳至Windows主機，該惡意容器映像檔便可透過此漏洞，對主機發動攻擊。
早在2月時，資安研究員Michael Hanselmann就已經發現該漏洞，並且主動回報至微軟安全性回應中心（MSRC）及Docker。微軟也在5月2日釋出的hcsshim 0.6.10版中修補了漏洞。
從源頭映像檔確保安全，Aqua推免費容器映像檔掃描工具MicroScanner
容器資安新創Aqua在近日釋出了一款免費的映像檔掃描工具MicroScanner。該公司強調，免費版所用漏洞資料庫，與付費商用版相同，「也讓開發者可以得到不錯的掃描成效。」不過相比付費版本，MicroScanner的應用情境較為陽春，僅能在Dockerfile執行建置階段時進行掃描工作。一旦MicroScanner發現映像檔內有高風險漏洞，系統會自動回傳安裝映像檔安裝失敗的訊息，同時，也會將相關資訊，使用JSON格式紀錄，回傳給使用者。藉此，從最初期的建置階段進行把關，企業就能確保映像檔安全無虞。

 
Google開源沙盒容器Runtime gVisor，與VM一樣安全但更輕巧
為解決容器的安全性問題，Google開源了用Go開發的沙盒容器Runtime gVisor，提供類似虛擬機器般的隔離安全性，但是更為輕巧，不過gVisor只實作Linux系統部分API，因此並非所有應用程式都能夠在gVisor執行，不過常用的Node.js、Java 8、MySQL以及Jenkins等應用程式都不是問題。
Google表示，容器的發明徹底改變了開發、封裝以及部署應用程式的方法，但是其曝露廣泛的系統表面，對於執行一些不受信任或是潛在惡意應用程式存在疑慮。而傳統的Linux容器並非沙盒環境，因為應用程式存取系統資源與非容器化的系統相同，都是直接呼叫主機核心，並以特殊權限執行，與硬體交互執行後將結果回傳給應用程式。


＠上標：甲骨文、GPU
@標題：甲骨文容器引擎再升級，讓Kubernetes可用GPU進行高速運算
＠內文：過去雖不及其他軟體大廠的步調快，但是甲骨文在近年擁抱容器技術、Kubernetes的速度也急起直追。在今年度歐洲舉辦的KubeCon及雲端原生年會中，甲骨文有了重大發布，宣布加強自家的甲骨文容器引擎（Oracle Container Engine），除了整併幾項重要的Kubernetes功能外，也讓該容器引擎能相容自家開源釋出的無伺服器專案Fn。
針對高效能應用，現在甲骨文也支援Kubernetes在Nvidia Tesla GPU上運作，甲骨文表示，在單一裸機實例中，搭配兩個Nvidia Tesla P100執行CUDA程式，運算力可達21 TFLOPS。
 

阿里雲也推純Kubernetes容器服務上線
阿里雲在去年11月進軍Kubernetes代管服務後，近日再加碼推出新的容器服務無伺服器Kubernetes叢集服務。
目前阿里雲所提供的Kubernetes服務，總共有兩種模式。首先是基本的代管Kubernetes叢集服務。第二種是這次新推的無伺服器Kubernetes服務，強調企業可以快速建立Kubernetes應用，阿里雲表示，在無伺服器Kubernetes的應用情境下，只需要5秒，就能完成Kubernetes叢集建置，再花額外30秒，就能搞定應用程式部署。而新收費制度也更為彈性，根據使用者所使用的CPU、記憶體量，隨需計價。而開發者可以逕行著手開發應用，不需要花費額外成本執行伺服器維運工作。
 
責任編輯／王宏仁
更多Container產品動態
Azure容器監控服務預覽版釋出，可用來監控Azure Kubernetes服務
Azure Kubernetes服務再升級，靠滑鼠點擊就能建置Kubernetes叢集

＠資料來源：iThome整理，2018年5月
",https://www.ithome.com.tw/news/122982,"新聞,Container,Azure,容器服務,IT周報,Kubernetes,gVisor"
122915,15,2018-05-04,Windows Server容器套件含遠端程式碼執行漏洞，用Windows主機執行容器要快更新,握有系統權限的管理員，若不慎將惡意映像檔上傳至Windows主機，該惡意容器映像檔便可透過此漏洞，對主機發動攻擊," 使用Windows環境執行容器的企業用戶要小心了，近日微軟公開了編號CVE-2018-8115的漏洞。在Windows Server容器套件hcsshim（Host Compute Service Shim）的函式庫中，隱含了遠端程式碼執行漏洞。微軟表示，該漏洞會讓系統無法正確認證使用者上傳的容器映像檔，因此，攻擊者可事先準備特殊設計的容器映像檔，裡頭打包著惡意程式碼。一旦握有系統權限的管理員，不慎將此映像檔上傳至Windows主機，該惡意容器映像檔便可透過此漏洞，對主機發動攻擊。
而早在2月時，資安研究員Michael Hanselmann就已經發現該漏洞，並且主動回報至微軟安全性回應中心（MSRC）及Docker。他表示，微軟在5月2日所發佈的hcsshim 0.6.10版已經修補。目前，企業如果使用Docker CE 18.03.1或Docker CE 17.05.0-rc1版，都已經內建該漏洞的更新檔，而使用Docker EE 17.06版的企業，Michael Hanselmann則提醒要下載最近期的更新檔。
基於和微軟所簽訂的協議，目前Michael Hanselmann還不能公開更多細節，不過他也預告，在5月9日時，相關漏洞的更多細節，他會親自在部落格上揭露。
 
 
",https://www.ithome.com.tw/news/122915,"新聞,Container,Docker,資安,Windows Server,漏洞"
122381,15,2018-04-12,OCI釋出容器映像檔規範，盼打通各家容器管理平臺,OCI推出發布規範專案，要進一步建立強固通用的標準，在原生雲端環境和容器生態系中，確保一致性以及容器的互通性。," 開放容器倡議組織（Open Container Initiative，OCI）要制定映像檔發布標準，打破各容器管理平臺的互通障礙。OCI啟動發布規範專案，以Docker Registry v2協定為基礎，訂立容器映像檔推送與拉取等行為的發布標準。
由Docker、IBM、微軟、紅帽及Google等廠商組成，負責建立容器標準的開源社群OCI，在2016年時怕標準遭特定廠商綁定，共同推出了OCI Runtime標準，並且規範容器映像檔建立、認證、簽署以及命名的方式。在2017年這個標準成熟後推出了OCI 1.0。
不過，雖然容器映像檔格式有了標準，但各家廠商卻把腦筋動到了管理平臺上，用自家的容器映像檔管理平臺標準綁住使用者，因此現在OCI推出發布規範專案，要進一步建立強固通用的標準，在原生雲端環境和容器生態系中，確保一致性以及容器的互通性。而由於Docker Registry v2協定，已經被社群廣泛接受遵循，因此最新的規範，便會基於這個既存的協定。
容器發布規範在GitHub上的提案，只有發布API的規範，並不包含Docker Registry的程式碼，不過Docker Registry則被當作參照實作，該協定還有其他非開源的實作，包括Google的gcr.io、Amazon ECR、CoreOS Quay、Gitlab registry，JFrog Artifactory registry、華為Dockyard等。
提案中指出，過去社群在討論OCI規範的時候，碰觸到映像檔發布主題，總會以先定義映像檔格式，先滿足產業需求在說。而現在Docker Registry v2協定，已是公認的OCI映像檔格式，未來或許會有其他更好的做法，但暫且就當作推送和拉取映像檔的產業發布規範的基礎。
Docker工程師兼OCI技術監督委員會主席Michael Crosby表示，Docker Registry已經是Runtime與映像檔的公認標準，有超過400億個拉取的映像檔遵循這個協定發布。
OCI聯盟執行總監Chris Aniszczyk表示，隨著雲端技術以及容器技術的發展，社群需要一個可靠的發布標準，以提高互通性，而OCI扮演中立角色來發展規範。
另外，該提案也提供容器生態系討論以及排程，來擴充映像檔發布規範。
",https://www.ithome.com.tw/news/122381,"新聞,OCI,Docker,Container"
122361,15,2018-04-11,GitLab與Google雲端整合，可自動部署應用程式至Kubernetes,現在GitLab工具點幾下滑鼠，就能將Kubernetes引擎叢集與GitLab專案連結，用來進行持續整合（Continuous Integration）的工作，並設定完整的持續部署（Continuous Deployment）工作管線。," 程式碼託管服務GitLab與Google雲端服務宣布，讓開發者可以直接用GitLab工具將應用程式部署到Kubernetes叢集。另外，Auto DevOps工具也支援Kubernetes，在合併程式碼後，能自動部署應用程式到Kubernetes引擎上執行。
現在開發者只要在GitLab工具上點幾下滑鼠，就能將Kubernetes引擎叢集與GitLab專案連結，用來進行持續整合（Continuous Integration）的工作，並設定完整的持續部署（Continuous Deployment）工作管線，包括即時預覽專案變更，以及自動部署應用程式到Kubernetes引擎上。
一旦Kubernetes引擎叢集與GitLab專案連結後，開發者便能將GitLab Runner部署到Kubernetes引擎叢集中，並且執行持續整合工作，並讓開發者對分配的資源做更細節的配置。想要啟用這個功能，只要在GitLab的使用者介面CI/CD選項中添加Kubernetes引擎，也能該選項中創建全新的Kubernetes引擎叢集。
另外，全新的GitLab Auto DevOps也整合了Kubernetes引擎，這是一個持續部署的工作管線，能夠自動為每個程式碼合併請求產生預覽應用程式，在未正式上線前，在動態的環境中先預覽應用程式的更新結果。同樣的，使用者也可以在CI/CD選項中，找到一般工作管線設定選項，選擇啟用Auto DevOps。
只要啟用Auto DevOps，系統會偵測程式碼語言，自動配置持續整合與持續部署工作管線。開發者只要發出了合併請求，GitLab便會執行預覽工作管線，先部署預覽應用程式到叢集上，供開發者測試，而當開發者完成合併程式碼，GitLab便會執行產品工作管線，正式部署應用程式到Kubernetes引擎上。
",https://www.ithome.com.tw/news/122361,"新聞,GitLab,google,Kubernetes,DevOps"
122101,15,2018-04-02,Container周報第58期：今年第一個Kubernetes 1.10新版出爐,火熱的容器管理平臺Kubernetes釋出了今年第一次改版Kubernetes 1.10。第一個特色是，要作為Kubernetes標準儲存介面的CSI（Container Storage Interface）的Volume外掛程式，也從Kubernetes獨立出來，以便第三方儲存廠商運用或整合到第三方儲存產品中。本地端儲存功能也進入Beta版本," 重點新聞時間：03/20~03/27
今年第一個Kubernetes 1.10新版出爐，內建開發者會愛的容器除錯機制
火熱的容器管理平臺Kubernetes釋出了今年第一次改版Kubernetes 1.10。第一個特色是，要作為Kubernetes標準儲存介面的CSI（Container Storage Interface）的Volume外掛程式，也從Kubernetes獨立出來，以便第三方儲存廠商運用或整合到第三方儲存產品中。本地端儲存功能也進入Beta版本。
其次，則是開始支援外部憑證來源（Alpha版），也意味著可以整合到雲端供應商的IAM服務或是和自建的憑證系統整合，如AD。這也是將Kubernetes叢集納入企業整體安全管理的關鍵機制。第三個重點功能是在安裝時就切換啟用CoreDNS，可以成為Kubernetes的服務Discovery功能。目前是Beta版。
另外，TLS bootstrap功能也進入穩定版，這個功能可以讓K8s叢集中的Kubelet自動建立TLS安全憑證，來強化容器存取的安全性，進入穩定版後，就可以在更關鍵的環境或正式環境中使用了。
開發人員會愛的新功能則是容器除錯機制，除錯是開發容器化應用時的麻煩事，過去得自行建立容器來安裝容器除錯工具，現在直接在Kubernetes中內建，可以提供相關的除錯Shell工具，debug也將成為新的指令之一。不過，目前仍是Alpha版，要等到下一個1.11版，除錯機制才會進入穩定版本。
其他小更新如強化了對Windows容器的支援，也實驗性地能支援Hyper-V環境部署。現在也可以建立Pod的安全政策，更細緻地管理Pod和容器的存取。更多內容
CNCF揭露中國容器市場大調查
近日，CNCF基金會公布了一份中國容器市場發展的最新調查結果。目前，有6%的回答者，部署了超過5千個容器，6成用戶部署了50～250個容器。中國容器用戶大多用於開發，只有32％作答者已經在正式環境使用容器技術。
而不意外地，Kubernetes是中國開發者管理容器的第一選，有35％作答者採用，但使用微軟Azure Container Service來管理容器叢集的比例也高達19％，排名第二。Docker Swarm用戶也有16％。在容器導入困難上，中國用戶認為，使用和部署上的複雜度是最大挑戰，不同於，歐美用戶則將安全視為部署容器的最大難題。
另外，這次調查也盤點了中國雲端供應商的普及程度，中國雲端平臺市占仍以阿里雲排名第一（55%），AWS以30％占比排名第二，而以28％些微落後而排名第三的反而是OpenStack類雲端服務，微軟Azure只有12％，而Google雲端平臺也只有6％的占比。更多內容
CNCF開源釋出跨雲CI平臺，要讓Kubernetes更容易支援混合雲
CNCF基金會在開放網路大會上，揭露了一個強化Kubernetes的跨雲CI（持續整合）平臺。CNCF人員還展示了，如何利用這CI平臺，來自動分散一套部署在Kubernetes上的ONAP系統，來擴大ONAP這套開源網路服務的負載能力。
CNCF執行總監Dan Kohn強調，這套免費的跨雲CI平臺，可以用來加速Kubernetes叢集在混合雲架構的運用。長期目標上，他指出，CNCF希望能將任何網路服務都部署到Kubernetes上，因此需要先發展出這類跨雲部署機制。
這個跨雲CI平臺還提供了一個儀表板功能、測試系統、狀態Repository伺服器。Gitab是這套跨雲CI平臺的主要貢獻者，而HashiCorp也支援了配置管理工具的開發。目前採Apache 2.0授權釋出。更多內容
常見強化Kubernetes安全的8種作法
TechBeacon科技作者近日整理了8種常見的Kubernetes安全強化作法。例如第一項就是來自Google Cloud產品經理Maya Kaczorowski的建議：完全關閉Kubernetes的網頁使用者介面。理由是，這個網頁管理介面使用了一個擁有高度特權的帳號，像是在Google的Kubernetes Engine服務中，早從1.7版就關閉了這項功能，來降低風險。
其他7項安全強化作法，如鎖住管理服務、確保憑證所在處的封閉性、使用可信任的內容（如可信任的映像檔來源）、更新後重新建立映像檔、永遠不要用root權限執行容器、善用Linux容器專屬安全機制、加密Kubernetes etcd等。更多內容
雲端DevOps平臺Cloudbees也能支援OpenShift，提供進階CI/CD服務
企業級DevOps服務平臺Cloudbees最近宣布，自家企業版Jenkins將可支援Red Hat OpenShift容器管理平臺，另外也可透過Jenkins X計畫來支援Kubernetes，以減少需部署的VM數量。
Cloudbees執行長Sascha Labourey估計，Cloudbees版Jenkins支援OpenShift後，可以協助企業串連DevOps流程，尤其是持續派送流程（Continuous Delivery）可以橫跨內部私有雲和公有雲間來串接。Cloudbees企業訂閱服務，可提供7天X24小時的企業級Jenkins專家支援。更多內容
GitLab的持續整合與交付工具將支援GitHub
企業程式碼代管服務GitLab近日改版，當中最重要的一項改變是讓持續整合（Continuous Integration，CI）與持續交付（Continuous Delivery，CD）也支援諸如GitHub或BitBucket等外部程式碼儲存庫，且可免費使用到明年3月。
持續整合指的是將專案的變更同步到專案的主幹上，持續交付則是將程式碼轉為可用軟體的過程，這些原本就是GitLab的強項，而GitHub則是採用第三方的服務。
此一宣布意味著GitLab用戶可在該站建立一個連結到GitHub程式碼儲存庫的CI/CD專案，當把程式碼發布到GitHub時，GitLab即會自動執行CI/CD，並將結果傳回GitHub。更多內容
開源授權管理新幫手，GitHub釋出開源套件相依檢查工具Licensed
GitHub開源自家用來檢查套件相依的工具Licensed，以幫助開源社群能用同樣的方式，簡化授權程序。
Licensed能用在任何的Git倉儲庫，對多個專案多語言類型和套件管理器，查詢、快取以及檢查相依關係的授權許可元資料（Metadata）。
不少套件的授權許可要求後續專案發布相依關係文件，GitHub指出，使用Licensed可以加速這件事，自動化建立與發布授權許可，並且為專案提供詳細的開源資源列表。當然，Licensed也能用來檢查專案與套件的任何相依關係，並自動產生報告，警告使用者應該注意或是違反授權許可的部分。更多內容
責任編輯／王宏仁
更多Container產品動態
IBM宣布更多中介軟體產品可部署在容器環境。
Rancher計畫在今年4月釋出2.0，將支援Kubernetes。
Docker企業版本將強化Layer 7應用層管理功能。
",https://www.ithome.com.tw/news/122101,"新聞,Container,Kubernetes,Jenkins,IT周報"
122137,15,2018-03-29,Kubernetes 1.10正式釋出，支援標準化儲存並新增Pod安全性政策,Container儲存介面（Container Storage Interface，CSI）能讓使用者像安裝Pod一樣，輕鬆安裝Volume插件，而這使得第三方儲存供應商可以脫離Kubernetes的核心程式碼限制，獨立開發自家的解決方案。," 開源Container調度平臺Kubernetes釋出了1.10版本，這個版本的重要更新包括支援標準化儲存的Container儲存介面（Container Storage Interface，CSI）、API聚合以及安全性的系列更新，而這也是CoreOS加入紅帽（Red Hat）的第一個Kubernetes新版本。
Kubernetes增加新功能的步調，會在一開始加入Alpha版本，並在後續的Kubernetes更新中，依情況轉為Beta版，最終成為穩定版加入Kubernetes的正式功能。Kubernetes開發團隊特別提到，容器儲存介面在Kubernetes 1.9時候加入，在1.10已經到了Beta版本，表示此功能進展快速。
Container儲存介面能讓使用者像安裝Pod一樣，輕鬆安裝Volume插件，而這使得第三方儲存供應商可以脫離Kubernetes的核心程式碼限制，獨立開發自家的解決方案。開發團隊表示，此設計能維持Kubernetes生態系中的可擴展性。
同時，Durable（Non-shared）本地端儲存管理在Kubernetes 1.10也成為Beta版，讓非透過網路連結的本地端連接儲存成為持久磁碟（Persistent Volume），提供使用者能以更高效能且低成本的方法，建立分散式檔案系統與資料庫。
持久磁碟在Kubernetes 1.10也有一些Beta更新，為確保儲存API物件被以正確的順序刪除，現在Kubernetes能防止Pod使用中的持久磁碟宣告（Persistent Volume Claims）被刪除，並防止被綁定在持久磁碟宣告的持久磁碟被刪除。
而API聚合功能在Kubernetes 1.10成為穩定版，現在開發者可以自己定義API伺服器而不需要更改Kubernetes核心程式碼。Kubernetes開發團隊表示，這是一個強大的功能，開發人員擁有Kubernetes高度自訂的能力，其所能提供的資源種類與Kubernetes核心有很大的不同，對於Kubernetes主要的擴充機制自訂義資源（Custom Resource Definitions，CRDs）感到不夠完備的使用者案例，API聚合可能是一個很好的解決辦法。而穩定版也意味著，開發人員可以把這功能應用在產品階段了。
Kubernetes 1.10也更新了Pod安全性政策。Kubernetes開發團隊表示，Container為主機上的獨立程序，開發者應停用不再執行的Container。而Kubernetes提供開發人員數種手段，以特殊權限存取主機，當這些手段被盜用將會成為攻擊的媒介。而Pod安全政策目的在於，以名稱空間限制Pod的執行種類，以減少攻擊面。
在3月被揭露的CVE-2017-1002101安全漏洞，允許Container對檔案系統存取任意得檔案，也在Kubernetes 1.10獲得修正。
",https://www.ithome.com.tw/news/122137,"新聞,Kubernetes,Container,CoreOS"
121916,15,2018-03-20,Container周報第57期：CNCF七大容器應用設計原則出爐，IBM將推裸機K8s服務,CNCF建議，在部建階段（Build time），要以「單一考慮點」（Single Concern）、「自我容器化」（Self-Containment）和「映像檔永久持續性」(Image Immutability)來設計。," 重點新聞：03/17~03/23
IBM宣布推出第一個裸機Kubernetes服務
就在IBM年度Think大會前，IBM雲端平臺技術長Jason McGeey在官網上宣布，旗下雲端容器服務增加了裸機Kubernetes服務（bare metal Kubernetes ），這也是業界第一個Kubernetes裸機服務。
Jason McGeey解釋，直接在硬體裸機上部署Kubernetes的好處，除了可以提供更高的效能來執行容器之外，還可以確保容器只在單一機器上執行，而不是在與他人共享的環境中執行，可以有更高的安全性。
此外，裸機部署Kubernetes，Jason McGeey補充，需要使用GPU來執行大量運算的容器應用程式，可以直接存取GPU硬體，來獲得更高的效能。更多內容
CNCF基金會發布容器化應用設計準則
近日CNCF基金會在官網上揭露了7個容器應用的設計準則，涵蓋了部建階段和runtime上的設計準則。CNCF建議，在部建階段（Build time），要以「單一考慮點」（Single Concern）、「自我容器化」（Self-Containment）和「映像檔永久持續性」(Image Immutability)來設計。
而在Runtime階段中，CNCF則建議，要考慮「高度可視化」（High Observability）、「生命周期一致性」（Lifecycle Conformance）、「執行可取代性」（Process Disposability）、「Runtime管制」（Runtime Confinement）來限制容器資源的使用。
紅帽也免費釋出了這個雲端原生應用程式的設計白皮書，進一步說明這些容器化應用設計準則的細節。更多內容
快速複製Kubernetes部署有新工具，Google釋出Skaffold
開發者經常要建立不同或類似的執行環境副本，以供測試與開發之用。為了方便開發者重製Kubernetes上的執行環境配置，Google近日在官網上，宣布釋出了Skaffold工具。這是一個命令列的工具，可以用來提供Kubernetes應用的持續部署（Continuous Development）之用。
開發者可以利用Skaffold來搭配本地端程式碼的迭代開發流程，來進行本地端或遠地端Kubernetes叢集的測試與驗證。
因為Skaffold不需要在伺服器端增加新的元件，因此可以減少對Kubernetes的負擔。另外也可以自動偵測程式碼的變動，並自動進行建置、發布或延後發布。另外，也具備了映像檔標籤管理機制，可以不用擔心Kubernetes設定檔的標籤更新。另外也支援現有的工具和工作流程，支援多種工作流程，也可支援多重應用程式的元件，來進行持續部署。更多內容
K8s出現兩個重大資安漏洞，免授權能存取或刪除任意檔案或目錄
Kubernetes產品資安團隊近日發現了兩個Kubernetes漏洞，分別列為CVE-2017-1002101和CVE-2017-1002102。目前已經釋出修補。
第一個漏洞1002101會讓容器在使用子路徑的掛載時，可以存取到任何路徑的權限，甚至是不應開放存取的系統核心目錄。
第二個漏洞1002102則讓容器可以透過加密、配置對應、保護或空間DownwardAPI來刪除任意檔案或目錄，甚至是執行中節點的檔案也能刪除。這兩個漏洞都恐造成Kubernetes很高的風險。CNCF基金會成員包括Google、紅帽也緊急搶修這兩個漏洞，已經釋出三個更新版本。影響版本包括Kubernetes 1.7.14, 1.8.9和1.9.4。紅帽也為了修補這兩個漏洞，預告OpenShift服務將會暫時停機一小段時間。更多內容
微軟開源釋出微服務平臺Service Fabric
微軟近日於官方開發者部落格上公布即將開源釋出微服務平臺Service Fabric的消息，將會在Github上，透過MIT軟體授權條款開源釋出，微軟更預計在接下來幾個月內，將該微服務平臺轉為開源專案，讓開發社群共同參與開發。
微軟表示，該微服務平臺是Azure的核心基礎架構，已經在微軟內部使用多年，協助管理上百臺伺服器，也支援了多個服務的底層技術，像是商用版Skype、Azure Event Hubs、Azure Data Factory、Azure Cosmos DB、Azure SQL Database等，甚至是Dynamics 365和Cortana。
未來，微軟的Service Fabric團隊目標是將該微服務平臺的開發流程，轉移到Github上，制定出明確的管理和貢獻引導，讓開發社群一同參與開發。另外一個目標則是要完成Windows和Linux版本的CI工作，完善環境建置、測試、部署等功能。更多內容
Vagrant釋出2.0.3版，終於可偵測既有Hyper-V來避免衝突當機
容器開發者常用的本機端VM模擬工具Vagrant最近釋出了2.0.3版，除了多項錯誤修補和效能強化之外，最重要的是提高與Hyper-V的相容性。
透過Vagrant，開發者可於本機端模擬其他的作業系統、組態及網路環境，甚至也可以實驗雲端主機的運作，但過去Vagrant要來開啟Hyper-V虛擬機器時，有時會和已經啟用的Hyper-V虛擬機器發生衝突而當機，現在2.0.3新增加了Hyper-V啟用狀態的偵測機制，可以減少發生資源衝突而讓容器化應用當機的情況。另外新版也強化了對Debian作業系上網路管理機制上對用戶配置的支援。更多內容
受NPM啟發，.NET Core 2.1預覽版新增Global Tools全域工具
微軟在.NET Core 2.1中釋出全域工具（Global Tools）預覽版，這個不少開發者引頸期盼的功能。全域工具可以讓開發者將.NET Core控制臺應用程式打包成NuGet套件，發布到Nuget.org或是任何NuGet套件伺服器，並供其他開發者安裝使用，其作用就和NPM全域工具相似。
只要可以安裝.NET Core的地方，就能使用全域工具，目前支援Windows、macOS與Linux。全域工具因為是控制臺應用程式，因此其打包與取用的方式就像是NuGet套件，而在預設的情況下，這些工具是相依於框架，包括所有NuGet的依賴項目，因此全域工具能在任何作業系統及晶片上執行。更多內容
責任編輯／王宏仁

更多Container產品動態
紅帽旗下開源網站推薦3個K8s安全部署
小心配置錯誤釀大貨，資安專家示範靠kubelet入侵K8s叢集
Jenkins X釋出Kubernetes的CI/CD工具
快速部署新工具gitkube登場，一次git push就能快速部署Docker映像檔
CNCF宣布接手代管GO語言開發的NATS訊息發布平臺專案
 
",https://www.ithome.com.tw/news/121916,"新聞,容器周報,K8s,CNCF,裸機,IT報告,NATS,gitkube,Jekins,kubelet"
121807,15,2018-03-19,Container周報第56期：大數據分析平臺Spark 2.3新版多了原生K8s支援,Spark在2.3新版中，開始原生支援Kubernetes，可以直接在一個現成Kubernetes 1.7以上版本部署的容器叢集中，執行Spark運算工作," 重點新聞：03/9~03/16
Spark釋出2.3新版，最大特色是原生支援Kubernetes
開源社群越來越多人使用Kubernetes來進行資料處理、資料分析和處理機器學習計算，Kubernetes也增加了不少擴充功能，資源客製化、控制器客製化，以便對更深度整合這類專屬應用程式。
現在熱門的大數據分析平臺Spark在2.3新版中，開始原生支援Kubernetes。可以直接在一個現成Kubernetes 1.7以上版本部署的容器叢集中，執行Spark運算工作，而且還可以利用Spark自身功能，來管理分散的資料處理或分析任務。Spark可以接使用Kubernetes叢集的命名空間或儲存空間，例如整合到外掛式驗證機制或Log追蹤上。
Spark原生支援Kubernetes最大的好處是，不用重新安裝Kubernetes叢集，或改變現有Kubernetes叢集的配置，只要建立一個新的容器映像檔，並指派合適的RBAC權限角色，給所要執行的Spark應用程式，就可以開始使用這個Spark程式了。
在2.3新版中還有不少重要更新，例如增加了新的DataSource機制、Structured Streaming API第二版，也強化了PySpark的效能。
容器叢集效能成新議題，HyperPilot開源釋出，要靠機器學習自動優化容器叢集的配置
藉助容器叢集，來支援大數據或機器學習分析所需的大型叢集，已是資料科學家常用的方法之一，但想要自己在雲端部署Docker容器叢集，第一個挑戰就是，要怎麼租用VM，才能省錢又能符合需要的效能？得同時考量VM規格、容器配置和應用程式的配置需求等多項複雜變因，來衡量成本，往往得靠資深的雲端架構師才有能力拿捏得當。
前Mesosphere分散式系統首席工程師Timothy Chen近日開源釋出了一套容器叢集配置自動化工具Hyperpilot，這是利用機器學習技術中的Bayesian Optimization最佳化技術，依據使用者提供的條件，來找出最佳的容器叢集所需要的VM架構配置，目前只能針對AWS上的VM規格為優化對象。
這套工具還提供了一個資源瓶頸分析工具HyperPath，可以從CPU、記憶體、網路、I/O的來評估資源瓶頸，開發者已配置的單一容器或單一節點的效能上限，方便開發者來衡量應用程式在這樣規格的容器或節點上的執行效能。
Timothy Chen率領的團隊也開發了新的Heracles 效能評估演算法，可供容器叢集控制器使用，來動態調整配置給應用程式的資源，根據Timothy Chen釋出的測試例子，可將一個Spark分析叢集的效能利用率提高2～3倍。
Docker前CEO轉戰區塊鏈新創，聚焦於分散式雲端儲存技術
前Docker CEO Ben Golub最近轉戰區塊鏈圈，加入美國一家利用區塊鏈技術，建立去中心化雲端儲存新創公司Storj Labs，任職臨時CEO。
Storj Labs透過區塊鏈技術，提供管理資料的開源平臺，針對全世界電腦未使用的多餘空間，透過以太坊分散式帳本來租用多餘的容量，提供有需要儲存空間的用戶購買，也就是說，用戶上傳文件後，平臺會先加密並且拆分成多個片段，分散儲存到多臺電腦中，Storj Labs表示，只有用戶知道資料保存的位置，能夠增加資料的安全性。
Ben Golub過去在Docker的初創期間，為Docker奠下基礎，也創造出亮眼的成績，Ben Golub也在Storj Labs的官方部落格，寫下自己為何加入該新創的原因，他表示，自己過去曾參與過6家新創公司，電腦計算現在正處於重大的改變，區塊鏈和分散式帳本能夠驅實現分散式網路和架構，打造可信賴且安全的模型，Ben Golub看見區塊鏈技術於分散式儲存發展的機會。
甲骨文容器服務也開始支援Kubernetes
甲骨文近日宣布了可以支援Kubernetes的Oracle Container Services 1.1.9版，目前可支援Kubernetes 1.9.1以上的版本，還無法支援舊版。可在Oracle Linux 7上，整合Docker版Oracle Container Runtime。目前已經透過 Oracle Container Registry服務釋出Oracle Container Services的映像檔。
在這個映像檔中，除了提供支援Kubernetes的Oracle Container Services所需程式和配置之外，還內建了Kubernetes儀表版軟體、叢集備份還原機制和Oracle雲端基礎架構的整合測試工具，Oracle還提供了安裝和配置腳本程式來簡化部署。更多內容
OpenStack新版不只強化vGPU，更增加新的Zun容器服務
開源IaaS平臺OpenStack日前釋出了第17個版本Queens。新版特別強化了vGPU的支援，現在可以啟用內建vGPU功能的VM了。另外也增加了一個用來管理硬體加速或軟體加速的框架Cyborg，可以支援GPU、FPGA、加密卡、DPDK/SPDK等，管理者可以將這些加速卡或硬體，指派給特定VM。新版也增加對邊緣運算架構（Edge Computing）的支援。
另外，新的Queens版本，也增加了不少容器功能，例如用來整合OpenStack和Kubernetes叢集網路的Kuryr框架，增加了CNI daemon機制，可以強化Kubernetes叢集的擴充能力。另外，OpenStack也增加了一個新的容器專案Zun容器服務，可以快速啟動和執行容器，而不用管理伺服器或叢集，也可以快速和企業網路、儲存機制整合。更多內容
Google用Kubernetes打造多人遊戲託管平臺
Google近日與法國一家知名遊戲開發公司Ubisoft合作，利用容器調度工具Kubernetes打造開源平臺Agones，來管理多人玩家進入遊戲的伺服器資源分配，Agones目前還是預覽版，已於GitHub開源釋出。
Google認為，這項新的專案將會對遊戲設計非常有幫助，現在透過Agones，取代原本伺服器管理和擴展的方式，直接透過包含Kubernetes控制器的叢集，來分配遊戲伺服器的資源，這樣的架構也可以直接透過Kubernetes API來建立專用伺服器。
開源的Agones專案透過原生的Kubernetes，可以直接在叢集中建立、執行和管理專用遊戲伺服器的程式，減少了大部分複雜的問題，此外，遊戲的開發人員也可以使用原本熟悉的Kubernetes工具來撰寫應用，除了伺服器的運行之外，Agones專案也支援遊戲中的服務，像是帳戶管理，透過同一個平臺來管理這些服務，可以減少開發團隊開發時的困難。
責任編輯／王宏仁
更多Container產品動態
Docker傳教士開始推廣Azure Kubernetes Service的部署經驗
Aqua Security 3.0新增容器安全平臺，來強化雲端原生應用安全
＠資料來源：iThome整理，2018年3月
 
 
",https://www.ithome.com.tw/news/121807,"新聞,Kubernetes,Spark,效能優化,Container,Hyperpilot,Docker,IT周報"
121876,15,2018-03-19,容器叢集效能成新議題，HyperPilot開源釋出，要靠機器學習自動優化容器叢集,利用機器學習技術中的Bayesian Optimization最佳化技術，依據使用者提供的條件，來找出最佳的容器叢集所需要的VM架構配置，目前只能針對AWS上的VM規格為優化對象。," 藉助容器叢集，來支援大數據或機器學習分析所需的大型叢集，已是資料科學家常用的方法之一，但想要自己在雲端部署Docker容器叢集，第一個挑戰就是，要怎麼租用VM，才能省錢又能符合需要的效能？得同時考量VM規格、容器配置和應用程式的配置需求等多項複雜變因，來衡量成本，往往得靠資深的雲端架構師才有能力拿捏得當。
前Mesosphere分散式系統首席工程師Timothy Chen近日開源釋出了一套容器叢集配置自動化工具Hyperpilot，這是利用機器學習技術中的Bayesian Optimization最佳化技術，依據使用者提供的條件，來找出最佳的容器叢集所需要的VM架構配置，目前只能針對AWS上的VM規格為優化對象。
這套工具還提供了一個資源瓶頸分析工具HyperPath，可以從CPU、記憶體、網路、I/O的來評估資源瓶頸，開發者已配置的單一容器或單一節點的效能上限，方便開發者來衡量應用程式在這樣規格的容器或節點上的執行效能。
Timothy Chen率領的團隊也開發了新的Heracles 效能評估演算法，可供容器叢集控制器使用，來動態調整配置給應用程式的資源，根據Timothy Chen釋出的測試例子，可將一個Spark分析叢集的效能利用率提高2～3倍。
",https://www.ithome.com.tw/news/121876,"新聞,容器,Docker,K8s,Hyperpilot"
121758,16,2018-03-13,Container雙周報第55期：Kubernetes成了CNCF第一個畢業專案，即將發布1.10新版本,1.10版將會支援更多線上正式環境需要的容器叢集管理機制，最大特色是Kubelet TLS Bootstrap功能終於支援正式環境，可以讓在一個新的Kubelet中，自動建立資安憑證，而不用像過去得手動設定，來減少憑證設定的繁瑣工作," 重點新聞（2月24日-3月8日）
Kubernetes成了CNCF第一個畢業專案
力推各種雲端原生技術的CNCF基金會，將旗下專案按成熟度區分成三個階段，現在終於出現了第一個畢業的專業，也就是當紅的容器調度平臺Kubernetes。
根據CNCF網站上資料，企業或社群可將專案捐給CNCF基金會來育成，基金會也成立了一個委員會（TOC）每12個月定期衡量旗下開源專案的發展成熟度。專案程式碼得採用ASL 2.0授權或類似授權釋出，並將相關商標轉移給CNCF。CNCF才會接手育成這專案（第一階段：接受期）。目前多數捐給CNCF基金會的專案，多處於孵化期（第二階段：育成期），由基金會來協助推動這些專案的發展，但若開源專案相關的社群機制和發展機制夠成熟，CNCF就會放手讓專案自主發展，也就成了畢業專案（最後階段：畢業專案）。
畢業條件主要有，核心維護者至少要來自兩個不同的組織或企業，避免一家獨大，其次是要建立一個核心基礎架構的維護團隊，並符合CNC的社群行為規範。另外也要有清楚的程式碼貢獻辦法和審查機制。程式碼也必須至少有一個公開儲存版本。
CNCF委員會認為，Kubernetes已經符合了這些條件，足以成為自行發展的成熟專案，因此，將其列入CNCF第一個畢業專案。
Kubernetes即將在3月釋出1.10新版本
去年快速釋出四次改版的Kubernetes，也即將在3月21日釋出今年的第一個的新版本Kubernetes 1.10版。1.10版將會支援更多線上正式環境需要的容器叢集管理機制，尤其是資安相關的功能。
例如，1.10版最大特色是Kubelet TLS Bootstrap功能終於支援正式環境，可以讓在一個新的Kubelet中，自動建立資安憑證，而不用像過去得手動設定，來減少憑證設定的繁瑣工作。
其次，Pod資安政策現在也可以套用到這個Pod自己所屬的API群組，目前還處於Beta版本，這個功能可以用來避免私有Pod能輕易取得未授權的行為，例如可以限制只有特定命名空間中的Pod才能寫入檔案或讀取機敏區域。另外一個實用的新功能是，現在可以管控節點對API的呼叫次數，目前是Beta測試階段。如此避免某些節點上的服務，出現爆量請求時，不會連帶塞爆了共用的API，進而影響了這些API對其他節點的服務能力。
在網路功能上（Beta階段），現在可以控制單一Pod的DNS，而不用侷限於整個叢集的DNS設定。1.9版就釋出的API Aggregation功能，在1.0也進入了穩定期，透過這個機制，開發者可以更容易打造第三方API來串接Kubernetes叢集，以便擴充現有Kubernetes的功能。
儲存機制也有不少改進，現在可以在叢集本地端提供持久儲存空間PersistentVolumes，而不用像過去得建立網路儲存空間。這個功能目前也是Beta測試階段。
 
微軟與Canonical聯手，改善Hyper-V的Ubuntu虛擬機器使用體驗
微軟計畫經理Craig Wilhite最近透露，使用者希望提升Hyper-V上Linux虛擬機器體驗，以與Windows虛擬機器感受相當，因此微軟決定為此投注資源，更緊密的整合Linux。微軟找上了在Linux上實作遠端桌面協定（Remote Desktop Protocol，RDP）的開源軟體公司XRDP，並且與Canonical合作，為即將到來的Ubuntu 18.04提供增強的虛擬機器功能。
Craig Wilhite強調，使用者未來只須要點擊3個按鈕，就能執行一個Linux虛擬機器。強化後Linux虛擬機器，提供更順暢的滑鼠使用體驗、整合剪貼簿、調整視窗大小和驅動重定向，這些雖然不是很大的功能改進，卻是很實際改善使用者體驗的功能。
強化Linux虛擬機器使用者體驗的功能，其達成的作法與在Windows增強的工作階段模式（Enhanced Session Mode）相同，是仰賴XRDP在Linux實作的RDP協定與Hyper-V接口相連，主機與客戶端以類似TCP的方式溝通，只不過是透過稱為VMBus的優化傳輸層，並且經過修改讓XRDP也可以使用。Canonical預計4月底在Ubuntu18.04版本正式提供。
Chrome OS可望開始支援Linux虛擬機器
Chromium開發人員在今年1月揭露了Project Crostini，指稱該專案將讓Chrome OS能夠執行Linux虛擬機器（Linux VM），且已釋出開發者版本，接著於2月宣布更新Chrome OS裝置政策，透露出在Chrome裝置上執行Linux程式的時日應該不遠了。
在Chrome OS上，通常是要先安裝Crouton工具才能執行Linux，但必須切換到開發者模式，因而犧牲了該平台的安全功能。
專門報導Chrome消息的Chrome Unboxed則公布了Project Crostini的畫面，顯示該專案等於是Chrome OS上的Linux終端，只要安裝了終端程式，Chromebook用戶就能執行Linux程式與使用命令列工具。
Mesosphere新版資料中心OS將全面支援K8s
 
容器管理平臺Mesosphere即將時出DC/OS 1.10版本，計畫將全面擁抱同為容器叢集管理平臺的競爭對手Kubernetes。
去年9月先釋出Beta測試版的1.10版，除了穩定性和安全性的優化之外，Mesosphere共同創辦人暨技術長Tobias Knaup最近預告也將全面支援Kubernetes，他解釋，但不會取代Mesosphere自家的Marathon，而是會以獨立主機服務的形式，在DC/OS中執行Kubernetes。
DC/OS也提供了快速安裝和升級Kubernetes的公職，只要單一點擊，就可以直接安裝，並且預設會採用高可用性配置來建立每一個Kubernetes叢集。Tobias Knaup，我們還是希望能盡量簡化維運工作的負擔。
 
Hadoop工具商MapR強化Kubernetes支援，在K8S分析大數據更穩定
知名Hadoop分析工具之一的MapR，最近在Strata Data大會上宣布，要提供進行容器整合機制，推出MapR Data Fabric的Kubernetes支援，可以讓MapR的Converged Data Platform大數據分析平臺可以提供容器上可用的永久儲存空間，也可供用來部署一個Stateful類型的容器應用。
MapR Data Fabric現在可以原生整合到Kubernetes的儲存空間，來提供永久儲存空間，可用來存資料庫、檔案或串流資料等。
 
更多Container產品動態
CNCF基金會發表Serverless白皮書，開始聚焦新架構
4大容器管理工具引發論戰，Rancher、Nomad、K8s和Mesosphere你用哪一個？
Atos發表紅帽OpenShift上的容器服務管理工具，可支援多雲部署架構
Tesla容器叢集配置不當遭駭事件引發更多後續效應，社群熱切討論K8S儀表版的設計
Dockercon年度大會議程揭曉，今年專門聚焦用戶正式導入經驗
Kali Linux登上Windows Store，但還不完全相容於Windows Defender
Netflix分享自家容器導入經驗，不靠K8s而是自建Titus容器叢集管理平臺
 
 
 
 
 
 
",https://www.ithome.com.tw/news/121758,"新聞,Kubernetes,CNCF,Container,Tesla,DockerCon,IT周報"
121380,16,2018-02-21,監理科技也能用DevOps！Chef釋出資安法遵自動化工具InSpec 2.0，支援雲端環境設定檢查,InSpec是一款免費開源的資安法遵自動化工具，在1.0版本提供On-Premises應用程式的設定檢查功能，到了2.0，InSpec能直接連接雲端服務供應商的API，幫開發者測試雲端環境設定安全性。," 自動化工具廠商Chef在2月20日釋出開源的資安法遵自動化工具InSpec 2.0，最新版本的InSpec支援測試雲端環境上的設定，也能對網路基礎架構或是Container等額外的元件進行測試。
Chef不只提供DevOps工具加速開發流程，現在更要企業重視安全性，達到DevSecOps（Development Security Operations），使用程序化結構以及自動化增進並擴展IT的安全性。InSpec是一款免費開源的工具，在1.0版本提供On-Premises應用程式的設定檢查功能，到了2.0，InSpec能直接連接雲端服務供應商的API，幫開發者測試雲端環境設定安全性。
產品行銷總監Julian Dunn舉例，像是在AWS S3服務，最常被忽略的安全性問題就是，該隱藏的機密文件因忽略權限設定而被公開，InSpec 2.0則能自動化的檢查這些設定。對於將應用程式部署在多個雲端服務的企業，將能大幅降低因疏忽造成的安全性問題，或是簡化繁瑣的設定與檢查程序。
Julian Dunn表示，目前InSpec 2.0先支援AWS以及Azure兩個雲端服務，未來將會繼續增加，而這次的更新還包含新增30項資源，用來幫助開發者測試一般系統及應用程式一致性設定，並且能讓開發者自行撰寫InSpec規則，來檢查SQL資料庫、網站伺服器或是Docker映像檔等設定。
除此之外，InSpec 2.0也宣稱，比起1.0版本，在Windows上運作效能提升90％，在Linux上則提升30％。InSpec 也能將結果輸出成JUnit格式，與CI/CD工具Jenkins整合。
",https://www.ithome.com.tw/news/121380,"新聞,Chef,DevSecOps,Cloud"
121087,16,2018-02-05,開發不只快更要安全，Lyft安全工程師談DevOps安全性,前維基百科安全工程師，也是現任的Lyft安全工程師Chris Steipp認為，Lyft的AppSec計畫的成功，有三點值得拿出來分享，第一、每一件都需要被測量，第二、尊重開發者的時間，在對的時間發訊息給開發者，第三、整個開發過程需持續性的回饋循環。," 企業在追求應用程式快速部署而導入DevOps，但同時安全性議題也不容被輕忽。叫車服務公司Lyft安全團隊在部落格發表文章，講述Lyft在DevOps環境如何兼顧應用程式安全性，不只是DevOps，而且是DevSecOps。
前維基百科安全工程師，現任的Lyft安全工程師Chris Steipp表示，Lyft開發程序是極度DevOps的環境。不同的團隊負責不同的產品，每個團隊都須達到各自的服務等級協定（Service-Level Agreement，SLA）以及回應時間等要求。每個團隊也都擁有完全控制自己產品的自由，包括決定產品建立以及執行的方式，甚至是產品更新的頻率，不少團隊選擇一天部署產品數次已增加新功能，不過在這個自由背後，隨之而來的責任是，這些團隊也必須為產品的安全性負責，像是確保安全性議題在時間內修補等工作。
Chris Steipp提到，在這樣的情況下，要在既有開發流程中，增加AppSec計畫是極度勞力密集的工作，不只要重新思考團隊如何互相配合，還要開發自動化整合安全工具，來整合現行的開發流。他認為，Lyft的AppSec計畫的成功，有三點值得拿出來分享，第一、每一件都需要被測量，第二、在對的時間發訊息給開發者，並尊重開發者的時間，第三、整個開發過程需持續性的回饋循環。
工具跟程序都需要可被測量，不僅僅是為了收集數據的目的，而是要讓團隊隨時注意指標，部分指標由AppSec團隊監控，但更有效率的方法則是由開發團隊自己監控，並對上面的數值負責。現在Lyft中每個開發團隊，都有一個以上的儀錶板，上面顯示著錯誤率、回應時間，或是符合SLA服務的百分比等數據。AppSec團隊的角色只在於提供儀錶板服務，以及追蹤過期卻未被修補的程序。
在AppSec計畫中，成功要素之二，在對的時間發訊息給開發者，並尊重開發者的時間。Chris Steipp指出，開發者每天都會收到來自各部門重要且有用的訊息，因此安全相關的訊息很容易被過濾掉，或是跟著其他訊息一樣，沉入待處理的工作堆中，直到前面工作被消耗完才會被注意到。
Chris Steipp也同意，作為有效率的開發者，的確需要設定許多訊息過濾條件以提高工作效率，但當AppSec團隊明確的告訴開發團隊本月是網路安全月，開發者就不應將XSS或是釣魚關鍵詞，作為訊息過濾條件。AppSec也應在適當的時機發出警告，像是在工程師開發新前端程式時，提醒他們要注意跨站腳本攻擊，或是他們在閱讀可疑郵件時，提醒他們網路釣魚攻擊。
在要求開發者重視安全性的同時，也必須尊重他們的時間，在不少時候，安全性工具在開發流程中可能造成訊息誤報，而導致後續作業受到阻礙。Chris Steipp說，曾經他們在GitHub上Pull Request前的統計分析系統，由於不精確的訊息回饋，造成工程師在合併程式碼時浪費許多時間，AppSec團隊收到反應後，為此開發了一套系統每30秒回饋系統狀態，大幅將每次程式碼合併的時間從1小時降到了7分鐘。尊重工程師的時間，AppSec團隊的安全性工作也才會被尊重。
第三點，整個開發過程需持續性的回饋循環。即使他們的AppSec團隊不大，但他們仍可以在開發流程中的13個時間點與開發者互動，這要歸功於高度自動化的工具，而且在實作自動化系統時，盡量讓上一個工具的輸出成為下一個工具的輸入。
像是他們讓開發團隊使用自動化評估問卷，以記錄團隊正在儲存資料的種類，以及儲存的地方，基於開發團隊自己的答案，如此在適當的時機提供反饋避免開發上的錯誤外，還能根據某些特徵，方便AppSec團隊進行稽核，並且將這些數據結果繪成數據圖，作為審查或外部安全評估之用。
",https://www.ithome.com.tw/news/121087,"新聞,DevOps,Lyft,Security"
121067,16,2018-02-02,AWS自動規模化服務翻新，統一管理多項服務的自動規模化設定,AWS發表了全新自動規模化（Auto Scaling）服務，使用者不再需為個別的服務，單獨設定警示或是規模化的工作，現在只需要將自動規模化服務指向想要設定的服務或是資源，系統將會協助使用者建立規模化的計畫。," AWS發表了全新自動規模化（Auto Scaling）服務，過去琳瑯滿目分別對應的負載平衡或是規模化的服務，現在AWS提供統一介面的自動規模化服務，不需額外費用，使用者僅需支付雲端網路監控服務CloudWatch Alarms，還有所使用的其他AWS資源即可。
AWS在2006年發表可規模化的隨需雲端服務後，不久便上線了EC2服務，配合Elastic Load Balancing、EC2 Auto Scaling還有Amazon CloudWatch，便可做到自動規模化。而後AWS還為其他服務增加自動規模化的服務，諸如ECS、Spot Fleets、DynamoDB、Aurora、AppStream 2.0以及EMR。
新的自動化服務將簡化使用者操作多個AWS服務時自動規模化的工作，這項服務奠基並一統現存的規模化服務，像是EC2 Auto Scaling groups、EC2 Spot Fleets、ECS tasks、DynamoDB tables、DynamoDB Global Secondary Indexes與Aurora Replicas。
使用者不再需為個別的服務，單獨設定警示或是規模化的工作，現在只需要將自動規模化服務指向想要設定的服務或是資源，系統將會協助使用者建立規模化的計畫。
AWS首席傳教士Jeff Barr表示，如果使用者過去試過任何服務的規模化設定，那便會很容易理解自動規模化的閾值設定。全新自動規模化服務給使用者不同的選項，使用者可以採用效能優先的設定，便能讓雲端資源應付突發性的高負載流量。也能使用成本考量優先的設定，系統規模會盡量向實際資源需求量靠攏，但是對於突發負載的反應會較慢。而使用者也能選擇中庸選項，根據使用者設定的閾值調整系統。
即日起美東（維吉尼亞北部）、美東（俄亥俄）、美西（奧勒岡）、歐洲（愛爾蘭）和亞太區域（新加坡）都可以使用這項服務，並陸續開放其他地區，Jeff Barr最後提到，目前初步提供這項服務，後續還有長遠的規畫，根據使用者的回饋會陸續推出。
",https://www.ithome.com.tw/news/121067,"新聞,AWS,Auto Scaling,Cloud"
120833,16,2018-01-19,雲端業績拉抬，IBM營收終於止滑，出現22季以來的首次成長,IBM估算，各種雲端服務（as-a-service類服務）合計的第四季營收更是亮眼，達到55億美元，比去年同期增加了30%。IBM推算，全年雲端業務的營收將達到170億美元，比前一年增加了24％。," IBM於本周四（1/18）公布的財報顯示，該公司終於終結了連續22季的營收下滑，於去年第四季創下225億美元的營收，比2016年同期成長了4%，亦達到5.17美元的每股盈餘。
在IBM於去年第四季所締造的225億美元營收中，有111億美元屬於關鍵策略（Strategic Imperatives）營收，已佔據IBM總營收的45%。而各種雲端服務（as-a-service類服務）合計的第四季營收更是亮眼，達到55億美元，比去年同期增加了30%。IBM推算，全年雲端業務的營收將達到170億美元，比前一年增加了24％。
所謂的關鍵策略亦即IBM從傳統軟/硬業務轉型的方向，涵蓋分析、安全、雲端影片服務與Watson Health等，奠基於IBM的認知解決方案及雲端平台，並分布在不同的業務類別中。
在IBM傳統業務持續下滑的同時，關鍵策略營收則穩定成長，且幾乎都有兩位數的成長，去年第四季亦成長了17%。
從各個類別的營收來看，去年第四季認知解決方案創下54億美元的營收，成長3%；全球商業服務營收為42億美元，成長1%；技術服務暨雲端平台的營收為92億美元，下滑1%；系統服務創下33億美元的營收，成長32%；全球融資服務營收為4.5億美元，成長1%。
儘管去年第四季可說是IBM這幾年來的里程碑，且營收與獲利雙雙超越了華爾街分析師的期待，不過IBM的周四股價僅微幅上揚了0.28%，以169.12美元作收。
",https://www.ithome.com.tw/news/120833,"新聞,IBM,Cloud,認知服務,Watson"
120184,16,2018-01-04,不再只搶雲端顧客，Amazon釋出離線版Linux 2搶攻線下企業市場，還享5年技術支援,現在Amazon的用戶不再只能選擇雲端上的Linux 2，也能選擇離線版，裝在企業擁有的伺服器上，或是其他虛擬技術上，如Docker、VMware、甲骨文VirtualBox 或是微軟Hyper-V。," Amazon不把只攻雲端用戶，反而釋出自家Linux版本Amazon Linux 2，可以安裝到企業內的伺服器，還提供5年技術支援，要來搶攻線下伺服器OS市場。
現在Amazon的用戶不再只能選擇雲端上的Linux 2，在自家企業擁有的伺服器上安裝離線版本，或是其他虛擬技術上，如Docker、VMware、甲骨文VirtualBox 或是微軟Hyper-V等。Amazon為此提供5年支援，提供安全補丁以及臭蟲修正。
此版本Linux具備經過Amazon調校且在AWS上達到最佳效能的LTS Kernel 4.9，擁有系統化的支援以及裝配較新的工具gcc 7.2.1、glibc 2.25和binutils 2.27，額外的軟體套件也能透過Amazon Linux Extras儲存庫安裝，像是Python、MariaDB或是Node.js都能在上面找到新版本。
Amazon此一動作明顯與過去想把客戶綁在雲端上的策略不同，以往競爭者會採取混和雲的策略與AWS服務對打，不過如今這戰局顯然會有所不同，而AWS蠶食伺服器與儲存裝置市場早已是事實，如今又開了塊戰場，與提供企業級Linux的Red Hat交手。
",https://www.ithome.com.tw/news/120184,"新聞,Amazon,Linux,Red Hat,Cloud"
119235,16,2017-12-07,Kubernetes原生雲端應用程式函式庫Metaparticle，開發、打包及部署一種語言就能搞定,Kubernetes共同創辦人Brendan Burns認為，開發者只需要會一種程式語言，就能應付像是開發分散式系統這種繁雜沉重的工作，將是未來的趨勢。," 自動部署、擴展和管理Container應用程式的開源系統Kubernetes共同創辦人Brendan Burns於KubeCon上，發表分散式應用程式編寫架構Metaparticle，這是一套為雲端原生應用程式而生的Kubernetes標準函式庫，目的是讓開發者使用自己熟悉的程式語言，就能開發分散式應用程式。
Metaparticle簡化部署應用程式的程序，像是打包應用程式進Container、複製、分享以及同步等等繁複工作。
Brendan Burns表示，這將是未來撰寫程式的趨勢，因為開發者只需要學會一種程式語言，就能用來應付開發分散式系統這種沉重的工作，而不必多學一種像是Kubernetes的陌生架構。他說，建造分散式系統就像是手工藝一樣，將很多像是皮革和銅片等素材編織起來，他自己喜歡像個工匠一樣的工作，Metaparticle讓這件事規模化。
Metaparticle不需要開發者重新撰寫系統設定，其方便的功能之一便是再利用其他任務所產生的元件。Brendan Burns在KubeCon上現場展示了Metaparticle的功能，他在四個Kubernetes所管理的container上執行了一個簡單的JavaScript 應用程式。目前Metaparticle開源框架支援JavaScript、Java和.NET，Brendan Burns希望大家可以加入這項專案計畫，並讓Metaparticle支援更多程式語言。
Brendan Burns認為，Metaparticle只是一項實驗，還需要很多調整，而且或許根本就是錯的方向，不過Brendan Burns對於原生雲端運算的發展，應該類似Metaparticle這樣的概念十分有信心。
",https://www.ithome.com.tw/news/119235,"新聞,KubeCon,Kubernetes,Metaparticle,Container,JavaScript"
119089,16,2017-12-05,邁入容器時代，企業如何確保資安? NIST發布指導方針提醒要注意6處風險,美國國家標準與技術研究院的資訊科技實驗室針對Container應用的安全公布了指導方針，提醒企業在管理容器時應注意兩個可能帶來風險的議題的6個需注意的環節," 美國國家標準與技術研究院（The National Institute of Standards and Technology，NIST）日前針對應用Container這項新興技術，公告了一份安全性指導方針，列出採用Container值得注意安全性挑戰，報告總結二個安全性弱點，以及六大環節的安全對策。
高機動性是Container的優勢之一，靈活的在不同執行環境與基礎架構中移動，但這個特性也成為了安全缺口之一。通常同一個Container映像檔會在不同的環境下使用，像是開發、測試到正式上線的環境，不過在實際上情況可能會因為應用程式的可移植性以及持續交付等環境，產生不可預期的執行情境，而安全性工具將無法預測這些可能產生的安全問題可能性。
第二個安全缺口在於，Container仰賴映像檔作為建立的藍圖，當有新的映像檔版本產生時，舊的Container會被消滅，而新的Container會依造新的映像檔被建立，因此建立映像檔在管理Container工作上背負重大的責任，不過因為Container這樣的運作模式，某部分安全性的責任會落到不擅長維運的開發部門上，像是作業系統更新的補丁，或是應用程式的版本更新，開發部門都需要頻繁的重新產生映像檔，但執行環境相關的安全性議題在維運團隊通常有較豐富的經驗與專業，當執行環境與程式開發綑綁在一起，便容易產生被人忽視的安全死角。
針對這兩個因為Container特性而產生的安全性議題，NIST提出有6處容易產生安全漏洞的環節，包括映像檔、註冊、Orchestrator、Container、Host OS以及硬體。
一、映像檔產生的漏洞可能來自於已知或未知的作業系統漏洞、設定上的疏忽或是惡意軟體，甚至是明碼儲存敏感資訊，然而很大的部分也來自開發團隊沒有意識到應負起安全性的責任，像是在Docker Hub上多數的基底映像檔都存在高優先度安全漏洞，如果開發團隊沒有留意，很容易將系統暴露在易受攻擊的環境中。二、註冊相關的議題，可能因為過時的映像檔、不安全的連線或是權限設定不夠周延。
第三個有安全風險的地方是Orchestrators，因為其控制著Container的生命週期，但可能因為網路連線的品質問題，產生臭蟲或是設定未能及時產生效果，導致未預期的存取發生。
第四至於Container本身可能遭遇的問題，需要注意Container內惡意程式碼會突破Container的限制，感染其他Container。第五項則是要注意每一個Host OS都有其受攻擊的弱點面，Host OS確保Container執行不受外界影響，最後一項是底層的硬體是安全環節的最根本，也必須留意。
",https://www.ithome.com.tw/news/119089,"新聞,NIST,Container,Bulletin"
118987,16,2017-12-04,圖靈耗費2年心力，但雲端加AI只用15分鐘，就破解了納粹Enigma密碼機,資訊科技的發展降低了破解密碼的成本，破解納粹密碼機Enigma成本只要10英鎊。," 人工智慧之父艾倫·圖靈因為破解了納粹的Enigma密碼，而終結了第二次世界大戰，幾年前還拍成了一部電影模仿遊戲。當時令盟軍頭痛不已的Enigma密碼機，碰到現今的雲端以及人工智慧技術可以撐多久？答案是不到15分鐘。
12月1日大資料服務供應商Enigma Pattern在倫敦的一場活動中，現場演繹如何用現代資訊科技，調度2,000臺虛擬機器暴力破解二次世界大戰納粹所使用的加密系統Enigma，而破解的過程甚至不到15分鐘，成本只花費10英鎊。
Enigma Pattern用德國格林童話當作教材，讓人工智慧學會德文，並用Python模擬出Enigma密碼機最先進的版本M4（德國海軍四轉子Enigma）。在破解階段，啟動解碼子開始測試所有可能的密碼組合，並把學會德文的人工智慧連接解碼子，並標記出已破解字碼。
Enigma Pattern的首席資料科學家Lukasz Kuncewicz表示，Enigma是一套複雜的密碼系統，即使知道訊息的語言是德文，破解仍然需要花費許多時間，更何況要測試數十億可能的組合，或許需要花上數周。而雲端科技加速了這個過程，一臺解碼子需要花費數周，同時使用2,000臺解碼子每秒測試4千1百萬種可能性，約測試過了320億種可能性，13分鐘後便能完全破解Enigma M4版本。
",https://www.ithome.com.tw/news/118987,"新聞,AI,Cloud,Enigma,密碼破解,圖靈"
118121,16,2017-11-19,【雲端巨頭、軟硬體IT大廠都靠攏Kubernetes】企業級容器軟體紛紛登場，K8s容器叢集管理成主流,容器調度工具龍頭已經由Kubernetes所拿下，從開源專案成為成熟商業軟體，而它的發展更讓容器技術進入新階段，各大廠商都得支援才能在容器市場有立足之地," 今年10月剛落幕的歐洲DockerCon大會中，容器技術龍頭Docker公司技術長Solomon Hykes忽然宣布，下一版Docker，將同時支援自家調度引擎Swarm和來自Google的調度平臺Kubernetes，臺下觀眾響起熱烈掌聲，因為這是一個容器圈等待已久的消息。
DockerCon的Solomon Hykes技術獨白，向來是每年容器圈技術風向球的重頭戲，但在這場歐洲DockerCon中，Docker卻得找來Kubernetes兩名共同創辦人站臺。三人就在臺上合影，Solomon Hykes居中，左邊是微軟Azure團隊傑出工程師Brendan Burns，右邊則是Google雲端部門首席軟體工程師Tim Hockin。
Solomon Hykes這個宣示的威力，就好比微軟執行長Satya Nadella那句「微軟愛Linux」般震撼，一手掀起容器熱潮的Docker，也不得不正視Kubernetes的影響力，就算是Docker掌握了主流容器格式，也得擁抱Kubernetes，提供原生支援，才得以在競爭激烈的容器生態圈中站穩。而Solomon Hykes這個宣布，也等於揭開了容器生態系的新序幕，Kubernetes成了眾人擁戴支援的新主角，連Docker都不例外。
不過，另一款容器管理工具Rancher執行長梁勝在自家部落格感嘆：「DockerCon與會者，多半期待Docker提出更具前瞻性的潛在商機。」
尤其，這次歐洲DockerCon主要訴求，聚焦在傳統應用程式現代化（Modernize Traditional Applications，MTA）專案，做為Docker生態系的夥伴，梁勝觀察，想要利用Docker這門技術進行創新的難度日漸提高。他舉例，過去Docker發表的產品，無論是Docker Swarm、Docker Compose、Docker網路及儲存套件都相當創新，但是，從這次歐洲大會來看，「現今容器技術的新發想，許多都是來自Kubernetes或CNCF生態系。」梁勝一席話，也道出了Docker公司近年面臨的創新瓶頸。
其實，早在去6月DockerCon就可看出Docker困境的些許端倪，Solomon Hykes當時一句話令人玩味：「現在沒有人關心容器技術了，應用程式才要緊」，那時Solomon Hykes早就察覺開發者的目光，已不再只是Docker，而是容器如何支撐企業運作的應用程式，才是真正重要的關鍵。
叢集管理是容器技術的新挑戰
在Docker熱潮逐漸冷卻後，容器技術生態系要開始踏入下個重要階段：如何靠調度工具管理龐大的容器基礎架構叢集。歸根究柢，容器只是打包應用程式的工具，企業關心的焦點，仍舊要回歸靠它所執行的應用程式。
在2016年我們採訪前Docker Swarm專案負責人陳東洛，他就曾透露：「叢集管理是未來容器技術的挑戰。」調度工具之所是容器進入企業環境的門檻，原因在於，如果沒有調度工具，Docker容器叢集就像失去指揮家的交響樂團，開始出現樂手走音、趕拍的異常狀況。
兩年前，容器調度工具的戰局，基本可以劃分為三大勢力，包含Swarm、Kubernetes以及Mesos，各技術都有其擁護者，像是總用戶數突破3億人的Twitter，或是蘋果語音助理Siri就是使用Mesos，作為其系統後端叢集的管理工具。
但是，三分天下的競爭態勢，至今已經逐漸明朗化，前身為Google自家內部容器調度工具Borg的Kubernetes，在2014年開源釋出之後，挾Google響亮的招牌、龐大的社群，Kubernetes開始出線，甚至拔得頭籌，登上容器調度的寶座。
維護Kubernetes專案的CNCF基金會，在今年6月時統計，目前使用Kubernetes作為容器管理工具的企業占比達77％，排名第二的Swarm則遠遠落後，只有21％，第三名則是13％的Mesos。
Kubernetes從單純開發工具逐漸向商業軟體發展
從Kubernetes各版本演進中，也可以看出它的功能，逐漸從以容器開發資源調度為主的平臺，踏入企業商用需求的範疇。在去年上半年釋出的1.2及1.3版中，其亮點主要是擴大其管理叢集規模，從1,000個節點擴充至超過2,000節點，使企業更能善用容器技術的輕量、快速部署特性，運作更龐大的運算叢集。去年秋天的1.4版則是開始加強Kubernetes的易用性，只需輸入兩個指令便可以部署一套容器叢集。
去年12月發布的1.5版，則是一個關鍵突破版本。Kubernetes瞄準了混搭容器平臺，居然可以同步支援Linux容器及Windows容器，倚重微軟環境又想擁抱容器的企業也能獲得解套，不用再各自管兩套環境，也降低了這些企業進入容器應用的門檻。Kubernetes跨入更廣大商用市場的企圖心更為明顯。
到了今年發布的1.6及1.7版，除了讓叢集規模擴大至5,000節點，Kubernetes也新增了角色權限存取機制（RBAC，Role-Based Access Control），限定使用者權限。在1.7版中，Kubernetes官方更以「里程碑」形容，無論在資安、儲存，或是系統的擴充性都有所進步，例如，在此版本開始支援資料加密，更在Runtime增加了一個整合層（Aggregation Layer），讓開發者可以自行串接第三方API，擴大容器生態系。到了最近一期的1.8版，則是繼續強化此工具的既有功能，像是先前是Beta功能的RBAC機制，此版已經變成正式功能。
支援Kubernetes已成各IT大廠必備戰略
Kubernetes的出現，讓許多原本著手打造自家容器調度工具的IT廠商，不得不放棄原本自家工具，轉而向它靠攏。像是紅帽在PaaS平臺OpenShift原先是使用自家開發的容器調度工具，但是礙於Kubernetes的聲望，便斷然捨棄並且在3.0版後開始支援Kubernetes；容器技術廠商CoreOS在今年2月時也宣布，自家容器作業系統Container Linux已經要停止支援自家調度工具Fleet，開發重心全部移轉至Kubernetes；提供公有雲服務的IBM原本是以Swarm為基礎發展自家調度技術，同樣，甲骨文原先也用自家技術提供調度服務，但是在今年起，雙雙都宣布要正式支援Kubernetes。
不只軟體大廠擁抱，硬體巨頭Dell、思科也都加入CNCF，就是看上Kubernetes，要讓自家產品也能整合新的容器管理調度平臺。首先是Dell在今年3月成為白金會員，也與社群密切合作，想要加強Kubernetes對於外部儲存設備的支援；思科除了是CNCF白金會員，近日還與Google盟，讓思科私有雲環境可以介接Google公有雲環境，並且使用Kubernetes。
甚至，看準容器基礎架構市場的商軟和雲端業者，大力開始將Kubernetes納入自家容器布局。像是提供公有雲服務的微軟、Google、IBM及甲骨文，微軟在Azure上釋出容器服務AKS，除了能在公雲執行調度任務，也可以靠Azure Stack在私有環境執行容器調度；Google的容器引擎GKE，除了能較快速支援新版Kubernetes，還能GCP上的大數據分析工具、無伺服器應用結合；IBM則將Kubernetes視作次世代的PaaS平臺，同步在公有、私有容器雲平臺支援；過去步調較緩慢的甲骨文，在今年也即急起直追，鎖定容器原生應用程式開發平臺。
而布局較早的紅帽，則是以PaaS平臺OpenShift為核心，將其定位為企業級Kubernetes平臺。而虛擬化龍頭VMware則在今年VMworld上跨出了關鍵一步，正式押寶Kubernetes，與Pivotal及Google聯手推出Pivotal容器服務，與自家SDDC架構結合。
面對Kubernetes、容器技術的熱潮，臺灣VMware副總經理暨技術長吳子強表示：「根據VMware執行長Pat Gelsinger的策略，現階段所有的產品線都必須與容器靠攏」，像是搭配NSX、vSAN等虛擬化解決方案，加強Kubernetes環境的自動化程度。
而臺灣紅帽資深解決方案架構師彭信忠表示，現今Kubernetes的功能已趨於成熟，不再只是開發者使用的工具，除了網路新創公司之外，國外也有金融業、汽車業者開始導入；臺灣IBM雲端事業部資深雲端架構師吳志忠則觀察，Kubernetes不能只能鎖定容器調度功能，還必須與其他生態系統介接，透過這個調度引擎，執行大數據分析、深度學習等運算任務。
Solomon Hykes當時這句「現在沒有人關心容器技術了，應用程式才要緊」點出了大規模應用叢集需求的崛起，但，Kubernetes取代了Docker，成了容器技術的領頭羊，容器技術發展重心已經開始轉移，軟硬體業者的支援，也帶動以應用系統為中心的容器商業軟體成熟，企業IT架構也多了一個更成熟的商用新平臺，新的容器競爭時代，正式揭開序幕。
",https://www.ithome.com.tw/news/118121,"新聞,Kubernetes,K8s"
118220,16,2017-11-17,【Kubernetes實戰經驗：91APP新零售平臺】新興系統要先容器化，再靠K8s實現IT微服務架構,儘管多數是.NET系統，91APP也積極擁抱輕量級容器技術，透過鄉村包圍城市的策略，新興系統先擁抱容器，下一步想轉型更高彈性的微服務架構，關鍵就是導入Kubernetes來管理複雜的容器叢集," 臺灣知名的新零售平臺供應商91APP，已有超過1萬家品牌企業，透過91APP平臺經營自家電商生意。為了承載旗下企業用戶整併線上、線下的零售業務擴充需求，成立不久，91APP很快就將自家平臺搬上AWS公有雲，近年更納入跨雲架構，也將部份新服務分散部署到Google雲端平臺GCP上執行，還利用Kubernetes（K8s）為基礎的Google容器引擎GKE，調度、執行新開發的容器應用程式。
91APP踏上容器化的旅程並不久，成立初期，該公司的應用程式都是以.NET框架開發，並且在微軟環境執行。但是，近年在微軟大力擁抱容器技術、走向開放的策略，不只推出了自家的Windows容器技術，重要產品如SQL Server、.NET核心也都可以在Linux環境下執行。
連微軟都開始大力支援，可見容器未來必然成為重要的IT技術。因此，91APP研發處系統架構部技術總監劉峰全也表示：「容器這門技術發展方向變得更加明朗，我們決定開始投資容器技術。」不過91APP是鎖定了以Linux為基礎的Docker容器，並且開始使用Linux、Node.js等平臺著手開發新系統。在2016年Q3後，該公司未來系統藍圖的規畫，已經將容器化、微服務轉型視為重要的轉型策略。
新興系統優先擁抱容器技術
91APP的容器化過程中，採取「鄉村包圍城市」的漸進策略，核心系統不先進行大規模修正，而是先從新興開發的應用程式切入，導入容器技術。林大維認為，這樣逐步加溫的做法，可以免除架構一次大更動的風險，「承受合理的風險，同時擁抱新技術往前進。」
雖然多半正式環境下還是以VM為主力，但是現階段部分系統的開發、測試環境，已經開始導入Docker容器。林大維舉例，現階段研發、產品團隊總共有140人，有許多專案同步進行開發，如果每個環境都得要手動建置，將會浪費許多時間。而Docker其一優點，就是開發者可靠映像檔建置統一環境，除了加強產品開發、測試到上線環境的一致性，除錯工作也因此變得更為順利。
微服務架構要以容器技術為基礎
目前91APP總共有兩個重要服務使用容器為基礎架構，並且利用Kubernetes做為調度引擎，而這兩個服務的共通點在於，不時會產生爆量事件，「因此很適合使用容器技術。」林大維表示，首先是該公司自建的使用者行為追蹤服務，其功能與Google Analytics類似，可用於分析其平臺上使用者的行為。
第二個服務則是通知中心，整合EDM、簡訊以及App通知，作為該公司與消費者的溝通管道，「碰上促銷或是特定節日時，該服務也會產生相當大的使用流量。」
而導入容器技術只是第一步，91APP的更長遠的目標是引入微服務架構。若使用VM打包這些應用程式，將使得部署成本變得非常可觀。劉峰全表示，因此要以先前導入的容器技術為基礎，憑藉其快速開啟、部署的特性，實現微服務架構，「容器與微服務是相輔相成的。」除此之外，容器技術讓跨雲IT架構變得可能。林大維表示，每個公有雲都有各自特色，但相比容器技術，VM與底層架構的相依程度更高，較容易被廠商鎖死。但是，微服務架構會導致應用程式部署變得更為複雜，因此管理這些龐大規模的容器叢集的工作，就得靠容器調度工具完成。劉峰全表示，過去他亦有研究DC/OS、Swarm相關的解決方案，各家也都有優點，像是Swarm在本地開發環境不會占用太多硬體資源，若開發者要在本地環境使用Kubernetes，還得安裝Kubernetes本機版Minikube。
GKE除容器調度外，還能整合GCP其他服務
而劉峰全認為，比較在AWS、GCP使用Kubernetes的經驗，在GCP上的使用體驗更為友善。首先，Google以Kubernetes開發的容器引擎GKE，除了提供方便開發者操作的命令程式介面外，「只需要幾秒鐘就能完成Kubernetes叢集的建置」，不僅如此，劉峰全表示，GKE還可以整合其他GCP上的服務，例如提供應用程式、Log監控的Stackdriver，確保容器應用程式的運作正常。再者，想切入大數據應用，GCP亦有雲端資料倉儲Big Query，或是支援串流、批次資料處理的Dataflow。
相比還未提供正式Kubernetes服務的AWS，劉峰全認為，在此環境Kubernetes叢集的建置工作就較為困難。過去是使用容器平臺Rancher管理主機上的容器。不過他表示，過去使用Rancher經常發生容器叢集故障的問題，直到後來使用Kubernetes安裝工具Kops，才讓建置過程變得較為順利。
而使用Kubernetes其中的一個挑戰，就是其改版速度相當快，每年至少會釋出3到4個大版本。劉峰全表示，目前91APP的Kubernetes已經更新至1.7.2版本，而在GCP環境中，GKE也會自動將Master節點上運作的Kubernetes更新到最新版，而使用者可以依據需求，決定要否更新其餘的Worker節點。
至於AWS環境，目前得仰賴系統管理員手動更新。為了避免更新造成系統不穩定，目前91APP將測試環境叢集獨立，並且整併正式環境、半正式環境。當測試環境更新並未發生異常，才會將新版Kubernetes導入正式環境。
引入新技術也會帶來組織面的變革
而導入容器、Kubernetes的影響，不單只改變了系統架構，同時也對91APP資訊團隊產生了影響。林大維笑著說，91APP始終抱持「自己的程式碼，自己維運」的想法，該精神也與近年的火紅的DevOps不謀而合，意味工程師在開發程式時，就得設法改善程式碼品質，減輕後續維運團隊的壓力。
劉峰全解釋，Kubernetes所帶來的變革，可從開發、維運兩個層面探討。首先，使用者可以透過Kubernetes定義系統元件的相依性，在部署組態設定中，撰寫甲元件、乙元件間的相依關性。因此，雖然導入微服務架構會提高系統複雜度，「但是開發者可利用Kubernetes的組態設定檔案，掌握各元件間的關係。」此外，過去重要服務一個禮拜僅能釋出一次更新，但是現在結合容器技術及Kubernetes，讓CI、CD自動化程度提高，「一天內能進行多次的部署。」
而在維運工作帶來的改變，「Kubernetes也能實現基礎架構程式化（Infrastructure as Code）」，他解釋，因為每一次部署都必須撰寫組態設定檔，因此基礎架構可以如程式碼開發般進行版本控制，當系統故障時，開發者也比較容易追蹤問題的起因。
引入Docker及Kubernetes改革自家IT架構，從單體邁向微服務
同時，IT架構走向容器化時，也逼得91APP開發團隊得要檢視過去的IT架構設計，是否能符合現代應用程式的思維。林大維表示，在傳統單套式架構中，許多企業也不重視系統組態管理，「只要系統能運作，僅更新程式碼，卻不重視系統組態。」但是在使用Docker、Kubernetes時，開發者都必須明確定義應用程式執行所需要的環境組態，也因此，企業必須顛覆過去程式開發的思維，讓應用程式具備水平擴充性，「逐步讓單體架構分解。」林大維笑著說，組態系統管理也是91APP的重要計畫，未來開發者除了交付程式碼外，還得同時交付組態設定檔，必須為自己開發的程式碼與組態負責，「容器化是我們的共識，而這些新技術將會讓91APP持續演進既有的IT架構。」
",https://www.ithome.com.tw/news/118220,"新聞,91 APP,Kubernates,K8s,微服務架構"
118153,16,2017-11-15,【深度剖析企業級K8s平臺】IBM Cloud Private以K8s為調度核心，主攻私有容器雲平臺市場,IBM不單是將Kubernetes視為容器調度工具，而是讓Kubernetes成為PaaS管理平臺的核心，要提供企業一套可以快速自建的私有容器雲平臺," IBM Cloud Private重點策略
1. 主打PaaS應用管理需求，強調快速自建的私有容器雲
2. 兼顧傳統IT需求，能同步管理容器及VM
上有AWS、GCP以及Azure，下有甲骨文競爭對手的IBM，在今年3月時宣布，正式在Bluemix容器服務上支援Kubernetes。目前這家公司支援Kubernetes的方式共有兩種。第一種是以公有雲平臺IBM Cloud Public的容器服務為基礎，支援容器調度功能。第二種則是在私有容器平臺IBM Cloud Private中，以Kubernetes為核心引擎，目前兩個平臺都已經支援至Kubernetes 1.7.3版。
而IBM調度工具架構的演進，總共可分為3階段。最初，IBM推出自家版本的Docker，並以Docker Swarm為基礎，自主開發了一套調度工具。第二階段中，則在單一平臺上同步整合Mesos及Kubernetes，使用Mesos管理系統資源，Kubernetes則專注在容器調度。而到了現今，則是全力押寶Kubernetes，透過它掌控容器調度、資源配置的任務。
公有雲平臺以Cloud Foundry為主要底層架構
現在IBM Cloud Public及IBM Cloud Private這兩個平臺上皆支援Kubernetes，但是平臺特色的定位，也影響該門技術的支援程度及實作功能。
目前IBM Cloud Public是以開源PaaS Cloud Foundry為基礎，許多服務仍要靠既有Buildpack，打包應用程式執行所需要的組態設定、環境。而容器調度任務則主要靠Cloud Foundry的Diego框架完成。以PaaS為基礎的優點在於，開發者只須關注程式碼開發，不須介入底層Docker容器的運作，但是其平臺僵固性也更高。
私有容器平臺用Kubernetes為核心，還能搭配其他開源工具
雖然目前IBM Cloud Public、IBM Cloud Private皆能作為容器執行平臺，但私有環境的目標是讓Kubernetes跟Cloud Foundry並存。
IBM Cloud Private雖支援Cloud Foundry，不過底層則是選擇Kubernetes為核心，整合了開源網路虛擬化工具Calico、Kubernetes打包工具Helm，以及IBM自家的行動應用程式管理工具Application Center。
而IBM Cloud Private除了有Kubernetes作為調度核心外，還得提供其他相關容器功能。例如，在此平臺也有提供容器漏洞掃描功能，想要部署在該平臺運作的容器，均得通過此程序，藉此確保既有Kubernetes環境中執行的容器不會受到影響。
以私有容器平臺而言，IBM不單把Kubernetes視為容器調度工具，如果將平臺上的Docker容器視為各自獨立執行的服務，此時Kubernetes便可以被視作PaaS，而IBM Cloud Private則成為企業內部的私有容器雲管理平臺。
以容器為基礎發展，也為企業使用者帶來更多自由度，例如，可以自由加入開源工具如Elasticsearch、Kibana或是Grafana等。
此外，現階段IBM Cloud Private也已經整合微服務管理工具Istio，主要用途為補強Kubernetes的網路功能。Istio現階段在此平臺主要滿足兩大需求。第一需求是支援路由功能，透過此工具管理、追蹤出入叢集的網路流量。而第二個功能則是資安監控功能，根據系統管理所定義的網路管理政策，限制系統服務的存取權限。
Istio團隊表示，想要開發穩定、鬆散耦合，又能進入正式環境的微服務相當具有挑戰性。隨著單體式（Monolithic）應用程式分解成微服務，軟體團隊必須考慮分散式系統如何整合各種服務，像是服務搜尋、負載平衡、容錯、監控。
而Istio提供的是「服務網」（Service Mesh）的概念，讓服務及網路之間擁有透明的架構層，提供營運商所需的控制能力，開發人員也可以專注開發程式碼，讓營運商脫離應用程式的功能開發與發布過程。而Istio的角色即是系統化地嵌入代理人，將各種不同的微服務變成單一的整合服務網路。
而近日所推出的0.2版，除了加強穩定性、表現效能之外，也加入一些企業所需的支援，像是TLS認證機制、TCP服務。同時，Istio開始支援多種開源工具，像是HashiCorp的叢集管理調度工具Nomad、服務探查工具Consul，還有Netflix開源釋出的雲端負載平衡工具Eureka。
Kubernetes操作介面仍有可繼續加強，增進易用性
不過，現在許多企業系統仍以VM環境為主力，還不能一次到位地邁入容器環境。因此，IBM以基礎架構管理工具Terraform，開發了IBM Cloud Automation Manager，即使只有Kubernetes，也能同步管理容器及VM。
目前Kubernetes最新的版本為1.8，而IBM已經開始支援1.7.3版，支援步調算是快。不過部分既有服務、產品還未能與容器平臺進行深度整合。例如，現在企業用戶使用Kubernetes必須透過傳統的命令程式介面操作，對部分非工程背景使用者可能較不便。而IBM現在也已經計畫，要推出更友善的Kubernetes操作介面。
同時，IBM也希望把Kubernetes變成新一代的PaaS平臺，並且將產品、服務容器化，透過Docker映像檔形式提供並收取授權費用，也能減低企業部署、安裝的難度。
",https://www.ithome.com.tw/news/118153,"新聞,IBM Cloud Private,K8s"
118151,17,2017-11-15,【深度剖析企業級K8s服務】微軟Azure Container Service多方管道支援K8s，雙吃Windows和Linux企業需求,在Kubernetes 1.5版同時支援調度Linux容器及Windows容器後，公有雲Azure可以一起通吃Linux及微軟環境的開發者," 微軟Azure Container Service重點策略
1. 單一平臺可管理Windows和Linux的容器叢集
2. 開發工具深度整合容器部署，挾開發工具生態系優勢搶攻企業市場
在微軟執行長Satya Nadella上任之後，近年微軟無論是擁抱Linux或是走向開源的可說成效有目共睹，其公有雲平臺Azure也依循著微軟擬定的戰略，一併支援Linux及Windows容器，根據微軟統計，在Azure上使用Linux容器才是主流。
起初，Azure容器服務最先整合的調度工具是Docker Swarm，後來除了整併Mesosphere的DC/OS外，今年2月也正式支援了Kubernetes，目前已經更新至Kubernetes 1.8.1版。在2016年7月加入微軟的Kubernetes共同創辦人Brendan Burns，也背負帶領Azure容器服務團隊的重任，找來這名大將，對微軟無疑是打上了一劑強心針。
現在Azure同時提供建置容器、VM基礎架構的服務，不過建置起這些基礎架構僅是第一步，後面的管理工作才是真的挑戰，像是開啟、關閉容器，或是隨需進行水平擴充。同時，容器環境的管理也要拉高自動化程度，讓開發者可透過工具調整基礎架構，不須介入底層機器的管理。因此，Azure容器服務的目的，便是方便企業架設容器應用程式運作的環境，透過容器調度工具，便可以控制容器叢集。除了容器服務外，企業還可以在公有雲環境的Azure Container Instances，或是混合雲解決方案Azure Stack環境使用Kubernetes，執行容器調度的工作。
另外，微軟也在GitHub上開源釋出的Azure容器服務引擎（ACS Engine），讓企業自行建立私有的容器服務，不過，這個引擎預設自動產生符合Azure容器環境的配置檔案，最大可以支援到1,200個節點的叢集規模，日後可以將自家容器環境直接轉移到Azure上部署，但沒有提供其他雲端供應商的環境配置範本，使用者得自行手動客製，這也是微軟用來吸引那群還不想上雲，又想試用容器的企業，讓他們成為日後Azure的顧客的綁定手法。
不過，現今微軟內部開發團隊也不閉門造車，在開發Azure容器服務引擎時，也在GitHub上與多方開源社群討論，顛覆過往內部主導專案進行方向的作法，扭轉為以社群、使用者為主要驅力。
Azure環境讓開發工具與容器大幅整合，開發容器應用更方便
而微軟除了Azure可以透過多元環境支援Kubernetes的優勢之外，其開發工具廣大的使用者，或是既有IT架構與微軟深入整合的企業，也都是這家公司可以搶占的市場。
例如，Linux作業系統廠商Canonical在9月時與微軟合作，為Azure環境推出專用版本的Ubuntu Kernel，可支援最新版本的Hyper-V。開發工具Visual Studio Code也內建了Docker工具列，開發者可以在統一環境內開發，不須切換至終端機環境，就可完成Docker容器的建置、部署作業。
Windows環境強力支援Linux，讓Hyper-V也能跑Linux容器
而近年則有兩個關鍵事件，讓微軟平臺與Kubernetes的整合程度加分許多。首先，去年釋出的Kubernetes 1.5版，居然可以一併調度Linux容器以及Windows Server容器，還能相容Windows Server 2016平臺。再者，今年4月的DockerCon中，微軟也宣布，使用者可以在Hyper-V環境，利用Windows Server中原生執行Linux容器。如此，不僅弭平微軟環境與容器技術的隔閡、擴大Windows Server的應用範圍，也替依賴微軟環境的企業做了解套，降低導入Kubernetes的難度。
",https://www.ithome.com.tw/news/118151,"新聞,Azure Container Service,K8s"
118150,17,2017-11-15,【深度剖析企業級K8s服務】Google雲端平臺容器引擎GKE總是最快支援新版K8s，要讓海量容器管理更簡單,企業在GCP上使用Kubernetes服務，除了可以快速嘗鮮Kubernetes新功能，還可以跟GCP上的大數據分析工具、無伺服器應用結合," Google雲端平臺容器引擎GKE重點策略
1.　主導Kubernetes平臺技術發展，搶先卡位容器市場至高點
2.　以應用叢集為管理核心，簡化大量容器節點管理的複雜度
早在10前就開始使用容器技術的Google，以原先自家內用的容器調度工具Borg為基礎，重新在2014年打造了一個開源的容器調度平臺，這就是Kubernetes專案的起源。Google也是率先將容器服務推上雲端的公有雲供應商，早在2014年11月時，就在自家公有雲平臺GCP上，以Kubernetes為核心調度引擎，推出了Google容器引擎（Google Container Engine，GKE）測試版，支援Docker容器的調度工作，2015年時，正式上線。
在Google開出第一槍，為搶占Docker容器調度的市場需求，各廠商也紛以各種形式支援Kubernetes，像是很早開始押寶的紅帽，在OpenShift 3.0版就已經完成整併。而微軟則在Azure上推行容器服務，除Kubernetes外，也相容DC/OS及Swarm。而今年則連IBM、甲骨文也在旗下雲端服務支援Kubernetes。這波熱潮，或許也是Google一開始未能料想的火紅。
Kubernetes自動化程度再升級，連節點修復都能自動化
雖然各家廠商支援Kubernetes的特色都有所差異，不過仍不脫離以此工具的核心調度功能為主，而已Kubernetes為核心的Google容器引擎也不例外。在9月底時，Google也宣布，已經開始支援部分企業用戶導入最新的Kubernetes 1.8版本。
目前運作在Google雲端平臺的GKE，主要鎖定了Docker容器調度需求，開發者可以直接宣告容器環境的組態，在JSON設定檔中，宣告CPU、記憶體以及容器複本數量。完成宣告後，Google容器引擎便會根據該組態設定，建置出容器基礎架構。而因應容器時代，Google也有推出自家的容器作業系統Container-Optimized OS，不僅內建了Docker runtime，也預先安裝Kubernetes執行所需要的元件。
在近日，Google也加強了Google容器引擎的自動化功能。首先是節點自我修復功能，目前是Beta版本。利用此功能，Google容器引擎可以透過Kubernetes內建的節點探測功能，定期檢查叢集內節點的運作狀況，若發現異常狀況，Google容器引擎便會啟動修復程序。第二個自動化功能則是自動升級功能，現在已經是正式功能，系統可以自動將Kubernetes叢集升級至最新版。
而想要在同一叢集內，建立出異質組態設定虛擬機，也可以利用Google所推出節點池（node pools）功能，在架設叢集時，單一叢集內可以使用不同規格（如CPU數、記憶體容量不同）的虛擬機器。因此，叢集內的節點，可以擁有不一樣的硬體規格，彈性滿足企業不同的需求。
支援SAP、微軟等商用大廠解決方案，增強GCP豐富度
除容器引擎外，現階段GCP支援容器功能為主的產品，包含了私密的Google容器儲存庫，以及加強CI／CD自動化流程的Google容器建置工具。
而Google的使用者，在GCP平臺上，同時也能根據自己需求，介接Google公有雲服務上其他不同種類型的服務，滿足不同的容器應用情境。例如，GCP平臺上所提供的紀錄監控功能，就包含了Stackdriver Logging、Stackdriver Monitoring，監控容器應用程式的運作狀況。而先搶先一步開始使用無伺服器架構的企業，現在也有Beta版本的Google Cloud Functions。
不僅如此，Google GCP上也支援了其他大廠的商用軟體解決方案。例如，Google也與SAP合作，現在GCP上可以原生使用SAP HAHA以及SAP商用軟體套件。同時，GCP也跨平臺支援微軟常見的商用軟體，包含SQL Server、Windows Sever及PowerShell等。
",https://www.ithome.com.tw/news/118150,"新聞,K8s,GKE"
117641,17,2017-10-23,IT活動報1【1023~1103】：南北週末兩大活動，中國MySQL高手臺北開講，南臺灣最大科技活動高雄登場,10月最後一週，在臺灣南北各有一場精彩的IT活動，週五在臺北先登場的是中國MySQL專家齊聚的2017開源資料庫活動，緊接著週六在高雄展開的是南臺灣最大規模的科技研討會MOPCON 2017。," 10月最後一週，在臺灣南北各有一場精彩的IT活動，週五在臺北先登場的是中國MySQL專家齊聚的2017開源資料庫活動，緊接著週六在高雄展開的是南臺灣最大規模的科技研討會MOPCON 2017。
焦點活動1:2017 開源資料庫「高峰匯」之未來趨勢 (10/27-28)
12位來自阿里雲、騰訊、京東、網易、螞蟻金服、去哪兒網和Grab（亞洲版的Uber）等MySQL資料庫或其他開源資料庫專家分享第一線資料庫應用和維運的經驗，也有MySQL核心開發者來揭露MySQL未來產品藍圖。
其中有幾場中國金融或電商平臺發展實戰經驗分享，如京東金融MySQL維運資深DBA潘娟則帶來資料庫自動維運的新作法，他稱為智能維運。騰訊金融支付部副總監姜承堯則是要分享財付通平臺上的MySQL資料庫叢集管理，如何管理一套可以用來支撐微信支付、手Q支付、紅包轉帳等超大規模的叢集。而螞蟻資料庫資深專家程哲橋則要介紹螞蟻金服自家服務平臺化轉型的過程中，如何因應各項維運異常處理。
另外也有多個大規模基礎架構維運的實戰經驗，如360基礎架構組技術經理陳宗志則是要介紹一套超大容量redis的解方pika，以及360內部如何部署到一套1000節點的資料庫叢集上。Grab工程師則分享Elasticsearch（ES）吳煒彬如何做到每天上億次查詢筆筆都毫秒完成的關鍵。阿里雲RDS團隊專家彭力勛揭露阿里雲下一代資料庫PolarDB架構設計關鍵，騰訊遊戲DBA分享如何用MariaDB解決遊戲特定場景應用等。
活動簡介：時間：2017.10/27~10/28（五、六）活動名稱：2017 開源資料庫「高峰匯」之未來趨勢費用：單日1000元，雙日1800元地點：台北市中正區濟南路一段321號 (臺北商業大學 承曦樓十樓國際會議中心)報名網址：https://www.accupass.com/event/1708250301346464572170
焦點活動2：南臺灣最大科技活動MOPCON（10/28-29）
已經連續舉辦6年的MOPCON，是南臺灣最大規模的千人科技聚會，今年由11個軟體社群聯合主辦，可說是不輸臺北開源人年會規模的南部開源社群年度盛會，也是南臺灣軟體聚落最大聚會。2012年從第一屆從行動科技應用相關議題切入，到今年不只技術、產品開發、軟硬整合應用到服務營運，兩天三軌議程超過30堂的演講，還涵蓋了不少熱門議題如機器學習、區塊鏈、IOT、VR/AR 到使用者經驗設計等議題。
美國紐約長島大學數位遊戲設計系的系主任將分享如何用軟體和遊戲建構社交經驗，開源社群大大jserv也將分享如何用區塊鏈技術打造數位證書的經驗，Google臺灣區雲端業務團隊負責人田哲禹則將分享Google尺度的IT營運經驗。翟神也連續三年南下分享，今年要分享和沛5年儲存研發成果Tera，如何將雲端儲存整合到Linux電腦電腦，將本地儲容量像雲端一樣大，又結合AI來優化快取的成果。
除此之外，既然是社群大聚會，多元化的交流活動也是MOPCON特色之一，包括兩天同步進行的Unconference，現在已經有AWS Serverless、Growth Hacker、Webduino、SUSI.AI、IoT加上電腦視覺的應用等自由議程，你也可以自己報名來分享一堂。
活動簡介：時間：2017.10/28~10/29（六、日）活動名稱：2017 行動科技年會MOPCON費用：一般票600元地點：高雄國際會議廳TCCK（高雄市鹽埕區中正四路274號）報名網址：https://mopcon.org/2017/
 
11月IT活動預告
●11/8（三）【機器學習】演講：機器人如何聽懂人說話  
曾以「一天搞懂深度學習」大受好評的台灣大學電機系助理教授李宏毅，要來告訴大家機器學習技術中的語音理解技術。這也是機器學習中，除了電腦視覺之外，另一個重要的AI電腦能力。附上李老師的「一天搞懂深度學習」300頁投影片連結
報名網址：https://learning.ithome.com.tw/course/Sm7So6Yjw地點：松山文創園區 製菸工廠- 美國創新中心 多功能教室 (台北市信義區光復南路133號)
●11/9-12（五～日）【AI】【資料科學】2017臺灣人工智慧年會+臺灣資料科學年會
從2014年的臺灣資料科學愛好者年會，到現在的資料科學年會，到了第四年，除了資料科學，還進一步催生了人工智慧年會。前兩天11/9、10是臺灣人工智慧年會，這是今年最大規模人工智慧研討會，集結了63位國內外、學界、業界專家。第二天開場演講是AlphaGo 首席工程師黃士傑將回臺分享AlphaGo Zero的精彩故事。這是新一代的AlphaGo Zero，只花3天就打敗全球最強的AI棋手AlphaGo。而後兩天，11/11-12則是臺灣資料科學年會，同樣也有68位學界和產業界專家來分享。
報名網址：http://datasci.tw/signup/地點：臺北南港 中央研究院人文社會科學館
●11/22（三）【區塊鏈】演講：分散式帳本／區塊鏈的具體應用
主講者SSX南星創速器 共同創辦人朱宜振(朱拉面)是臺灣第一代的網路創業家，現在投入Fintech領域，也是臺灣最能把區塊鏈應用解釋透徹的專家之一。這一場將聚焦區塊鏈基本知識，以及物聯網應用。目前雖已額滿，但可留意有空名額將隨時釋出。
報名網址：https://learning.ithome.com.tw/course/587q1jlZP地點：松山文創園區 製菸工廠- 美國創新中心 多功能教室 (台北市信義區光復南路133號)
●11/23～24（四、五）【區塊鏈】2017區塊鏈愛好者大會
第一天公共區塊鏈應用為主，包括英國監理沙盒經驗、臺中區塊鏈應用、RegTech監理科技為主題，再延伸到四軌應用類議題，包括了內容存證Notary、金融科技Fintech、醫療照護 Healthcare和資產管理 Wallet等四大議題的分場分享。
第二天則有Hyperledger專案成員來臺分享最新進展，下午則是四軌基礎議題，包括了開發平台Platform、代幣應用Token、責信監管Regulation和學術調研Research的分場分享。
報名網址：http://seminars.tca.org.tw/D15n00197.aspx地點：集思北科大會議中心臺北市忠孝東路三段1號
講者招募情報：
1. iThome #Serverless Day 講者開Call囉！（10/30截止）
投稿網址：https://ithomeonline.typeform.com/to/E9m2Lj活動日期：12/07(四）
從虛擬機器到容器，下一個新的應用架構趨勢是Serverless，不是不用伺服器，而是新架構讓你站在雲端平臺的肩膀，不用再煩惱伺服器端的維運，甚至是VM或容器等基礎架構的維運，只要專注在實現業務邏輯和應用服務就好。可口可樂就是用Serverless架構，來支援自動販賣機後端的雲端系統，取代原有的AWS EC2虛擬機器，在每月3千萬次呼叫的初期低用量下，省下了65%的成本。相關報導可口可樂的Serverless之旅 https://www.ithome.com.tw/news/112431
iThome也將在今年首度在臺灣舉辦Serverless Day，來介紹這股超越VM和容器的新一代架構風潮，也廣邀臺灣Serverless專家上台分享。
我們提供2種舞台，歡迎您參與投稿：
（1）40分鐘演說（講酬$3,600，含全日入場）
（2）25分鐘演說（講酬$2,500，含全日入場）
2.全臺規模最大資安盛會：2018年臺灣資安大會招募各主題資安講師（11/17截止）
投稿網址：https://seminar.ithome.com.tw/live/cfs_cybersec/index.html活動日期：2018年3/14～15
iTHome已經連續舉辦3年的臺灣資安大會，超過5千人報名，100位講師登台。如果你有最新的資安技術研究、最佳資安實務作法、最精彩的資安事件分析、尚未公布的攻擊手法或漏洞資訊，或者你可以帶來深度的資安知識，讓聽眾對於資訊安全有更深刻的領悟，都可以投稿。有數十場演講場次，公開徵求講者。
最夯投影片分享
9月4～6日在臺灣首次舉辦的DevOpsDays活動順利落幕，你若沒有趕上這一次全臺DevOps經驗大交流，也沒關係，可釋出的講者投影片，已經公布在活動官網了，還有包括線上共筆和多篇精彩的心得分享。
DevOpsDay臺北 精彩簡報: https://devopsdays.tw/agenda.html
DavOpsDay臺北各堂重點筆記共筆網址Day1共筆   Day2共筆
 
",https://www.ithome.com.tw/news/117641,"新聞,IT活動報,MySQL,行動應用,人工智慧,資料科學,DevOps"
117322,17,2017-10-10,Chef推出自動化部建服務Habitat Builder，一鍵就能部署雲端原生應用,Habitat Builder是一個軟體即服務SaaS平台，可協助開發人員建置與部署容器應用程式至不同的雲端或是容器調度平台," 老牌應用程式組態工具Chef在本周一（10/9）發表了開源自動化派送專案Habitat的商用版Habitat Builder服務，這是一項代管服務，能夠簡化開發人員建置及部署應用程式的流程。
Habitat開源專案主要提供各種工具以自動打包程式並部署於不同的平台上，而Habitat Builder則是一個軟體即服務（Software as a Service，SaaS）平台，可協助開發人員建置與部署容器應用程式至不同的雲端或是容器調度平台。
以Habitat打包的程式沒有特定的輸出格式或運作環境，是在部署時才需要決定，它亦提供各種熱門程式語言的支架，如Node.js、Java與Ruby On Rails等，可自動偵測所使用的語言並完成應用程式的建置，部署用的成品即已包含程式、函式庫，及適用於雲端或傳統架構的元件。
IDC專案副總裁Stephen Elliot表示，雖然容器於可攜式上的好處已普遍被認同，但應用程式周期缺乏一致的包裝及調度卻限制了部署的規模，拆離包裝、部署與成品則能在一定的軟體品質與遞交速度下完成業務目標。
在雲端操作的Habitat Builder有三大基本服務，分別是建置服務、成品商店及應用程式監督，其中的建置服務帶來致的包裝與建置能力；成品商店則有公共與私有倉庫可用來存放已可部署的成品版本，且支援TAR、Docker、CloudFoundry或Kubernetes；應用程式監督主要控管運作環境的生命周期、配置更新、叢集拓樸及更新策略等。
Chef行銷副總裁Marc Holmes指出，縱使市場上有許多很棒的工具可打造容器程式，但現代的應用程式團隊還需要在不同的架構上包裝及部署程式，Habitat Builder供應了一致的包裝能力，也可因應不同的部署對象，藉由明確的分工將讓團隊關係更為緊密。
Habitat Builder目前處於免費預覽階段，價格稍後才會宣布。
",https://www.ithome.com.tw/news/117322,"新聞,Habitat,Chef,容器調度,自動化部署,DevOps"
117318,17,2017-10-10,GitLab增資2000萬美元，Google創投入列,GitLab號稱為全球最大的企業程式碼代管服務，全球總計有超過10萬家組織藉由GitLab自行代管，且有67%的開發人員偏好採用GitLab的就地部署解決方案。," 採用Git進行版本控制的程式碼代管業者GitLab周一（10/9）宣布增資2000萬美元，且該輪增資是由Google創投（Google Ventures，GV）領軍，公司市值已是去年增資時的2倍。
外界經常將GitLab與GitHub相提並論，這兩大業者皆提供基於Git的程式碼代管服務，惟GitLab採用開源碼授權，免費提供公共及私有倉庫，而GitHub則是全球最大的開源碼代管服務，但必須付費使用私有倉庫。
此外，GitLab號稱為全球最大的企業程式碼代管服務，全球總計有超過10萬家組織藉由GitLab自行代管，且有67%的開發人員偏好採用GitLab的就地部署解決方案。
GitLab表示，全球的軟體定義趨勢，再加上開發人員的角色從單純的開發轉至開發暨維運（DevOps），他們需要可加速工作流程及簡化開發程序的各種工具。因此，GitLab將利用新資金來推動DevOps世界，在其他產品專注於讓開發與維運互動時，GitLab將打造全球第一個整合開發與維運的產品，同時計畫針對包裝、發行、配置與監控軟體添增新功能。
GitLab周一也宣布WordPress創辦人Matt Mullenweg將加入該公司的董事會，打算協助GitLab達到與同屬開源專案的WordPress一樣的成就。
",https://www.ithome.com.tw/news/117318,"新聞,DevOps,GitLab,Git,Google Ventures"
117251,17,2017-10-03,跟進企業級容器服務市場，甲骨文發表容器原生程式開發平台,該平台的兩個基礎元件為Oracle Container Engine及Oracle Container Registry Service，前者為Kubernetes容器調度管理服務，後者則是Docker儲存庫服務," 甲骨文（Oracle）於周一（10/2）發表了容器原生程式開發平台—Oracle Container Native Application Development Platform，以協助開發人員建置、部署與操作基於容器的微服務及無伺服器應用。
該平台的兩個基礎元件為Oracle Container Engine及Oracle Container Registry Service，前者為Kubernetes容器調度管理服務，後者則是Docker儲存庫服務。
Kubernetes現為全球最受歡迎的容器調度管理工具，根據調查，目前容器部署的前五大難題依序是儲存、安全、網路、複雜度與調度解決方案的選擇，而Oracle Container Engine即是整合了標準版Kubernetes、控制、安全與效能的Kubernetes服務。
新的容器儲存庫服務相容於Docker v2 API，提供私人儲存服務，且與Oracle Container Pipelines及Container Engine緊密結合，以提供端對端的容器生命周期管理。它允許使用者檢視儲存庫中的映像檔，或是於建置流程中使用這些映像檔，亦能直接利用傳統的Docker CLI來連結儲存庫。
",https://www.ithome.com.tw/news/117251,"新聞,甲骨文,容器,Container,Kubernetes,OCE"
116650,17,2017-09-05,臺灣首場全球性DevOpsDays大會開跑,為推動DevOps這波技術與文化的轉型運動，全球性的DevOpsDays技術系列盛會，今日（9/5）假國立臺灣大學社會科學院大樓舉行，現場邀集多位該領域的技術專家，吸引將近500位臺灣軟體開發人員參與。," 在臺舉辦的DevOpsDays Taipei大會，今日（9/5）正式登場，首度舉辦即吸引了近500位臺灣軟體開發與維運人員共襄盛舉，現場並邀集超過20位領域的技術專家，分享第一手DevOps技術和經驗，共同推動新一波技術與文化的轉型運動。
此活動為全球性的技術系列盛會，由各地城市組織與發起，探討軟體開發、IT架構維運與兩者之間的議題，常見議程包括了自動化、測試、資訊安全與組織文化。 這是自2009年出現DevOps風潮以來，2015年臺灣首次舉辦大型DevOps研討會後，全球性的DevOpsDays大會終於也在今年臺灣落地發展，不僅象徵著與世界脈動接軌，也突顯臺灣在此開發維運變革的聲量。
在為期兩天的議程中，除了今日早上的3場主題演講之外，還有超過20場以上的講座，由致力於DevOps的各個高手輪番上陣，不僅讓現場聽眾可以更深入認識DevOps文化，對於敏捷開發觀念與實務也能有所收穫，針對自動化、持續整合的技術也有深入的分享，還能與導入DevOps的企業交流。
DevOps Taiwan創辦人陳正瑋表示，目前已知今年全球共有51場DevOpsDays的活動，這次臺灣也能置身其中，迎上這股潮流。對於還不夠了解DevOps的人，他表示，相較於一般技術研討會的差異，DevOps不只是跟技術有關的活動，如果回顧它的發展歷史，最初並不是想要完全解決技術的問題，當中還包括了溝通的問題、團隊協作的問題，以及組織文化的問題，要讓你的開發和維運團隊可以合作。他鼓勵所有投入DevOps的人，也提醒大家莫忘初衷。


在這次DevOpsDays的主題演講中，都是與會者相當感興趣的演說，包含像是擔任主題演講的Gogolook伺服器總監葉與敏捷教練葉秉哲，暢談他在GogoLook帶動轉型的三階段經驗分享，緊接著第二場主題演講是Odd-e敏捷教練陳仕傑，也分享了怎麼說服老闆接受敏捷，讓現場參與者聽得相當全神貫注。

同為舉辦方的iThome總編輯吳其勳也表示，這次在臺灣敏捷協會（Agile Community TW）、DevOps Taiwan與iThome共同聯手之下，終於讓DevOpsDays正式在臺灣落地發展。在這次活動中，包含臺灣DevOps領域技術專家，像是GogoLook伺服器總監與敏捷教練的葉秉哲，以及暱稱91的Odd-e敏捷教練陳仕傑 ，也邀請了包含身為Nutanix資深架構師劉征、華為技術軟體工程技術專家王磊，及多位中國DevOps高手組成的專家團，來分享他們的心法與經驗。
在多場主題演講與講座之外，現場也安排了許多活動，讓與會者可以盡情交流，像是場外也布置了能讓參與者吐露心聲的調查表，問題包括：目前導入DevOps的進展？你覺得DevOps與什麼有關？採用Agile的原因？目前使用的Agile practices？可以讓與會者知道在DevOps發展這條路上並不孤單，或是了解到，原來大家導入狀況都是這樣。在會後也將舉辦Party活動，讓與會者能有更多時間可以交流，在享受美食、聊天的同時，也許一場臨時的小型演說與討論也就此展開。
事實上，在昨日下午先行展開的Open Space（開放空間會議）活動，就已經吸引了250人參與，活動講師葉秉哲與現場的工作人員，都以「瘋狂」一詞來形容昨日場面，顯示大家對DevOps的參與熱度。在這個Open Space形式的交流活動中，每個人都能提出想討論的議題，各自形成討論小組，讓大家能夠一起交流實際的經驗並分享，在一問一答之間，不斷反思而得到更多啟發，這是臺灣大型技術研討會少見的交流形式。出乎預期的熱度，比前年DevOps 2015參加者更甚，也讓我們見識到，此全球熱門的IT議題，在臺灣也已經醞釀出不小的聲量，並持續獲得企業的關注。

由臺灣敏捷協會、DevOps Taiwan與iThome共同舉辦的臺灣首次DevOpsdays Taipei大會，今日（9/5）假國立臺灣大學社會科學院大樓舉行，一早就有近500位軟體開發人員湧入現場，不僅為首次活動拉抬不少聲勢，也看出大家對於DevOps的期望，實現開發和維運合而為一。

 
在多場主題演講與講座之外，DevOpsdays Taipei大會現場外面，也保留了議程前一日的Open Space活動成果，有興趣的人都能前往一探究竟。


 附帶一提的是，從全球DevOpsDays的時程來看，倫敦場也將於明日（9/6）開始進行，這股浪潮正持續在全球發酵。

",https://www.ithome.com.tw/news/116650,"新聞,DevOps,DevOpsDays"
116563,17,2017-09-01,老牌組態管理工具廠商Puppet進軍臺灣，11月在臺北開辦原廠教育訓練課程,過去在臺灣想要學習使用開源開發工具，大多得靠開發者自己上網閱讀使用文件、瀏覽國內外的軟體開發論壇，或在開源社群舉辦的活動上向大神請教。不過這一次，老牌組態管理工具廠商Puppet開始進軍臺灣，開始在亞洲國家如新加坡、香港、日本及臺灣等地巡迴開課," 過去在臺灣想要學習使用開源開發工具，大多得靠開發者自己上網閱讀使用文件、瀏覽國內外的軟體開發論壇，或在開源社群舉辦的活動上向大神請教。不過這一次，老牌組態管理工具廠商Puppet開始進軍臺灣，開始在亞洲國家如新加坡、香港、日本及臺灣等地巡迴開課，已經敲定在今年11月7日至9日舉辦，地點則是選在臺北的文化大學教育推廣部舉辦，報名價格為2,400美元（約臺幣7萬2千元。）
Puppet是由Puppet Labs在2005年所開發，是一款由Ruby所撰寫的開源組態管理軟體，使用Puppet自有的宣告式語言或是Ruby特定領域語言（Domain-Specific Language，DSL）進行開發，亦可在Linux、Unix及Windows等作業系統運作。
該軟體採用主從式架構，由Puppet客戶端及一個或多個Puppet主機所組成，而客戶端定期與Puppet主機連線，取得最新的組態設定。而使用者得以Ruby特定領域語言來撰寫組態樣板，稱之為宣告檔，而Puppet主機再依據宣告檔的內容，自動在客戶端部署一臺伺服器所需的軟體。
目前Puppet在財星100大企業中的採用率高達75％，也相容AWS、Azure、Google及IBM這四大公有雲廠商。除了傳統的VM環境外，Puppet亦支援容器技術Docker及容器調度工具Kubernetes。
Puppet亞太區客戶經理陳珮珊表示，無論是Windows、Linux環境中使用開源版本、企業版本的開發者，在Puppet舉辦的這3天課程，會由原廠工程師協助使用者了解該工具的實作方式，「了解Puppet程式碼並編寫自己的模組，學習如何透過Puppet管理基礎架構。」
在為期3天的課程中，學員會從安裝企業版Puppet為起點，開始學習如何撰寫基本的類別，以及開始從既有Puppet提供的模組為基礎，開發屬於自己的模組。之後講者也會結合相關的實際使用案例，「在完成課程之後，學員可以利用Puppet部署基本的系統組態配置。」Puppet表示。
而Puppet也表示，參與這門課程的學員，必須對命令程式列操作有基本的認識，例如Bash、PowerShell，同時也要對作業系統有基礎概念，如系統服務、程式碼打包以及組態設定文件等。
",https://www.ithome.com.tw/news/116563,"新聞,Puppet,組態管理工具,DevOps,Docker,IBM,AWS,Azure,google,容器技術"
116519,17,2017-08-30,加入發展企業級Kubernetes應用戰局，VMware與Pivotal、Google合推容器調度指揮服務,繼推出自家的容器平臺與執行環境，VMware今年與Pivotal、Google Cloud Platform聯手合作，推出Kubernetes容器調度指揮服務," 【美國拉斯維加斯現場報導】以提供伺服器虛擬化平臺與相關管理應用軟體著稱的VMware，近年來除了持續發展私有雲與混合雲應用之外，也積極投入雲端原生應用（Cloud Native Application）的支援，例如去年他們陸續推出了Photon Platform、vSphere Integrated Containers，跨入container的領域，而今年的VMworld用戶大會上，他們在這部份又有驚人之舉，那就是與同屬Dell Technologies集團的Pivotal，以及公有雲服務業者Google Cloud Platform共同合作，宣布推出名為Pivotal Container Service（PKS）的容器雲端服務，目的是提供 一套立即可用的Kubernetes容器調度指揮系統。

 

就運作架構而言，這套服務主要是基於VMware vSphere伺服器虛擬化平臺，以及Google Cloud Platform雲端服務而成，並持續相容於Google所發展和維護的叢集管理器和協調系統──Google Container Engine（GKE），至於PKS何時正式開始提供？VMware預計是在今年第四季，屆時除了雲端服務之外，VMware還會同時推出獨立的產品，可整合在Pivotal維護的平臺即服務（PaaS）軟體建置套件Cloud Foundry（PCF），以及VMware發展的軟體定義資料中心（SDDC）基礎架構。

 


 
",https://www.ithome.com.tw/news/116519,"新聞,Kubernetes,Container,VMware,Pivotal,GCP"
115208,17,2017-06-29,第一個社群版Docker新版正式登場，開始支援多階段部署,在新版本中，Docker最強調的新特色，就是支援多階段建置（Multi-stage builds）功能，其特色在於，在單一Dockerfile中，開發者可以在系統完成最終的建置過程前，自訂多階段的建置過程，像是進行編譯、設定系統組態," Docker在今年邁向商業化的步伐頻頻，首先在DockerCon高峰會上推出Moby專案跟LinuxKit，一舉為社群及企業畫上一道明確的界線，引起了社群高度不滿，認為Docker將共同開發的結果收割成自家商用產品。再者，Docker也換了新執行長，找來了SAP軟體老將Steve Singh坐上大位，前執行長Ben Golub則繼續留任董事會。
而在切分Docker商業版本及社群版後，近日Docker公司釋出了第一個全部由Moby專案建置的Docker社群版（Communtiy Edition，CE）17.06版。
在新版本中，Docker最強調的新特色，就是支援多階段建置（Multi-stage builds）功能，此功能雖然在今年4月時就已在DockerCon中發表，不過到了這個新版本才變成正式功能。Docker開發者社群總監Mano Marks而多階段建置的特色在於，在單一Dockerfile中，開發者可以在系統完成最終的建置過程前，自訂多階段的建置過程，像是進行編譯、設定系統組態。而此作法的優點在於，開發者可以利用容量較大的映像檔，完成前階段的建置工作，「但是最後完成的映像檔，只有運作應用程式所需要的檔案。」因此，靠這個新功能，Docker可以讓映像檔尺寸縮水。
在網路功能方面，在新版本中，也支援了Macvlan、IPVlan、橋接網路（Bridge）等網路架構。在實際應用中，Docker舉例，在Macvlan網路架構下，使用者首先可以針對Worker節點，訂定一套網路組態設定，而後續建置Manager節點的網路時，套用相同的組態設定。
再者新版本也加強Swarm mode的功能。首先是組態物件（Configuration Objects），在使用Swarm mode時，開發者可以利用Docker既有傳輸密碼、SSH私鑰或SSL憑證等數據的方式，遞送這些組態設定。
Docker也透過縮短憑證替換的周期，藉此加強使用上的安全。Docker解釋，swarm mode的公開金鑰基礎架構（PKI）內建在Docker中，「讓使用者能安全的將容器部署在調度系統」，同時，在swarm中的各節點間的通訊，都是仰賴TLS協定進行加密、封裝。相當仰賴憑證系統運作之下，在新版中，使用者可以自由設定憑證輪調的周期，「快至每小時更換一次。」
而Windows版、Mac版Docker也有了數項更新，例如新增GUI使用介面，開發者可以點選，執行移除檔案、重新設定，或是解除安裝。再者，現在使用者桌面板Docker的使用者，可以靠本地端新增的憑證，存取容器儲存庫，「包含Docker認證儲存庫，或是外部的開源儲存庫。」
",https://www.ithome.com.tw/news/115208,"新聞,Docker,Moby,容器技術,Container"
115074,17,2017-06-23,蔡學鏞：別再用物件導向，純雲架構最好改用函數式設計，5大架構秘訣公開,「你說的雲，是哪一種雲？」擁有多年雲端架構師經驗的北京全棧科技聯合創始人蔡學鏞表示，目前大家對雲的定義都不大一樣，企業要用要先釐清是哪一種雲，再加上傳統的程式設計方法不適合雲端平臺，他建議，程式設計師要結合架構師，找出新的程式設計方法。," 「你說的雲，是哪一種雲？」許多企業都認為將系統和資料上雲端有很多好處，不但可以節省成本又可以彈性調用資源，那為什麼不搬上雲端呢？曾在大陸擔任阿里巴巴支付寶、中國銀聯、創新工場、中國平安保險集團等公司的架構師，擁有多年雲端架構師經驗的北京全棧科技聯合創始人蔡學鏞表示，企業設計軟體時，是否考慮到雲端平臺的特性是相當重要的課題，他也指出，目前大家對雲端的定義都不大相同。
他認為，目前比較流行的是FaaS（Function as a Service）和BaaS（Backend as a Service），FaaS就是將程式拆成各自獨立的功能，各個程式之間互相沒有關聯，BaaS則是用Open API來用開發服務，像是用戶的身份認證，這兩種雲端設計方式可以讓程式更加自動化，減少程式運作維護的工作量，也讓程式設計師可以不用考量系統流量瞬間爆量的問題。
而現今有許多企業會在PaaS層上設計服務，但他提醒，若不是像用Spring Boot框架開發，很容易還是將程式和資料庫綁在一起，若將兩者綁在一起，則不適合雲端的平臺。
蔡學鏞將雲端程式設計分成Who、What和How，設計程式時分為兩種工程師，一種是程式設計師，負責設計與業務領域相關的功能，設計的方式則可用領域導向的方式（Domain Driven Design, DDD）的方式，他表示，DDD的設計方式一直都不太流行，但是最近因為流行微服務，而DDD又開始興起。
第二種工程師則是架構師，他說明，這個詞大約2000年才誕生，與網路的興起密不可分，架構師主要從事的不是功能的設計，而是以系統運作為導向的設計，包括系統的負載量、安全性等，他建議可用的設計方式是Patterns of Enterprise Application Architecture（PEAA）。
「我也開始在轉型！」蔡學鏞表示，由於雲端平臺的興起，將許多架構師的工作都可以方便快速地完成，且許多雲端架構的問題都有規則可循，架構師的價值也越來越式微，他也在思考自己要如何轉型，他認為，程式設計師要結合架構師的角色，找到新的程式設計方法。
由於現在系統需求快速且多變，蔡學鏞認為，過去傳統的程式設計方法已經不管用，主要是因為傳統的物件導向程式設計的結構有些問題，他指出，以前的程式設計都將業務和資料緊緊地綁在一起，但是綁在一起的作法並不適合雲端平臺，物件導向的觀念在敏捷開發也完全不適合。
他點出傳統物件導向設計的眾多問題，舉例來說，蔡學鏞以前在保險公司擔任架構師時，保險的規則非常繁雜，高達1,000萬條，也有許多幽靈規則，平時都沒有執行，但是沒有人敢調整，深怕一調整系統會當掉。
另外，法規和業務調整的變動也會影響著前端的服務模組、API，以及後端調用資料庫和串連外部系統的設計，還有FaaS的設計強調沒有狀態（State），但是物件導向的物件都是有狀態，他建議，企業若要使用雲端，則要使用函數式的程式設計。
蔡學鏞歸納出五個函數式程式設計的原則，首先，設計業務功能的模組要分開，且分的越細越好，第二要採用非同步的調用方式，讓程式無需等待被調用函數的返回值，就讓程式繼續執行，第三是他認為最關鍵的，就是只要資料最終一致化就好，不需要每筆資料都變成即時交易，第四則是盡量將功能都API化，甚至他建議可以先從外圍的Interface開始設計，最後物件必須是無狀態，這樣系統面對較高的流量，就能同時開啟多個Instance。
除了上述的五大原則之外，蔡學鏞也認為，在設計雲端架構的系統時，必須對資料非常了解，有些是需要和業務人員一同合作來了解，像是資料的重要性、保密性、調用資料的費用和業務一致性，舉例來說，金錢和地址的資料遺失重要程度就不同，且也要依照不同的資料類型，將資料放在適合的資料庫，並用不同的方式存取。
有些資料的釐清，工程師則是可以透過技術或是統計的方式來理解，像是調用資料的頻率、資料筆數、資料老化現象等，他認為，只要是透過技術可以了解的，就能將規則用成通用的方式放在雲端平臺，他舉例，由於火車時刻表屬於不容易變動的資料，就不需要頻繁地調用資料，避免浪費調用的成本。
最後，資料的互相調用也是重要的議題之一，他表示，調用資料時除了可以用密碼的方式確保安全性之外，其實還可以用Attribute-Based Access Control的方式，利用調用和被調用的資料都有各自專屬屬性的特性，來做精細的比對。
",https://www.ithome.com.tw/news/115074,"新聞,Cloud,Cloud Summit 2017,FaaS,BaaS"
114818,17,2017-06-19,Container雙周報第36期：Docker企業版納入英國政府雲計畫，公部門可線上採購容器解決方案,使用容器技術的風也吹進了英國政府，近日Docker企業版已被英國政府認證，納入政府雲計畫G-Cloud 9中," 重點新聞（06月03日-06月16日）
·Docker企業版納入英國政府雲計畫，公部門可線上採購容器解決方案
Docker表示，英國政府的軟體開發流程逐漸擁抱雲端技術及DevOps，並且開始尋找小型供應商，避免與大型IT廠商簽訂長期契約。而使用容器技術的風也吹進了英國政府，近日Docker企業版已被英國政府認證，納入政府雲計畫G-Cloud 9中。Docker表示，G-Cloud 9是英國政府所推出的雲端計畫，目的是在公布門推動使用雲端服務。在Docker被納入G-Cloud 9之後，公部門可自行選擇適合的容器解決方案，「免除冗長、競標的採購流程。」更多資訊
·甲骨文擁抱Docker更進一步，將中介軟體Oracle Coherence在Docker Store上釋出
繼甲骨文產品開發部門副總裁Mark Cavage在DockerCon上宣布，只要經過甲骨文認證核可的Docker應用程式，「我們都視其為第一優先」，並將自家的Oracle資料庫、Oracle Linux、Java以及中介軟體都登上Docker Store後，近日甲骨文自家的中介軟體解決方案Oracle Coherence也登上了Docker Store。
甲骨文表示，記憶中的Java資料網格（In memory data grids）除了會共享功能外，它們通常也是由數個Java虛擬機器（JVM）所組成，並自成一個獨立叢集。一般在叢集內進行探查的方法，是在JVM開啟後，利用多址傳送（Multicast）完成，「不過在Docker容器內卻不管用」，導致必須探查任務必須靠人工作業。
而目前甲骨文已經讓Oracle Coherence可在Docker Swarm上執行，在叢集開始執行時，開發者可提前輸入一份紀錄各容器IP位址的清單，「使用者也可以替Docker容器指派一個固定IP。」更多資訊
·微軟開源釋出容器開發工具Draft，加快應用程式在K8s環境部署
在今年4月微軟併購Kubernetes工具開發商Deis後，微軟在近日也開源釋出了容器應用程式開發工具Draft，加速應用程式在Kubernetes環境的部署流程。
目前帶領微軟Azure容器服務團隊的Kubernetes共同創辦人Brendan Burns表示，雖然Kubernetes在部署、管理容器應用程式的規模有目共睹，「但為K8s開發應用程式先階段仍不容易」，特別是不熟悉容器、雲端原生應用程式的開發者。
Brendan Burns認為，而Draft推出的目的，「就是要協助使用者開發出第一個可以在Kubernetes上運作的容器應用程式。」他解釋，在開啟Draft後，系統會自動掃描程式碼，並且建置出一套周邊支援環境（Scaffolding），協助開發者將應用程式容器化。同時，Draft也會使用內建的許多模板，替應用程式產生紀錄映像檔建置步驟、參數的Dockerfile，「企業也可以使用自家模板，建置客製化的系統環境。」
而Draft的效果不只如此，Brendan Burns表示，開發者還可以利用Draft，在既有Kubernetes叢集中部署新伺服器，「並且保持與本地開發端環境的程式碼一致。」而Draft實作如此這個功能的作法，就是在遠端的Kubernetes環境加入一個Draft Server，而本地端的Draft Daemon會自動同步遠端與本地端的程式碼。更多資訊
·CoreOS釋出容器漏洞掃描工具Clair V2.0.0版
開始有許多企業開始將容器視為可用於正式環境內的技術，CoreOS表示，容器技術雖然好用，可以維持軟體部署的一致性，但卻也是把雙面刃：「如果容器像個黑盒子，開發者該如怎麼確定裡頭運作什麼軟體？」CoreOS表示，容器漏洞掃描工具正是要解決這個疑慮，而自家的Clair的功能，就是對容器映像檔定期分析，並從公開漏洞資料庫讀取資料，確保容器映像檔的安全性。
而CoreOS提升容器透明度的做法，就是新增其支援的Linux作業系統映像檔，例如，Clair現在已經延伸支援Alpine Linux 3.3至3.5版。另外，針對企業市場，新版本也能相容Oracle Linux 5到7版。更多資訊
·甲骨文要投入工程資源，擴大經營Kubernetes社群
商用軟體大廠甲骨文近日在2017 CoreOS高峰會上宣布，未來要投入工程資源在Kubernetes專案，「Kubernetes目前是數一數二的容器調度工具，我們也看好它的成熟度及未來發展方向。」
過去作為Node.js專案領導人，而現在任職Oracle軟體工程師的Timothy J Fontaine表示，甲骨文也開始與CoreOS擴大合作，要讓CoreOS自家的容器作業系統Container Linux可以在Oracle雲端基礎架構中執行。更多資訊
·CoreOS自家容器作業系統Container Linux功能再升級，加強K8s節點OS更新自動化
在2017 CoreOS高峰會上，CoreOS除了與甲骨文擴大合作，要讓自家容器作業系統Container Linux進入甲骨文雲服務上外，也宣布Container Linux的功能要再加強，讓每個Kubernetes節點的作業系統更新程序自動化。
CoreOS表示，在公有雲、私有雲基礎架構中，主要可畫分成3大層。首先是叢集調度系統，將硬體資源轉換成統一資源池。再者是部署在調度工具上的應用程式，最後才是運作在每個節點中的作業系統。
而CoreOS表示，自家開發的Operators的理念，就是將複雜的維運知識，轉換成軟體執行。在這次所釋出的Container Linux Update Operator，負責安排CoreOS自家K8s商用平臺Tectonic的更新行程，首先，每個節點中都會安裝一個Update Agent，當它偵測到有新版系統，會提出該節點需要重啟的需求。再者則是靠Update Operator執行Kubernetes的部署任務，該元件會安排每個節點的更新時程，同時確保更新不會對服務可用性造成影響。更多資訊
·容器安全廠商Aqua開始支援IBM Bluemix
越來越多企業在公有雲、私有雲上部署容器應用程式，而容器安全議題將會成為企業關注的焦點，在近日容器安全廠商Aqua也開始支援在IBM Bluemix容器服務中部署自家的服務。
Aqua表示，面對已知威脅，只需要掃描該容器映像檔是否存在漏洞即可，「但是面對那些未知的威脅呢？」因此，透過減少潛在攻擊表面即可強化安全，「而微服務架構在這方面派得上用場。」Aqua解釋，因為微服務限制該系統元件可執行的任務，藉此控管微服務的系統權限。更多資訊
Container產品更多動態
·Rancher與加拿大雲端服務商Cloud.ca結盟更多資訊
·網頁應用程式管理工具Redmine Docker映像檔開始支援PostgreSQL更多資訊
·Google開源Distroless專案，縮減容器映像檔大小更多資訊
·容器管理工具Navops Command 1.2版釋出，讓Kubernetes上執行的容器應用程式更有效率更多資訊
·容器管理平臺Apcera也支援ASP.NET核心更多資訊
·Mesosphere推出Fast Data應用程式參考架構更多資訊
·甲骨文擴大與CoreOS合作，要讓Container Linux可在甲骨文公有雲上運作更多資訊
·容器資安廠商Twistlock用機器學習偵測惡意行為更多資訊
Container資源
※觀點：應用程式才是重點，而不是容器技術
※觀點：比較Kubernetes、OpenShift及商用k8s平臺Tectonic
※觀點：容器非兒戲，企業已開始認真看待
※觀點：如何開始著手開發雲端原生應用程式
※心得：用微服務重構既有應用程式
※心得：容器技術及即時監控系統
※心得：容器技術如何節省雲端成本
※心得：一探容器調度的藝術
※心得：在正式環境中導入Docker容器
※心得：在正式環境導入Docker Compose的10個訣竅
※How-To：用CLI部署Docker Swarm
※How-To：靠AWS Lambda執行Docker容器
※How-To：利用容器技術完成持續部署任務
※How-To：結合Docker，在正式環境部署PHP、Laravel應用程式
",https://www.ithome.com.tw/news/114818,"新聞,Oracle,IT周報,Container,容器技術,CoreOS,Docker,Kubernetes"
114936,18,2017-06-14,Pure Storage儲存系統軟體大更新，增加近30項特色，其中又以執行虛擬機器和容器最為吸睛,以全快閃儲存陣列闖出名號的Pure Storage，今年將發布系統軟體平臺的重大更新版本，除了針對企業一線儲存應用，繼續強化高可用性的相關機制，在虛擬機器、Container、大數據分析，以及雲端管理等層面上，都推出了不少新特色，一改過去作風，大膽展現該公司希望囊括企業資料中心、雲端服務、邊緣運算的企圖心," 【美國舊金山現場報導】全快閃儲存陣列市占前五大廠商當中，唯一一家單做這類型產品的Pure Storage，於本週舉辦的全球用戶大會Accelerate 2017期間，總共宣布超過25項系統軟體方面的新增特色，堪稱是該公司成立以來最大規模的產品技術發表，也展現他們在雲端當道的時代下，有意藉由軟體創新為全快閃儲存陣列拓展更多型態應用的決心。

Pure Storage首先針對旗下兩大儲存系統的軟體平臺，發表了新版本──FlashArray//M系列和//X系列機型所用的Purity//FA作業系統，推出5.0版，FlashBlade系列機型所用的Purity//FB作業系統推出2.0版，並藉這兩個平臺的大幅更新，希望分別搶攻企業一線儲存應用，以及大數據進階分析等兩大領域。
同時，該公司以軟體即服務（SaaS）型態所提供的儲存管理雲Pure1，如今也新增了AI智慧管理引擎Meta，透過一系列特色，協助Pure1自動預測分析所有Pure Storage儲存陣列的效能與用量，以便進行最佳化與規畫，Pure Storage希望能以此切入自動駕駛車的儲存應用，使Pure1能跨到邊緣運算（Edge Computing）的應用。
這三大產品與服務的新走向，其實也象徵Pure Storage所著眼的未來發展目標，不再局限在全快閃儲存陣列本身，僅看重企業資料中心環境所執行的關鍵應用系統（Core），而是想要同時涵蓋到多雲（Multi-Cloud），以及邊緣（Edge）等環境的創新應用。

以Purity//FA 5.0而言，Pure Storage加入多種新特色，並以「The New Tier 1」自我期許，他們的主要訴求是希望重新定義一線儲存（Tier 1 Storage）的基準，透過對於系統與資料可靠度的提升技術，以及針對資料縮減、開放雲端服務整合、新傳輸介面（NVMe）等層面的強化，在傳統一線儲存系統和專屬全快閃儲存陣列各有所長的局面下，找出魚與熊掌兼得的方法。

在高可用性方面，Purity//FA 5.0推出了ActiveCluster，可支援在多站點之間建立叢集的主動式備援架構。現在，企業能在多臺FlashArray之間，建立延伸叢集（Stretch Clustering），在搭配Pure1的Cloud Mediator協調下，號稱只要4個步驟的指令操作，就能完成組態設定，不需要設立閘道與見證站點（third-site witness）。

對於服務品質的控管（QoS），Purity//FA 5.0也在原本的Always-On QoS之外，添加了基於政策執行的作法Policy-based QoS，可根據工作負載的重要性而區分不同等級的優先順序，也能針對多個工作負載的存取，訂出各自的限制，以支援服務供應商的多租戶業務使用。

此外，Purity//FA新版終於支援VMware Virtual Volumes（VVols），可對VMware的伺服器虛擬化／私有雲平臺，提供基於政策的儲存自動管理與遵循。而且，Purity//FA本身就內建了VASA Provider，可加速VMFS檔案系統的存取、增進VVols的轉換，進而簡化實體轉虛擬，以及虛擬轉實體的遷移作業。

而在快照應用上，Purity//FA新版的Snap功能，可讓FlashArray將本身的快照，搬移到FlashBlade和NFS。除此之外，企業若要將快照移到公有雲服務，Pure Storage也在Purity//FA當中提供CloudSnap功能，第一步會先支援AWS，企業可將快照備份到S3和Glacier，若要從這當中的快照進行資料還原，可在EBS裡面選用復原機制，或是回復至FlashArray。


上述這些特色都是針對儲存層面的應用，Purity//FA這次改版最令人意外的部分，在於增加了可直接執行虛擬機器和Container的能力，也就是說，企業可直接把FlashArray這套全快閃儲存陣列，當成伺服器虛擬化平臺來使用，這項新功能被稱為Purity Run，用戶在Purity//FA系統當中，可建立多個處理器與記憶體存取彼此隔離的環境，企業能以此執行邊緣運算、資料分析、資料庫等應用系統。

而在Container環境的搭配上，Purity//FA 5.0也將支援Docker Persistent Volumes的用法，Pure Storage會在FlashArray當中，提供認證過的Docker Persistent Volumes外掛程式，讓全快閃儲存陣列能夠延伸到容器化的應用程式當中使用，在此同時，相關的儲存整合也會擴展到各種資源調度指揮平臺，像是Swarm、Kubernetes和OpenShift。

整體而言，Pure Storage在2017全球用戶大會上，宣布了如此大量的軟體新特色，的確讓人眼睛為之一亮，當中已經正式推出上市的部分，超過一半，其他項目則要等到第三季、第四季之後，才會推出。

",https://www.ithome.com.tw/news/114936,"新聞,All Flash Array,Container,Big Data,AI"
114817,18,2017-06-12,傳統SI公司200位外勤管理經驗平臺化，將內部業務轉型新營利服務,全臺近半ATM都由三商電腦200位外勤負責維護，不論上山或離島，遇到故障就得出動，但未來幾年線上金融、行動支付越來越盛行，也衝擊了ATM的使用，更影響到三商的維運服務，如何轉型？成了這家老牌40歲老牌SI的新考驗," 「傳統的營運模式已經無法因應多元的應用情境和快速變化的產業需求！」三商電腦雲端及行動服務事業部業務副總經理蔡忠維表示，數位轉型已經成為各產業的當務之急，企業要創造出新的契機才能因應市場快速變化的衝擊。
三商電腦隸屬於三商控股集團，旗下產業橫跨零售、餐飲、證券、壽險等，三商電腦成立41年來，主要都是提供系統整合服務和維運的業務，其中分為金融、公共、工程維修和雲端及移動事業部門，主要的營收就是來自銀行的ATM和補摺機等設備，另外，也有承攬政府大型專案的開發和建置。
不過，蔡忠維指出，隨著信用卡普及和行動支付興起，事實上鈔券的使用率和需求都在下降，他預估，未來10年整個ATM市場需求只會剩下目前的7成左右，因此，目前企業面臨嚴峻挑戰，不僅如此，政府的專案承攬也有不確定因素，再加上專案是任務性質導向，專案之間需要的技術和領域知識都不一樣，專案團隊的建置和維持都不容易。
這樣的困境讓三商電腦開始思考，思考往後10年怎麼透過原本具備經驗，搭配現在主要的趨勢和技術，開發新的應用，為企業創造另一個新的營收模式。因此，雲端及移動事業部在3年前成立，成立的原因即是要開發出新服務，創造穩定的營收。
全臺總共有2萬7千多臺ATM，超過一萬臺都是由三商電腦提供，為了維護眾多的自動化設備，三商電腦在全臺包括離島共設有14個據點，管理超過200位維修工程師，目前可以做到故障叫修2小時到場，4小時完修的服務水準，於是，三商電腦決定將原本傳統管理外勤人員的經驗，轉換成雲端平臺，甚至將這個平臺變成服務，成為對外獲利的新模式。
他表示，外勤管理包含排班、派遣、到點執行和執行結果回報等工作，目前大多數的企業，在外勤管理上還是採用較傳統的方式，透過電子郵件或是電話溝通，而有些企業則是用Google日曆來管理，再透過通訊軟體掌握目前執行狀況和追蹤結果，此外，所有單據需要簽名，目前還是透過紙本作業，讓外勤人員帶回，再交給後端的作業中心人員建檔，至少都要花上2-3天的時間，不但效率低，還容易出錯。
雲端外勤管理系統則提供完整的外勤管理功能，像是任務、訊息和表單管理等，後臺管理人員可以透過Web平臺來安排排表和派遣人員，外勤人員也可以直接透過手機App接收到派遣任務，到點執行任務還可以打卡或是拍攝照片回報。任務結束之後，若需要收集表單資料，可以在App上填寫表單，給客戶簽名，結案後送到後臺儲存，簡化了以往繁瑣的流程。
這個雲端管理平臺去年10月才上線，目前就已經超過250家企業註冊使用，隨著使用的企業越來越多且產業多元，蔡忠維指出，「系統架構的擴充性、資料和系統安全性和穩定度都是考量的重點。」
他進一步解釋，由於一開始使用的企業數並不多，不過，平臺上線後使用的企業逐漸成長，還有偶發的瞬間負載量問題，因此，系統架構的擴充性就變得很重要，另外，確保資料和系統的安全，也是多數企業關注的議題。
他也指出，由於企業應用情境多元，有些是在白天使用，像是業務人員或是維修，有些是在晚上，比如說酒促小姐和清潔打掃人員，所以系統必須要24小時不斷提供服務，在整個系統的穩定度部分，也是主要考量的因素之一。
「這個平臺全部的服務都在AWS上運行，」蔡忠維表示，綜觀所有的考量，三商認為AWS提供許多服務，可以依照需求搭配使用，舉例來說，手機App端拍攝的照片用S3儲存，Web端則用CloudFront儲存靜態網頁跟圖片，由於CloudFront將儲存在S3的檔案，複製世界各地的AWS節點，可以針對使用者的請求（Request），自動調派最近的節點回覆，加快網頁運作的效率。
另外，資料庫用RDS和Multi-AZ服務，可以將資料同步抄寫到異地備份，還可以做到容錯移轉（Failover），確保系統穩定度，其中，像是Log檔的關聯式資料，因為則是使用DynamoDB處理，透過NoSQL資料庫服務，適合所有需要一致性且延遲低於 10 毫秒的任何規模應用程式不被較耗時的服務影響，耗時的服務就藉由無伺服器運算Lambda服務處理。
安全性的部分，App端不會存取敏感的個人資料，上線前也會先將敏感的個人資料做混淆化（Obfuscation）的處理，App到伺服器端用VPC建立私有網路環境，將核心系統和外網隔離，最後由Cloud Watch監控系統運作狀況。
後端的系統開發部分，程式出版前會先審核程式碼（Code Review），也會管控使用者和系統的使用權限。
蔡忠維也點出AWS具有雲端網路負載平行器（Elastic Load Balancing，ELB），能夠解決偶發性的流量高峰問題，他解釋，雖然企業應用情境多元，但是使用者有些共通性的行為，像是任務回報都會集中在下班之前，另外有很多企業利用表單功能製作出勤考核表，紀錄外勤人員出勤狀況，回報的時間點大約都落在下午4-6點，這樣的現象隨著企業使用戶增加，越來越明顯。
「瞬間非持續的負載，如果將系統配置到最高需求，不是有效益的作法，」他表示，透過部署AWS的ELB，平時就運行單一EC2服務，當瞬間負載超過警戒值時，會自動部署另一個EC2服務，將超過的負載量分流，等到流量下降至警戒值內，就能回復成單一EC2服務。
",https://www.ithome.com.tw/news/114817,"新聞,Cloud,AWS,外勤管理,ATM"
114800,18,2017-06-07,AWS：Cloud是企業轉型的助力，未來大數據、AI和IoT的整合成為關鍵,"AWS於6日舉行為期兩天的高峰會，這是AWS第二次在臺舉辦，吸引了超過2,000人參加，議程包含30個技術論壇，和15個合作夥伴的攤位，這次高峰會聚焦於大數據、AI和IoT三大領域，也請來了多家企業一同前來分享使用AWS服務的經驗"," 今年是AWS第二次在臺舉辦高峰會，吸引了超過2,000人參加，議程包含30個技術論壇，和15個合作夥伴的攤位，AWS副總裁及大中華區執行董事容永康表示，今年AWS提供公有雲的服務邁向第11個年頭，使用者涵蓋全球190個國家，除了一般的企業、新創，甚至連政府部門和大學都有使用AWS的服務，這次高峰會聚焦於大數據、AI和IoT三大領域，也請來了多家企業一同前來分享使用AWS服務的經驗。
「未來10年的趨勢，就是如何將大數據、物聯網和AI整合在一起，」容永康表示，雲端的服務提供企業轉型和升級所需的助力，以往使用這些技術來分析數據，需要花上幾千萬來部署本地端的基礎建設，現在，雲端的服務依照使用量付費，能夠提供企業用幾塊美元就能做到超大型企業才能用的技術。
AWS這次活動，展示了AWS在去年11月釋出的一系列新產品，包含AI和物聯網平臺，AI從最上層的服務、平臺，到底層的框架和基礎建設，都有提供企業相對應的解決方案，物聯網平臺則是從數據收集、儲存、分析，到後端處理的服務一應俱全，他表示這是從雲端、端點和服務三方面，提供涵蓋層面最廣的解決方案給企業。
其中，容永康特別介紹一個可在端點裝置上，執行點對點運算的新服務Greengrass，端點裝置能夠執行AWS Lambda函數，並且同步數據，進而減少端點裝置將數據傳送到雲端的成本。
臺灣已有不少企業使用AWS的服務，玉山銀行就將不涉及個人隱私的數據，放上AWS的公有雲，像是網站的點擊資料，「現在不創新就等著被取代！」玉山銀行數位金融事務處資訊發展部協理李嘉銘表示，企業不但要創新，創新還要到位，他提供ABCD這4項指標，來檢視創新是否到位，分別是AI、Blockchain、Cloud和Data。
玉山的作法是將數據的收集放在雲端，再透過大數據分析和AI的技術，提供客戶理財金融服務，他指出，雲端提供企業高彈性和低成本的兩大特色。
在AWS提供的眾多服務中，值得注意的是，AWS在提供企業建置更聰明的智能應用中，新增了一項文字轉語音的服務Amazon Polly，這項服務與一般的文字轉語音不同，是能將文字轉為模擬人類說話的方式，支援24種語言和47種聲音，光是英文就分為七種腔調，讓企業可以選擇適合的語音，這項服務提供了企業建置Chatbot新工具，不過，目前還是尚未支援中文。

 
",https://www.ithome.com.tw/news/114800,"新聞,AWS,AI,大數據,Cloud"
113899,18,2017-05-13,【從Docker到Moby】Docker如何將容器平臺變成一門好生意？,從今年4月的DockerCon之後，所有Docker的一切程式碼、工程師資源、所有元件，甚至是Docker自身的程式碼，都將屬於這個新的開源專案Moby，這正是Docker要將容器平臺打造成一門好生意的關鍵," 「這是有史以來，Docker最重要的專案，可以將Docker生態系帶向下一個階段。」Docker創辦人兼技術長Solomon Hykes最後如此介紹，「從今天開始，所有Docker的一切程式碼、工程師資源、所有元件，甚至是Docker自身的程式碼，都將屬於這個新的開源專案Moby。」他強調：「這也是我心中最想要的容器專案。」
4月18日早上9點，5,500人齊聚美國奧斯汀，參加容器圈年度最重要的技術大會DockerCon，在主要演講結束的最後半小時，Solomon宣布了Moby專案的消息，臺下似乎還沒意識到這是一個影響全球所有Docker開發者、使用者、貢獻者的一個新專案。連Solomon都不得不中斷演講，提醒臺下與會者，別分心發訊息或看郵件，因為這是一個影響所有容器生態系的新計畫。
Solomon沒有明講，而是等到了演講結束後，眾人才發現，在GitHub開源專案代管平臺上最火紅的這個Docker專案網頁，竟然換了名字，不再叫做「Docker」，而是變成了「Moby」。
這個從2013年1月13日開始啟用的容器開源專案Docker，超過3,300名開源開發者共同貢獻，部署到1,400萬臺容器主機上，開發出90萬個Docker應用，累計超過120億次映象檔下載數的Docker專案，從此，變成了Moby專案。
使Docker公司極力澄清，舊有Docker專案還在沒有刪除，只是搬回Docker公司網站上維護，但所有Docker擁護者未來唯一的主要容器技術來源就是Moby，這個消息大大震撼了各大容器社群和開發社群，甚至引起了Docker該不該改名的網路論戰，連Solomon都在Docker專案，喔，現在應該說Moby專案網站上一一回覆開發者的質疑，「最常用的啟動指令docker Run是否從此要改成moby run呢？」，不，Solomon強調：「一切都沒變，對開發者而言，什麼都不會改變，」他解釋，只是存放Docker程式碼的目錄名稱換了，就像多年前，Docker 專案從dotCloud網站，搬到GitHub網站上一樣。
3年前，因為Docker太過火紅，甚至專案發起者Solomon都將自家公司dotCloud名稱改以Docker為名。第二次改名更大膽地，事前一點通知都沒有，Solomon就將這個在全球擁有17萬人社群規模的專案名稱，換成了Docker公司吉祥物的小名Moby，也就是Docker Logo圖案上的藍鯨，牠的全名是Moby Dock，參考自知名小說白鯨記（Moby Dick）。
就像如果Linux或Android哪一天若是改名，勢必會衝擊全球開發圈一樣，這類幾乎成了IT技術根本基石之一的火紅開源專案，一舉一動都格外令人注意，更遑論是徹底換掉名稱。為何Solomon寧可冒著惹惱開發社群的風險，也要改名？Solomon給的理由是，Docker生態系，需要一個新的架構，才能繼續擴大，而Moby就是那個答案。
雖然在2013年時，Docker一問世，不論是雲端龍頭或軟體巨頭都紛紛支援，如Amazon、微軟Azure、IBM Softlayer、Rackspace、Google、Heroku、OpenStack等，連十年前就開始採用容器技術，一周就要啟用20億個Container的Google，都公開力讚Docker公司，才真正讓容器技術容易可用，而決定力挺。而傳統虛擬化技術龍頭VMware更是在2014年8月的VMworld年度大會上宣布擁抱Docker。
這時的Docker，不過是一家問世不到2歲的年輕新創，就立刻成了最火紅的雲端技術。不過，Solomon打從一開始釋出Docker時，他就相當清楚，「唯有Container生態系成功，Docker才會成功。」他強調。

Docker將原有Docker專案更名為新的Moby開源專案，並提出了一套組合容器化應用系統的組合框架，要讓企業能夠快速打造一個專屬的客製化容器系統。

開拓期（2013～2014）：開源模式
Solomon將過去幾年來的Docker發展分成三個階段，第一階段，2013～2014年是開拓階段（Pioneers Age）。Docker開源釋出後，不只是Docker公司成員，連帶吸引了上百位開發者投入，發展出了十多個相關專案，全球實際部署Docker的系統也有上千套。開發者最常從Docker Hub上下載映像檔來部署環境，從Docker Hub下載次數更容易反映出Docker使用的熱度，2年下來，映象檔下載次數很快達到1億次，「這時期帶動容器生態發展的動力是開源生產模式。」Solomon表示。
嚐鮮期（2015～2016）：開放元件模式
2015年到2016年則是初期採用者為主（Early Adopters）的嚐鮮期，看好者居多，但真正敢在正式環境採用Docker的企業仍是少數。不過，越來越多人開始發現，在Linux伺服器上打造雲端原生應用是一個不錯的選擇，這也成了Docker生態系中最大宗的應用情境。Solomon採取了新的戰略來推動容器生態系，他解釋，開放元件（Open Components）生產模式是第二階段的發展關鍵。
Docker開始以打造開放元件為重心，推出了如libcontainer、libnetwork、Notary、runC，都是為了將Docker容器技術打造成更開放，可以支援更多平臺的架構。
開放元件模式果然也帶動了容器生態的第二波成長。相關專案數從2位數增加到了3位數，超過1百項，貢獻者也比第一階段暴增了近10倍，超過了1千人，全球部署主機數量達到上萬個，而Docker Hub的下載次數更是驚人，從2015年初的10億次，在2016年中達到了60億次下載量。
第一階段的開源策略，Docker社群成功吸引到了頂尖技術高手而茁壯，如不少Go語言知名開發者或科技龍頭內部高手都參與了Docker專案。而第二階段的開放元件策略，讓Docker不只是一項產品，而成了一個由多種容器元件組合而成的平臺，打造出了更專業分工、精緻化的功能元件，一來吸引了更多開發者的加入，另一方面也更能符合不同應用，甚至是不同平臺的特殊需求。連微軟都大力投入，要將Docker容器技術帶進Windows世界。
但是，從開拓期的開源模式，到嚐鮮期的開放元件模式，Solomon以汽車產業的發展來比喻，就像是手工打造汽車，才剛邁進了機器化生產階段，但距離便宜、大量生產，甚至可以大量客製化的階段，還有一段距離。
爆發期（2017～2018）：共享元件和通用組合
Solomon認為，2017到2018年是容器技術成為主流應用的關鍵階段，需要將容器技術拓展到每一種運算類型，不只是資料中心、伺服器，還要能運用在桌上型PC或手機裝置，甚至也要能運用在IoT裝置上。
他想將容器打造成可以運用在各種運算情境的核心引擎，就像汽車產業已經細分成更多類型的車輛，跑車、房車、休旅車、遊覽車、貨車，甚至兩輪的機車和四輪的汽車一樣，關鍵元件都是汽油引擎。
在主流應用階段，Solomon預估，將會有1千個相關專案，貢獻者將再提升一個量級，達到1萬人，而部署量則將倍增到百萬套系統的規模，更重要的一點是，得打造出「高度專殊化參與」的模式（Highly Specialized Participants）。意思是，可以讓每一個人打造出各自專屬的容器化環境，但彼此又有一套互通或共用的樣版或規範以快速借鏡。
「需要新的架構，才能創造出一個具備高度擴充力的新Docker生態。」他說，而且主要運用情境更為複雜，必須能通吃不同桌面環境（Mac OS和Windows 10），不同伺服器環境（Linux和Windows Server）以及不同雲端平臺（AWS、Azure和GCP）。
原有開放元件，儘管有大量開發者，推出多種功能元件，但每個人各自推出了自己的容器化系統建置或部署方式，彼此不易快速複製和擴散，而拖慢了生態系的擴大速度。因此，借鏡高度自動化的汽車產業作法，Solomon認為，必須推出通用組合方法（Common Assembles）才能解決。
Moby專案最大特色不只是新的專案名稱，還提出了一套組合容器化應用系統的組合框架（A Framework to assemble）。Moby除了涵蓋了原有Docker開源專案的所有程式碼，多達80多個元件函式庫之外，還提供了一個將自製元件打包成容器化元件的工具，以及Docker從百萬個Docker節點部署經驗中，歸納出來的容器系統組建參考文件，等於是提供了一套內有全套容器工具和容器系統建置方法學（和通用範本）的懶人包。
Solomon以自家經驗舉例，建立一個容器系統的開發專案，包括系統架構、開發環境準備、專案規畫等，現在只要一個周末就可以完成。目前Docker公司內部若有新研發專案時，已經採用了Moby框架來組建。
過去Docker專案以服務開發者和Docker使用者為主，但是Moby專案更進一步要服務系統設計者，Solomon表示，要讓系統管理者或架構者，更容易打造出容器化的應用系統。過去可能得花上好幾個月來建立一個研發專案所需的軟體環境，「現在就只是一個周末專案。因為Moby專案提供了常用容器化系統設計參考，不用重頭開始規畫。」
不過，推出通用組合框架的策略下，仍然可以沿用舊名，為何非要將Docker專案改名為Moby？Solomon沒有正面回答，只說這樣的開放管理（Open Governance）專案模式，是借鏡於Fedora的成功經驗。
Solomon沒說出口的是，Fedora經驗的另一個重點，就是紅帽的開源商業模式。紅帽早在1994年就釋出了Red Hat Linux 1.0版，以桌面環境使用者為主，但是到了2003年，紅帽推出Red Hat Linux 9.0版後，就決定轉而專注於伺服器版本，也就是後來的Red Hat Enterprise Linux（RHEL），自己不再推出桌面版本，反而改由Fedora開源社群接手桌面版本，以Fedora Linux（第七版前稱為Fedora Core）為名免費釋出。
不過，紅帽仍是Fedora Linux的主要贊助者，甚至紅帽將Fedora Linux版本視為練兵場，來測試許多新功能，經過社群試用確認可行後，才正式納入企業版RHEL中來銷售。儘管紅帽產品仍堅持全面開源，但紅帽將商業產品和社群專案區隔成不同的品牌，並在企業級產品則提供了更多技術支援和顧問服務，以訂閱制度的收費模式來獲利，這也讓紅帽在2012年時，成為第一家營收超過10億美元的開源軟體業者，去年營收更是突破了20億美元，甚至得到了單筆1億美元的訂單。
開源軟體目前常見的商業模式有好幾種，除了紅帽模式之外，以開源XEN技術，打造出AWS雲端服務來收費的Amazon是另一種成功模式，不過Amazon是在EC市場站穩腳跟之後，才投入雲端服務市場，就算因大舉將營收繼續投入研發和業務推廣，AWS很長一段時間處於獲利負成長的情況，Amazon也絲毫不擔心，因為持續成長的用戶租金，仍可維持AWS營運所需的現金流，甚至還可以憑電商營收來支撐。
將核心產品開源的Docker公司，一開始看似要效法AWS模式，將核心技術開源，並以Docker Hub雲端服務來收費，但又為了推廣，Docker Hub還效法GitHub開源專案代管平臺的作法，採取了公開免費而私有需付費的策略，只對不想公開自家Docker Image的使用者收取代管租金。
儘管Docker Hub下載數快速暴增，代管的映象檔數量也越來越多，但Docker雲端服務項目，仍只有少數幾項，沒有向AWS那樣發展成數百、甚至上千項的雲端服務種類。經過3年，即使Docker再火紅，仍對實際營收數字秘而不宣，僅暗示仍處於赤字階段。
大舉借鏡紅帽開源商業模式
但最近2年，Docker商業模式有點不一樣了，開始提供收費的官方技術支援Docker Commercially Supported，甚至推出搭配官方技術支援的Commercially Supported Docker Engine版本，採年費訂閱制，越來越像紅帽的商業模式，甚至在今年3月時，直接推出了Docker Enterprise Edition（Docker EE），來取代Docker Commercially Supported版本，並將免費的Docker Engine更名為Docker Community Edition（Docker CE），等於將Docker產品分成了企業版和社群版兩種。依技術支援等級不同，Docker企業版還分成三款，EE基本方案、EE標準方案和EE進接方案，年費從750美元到2,000美元不等。至此，Docker效法紅帽模式，只剩下了關鍵一步。在DockerCon大會上，Docker正式將開源專案改名為Moby，就如同紅帽RHEL和Fedora Linux的關係一樣，將開源專案品牌和商業產品品牌切割，這正是Solomon沒說出口的另一個原因。

Docker越來越像是效法紅帽RHEL和Fedora的雙軌模式，一方面區分商業產品和社群品牌，另一方面開始以付費訂閱制來提供商業級產品和技術支援。（圖片來源／Docker）

2017年將主推Docker商業版
在DockerCon第二天，當時仍是Docker執行長的Ben Golub，就完全聚焦在Docker企業布局的說明，他將2017年視為Docker推出商業級產品的關鍵一年，也意味著，如何搶攻企業市場，將成為Docker今年的年度目標。這也反映在Solomon Hykes揭露了產品戰略方向上，不只聚焦於開發者，開始擴大到服務系統管理者，系統架構者，要從更大的企業架構來研發Docker產品的策略。
拉攏更多指標性商業軟體廠商的支援，也是Docker接下來的目標，要讓大型企業慣用的產品能支援Docker，來吸引更多大型企業的採用，不只是微軟站臺力挺，甲骨文也成了Docker陣線的成員，甚至甲骨文將主力產品Jave環境、Oracle Database和中介軟體平臺Weblogic Server都放上了Docker線上商店，提供甲骨文官方打造的Docker映像檔版本，這不僅宣示了甲骨文環境正式擁抱Docker，也是Docker影響力，不只深耕IT基礎架構，也開始向上拓展到更多企業關鍵應用生態鏈的起步。

除了繼續擴大原有Docker生態系之外，Docker也開始透過認證制度，來建立一個企業級產品的生態系。（圖片來源／Docker）

",https://www.ithome.com.tw/news/113899,"新聞,Docker,Moby,Container,容器"
114086,18,2017-05-10,Docker專案突然更名，紅帽CEO怎麼看？,紅帽執行長Jim Whitehurst認為，既然容器與Linux密不可分，無可避免地，Docker也必須開始布局Linux事業," 今年DockerCon上，Docker揭露了兩個重要發表，第一是將Docker專案改名為Moby，並且推出LinuxKit，能在任何平臺建立Docker環境的通用工具。但是Docker公司的策略，讓許多開發者大為火光，認為社群協力開發的成果被收割為商用軟體。而iThome也專訪紅帽執行長Jim Whitehurst，解讀Docker發布這兩個重要專案的布局。
 Q  你怎麼看待Docker發表Moby及LinuxKit專案？
 A 目前局勢尚未底定，不過我知道很多開源軟體開發者，對於Docker推出Moby跟LinuxKit專案很生氣。雖然我還不確定Docker公司未來的發展，但Docker推出LinuxKit，的確證實了紅帽長期以來對容器技術的看法－－「容器就是Linux，反之亦然。」既然容器與Linux密不可分，Docker也必須開始布局Linux事業，我認為此事無法避免。像是紅帽創立20多年來，都是以Linux為核心發展，我們很樂意一同和Docker競爭，不過同時我們雙方也互相合作。
剛卸任Docker執行長的Ben Golub，先前就是Gluster（紅帽併購的開源儲存產品）的執行長，之後我們也會一起討論未來的合作方向。
 Q  未來會有更多紅帽的服務透過OpenShift提供、派送嗎？
 A 目前紅帽幾乎將所有的服務都使用容器技術打包，並且透過OpenShift平臺發布。目前我們正利用OpenShift平臺，建立一個軟體生態系，讓開發者可以更簡單的使用開源軟體。
紅帽很樂意變成軟體業界的Netflix，利用OpenShift提供這些很棒的軟體。Netflix讓消費者可以利用電腦、電視或是手機收看影集，而開發者可以透過OpenShift平臺，從不同地方下載企業軟體，讓開發者取得軟體變得更簡單。
",https://www.ithome.com.tw/news/114086,"新聞,紅帽,高峰會,Docker,容器技術,Container"
113898,18,2017-05-10,【Docker通吃全平臺秘密武器】容器專屬超迷你OS包LinuxKit登場,LinuxKit是一個全容器化的超迷你Linux環境，目標是在任何OS中建立執行容器的環境，這正是Docker打通Linux和Windows壁壘的關鍵," 二年前，當微軟宣布要在下一代Windows Server中支援Docker的時候，大家就在猜測，微軟會如何將原生自Linux世界的Docker，轉移到Windows世界中。
當時Docker圈有一種半開玩笑的說法是，「乾脆直接在Windows中裝一套Linux好了。」之所以是玩笑，因為Docker問世的目的，不只是為了讓應用程式可以到處部署，還希望可以比VM更善用系統資源，不要再透過一層Guest OS來執行程式碼。若只是在Windows Server中裝上一套Linux，再來跑Docker環境，豈不是多此一舉。沒想到，當時圈內流傳的這句玩笑話，竟然成真了。
微軟早在去年Window Server 2016問世時，和Docker聯手打造了一個Windows版本的Docker引擎，安裝在Windows OS中來執行，讓Docker映像檔可以部署到Windows環境，微軟後來甚至在Windows核心中，增加了一個Linux子系統，採用Ubuntu的使用者模式，可以用來運作Linux腳本程式，讓Windows和Linux兩個世界的距離，更拉近一點，但還沒做到可以讓Linux應用程式，直接在Windows環境中執行的理想目標。
直到今年DockerCon大會，Docker技術長Solomon Hykes發表了一個工具，它不只是在Windows中建立Docker環境的工具，甚至是能在任何平臺建立Docker環境的通用工具，也就是LinuxKit。
打造通用型超迷你Linux環境
過去，Docker為了讓容器環境支援不同平臺，分別為不同平臺開發了各自的Docker引擎版本，但這個作法畢竟不是長久之計，一旦出現了新的執行環境， Docker就得再推出一個新的Docker版本，而且支援的平臺越多，要維護的版本就越多，Solomon一直想找出一個一勞永逸的辦法，而最簡單的方法，就是想辦法將Linux環境帶到不同的平臺中，就不用為每個平臺開發各自的Docker引擎版本。
直到去年1月時，Docker併購了Unikernel Systems，這家公司打造出了一個只允許單一使用者，只能執行單一執行緒的超迷你作業系統Mirage OS——這個源自XEN計畫，採用了unikernel架構的作業系統，因為只保留執行應用程式所需的最少必要元件，去除了多緒執行等，因應複雜應用程式而生的作業系統核心服務，安裝後的大小不到3MB。
而Docker在併購Unikernel Systems團隊之後，也就掌握了自行設計底層Hypervisor和Unikernel作業系統技術，並交由這個團隊設計出了LinuxKit這個Linux子系統工具包。
Solomon這樣介紹，LinuxKit就像是專門用來執行Container的一個安全、精簡、可移動的Linux子系統。他解釋，在安全設計上，因為功能精簡，不像Linux內建超多項系統服務，因此出現資安漏洞的風險更低。而在系統精簡設計面，以最小的檔案容量，最快的啟動時間為原則，所有系統服務都是容器，任何元件也都可以抽換，讓系統具備彈性瘦身的能力。
不只跨平臺和跨雲，還能Intel和ARM架構雙棲
然而，採用子系統設計架構，是為了更容易移植和部署到不同的作業系統或平臺上，Solomon指出，LinuxKit的目標是要通吃桌面PC、筆電、伺服器、IoT裝置和大型主機的作業系統，甚至要Intel和ARM處理器雙棲，還要能支援虛擬化平臺和Bare Metal部署。
目前LinuxKit已經可以順利在OSX/hyperkit、VMware、Qemu/KVM環境中執行，也可以支援Google Cloud和Packet.net雲端環境。而AWS、Azure、Windows、Bluemix等環境也已支援，但CLI命令的部分還未完全整合。
另外，Docker團隊也正在開發對ARM 64架構處理器的支援，若可實現這項計畫，等於可以將LinuxKit，部署到採用ARM 64架構的Android手機上，未來，Docker也計畫擴大支援所有ARM處理器，甚至是其他系統架構如大型主機。
「在Windows內裝一套Linux。」這句話實現了一半，因為不是安裝一套完整的Linux，而是LinuxKit這個子系統，但不只是Windows，未來任何可以執行LinuxKit的平臺或環境，都將成為Docker的標準執行環境。因此，LinuxKit不只是打通了Windows和Linux的高牆，而是將全世界都推平，讓Container通行無阻的關鍵神器。
",https://www.ithome.com.tw/news/113898,"新聞,LinuxKit,Docker,Moby,Container,容器"
113896,18,2017-05-07,Docker商業戰略舵手站上第一線，SAP軟體老將接掌Docker執行長,Steve Singh是誰？為何就在Docker準備大舉進軍企業，培植完整企業生態系，將Docker推向主流商架構之際，卻陣前換將？," 就在DockerCon大會落幕不到半個月，正當容器社群還在為Docker換掉開源專案名稱而爭論不休之際，Docker突然宣布更換執行長，由Docker董事會主席Steve Singh接任，成為掌管Docker未來發展的新任執行長。
在此同時，Solomon Hykes仍舊是技術長，但從Docker成立之初就擔任執行長的Ben Golub，則轉而繼續留在Docker董事會成員。
Steve Singh是誰？為何就在Docker準備發展企業生態系，將Docker推向主流商架構之際，陣前換將。Steve Singh是商務支出管理平臺服務Concur的創辦人，SAP在2014年時，以83億美元買下Concur，而Steve Singh也成SAP管理高層之一，負責SAP旗下全球商業網路策略產品，除了Concur平臺，還負責管理SAP旗下超過150萬家供應商的Ariba採購平臺。他不只是成功的雲端創業家，也是熟諳企業應用市場的經營者，因為負責SAP旗下最大的雲端事業部門，和SAP經常往來的大型企業CIO們熟識。為了接掌Docker，Steve Singh也在4月底離開了SAP。
早在2016年10月，Steve Singh就成為Docker董事會主席，當時仍是Docker執行長的Ben Golub就透露，2017年將是Docker推出商業級產品的第一年，這也是Docker接下來最重要的目標。
Ben Golub希望借重Steve Singh的經驗，將Docker公司推向全球，成為世界級規模的企業。換句話說，早從8個月前，Steve Singh就開始參與Docker新戰略的訂定，甚至成了主導Docker商業化戰略的董事會的主席。
在Docker宣布新任執行長之後，不少美國媒體逼問Steve Singh，是否將帶Docker走向IPO上市之路，但Steve Singh不漏口風，他僅提到，目前的首要目標是確保Docker的開源創新能力，同時又能將Docker產品推向企業用戶。
",https://www.ithome.com.tw/news/113896,"新聞,Steve Singh,Docker,Moby,Container,容器"
113868,18,2017-05-03,紅帽聯手Amazon壯大容器平臺OpenShift，能直接部署AWS服務,紅帽和AWS進一步擴展策略聯盟，整合容器平臺OpenShift和AWS雲端服務，讓使用者能直接在OpenShift平臺上部署與存取AWS雲端服務，提供用戶建立和擴展以容器為基礎的企業應用程式，而這項整合服務預計在秋天正式上市。," 紅帽（Red Hat）和Amazon Web Service（AWS）於本周二（5/2）共同宣布擴展策略聯盟，整合容器平臺OpenShift和AWS雲端服務，允許使用者從本地端（On-Premises）或雲端的OpenShift平臺部署AWS雲端服務，這項整合服務預計在秋天正式上市。
其實，紅帽和AWS早在2008年時就已共同合作，整合Linux作業系統Red Hat Enterprise Linux（RHEL）和AWS，讓使用者在AWS平臺上能執行RHEL。
而AWS和紅帽此次發布的整合服務，將能讓使用者可以透過具備AWS的運算、資料庫、分析、機器學習、網路、行動等各式各樣應用服務的OpenShift平臺，來建立和擴展以容器為基礎（Container-Based）的企業應用程式。
根據紅帽官網，使用者可以在OpenShift控制臺透過幾下點擊，就能直接部署AWS服務，例如，Aurora、Redshift、EMR、Athena、CloudFront、Route 53、Elastic Load Balancing等。另外，這項整合服務也將能加速OpenShift用戶的開發效率，因為用戶無論在本地端或雲端，都能在同一個應用程式開發平臺上建立自己的應用服務。
紅帽總裁暨CEO Jim Whitehurst表示，AWS與紅帽的策略聯盟將能加快使用者直接從OpenShift平臺存取AWS服務的速度，且提供用戶在混合雲環境中，能夠利用AWS和OpenShift整合的優勢，以及獲得紅帽與AWS的技術支援。
除此之外，紅帽和AWS也計畫，未來將更進一步合作開發，來加強AWS和容器調度平臺Kubernetes的整合。
",https://www.ithome.com.tw/news/113868,"新聞,Red Hat,Amazon,AWS,OpenShift,Container"
113568,18,2017-04-29,開源OPNFV專案推出新版NFV框架Danube，開始整合DevOps,Danube新版透過加入自動化開發維運流程DevOps，能透過IT自動化、持續整合和持續交付，提供企業加速NFV功能測試和自動化部署," 企業要加速NFV開發測試和部署將有新作法。開源OPNFV專案最近推出的最新一版NFV框架Danube，開始加入自動化開發維運流程DevOps，能透過IT自動化、持續整合和持續交付，以提供企業加速NFV功能測試和自動化部署，並也持續改進NFV功能，以及提高NFV的資料傳輸層效能。目前Danube已正式開放提供下載使用。
新版NFV框架Danube釋出
新版開源NFV框架Danube也是OPNFV專案推出的第4個版本，相較於前一版的Colorado主要專注於擴大NFV應用和服務發展，NFV框架新版本Danube最大特色是將可供自動化協同維運和開發的DevOps帶進了NFV。Danube針對DevOps自動化和測試，結合上游的協同式開發、整合及部署，並在合併發布程式碼的應用當中，提供了整套的持續整合（CI）及持續交付（CD）工具，來優化相關程式開發、測試，以協助企業加快虛擬化網路功能測試及自動化部署。
Danube新版本還建立一個可供動態配置的實驗室資源，例如基於社群測試的實驗基礎架構（Community Test Labs Infrastructure），可以讓開發人員在不同應用情境和硬體平臺上，來開發測試和部署虛擬化網路功能；另外在OPNFV 的測試套件也加入壓力測試，並新增Common Dashboard 儀表板，能完整呈現NFV功能測試視圖。
Danube也支援多個涵蓋運算、儲存和網路虛擬化的開源專案，包括了雲端管理協作平臺OpenStack、軟體定義分散式儲存系統Ceph、虛擬化平臺KVM、SDN控制器軟體OpenDaylight、SDN網路作業系統ONOS，以及雲端網路虛擬化平臺OpenContrail。
OPNFV在新版NFV框架也特別加強提升NFV網路效能，像是能整合網路第2層和第3層的轉發，來加快資料傳輸層（Data Plane）的封包傳遞，並也增加更多可用於NFV效能測試的自動化框架和套件，例如能用在Open vSwitch虛擬交換器，提供加速封包處理所需的函式庫和驅動程式的資料層開發套件DPDK，還有可供效能評估測試的初步運算次級系統，以及另一個可用於儲存次系統的效能測試。
新版NFV框架也持續改進NFV功能，像是開始支援NFV管理和協作軟體堆疊（MANO）的基本功能，也強化了NFV基礎架構（NFVI）/虛擬基礎架構管理者（VIM）的核心功能，包括了IPv6、服務功能鏈（Service Function Chaining）、L2 及L3的VPN、故障管理及分析，並也整合由ECOMP與 Open-O合併即將推出的開放網路自動化平臺ONAP；另在NFV基礎架構的Network Telemetry應用部分也開始支援了服務保障（Service Assurance）template），以及增加做為常用YANG 與 TOSCA建模語言之間轉換的功能。
",https://www.ithome.com.tw/news/113568,"新聞,OPNFV,NFV,Danube,DevOps"
113309,18,2017-04-16,【Google雲端產品新布局】100項Next重點發布大整理,Google今年的雲端策略是主打自家雲端服務的多樣性和廣度，在Next大會中一口氣宣布了近百項更新，涵蓋基礎雲端服務、資料應用服務，到上層G Suite辦公室協作套件都有多項新特色," 今年Next大會格外不同，Google不只首次在舊金山Moscone會議中心舉辦了連續三天的全球雲端用戶大會，還發表了一連串的新服務與產品更新。Google Cloud行銷總監還整理出了100項Next 2017的重點發表。不同於去年，Google形容自己是雲端技術的領先，今年則是強調自家雲端服務的多樣性和廣度。
儘管，這100 項發布不全都是在Next首度發表的產品、服務或計畫，而更像是GCP平臺近期新特色的總整理，但可從中一窺Google今年布局雲端競賽的第一波戰略重心和特色。

Google Cloud搶進企業雲端最指標性的合作夥伴之一就是與SAP的結盟，SAP關鍵產品開始可以支援GCP平臺。

Google最新併購
 1  Kaggle：Google宣布正式併購全球最大資料科學家社群和競賽平臺，上有80萬名資料科學專家或愛好者註冊。
 2  AppBridge：這是Google沒有在主題演講中提及的另一樁併購案。溫哥華這家新創公司AppBridge的主要服務是，可將企業檔案伺服器的資料，快速轉移到G Suite和Google Drive上。
雲端資安
 3  雲端Identity-Aware Proxy（IAP）Beta版：可提供企業從應用層級來管控存取安全，可以限制重要應用系統，在任何地方的存取權限（帳號或群組），而不需要VPN。
 4  資料外洩防護（DLP）Beta版：可以自動分辨超過40種敏感資料類型，再從中遮蔽敏感資訊內容，避免外洩，連圖片或即時視訊影片中的敏感資料都可以即時遮蔽。可自行客製敏感資料特徵。目前已用於Gmail和Google Drive上。
 5  金鑰管理服務（KMS）正式版：專門用來產生和管理雲端平臺所用的對稱加密金鑰。
 6  GCP可強制用實體金鑰驗證：可強制任何GCP應用的存取行為，須搭配實體金鑰卡來驗證。
 7  保管箱（Vault for Google Drive）正式版：用於Google Drive的封存和電子蒐證服務（eDiscovery）的Vault推出第二版，新增了資料生命周期管理。
 8  自製安全晶片Titan：Google揭露了一款自行打造的安全晶片Titan，可從硬體層來提供加密機制，內建了硬體亂數產生器，可供加密驗證之用，並採用了專屬加密處理器和獨立記憶體以避免遭破解。已部署在GCP所用的伺服器。
GCP資料分析
 9  BigQuery資料傳輸服務封閉測試版：可以自動將SaaS應用的資料，匯入到BigQuery中。例如只需幾個點擊，就可以快速將Google帳號所管理的廣告資料全數匯入BigQuery，包括Adwords、DoubleClick Campaign Manager、DoubleClick出版者報表、YouTube內容與通路擁有者報表等。
 10  資料預處理服務Cloud Dataprep封閉測試版：這是用於預先梳理資料的工具，能自動辨識上傳資料的Schema架構、型態等，來整理資料，以便後續匯入機器學習服務進一步分析。
 11  全新商業資料集：新增更多商用資料集，包括了Xignite金融市場資料集、HouseCanary房地產資料、Remine房屋銷售資料、AccuWeather歷史天氣資料、道瓊歷史新聞資料。
 12  Cloud Dataflow正式支援Python：可用於批次和串流分析的Google資料處理服務Cloud Dataflow，過去只支援Java，現在開始正式支援Python。
 13  Stackdriver監控服務支援Cloud Dataflow測試版：可用Stackdriver分析和存取Cloud Dataflow上的任務Metrics，並設定特定的預警指標。
 14  Google雲端資料實驗室正式發布：這是一套互動式資料科學流程工具，可在Jupyter 編輯器上，用標準SQL、Python和Shell指令來建立資料分析流程。
 15  Cloud Dataproc更新：這個用來管理Hadoop和Spark等大數據服務的資料流程工具新增多項功能，如任務失敗時的重啟機制、GPU支援、雲端標籤、測試用的單節點叢集等。
GCP資料庫服務
 16  Cloud SQL資料庫服務PostgreSQL測試版：先前只提供MySQL資料庫服務，現在又新增加了PostgreSQL資料庫服務。
 17  支援微軟企業版SQL Server 正式版：Google運算服務GCE正式支援微軟企業版SQL Server，外加可支援Windows Server 容錯移轉叢集（WSFC）和SQL Server AlwaysOn 可用性群組。
 18  Cloud SQL的MySQL資料庫服務強化：32核VM的可用記憶體上限，增加到208GB，另外也新增IAM資源控管機制。
 19  Cloud Spanner：2月中發表的新服務，Google宣稱這是第一套可以水平擴充的關連式資料庫服務，也在NEXT大會中現場展示其快速擴充的威力。
 20  SSD永久磁碟效能改善：主要提升了IOPS效能。32核vCPU的虛擬機器所用SSD永久磁碟的IOPS可達讀取40K次，寫入30K次，每秒資料吞吐量800MB。16～31核vCPU的虛擬機器SSD硬碟IOPS也有提升。
 21  Bigtable服務可支援聯合查詢：BigQuery現在能查詢儲存在Cloud Bigtable上的資料，可用於大量分析如金融服務，或需低延遲的IoT應用。
GCP機器學習服務
 22  雲端機器引擎正式版終於來了：可供企業在雲端正式環境中訓練和部署自家機器學習模型。
 23  雲端影音智慧搜尋封閉測試版：只需提供想找的物件名稱或描述，可自動分析大量影片，找出有此目標物件的所有影片片段。
 24  雲端視覺API正式版：這是一個可以自動分類大批圖片的API，還可參考數百萬個儲存在Google知識圖譜上的物件來強化辨識能力，還新增了OCR文字辨識功能。
 25  機器學習進階解決方案實驗室（ASL）：提供線上訓練課程，也可申請到Google總部，與Google機器學習專家面對面諮詢。
 26  Cloud Jobs API：通勤API的新功能，可依據通勤時間和交通工具，來尋找方便通勤的職缺。
 27  機器學習新創競賽：Google和多家創投聯合舉辦，最高可獲得50萬美元的投資或100萬美元的GCP額度。
GCP費用與支援服務
 28  GCE運算服務降價：降價幅度最高達8%，但各地區折扣不同。
 29  新增長期保證租用折扣：只要用戶一次租用1年或3年期，可再折扣，最高折扣57%（視VM規格而定），不過只能租用限定規格的套裝VM。
 30  GCP免費試用期延長為1年：原有60天試用期延長至1年，連VM都可試用，額度300美元，用完即到期。
 31  新工程支援方案：增加了3種工程支援方案，按人月計價，解答開發問題的開發工程支援（上班時間回覆）、生產工程支援（1小時內回覆），以及最高等級的隨時待命支援（配備專屬Google工程師，全天15分鐘內回覆，全年無休）。
 32  Google雲端社群網站：專屬社群平臺，可提供教學、聚會，以及技術支援等。
GCP開發者平臺和工具
 33  AppEngine高彈性環境正式推出：Google的PaaS平臺AppEngine開放用戶可以彈性修改執行環境，也擴大支援主流開發語言，包括Java 8、Ruby、Go、Python 2和3、C#、PHP 5和7和Node.js。另外也支援Docker。
 34  Cloud Functions進入公測階段：這是Google的Serverless服務，進入開放測試階段，每月呼叫次數超過2百萬次才開始計費。
 35  Firebase正式整合GCP：App後端服務通用平臺Firebase更深度整合GCP，包括儲存功能整合到Google雲端儲存、也和Google Cloud Function整合，讓行動開發者更容易在App後端採用Serverless架構。
 36  Cloud Container Builder：可在GCP上布建Docker容器的工具，可建立自動化流程，以持續部署容器化應用。
 37  社群教材測試版：開放社群成員提出GCP How To的需求，或自己寫一份上傳。
GCP基礎架構
 38  宣布加州雲端營運中心：將在加州設立一個Region級雲端營運中心，鎖定美西用戶。
 39  宣布蒙特婁雲端營運中心：將設立加拿大境內第一座Region級的雲端營運中心。
 40  宣布荷蘭雲端營運中心：將在荷蘭設立一座Region級雲端營運中心，這是Google在歐洲的第五座資料中心。
 41  GCE容器服務新增管理節點功能：GKE節點新增了自動監控和自動修復功能，來確保容器叢集可用性。
 42  虛擬機器規格翻倍，支援64核心：虛擬機器可用vCPU數量從32增加到64個，單一VM記憶體上限可達416GB。
 43  內部負載平衡機制正式版：可動態分散內網IP的網路負載流量，微服務架構利器。
 44  跨專案網路測試版：可跨多個GCP專案建立共用網路，來簡化多租戶架構的部署。
企業協作套件G Suite
 45  新增小組雲端硬碟：可建立多人共享的雲端硬碟，刪除帳號仍保留檔案。
 46  新增Drive File Stream：將網路檔案串流發布到桌面PC，方便直接存取雲端檔案，而不用儲存在本機。
 47  雲端硬碟保管箱正式版：Gmail保管箱現在也支援Google雲端硬碟，可用來控管檔案的存取政策。
 48  小組雲端硬碟快速存取：利用機器學習技術，自動推薦常用檔案。
 49  Hangouts Meet正式版：Hangouts視訊推出免帳號小組視訊會議功能，只要使用驗證連結就可加入視訊。
 50  Hangouts Chat聊天室先期測試版：小組聊天室功能，可整合G Suite或第三方企業App。
 51  @meet對話機器人：Hangouts內建的會議排程機器人。
 52  Gmail Add-ons開發預覽版：可將第三方的應用整合到Gmail中，在網頁版、Android和iOS平臺版的Gmail中執行。
 53  可用Google Sheets編輯Salesforce商機資訊：不用匯入，就可以同步編輯Salesforce商機清單。
 54  Jamboard電子白板：將於5月上市的55吋電子白板產品，可整合G Suite。

不只搶攻雲端協作和辦公室平臺市場，Google推出了電子看板產品Jamborad，來進軍企業實體會議室，要打造出線上線下整合的數位工作職場。

Android和Chrome裝置
 55  安卓版Kiosk App登上Chrome：可在Chrome筆電或平板上安裝安卓版Kiosk App，來建立自助式服務。
 56  Chrome數位看板管理平臺試用：可用來測試Chrome數位看板的部署。
 57  Kiosk應用專屬Chrome裝置管理API：可管理Chrome裝置上的Kiosk執行政策。
 58  Chrome穩定性API：可供 Kiosk App開發者提高系統可靠度，例如系統當機時自動重開。
GCP企業案例
 59  高露潔－棕欖：280,00員工導入G Suite。
 60  迪士尼旗下消費者產品互動媒體DCPI：今年計畫轉移老舊系統到Google雲端，也將用AI來強化新的銷售方式。
 61  eBay：使用GKE容器引擎、機器學習技術和AI來打造個人化的自助購物助手ShotBot服務。
 62  HSBC銀行：導入Cloud DataFlow、BigQuery和相關資料分析服務來進行關鍵應用的POC驗證。
 63  英國保養品公司LUSH：用6周將電商網站從AWS轉移到GCP平臺。

Next大會展示攤位也出現了多家GCP導入企業的展示，例如英國保養品牌Lush攤位上，就詳細比較了導入GCP前後的效益。

 64  Oden科技：參加Google雲端新創計畫，改用GCP來部署自家工廠雲端平臺。
 65  Planet衛星影像公司：2月時轉移到GCP上部署，並釋出了全球衛星瀏覽平臺測試版，可提供每日更新的衛星空照圖。
 66  Schlumberer油田服務公司：使用GCP上的HPC服務來擴充自家資料分析平臺的運算規模。
 67  家得寶（Home Depot）：將官網轉移到GCP上，並採用CRE（Customer Reliability Engineering）服務，來因應黑色星期五和網路星期一的爆量採購流量。
 68  Verizon電信：15萬名員工導入G Suite。
合夥夥伴
 69 ～ 93  強化雲端生態系25項新計畫：Google在Next大會揭露了25項與合作夥伴的新計畫，涵蓋了G Suite、GCP MAP、裝置和教育領域的合作，Accenture （行動開發）、Alooma（資料分析整合）、Check Point（雲端驗證）、CloudEndure（轉移服務）、Coursera（訓練課程）、DocuSign（數位簽章）、Egnyte（整合Google文件）、iCharts（樞紐分析整合）、Intel（新世代CPU採用）、Intuit（推出Gmail Add-Ons）、Liftigniter（點擊行為分析）、Looker（支援BigQuery資料轉移服務）、MicroStrategy（整合Cloud SQL）、Pivotal（第一個CRE合作夥伴）、ProsperWorks（推出Gmail Add-Ons）、Qwiklabs（實作教育訓練）、Rackspace（第一家GCP管理服務商）、 Rocket.Chat（GCP新產品整合）、Salesforce（推出Gmail Add-Ons）、SAP（產品支援GCP）、Smyte（導入GKE容器服務）、Veritas（360度資料管理）、VMware Airwatch（企業行動應用管理）、Xplenty（支援Spanner新資料庫服務）、Zoomdata（支援Spanner新資料庫服務）
 94 ～ 100  雲端生態經營7項新作法：為了培養更多合格的合夥廠商，Google也推出了合作夥伴訓練計畫。其次則設立了全球夥伴獎，遴選出過去1年內，12家表現優異的雲端合作廠商。第三是推出了夥伴低利貸款計畫。第四，對既有合作廠商也提供了激勵機制（低利貸款、補助金、折扣）。第五是在Orbitera雲端市集上，推出了GCP合作夥伴專用測試碟。第六是設立Windows夥伴計畫，吸引Windows社群來解答GCP上的Windows問題。第七則開放合夥夥伴申請「專業能力認證」，由GCP背書具備特定雲端技術能力。

不同於過去以科技應用體驗或新技術展示為主，今年Next大會更強調各項GCP雲端解決方案的展示。

 相關報導  「Google前進企業雲端大挑戰」
",https://www.ithome.com.tw/news/113309,"新聞,google,雲端,Cloud,NEXT"
113307,18,2017-04-16,Google女王新四大策略鎖定雲端企業,在今年3月的第二次Next全球雲端大會上，Google雲端資深副總裁Diane Greene不只要展現過去一年全力推進企業雲端市場的成果，還要揭露下一步的策略," 今年1月，雲端管理業者RightScale如同往年一樣，照例發表了2017年的雲端現況大調查結果，這次調查了1,002位企業端技術人員，95％來自那些已上雲端的企業。根據這份報告，大型企業高達85％採取多雲策略，若不論企業規模，採用公有雲者平均導入了1.8朵不同廠牌的雲。
在千人規模以上的大型企業中，採用AWS來執行企業系統的比例，從去年的56％略增加到了59％，穩坐公有雲導入龍頭寶座，而排名第二的Azure，其大型企業採用率則從去年的26%大幅提高到了43％，Google雲端平臺也有不小的成長，採用率從9%增加到了2017年的15％，拉開了與IBM的差距。IBM採用率雖然也有成長，從去年的7％增加到今年的10％，因進步幅度不如Google，而排名第四。Google可說是成了公有雲第三大供應商，但仍遠遠落後於AWS和Azure。
也因此，在今年3月的第二次Next全球雲端大會上，Google雲端資深副總裁Diane Greene不只要展現過去一年全力推進企業雲端市場的成果，還要揭露下一步的策略。
今年NEXT規模更大，擴大為三天活動，超過200場演講，參加人數成長了5倍，從去年2千人增加到上萬人，活動場地也從港邊倉庫，改到了大型會議中心Moscone Center舉辦。Google今年主打自家雲端服務的多樣性和廣度，三天活動中提出了100項發布，包括了58項雲端產品或服務的更新，25項與合作夥伴的新計畫、10家企業應用案例和7項發展雲端生態系的新作法。從中可以看出Google女王吸引更多雲端企業的新四大策略。
策略1：積極結盟企業級IT同業，強化雲端生態系
Diane正式宣布與德國軟體大廠SAP策略結盟，也將聯手開發企業級軟體的功能。SAP執行董事Bernd Leukert表示，SAP HANA正式認證GCP，現在可以部署到GCP雲端環境，甚至以Cloud Foundation打造的SAP雲端平臺，也可在GPC執行。SAP HANA記憶體式即時分平臺軟體，也是SAP雲端ERP的核心，早在2015年就支援AWS，去年中開始支援微軟Azure，現在終於也支援GCP了。
Bernd Leukert預告，將和Google聯手開發更多企業應用功能，將Google機學習技術和SAP企業應用整合，G-Suite也將可以整合到SAP產品中，例如將Gmail整合SAP雲端顧客關係管理系統，或將Google試算表與SAP BusinessObjects Cloud整合等。另外，SAP也正與Google聯手開發一套企業公有雲資料代管的解決方案，來符合法規遵循或企業風控的需求。不只SAP，Google也宣布和多家企業級IT產品公司結盟，如Intel、VMware、Pivotal、Check Point等。
另外Google也推出多項發展雲端生態系的新作法，如為了培養更多合格的合夥廠商，Google推出了合作夥伴訓練計畫。其次則設立了全球夥伴獎、推出了夥伴低利貸款計畫。對既有合作廠商也提供了激勵機制，更在Orbitera雲端市集上，推出了GCP合作夥伴專用測試碟。另外，還設立了Windows夥伴計畫，吸引Windows社群來解答GCP上的Windows問題。
策略2：主打大型標竿企業案例，建立業界口碑
第一天開場演講中，多家財金五百大企業如Verizon電信、HSBC匯豐銀行、全美第二大零售業家得寶Home Depot、迪士尼、高露潔－棕欖和eBay等公司的IT主管，上場揭露導入G-Suite或擁抱GCP的經驗。Alphabet執行董事長Eric Schmidt更直言：Google也有大型企業用戶了！
高度仰賴大量委外的高露潔－棕欖，決定在2016年開始採用G-Suite，花了6個月導入到全球28,000名員工，現有9成員工協作都透過Google Drive。高露潔資訊長Mike Crowe表示，下一步是希望使用機器學習來分析從SAP產品產生的資訊。美國電信公司Verizon也轉而擁抱G-Suite，規模比高露潔更大，準備擴大導入到全球15萬名員工。
美國第二大零售業者家得寶The Home Depot去年花了半年將官網轉移到Google，就是為了要採用Google去年剛推出的CRE服務，來撐過黑色星期五和網路星期一的網路搶購人潮。家得寶下一步準備將2000年累積至今的資料放到Google BigQuery上來進行分析。
全球最大跨國銀行HSBC也開始將100PB資料量的傳統資料倉儲系統搬上Google Cloud雲端，還要使用BigQuery和機器學習技術來防制洗錢。迪士尼旗下消費者產品互動媒體技術長Mike White則已經將迪士尼網站全部轉移到Google雲上，日常報表都由BigQuery產生，而不用自己開發來釋出開發人力，聚焦在如何用強化說故事的服務，例如用機器學習來協助設計故事的角色，很快也會用AI來強化新的銷售方式。
策略3：打造全套式分析平臺服務，來擴大AI平臺吸引力
不少大型企業擁抱GCP的關鍵因素是機器學習服務，Google已深知自己這項強項，更試圖打造出一個能夠涵蓋資料來源整理、資料準備、資料轉移上雲端、大數據分析到新一代水平擴充式資料庫技術的全套式資料分析服務，因此新增數十項資料分析和資料庫的新服務，例如推出了新的資料預先處理服務Cloud Dataprep。這些都是為了更能吸引企業將更多資料放上雲端，進而來串接Google的機器學習分析服務。
Google雲端人工智慧與機器學習首席科學家李飛飛也宣布了Google機器學習的未來戰略目標是「AI大眾化」（Democratizing AI）以及幾項AI新服務，Google雲端機器學習引擎終於釋出正式版本了。Cloud Vision API則釋出1.1測試版，新增加了OCR文字辨識功能，可用來辨識法律合約、論文、書籍等大量文字的文件內容。
Google也宣布併購了全球最大資料科學社群和競賽平臺Kaggle，擁有近80萬名資料專家註冊。李飛飛解釋，AI大眾化的關鍵是得降低AI的進入門檻，使它能被廣大的開發人員社群、使用者及企業所接受，才有能力應用它，而延攬Kaggle團隊將可加速此一任務。
策略4：G Suite辦公室協作平臺成主角，更要搶攻實體會議室
Google Cloud不只是IaaS、PaaS或資料分析服務，另一個搶攻企業市場的重點產品則是G Suite，這也成了Next大會第二天的重點發表，大多是聚焦在G Suite協作功能強化，尤其在Google Drive有5項更新，鎖定了企業內部分享檔案的需求，也就是想成為企業內部的共享網路硬碟服務。另外一個Google沒有著墨太多的是Gmail將開放Add-ons擴充功能，目前還處於開發者預覽版。Gmail Add-ons將允許第三方開發者商，在Gmail內提供App功能，等於可以將Gmail變成另一個新的App平臺，就像是Chrome Add-ons擴充功能市集。
不只搶攻雲端協作和辦公室平臺市場，Google推出了電子看板產品Jamborad，來進軍企業實體會議室。Jamboard是一臺具有55吋4K觸控螢幕的雲端電子白板，還能存取Google Docs、Google Sheets、Slides、Drive、Calendar等雲端服務。結合G Suite和Jamboard，Google試圖要打造出線上線下整合的數位工作職場平臺。直到了2017年Next大會後，Google才真正成為企業雲端市場的真正競爭者之一。
 相關報導  「Google前進企業雲端大挑戰」
",https://www.ithome.com.tw/news/113307,"新聞,google,雲端,Cloud,NEXT,Diane Greene"
113093,18,2017-03-29,Kubernetes 1.6新版大變革，新增角色權限控管，叢集上限倍增達5千節點,"今天Google正式釋出Kubernetes 1.6版，其中包含Beta版本的RBAC機制，讓叢集管理員可以針對特定使用者、服務帳號，進行更精確的資源存取控制。除此之外，新版本更讓叢集規模從2,000個，擴大至5,000個節點，比前一版多了2.5倍"," 先前Kubernetes在新版規畫中，就預告了1.6版將新增角色存取控制機制（Role-Based Access，RBAC），引起眾人高度期待這個可以讓容器叢集管理更進一步的功能。果不其然，Google今日正式釋出了Kubernetes 1.6版，如期推出了RBAC機制Beta版本，讓叢集管理員可以針對特定使用者或服務帳號的角色，進行更精確的資源存取控制。除此之外，新版本可支援的叢集規模從2,000個節點，擴大至5,000個，可支援的Pod總數量也提高到15萬個。
第一特色：擴大叢集規模，加強叢集聯邦功能
在此版本中，Kubernets總共新增了5大特色。Kubernetes早在半年前就開始採用CoreOS的組態管理、服務探查工具etcd，這次改版更將Kubernetes底層架構預設改成etcd v3版本，因此可支援的叢集規模也擴大至5,000個節點，可支援的Pod規模也增加到15萬個（Pod是由多個容器組合的一個容器包）。
Google表示，若需要規模超過5,000個叢集，或是服務靠跨多個資料中心或多雲架構，新版本還加強了叢集聯邦（Federation）功能，使用者得以組合不同區域的Kubernetes叢集，而系統會確保跨區的叢集的環境部署的一致性。
Kubernetes在1.5版中就推出的命令程式介面Kubefed仍處於Beta版，不過增加了更多本地端功能，例如開發者可以利用Kubefed指令，系統可自動完成叢集的DNS組態設定。
第二特色：靠角色存取控制機制加強安全
過去，Kubernetes是透過節點本地端的設定檔來設定權限，使用ABAC（Attribute-Based Access Control）模式，例如可透過配置設定不同帳號所能存取的API權限。
但在新版中，則新增了角色存取控制機制，可以直接用API來取得不同帳號的權限管理政策，來控制使用者帳號或服務，可將系統資源指派給特定命名空間，讓所屬帳號來存取。
對於想要將Kubernetes升級至1.6版本的企業，在系統權限控管轉換時，Google提出了兩種解法。第一種作是讓ABAC、RBAC機制並行使用。Google舉例，系統會先透過RBAC authorizer處理API請求。如果RBAC authorizer並未核准，接著ABAC authorizer則會接手。
第三特色：強化使用者對Pod的控制
新版本中，Kubernetes也加強使用者對Pod的控制程度，像是指定每個Pod一個節點標籤（Node Label），藉此限制Pod只能在特定節點、叢集中運行，目前此功能也處於Beta階段。
而節點標籤所能完成的設定不僅只是如此，開發者也能自己調整，指定特定的主機名稱、硬體架構、作業系統版本等參數。
除了限制Pod在特定節點上運作，開發者也可以將Pod排除於特定節點上運作。Google舉例，企業可藉此限制使用者只能存取部分節點，或是利用節點標籤，讓Pod在特殊規格的硬體上運作。
第四特色：儲存動態分配
1.6版現在內建了常用雲端儲存服務物件，包括 AWS、Azure、GCP、OpenStack和VMware vSphere的儲存空間，都不需要在手動配置就能使用。這也意味著，當有物件刪除釋出儲存空間時，就可以用程式自動閒置的外部儲存資源指派給新的Pod，來實現動態儲存分配的效果。
另外，Google表示，現在Kubernetes中的持久磁碟（Persistent Volume）子系統也提供兩組API資源，讓使用者、系統管理員了解儲存資源的使用現況。這兩組API分別是PVC（PersistentVolumeClaim）以及PV（PersistentVolume）物件，讓儲存可以擺脫各異質環境所制定的相異規則，使Pod可以橫跨不同的雲端、本地端環境運作。此外，Google表示，結合StorageClass物件及動態建置磁碟（Dynamic Volume Provisioning）功能，企業不需要先前準備建置作業，就可隨需建立、刪除儲存物件。
在新版本中，StorageClass也預設支援AWS、Azure、GCP、OpenStack以及VMware vSphere等環境，「使用者不需手動設置StorageClass物件。」Google表示。
第五特色：更新容器Runtime介面及背景常駐程式
「雖然使用者不見得會直接和容器Runtime、API Server直接互動，但它們是組成Kubernetes的基礎元件。」Google表示，在1.6版中負責檢查節點組態是否正確的Kubelet，現在已經支援Docker容器Runtime介面（Container Runtime Interface，CRI），不過此功能目前還處於Beta版。
此外，Kubernetes現階段也有支援其他的容器Runtime，像是符合開放容器實作標準的Cri-O、以Hypervisor為基礎的Frakit，以及CoreOS的rkt。
",https://www.ithome.com.tw/news/113093,"新聞,Kubernetes,叢集管理,容器技術,google,Docker,Container"
112828,19,2017-03-24,Container雙周報第30期：Docker和CoreOS雙雙捐出容器核心Runtime,在Docker跟CoreOS分別將核心專案貢獻給CNCF後，除了可以為容器技術帶來另一波創新，同時也可以確保技術社群繼續合作," 重點新聞（03月11日-03月24日）
·容器核心元件變成公共財，Docker和CoreOS雙雙將自家容器Runtime捐給雲端原生運算基金會
在去年Docker將Docker Engine內的核心元件Containerd開源，為容器格式標準化踏出關鍵一步後，近日Docker和CoreOS一同宣布，Containerd和rkt專案都要貢獻給雲端原生運算基金會（CNCF）。Docker技術長Solomon Hykes表示，在過去4年中，他看見Docker為產業帶來前所未見的顛覆、創新，「將Containerd貢獻給CNCF，將為容器生態系帶來下一波的創新動能。」而CoreOS技術長Brandon Philips表示，將rkt、Containerd這些專案貢獻給CNCF，也能確保容器社群繼續合作。
為何Docker特別屬意CNCF，Solomon Hykes解釋，有3大原因。首先，Containerd是Docker的核心元件，已隨Docker部署到數百萬臺機器上，希望透過CNCF組織持續推動容器化風潮。再者，Google早就將Kubernetes貢獻給CNCF，雖然Kubernetes從1.5已經支援Docker，但Solomon Hykes和Kuberntes專案關鍵人物都希望，讓Containerd成為Kubernetes的重要核心runtime，捐給同一個機構有助於整合。另外，CNCF也擁有不少與容器相關的重要開源專案，像是gRPC以及Prometheus。更多資訊
·IBM Bluemix容器服務也開始支援Kubernetes
容器調度的戰局中，Kubernetes目前已經是聲望最大的專案，除了GCP、AWS及Azure三大雲環境都支援，現在連IBM旗下的Bluemix PaaS平臺的容器服務，也宣布開始支援Kubernetes。不過，目前這個服務還是位於Beta版本。
IBM表示，企業在Bluemix除了能使用Docker及Kubernetes，加速應用程式交付外，還可以結合Watson的雲端認知服務。而在使用者在Bluemix上建立Kubernetes叢集後，就可以同時運行無態、有態應用程式。更多資訊
·DC/OS 1.9版釋出，強化大數據分析服務和自動化部署
距離1.8版釋出才5個月，Mesosphere近日又迅速推出了DC/OS 1.9版。Mesosphere表示，新版簡化了大數據平臺的建置，甚至只需點擊幾個按鍵就能部署多種大數據服務平臺。也新增了7個資料服務，可供企業快速部署，包括了Alluxio、Lightbend、DataStax、dataArtisans、Couchbase、Redis Labs、Confluent。
1.9版特別強化了資料服務自動化部署機制，開發者可以只靠一行指令，部署Spark、Cassandra、HDFS、Kafka及Elasticserach等工具，而DC/OS也降低每個服務實例的大小，藉此提升服務實例的密度。另外，這版本中，Mesosphere也開始支援了Kubernetes及Docker Swarm，讓開發者可以將這些大數據服務部署於容器中運行。更多資訊
·Container6大資安迷思
對比Container，不少企業仍抱持傳統VM技術更為安全的想法。過去任職排名財星500大的化學廠商Albemarle資安長， 現在為容器資安廠商Twistlock技術長John Morello表示，他不時聽到有關容器技術安全議題的錯誤認知，「它們像都市傳說般存在，不停地被覆誦。」
第一迷思：容器也能越獄（Jailbreaks）。他認為，越獄聽起來很嚇人，但是現實中卻很少發生，「多數攻擊是鎖定攻擊應用程式，若已入侵應用程式，何必還需越獄呢？」John Morello表示，對企業真正重要的問題在於，了解駭客發起攻擊的時間點，以及系統是否已遭攻擊。
第二迷思：Container得解決多租戶問題，才可以用於正式環境。他解釋：「沒有一家企業真的需要因此而困擾。」只要將應用程式拆分為多個微服務，並且部署在VM中即可解決。
第三迷思：靠應用程式防火牆，就可以保護容器應用。他表示，因為容器應用經常在幾秒內就會切換所在主機，甚至連資料流量（payload）都採加密傳輸的狀況下，「應用程式防火牆可說是無用武之地。」容器安全性高度仰賴開發者的資安意識，得開發出夠安全的微服務架構才行。
第四迷思：端點防護可以保護微服務。John Morello表示，端點雖然很適合保護筆記型電腦、PC以及行動裝置，「但是端點防護並不是為保護微服務而生」，它也無法介入Docker runtime以及容器調度的運作。
第五迷思：在Dockerfiles的FROM指令加上latest參數就能取得最新版本。他解釋，容器漏洞管理並不如表面上簡單，「原始映像檔不一定永遠都會隨著專案更新」，取得最新版映像檔Base Layer，並不代表會將映像檔中每一層都同步更新。
第六迷思：無法分析容器中的惡意行為。John Morello表示，容器行為可以監控。有幾個方法如，容器manifest檔詳細描述了容器的行為，可以用來轉換出資安特徵檔。再者，容器組成會有一定的合理性，例如開發者常會把幾個知名應用系統組成一包容器微服務來執行，容器部署比VM部署更可有基本規則可參考。另外，容器只有在更新程式時才改變，一旦發現Container運作行為變了，「不是組態設定改變，就是遭受攻擊。」更多資訊
·Intel自家容器技術Clear Containers釋出2.1.1新版，支援Docker Swarm及Kubernetes
在2015年Intel為了卡位輕量級作業系統，也推出自家的容器技術Clear Containers，在近日，Intel宣布推出Clear Containers 2.1.1版，同時支援目前市面上的主流容器調度工具，如Kubernetes、Docker Swarm。主要有3個特色：一、加強容器網路功能，支援更複雜的網路組態設定。二、將容器工作流程隔離於命名空間，加強隔離性及安全性。第三是加強了工作流程監控功能。更多資訊
更多產品動態
·Docker將Containerd專案捐給雲端原生計算基金會更多資訊
·AWS版Docker登上AWS市集更多資訊
·資料中心作業DC/OS推出1.9版，加強支援容器技術及大數據服務更多資訊
·Apache Mesos 1.2.0版釋出，強化Mesos容器化功能更多資訊
·紅帽更新Fedora Atomic，加強軟體打包功能更多資訊
·Google App Engine開始支援ASP.NE核心更多資訊
·Google GCP支援PHP 7.1版更多資訊
·紅帽OpenShif支援企業靠New Relic監控應用程式運作更多資訊
·開發板UP board支援Docker容器更多資訊
Container資源
※官方：MapR如何讓大數據Docker Container變得更輕量
※官方：Aqua Security確保Kubernetes部署安全的方式
※觀點：Docker官方開發流程參考架構
※觀點：容器技術安全的六大迷思
※How-To：用DataDog監控Kubernetes
※How-To：用Docker Swarm設立高擴充性系統
※How-To：建立Windows Docker持續整合流程
※How-To：用Docker運作加密Windows網頁
※How-To：操作Docker機密管理
※How-To：替Docker化Elasticsearch建立快照
※How-To：打造樹梅派的64bit Docker OS
※How-To：監控Docker中運作Java應用程式
※How-To：確保容器化MongoDB的運作安全
",https://www.ithome.com.tw/news/112828,"新聞,IT周報,Docker,Kubernetes,容器技術,Container,容器資安,Docker Swarm"
112625,19,2017-03-08,微軟Visual Studio 2017正式版出爐，效能比舊版快3倍,微軟在Visual Studio 2017發表會上宣布，Visual Studio 2017正式上市（GA），並開放使用者下載。新版VS主要提供開發者用來建置雲端和行動應用，且加快開啟、載入和除錯的速度。另外，微軟宣稱，VS 2017比VS 2015的效能快3倍。," 今年適逢Visual Studio發行20周年，微軟舉辦了為期2天的Visual Studio 2017發表會，並在本周二（3/7）宣布，Visual Studio 2017正式上市（GA），現在已開放使用者下載。同時，微軟也發布了Visual Studio系列產品的更新。
新版Visual Studio（VS）主要提供給開發者用來打造雲端、行動平臺等應用，加強了開發者的生產效率和效能，且微軟宣稱，VS 2017的效能比VS 2015快3倍。
除了強化效能外，新版VS也新增了Xamarin Forms預覽器（Xamarin Forms Previewer），提供開發者能在編寫XAML程式的同時，就能預覽iOS和Android行動App的使用者介面。

（圖片來源／微軟）
在開發方面，VS 2017新增支援.NET Core 1.0和1.1版應用程式的開發，且強化Container的開發，支援Windows和Linux平臺上容器化（Containerized）應用程式的建置。另外，新版VS也擴增支援在Azure App Service雲端服務中託管.NET Core容器化應用程式，並簡化了Container的部署。
除此之外，開發者在新版VS中將不需要建立專案（Project）或解決方案（Solution），就能直接開啟檔案，VS 2017還加快了開啟、載入和除錯的速度，並提供使用者輕量級和模組化的安裝程序，讓使用者能選擇自己想要安裝的元件。
另外，VS 2017也改善了IntelliSense的過濾與搜尋功能，強化了Navigate To的過濾及預覽能力，以及嵌入即時程式碼分析的即時編輯功能等。
而微軟在去年11月發布Mac版Visual Studio和Visual Studio Mobile Center的預覽版，以及Visual Studio Team Foundation Server 2017正式版。在此次的Visual Studio 2017發表會上，微軟釋出了Team Foundation Server 2017更新版1（Update 1）、Mac版Visual Studio預覽版4和Visual Studio Mobile Center預覽版更新。
另外，根據微軟官網，Visual Studio每月活躍用戶增加了25％，輕量版Visual Studio Code開發工具的每月活躍用戶則達130萬人，Mac版Visual Studio則增加了2倍的每月活躍用戶。
",https://www.ithome.com.tw/news/112625,"新聞,微軟,Visual Studio 2017,Container,Xamarin,開發,GA"
112302,19,2017-02-21,容器資安廠商Aqua推網路奈米切分功能，加強容器網路連線安全,Aqua共同創辦人兼技術長Amir Jerbi表示，網路分割並不是近年才有的觀念，但是隨著VM、軟體定義網路的技術進步，使得微切分（Micro-Segmentation）技術興起，而容器技術的到來，使得情況變得更加複雜," 過去來自Intel Security、CA Technologies及Imperva的團隊成員，看到容器技術在未來的發展性，因此組成了容器資安廠商Aqua。而近日他們也推出了Aqua 2.0平臺，利用奈米切分（Nano-Segmentation）功能，加強容器的網路安全。
Aqua共同創辦人兼技術長Amir Jerbi表示，網路分割並不是近年才有的觀念，但是隨著VM、軟體定義網路的技術進步，使得微切分（Micro-Segmentation）技術興起，像是VMware所推出的Ｎ網路虛擬化平臺NSX，隨著容器技術的到來，使得情況變得更加複雜。
Amir Jerbi表示，在同一臺主機上運作的容器，可以和彼此溝通，但是傳統的防火牆、網路設備，卻無法追蹤它們的溝通行為。同時，容器也可以跨主機連線，「但是就外面看來，是主機在進行連線，而非在它之上運作的容器」，使得流量控制變得更為困難。此外，與容器不只可以彼此連線，也要跟資料庫、持久儲存設備溝通。
而Aqua實作奈米切分的方法在於，「使用容器產生的中介資料、系統數據，自動產生奈米切分」，透過容器調度工具，平臺會指派容器負責特定的Logical Service。
利用Aqua平臺，使用者可以監控Container的網路連線行為，無論是外部連線、內部連線，以及存取公共網路等事件。Amir Jerbi表示，一旦使用者完成固定的網路連線拓樸，「就無法形成新的連線路徑。」除此之外，企業所應訂的網路資安政策，不會因為切換該服務的實體位置、調度工具而改變。
",https://www.ithome.com.tw/news/112302,"新聞,容器安全,資安,Container,容器技術"
111650,19,2017-02-04,IT月報｜雲端IT焦點回顧 (2017/01),谷歌旗下雲端平臺新增金鑰管理服務（Cloud KMS），以協助企業建立、使用及銷毀於雲端上所使用的加密金鑰。微軟宣布加入車聯網戰局，針對汽車產業推出連網汽車平臺，協助車廠打造智慧車,"  Google   金鑰管理 
Google Cloud新增金鑰管理服務，美、日、臺測試上線
Google於旗下雲端平臺新增了金鑰管理服務（Cloud KMS），以協助企業建立、使用及銷毀於雲端上所使用的加密金鑰，該服務目前僅於包括美國、臺灣與日本等數十個特定市場上線，仍屬於測試階段。用戶能夠在Cloud KMS上管理對稱加密金鑰，用以保護儲存在Google雲端平臺或其他環境中的資料，藉由Cloud KMS API就能建立、使用、旋轉或銷毀金鑰，以直接整合到提供身分管理的Cloud Identity Access Management 或是稽核的Cloud Audit Logging等雲端服務中。（詳全文）
 
 微軟   車聯網 
微軟推車聯網雲端平臺，助車廠打造智慧車

全球瘋車聯網，微軟也宣布加入戰局，不過微軟並非要研發自家智慧車產品，而是針對汽車產業推出連網汽車平臺（Microsoft Connected Vehicle Platform），今年內便會推出預覽版。微軟業務發展執行副總裁Peggy Johnson表示，汽車產業正面臨連網、自動駕駛與電力化等挑戰，微軟看準車廠在相關軟體能力的需求，而推出基於Azure雲端平臺的新連網汽車平臺。該平臺主要將協助車廠將車上新增的各種感測器蒐集到的資訊，進行相應的處理，達到車廠預設的相關智慧連網功能，具體作法包括，將Cortana虛擬助理、Dynamics商用軟體、Office 365、Power BI與Skype等產品與車載資訊系統整合等，目前已有雷諾日產（Renault-Nissan）汽車聯盟宣布採用。（詳全文）
 
 紅帽   混合雲 
強化混合雲管理，紅帽釋出新版雲端管理工具CloudForms 4.2

紅帽正式推出新版雲端管理工具CloudForms 4.2，這套工具是紅帽基於去年12月底所取得的開源ManageIQ Euwe技術，已強化了數項在管理OpenStack上的能力，包括支援浮動IP分配、備份管理與拓墣視覺化等。紅帽CloudForms資深產品管理師Geert Janse指出，在微軟Azure雲端平臺上，已新增Azure資源管理API，其中包括記憶體、硬碟和網路I/O等功能。而在Google 雲端平臺上，CloudForms 4.2則新增加Google雲端監測API。（詳全文）
 
 AWS   AI 
AWS收購AI資安公司Harvest.ai，也要用人工智慧強化雲端安全
亞馬遜AWS宣布以約1,900萬美元，收購網路資安公司Harvest.ai，以強化企業機密資料儲存在AWS的安全性。AWS執行長Andy Jassy指出，現在AWS也正在積極研發人工智慧（AI）技術與相關服務，目前在公司內部已經有數以千計的員工持續投入中。Harvest.ai兩位創辦人先前任職於美國國家安全局（NSA），主要運用機器學習和人工智慧技術，來監測員工以防止企業關鍵資料外洩和應用程式遭駭客攻擊，也就是說，Harvest.ai藉分析公司關鍵IP的用戶行為，進而辨識是否有未經公司許可的人士偷竊企業智慧財產權文件等重要資料，一旦被駭Harvest.ai會阻止該攻擊，以防止企業機敏的資料外洩。（詳全文）
 
 亞馬遜   無人機 
亞馬遜研發以飛船作空中倉儲，在雲端打造無人機送貨轉運站
美國專利文件公布亞馬遜一項美國專利，顯示這家電子商務巨人可能將發展空中倉儲，未來可發展配合無人機送貨的新服務。根據美國專利商標局的文件，這項空中交付中心（Airborne Fulfillment Center）的技術是一個看似巨型飛行船的倉儲中心，能夠飛行或飄浮在城市上空，但是也具備了螺旋槳等動力裝置以移動到適當的地區。它可以乘載倉儲人員與運送貨物，而亞馬遜藉由小型飛船能夠將人員與貨物往返運送於地面及空中，同時可以清運廢棄物。此外，它也擔任無人機的母艦，消費者下單之後，亞馬遜再利用無人機將貨物運送到府，之後再返回飛船上。（詳全文）
 
 甲骨文   以色列 
甲骨文宣布在以色列特拉維夫城建雲端創業加速器
甲骨文計畫在以色列特拉維夫城（Tel Aviv）建雲端創業加速器（Startup Cloud Accelerator），以協助甲骨文加快在地的雲端創新技術發展，而該全球性專案將投資數百萬美元。甲骨文產品開發資深副總裁Reggie Bradford指出，未來5至10年間，雲端將主導未來新商業模式的創新與發展，但截至目前為止只有百分之六的企業將工作負載搬上雲端。由於以色列特拉維夫城是繼美國矽谷第二個重要的創業地區，在發展雲端上，新創公司往往是發展新技術和新商業模式的關鍵，透過成立雲端創業加速器可以協助新創公司運用甲骨文的軟體與服務打造自家的平臺，以研發更多新技術與創新服務等。（詳全文）
 
 IDC   公有雲 
IDC：2017年全球雲端IT支出達442億美元，其中61%經費將砸在公有雲
研究機構IDC發布今年雲端IT基礎架構追蹤季報指出，2017年全球雲端IT產品及服務支出將近442億美元，其中近百分之六十一預估投資在公有雲資料中心，而其中百分之十五則投資在私有雲環境。綜觀企業投資在整體IT基礎設施，包括伺服器、企業儲存和乙太網路交換器，和去年同一季度相比將增加約百分之十八。IDC儲存系統研究總監Natalya Yezhkova指出，預估下一季度，企業投資在雲端IT基礎架構上的金額將增加，主要擴大全球超大規模資料中心上投資支出，另外，也預估越來越多企業將在自家資料中心建私有雲。而來到2018年，IDC預測將近五分之四的IT企業將開始打造混合雲架構，而對於公有雲廠商來說，2020年營收和2015年相比將成長3倍。（詳全文）
 
 Nvidia   線上遊戲 
Nvidia將GeForce Now搬上雲端，連Mac Air都可玩大型多人線上遊戲

Nvidia在CES上推出了一款GeForce Now for PC and Mac雲端遊戲，Nvidia藉由提供玩家一臺GRID雲端虛擬電腦，讓玩家用筆記型電腦，甚至可用如Mac Air等，在雲端主機上，直接從遊戲商Steam、Origin、UPlay等取得遊戲，載入完成之後，再將畫面傳送到自家的電腦主機上。而這一項服務採用Nvidia的雲端伺服器，內嵌GTX 1080、GTX 1060 獨立顯卡以進行模擬運算，而Nvidia指出，GeForce Now for PC and Mac預計在今年3月正式推出。（詳全文）
 
 蘋果   資料中心 
蘋果將在美國亞利桑那州建資料中心，掌管雲端服務與高科技製造等
根據美國聯邦政府發布的通知指出，蘋果正在計畫在美國亞利桑那州梅薩市（Mesa City）建立一座全球資料指揮中心（Global Data Command Center），除了將會整合現在位於美國奧勒岡州和北加州的資料中心之外，也將生產以及組裝高科技產品，與負責雲端服務iTunes與iCloud等。另外，蘋果也計畫於亞利桑那州境內建造太陽能發電廠，預估能夠生產約50MW的電量，除了能夠供應該全球資料指揮中心所需要的電量之外，也計畫對外販售電力。
",https://www.ithome.com.tw/news/111650,"新聞,Cloud,雲端"
111531,19,2017-01-31,Container雙周報第27期：Canonical加入容器調度戰局，推出自家版本Kubernetes,重點新聞（01月21日-02月10日）," 重點新聞（01月21日-02月10日）
·Canonical加入容器調度戰局，推出自家版本Kubernetes

容器調度工具在去年掀起戰局後，目前Kubernetes聲勢相當浩大，除了OpenStack、紅帽、CoreOS等廠商都力挺外，近日連Ubuntu背後的Linux作業系統廠商Canonical也開始加入戰局，要推出自家版本的Kubernetes。Canonical表示，自家版本Kubernetes的目標，在於讓開發者可以更簡單地在公有雲、本地資料中心、裸機環境，甚至，開發者自用的筆記型電腦上部署Kubernetes。
Canonical也列出自家Kubernetes的幾大特色：
1.完全相容於Kubernetes 1.5.1版
2.支援容器網路介面（CNI，Cotainer Network Interface），開發者可以利用Cailco、Weave這類以CNI為基礎的軟體定義網路應用程式
3.不再預設支援Elastic Stack，不過開發者仍然可選擇Elastic Stack作為部署選項
4.新增Kubernetes主節點（master）、工作節點（worker）相關的除錯指令
更多資訊

·Docker 1.13版推出，加強內建容器調度功能
繼去年DockerCon上推出Docker 1.12版，把容器調度功能Docker Swarm mode納入Docker引擎，一舉使多主機環境也能部署多容器應用程式。
近日，Docker則更近一步，在Docker 1.13版本中，讓開發者可以用Docker Compose文件，部署Swarm Mode服務。Docker表示，透過Docker Yml文件，開發者不僅能指定支撐每個服務所需要的實例數目，也可以設定系統滾動式更新規則（Rolling Update Policies）。
除了加強調度功能外，Docker官方也列出了1.13版本的幾大特色：
1.新版CLI可以相容於舊版背景程式（Daemon）
2.新增清除指令，讓使用者可以看到Docker目前使用的硬碟空間，便於進行系統清理
3.重新組建CLI，加強Docker操作性
4.新增實驗性的系統監控指令，使用者可以從所有容器中，下載其運作服務的Log紀錄檔
5.加強建置功能，簡化使用者建置映像檔的程序
6.Azure版Docker及AWS版Docker將要進入正式環境
更多資訊
·紅帽推出OpenShift容器平臺3.4版，加強容器儲存功能
紅帽推出OpenShift容器平臺3.4版，此版本除了讓傳統應用程式、雲端原生應用程式，同時都能建置無狀態（Statelesss）、有態（Stateful）儲存，也加強了多租戶功能，讓應用程式可以在混合雲環境中部署。
紅帽OpenShift副總裁暨總經理Ashesh Badan表示，OpenShift容器平臺3.4版除了可滿足既有應用服務的需求，也並提供建置與部署雲端原生應用程式所需的工具與服務。企業客用戶也能混合雲環境中，滿足有態與無狀態應用服務儲存需求。
目前OpenShift在私有雲、公有雲環境的支援選項，包含了OpenStack、VMware、AWS、Google GCE以及微軟Azure。紅帽也提供了4種相異的部署參考架構（Reference Architecture）。第一種是支援紅帽自家第八版的OpenStack（OSP 8）。再者是VMware vCenter 6.0版。在公有雲環境部署上，OpenShift除了支援Google GCE，也相容於目前公有雲龍頭AWS，「妥善利用Kubernetes及AWS平臺原生的高可用性功能。」紅帽表示。
為了讓企業更容易在自家資料中心、雲端化基礎架構上使用容器調度工具，OpenShift容器平臺3.4版中的調度工具，則是以Kubernetes 1.4版本為基礎，加強了以下三大功能：叢集儲存、工工作自動化，以及容器網路功能。
像是此版本中，OpenShift開始支援使用者建置不同種的儲存類型。紅帽表示，企業為了要在叢集中使用儲存功能，過去都得必須透過系統管理員，預先在後端儲存系統保留一定的儲存空間，「但是其中的問題在於，很難預測需要提前準備多少儲存空間。」
而紅帽在新版本中，則提供了動態建置（Dynamic provisioning）儲存的選擇，例如AWS、OpenStack Cinder、GCE、GlusterFS，以及Ceph RBD等儲存套件。開發者只需要讓雲端環境與系統後端的儲存架構一致，「系統會自動切割出任何大小的儲存空間，系統管理員不需要預先準備。」更多資訊
·雲端服務新創Platform9正式推出託管Kubernetes服務
在去年雲端服務新創公司宣布推出託管Kubernetes服務（簡稱PMK，Platform9 Managed Kubernetes）後，近日Platform9首席架構師Bich Le表示，此服務已經進入正式版本。他表示，許多企業用戶已經同時在本地、雲端部署Kubernetes，「必須透過一個統一平臺，對這些Kubernetes叢集進行管理。」
Bich Le表示，Kubernetes目前是領先的容器調度框架，「打造它的工程師，擁有大規模使用容器化應用程式的經驗。」而Kubernetes的設計也擁有許多優點，例如節點（Pod）的設計，讓各個容器間彼此密切合作，但是在維護程式碼時，同時可確保相異容器的獨立性。
不過，在使用Kubernetes也擁有許多挑戰。首先，要設定正確的組態相當困難，「設定錯誤會導致效能表現不佳。」再者，Kubernetes也不容易在跨雲、跨資料中心運作。
而Platform9所推出的託管Kubernetes服務，最先標榜的優點就是易於使用，提供企業選擇不同的硬體平臺、作業系統中部署高可用的Kubernetes叢集，像是自家資料中心、AWS、Google GCE，或是微軟Azure皆可。
PMK的設計架構中，總共包含了兩個重要元件：資料平臺以及控制平臺。在這兩層架構中，分別都會部署Platfrom 9 Agent，透過最上層的管理平臺，完成監控、管理等任務。Bich Le表示，由於管理平臺的運作，就如同使用SaaS應用程式一般，「只要申請帳號，就可以開始部署Kubernetes叢集了。」更多資訊
·容器安全平臺Twistlock登上Oracle Cloud
標榜保護Docker容器運作安全的容器安全廠商Twistlock，在今年初宣布與甲骨文合作，使用Oracle Cloud的企業用戶，可以透過Twistlock，確保其Docker Container的運作安全。目前Oracle Cloud除了包含IaaS、PaaS、DBaaS等服務，也提供CRM、HRM及ERP等SaaS服務。
Twistlock技術長John Morello表示，Oracle新提供的裸機雲端環境（Bare Metal Cloud），讓企業不需要透過Hypervisor也能運作工作流程，同時也可以享受雲端環境便利的操作性，「在Oracle Cloud運作Twistlock，與在一般VM環境並沒有任何差別。」
此外，企業用戶在Oracle Cloud下載Docker映像檔運作容器時，Twistlock平臺也將提供Runtime防禦、漏洞管理等服務。另外，John Morello表示，許多使用Oracle Cloud的企業偏愛選擇Java環境，因此除了偵測映像檔底層Layer漏洞外，Twistlock也會提供偵測開發套件JDK漏洞的服務。更多資訊
更多產品動態
·Docker 1.13版推出，開發者可用Docker Compose文件部署Swarm Mode服務更多資訊
·無伺服器微服務平臺IronFunctions推出Alpha 2版，支援.NET Core更多資訊
·新版紅帽CentOS Atomic Host支援用Container運行Kubernetes更多資訊
·託管混合雲服務新創Platform 9正式推出託管Kubernetes服務更多資訊
·Twistlock 1.7版推出，加強Runtime防禦架構更多資訊
·甲骨文Oracle Cloud開始支援Twistlock，保障Docker容器運作安全更多資訊
·紅帽Linux管理介面Cockpit 129版推出，修復Debian及Fedora更新的問題更多資訊
·Kubernetes新創公司Skippbox釋出開源專案Kubewatch，開發者可透過Slack得知k8s運作情形更多資訊
·Linux作業系統廠商Canonical也推自家版本Kubernetes更多資訊
Container資源
※觀點：如何開始往微服務架構移動
※觀點：Kubernetes的過去、現在及未來
※觀點：Docker 1.13有什麼新東西？
※觀點：比較Docker Swarm、Kubernetes以及Mesos
※影片：迪士尼如何用Kubernetes實現多雲架構
※How-To：Docker化Ruby應用程式
※How-To：用CodeShip跟Packer建立Docker映像檔
※How-To：DIY裸機Kubernetes GPU叢集
※How-To：如何將Jenkins CD環境轉移到Kubernetes
※How-To：在半小時內設定OpenShift叢集
",https://www.ithome.com.tw/news/111531,"新聞,紅帽,Container,Docker,Twistlock,Kubernetes,IT周報"
111212,19,2017-01-17,Rancher跨出Linux世界，開始支援Windows Container,Rancher共同創辦人Will Chan表示，目前業界仍然不少的工作流程的運作，相當仰賴Windows Server，在可預見的未來中，Windows在企業IT環境中，仍然會占有一席之地," 繼上版Rancher 1.2版開始支援調度工具Kubernetes，近日更Rancher更宣布，因為使用者頻繁地提出要求，希望Rancher可以相容於Windows Server 2016。因此在1.3版中，Rancher將要支援Windows Container。Rancher共同創辦人Will Chan表示，此版本除了修改使用介面、更改DNS引擎，也改善了Kubernetes及相關工具的使用經驗。
Rancher 1.3目前僅是開始實驗支援Windows Container，「但為了讓Container技術能受到企業更多青睞，這是重要的一步。」Will Chan表示，目前業界仍然不少的工作流程的運作，相當仰賴Windows Server。而在可預見的未來之中，Windows在企業IT環境中，仍然會占有一席之地。
Will Chan表示，Rancher的目標，是讓應用程式可以橫跨異質雲端環境及基礎架構中運作，「達到真正的可攜帶性」，而支援Windows Container正是達成此目標的關鍵一步。
",https://www.ithome.com.tw/news/111212,"新聞,Rancher,Container,容器作業系統,容器技術,Windows Container"
111019,19,2017-01-11,【2017關鍵趨勢：Container】Docker邁入穩定成長期，大型雲端企業比新創更愛用,Container戰場已從廠商技術拉鋸戰，走入企業，大型雲端企業採用率更破2成，若加上小規模試用者更是過半數，大型雲端企業比新創小公司更愛用Docker," 容器風潮火熱，大型公有雲廠商Google、AWS及Azure都紛紛推出容器服務，在私有環境中，VMware也得支援Docker滿足企業需求。不過令人好奇的是，容器究竟有多熱？提供基礎架構監控服務的Datadog，以1萬家導入公有雲、私有雲技術的企業用戶為母體，根據其蒐集線上運行的一手資料，展開一場全球最大規模的Docker導入率普查。

在2015年5月時，研究顯示僅有8.2%的雲端企業開始導入Docker，僅經過1年，2016年同期，Docker使用率已經突破一成，上升至10.7％。
針對這一成使用Docker的企業，Datadog也更深入地進行分析，發現Docker採用率與基礎架構規模大小，兩者呈現正相關。基礎架構規模超過500臺伺服器的公司，Docker的導入率則超過20％，加上正嘗試使用的企業，其比例就超過一半，剩下只有不到4成的大型雲端企業從未使用過Docker。
反之，基礎架構規模小於100臺伺服器的中小企業，Docker導入率則低於20％，超過80％從未使用過Docker。
Datadog所進行的研究顯示，容器技術雖不如Docker宣稱的火爆，但的確能看見企業導入率逐漸上升的趨勢。同時，Docker的使用率，隨著基礎架構規模成長，也能瞥見企業對於這門技術抱持一定信心。不過，如此狀況，也可能出於大型企業擁有更多研發資源，因此較敢放手嘗試新技術。
掀起這波狂潮的Docker技術長Solomon Hykes，在去年度DockerCon中也大喊：「現在沒人關心Container了，因為應用程式才要緊」，更點出Container的重點戰場，已經從各容器廠商間的技術拉鋸戰，開始走入各家企業的資料中心，在正式環境中，扮演運行應用程式的角色，而Docker化應用程式也已經超過了46萬個。
因此，容器調度工具也是今年度的重要戰場。除了Kubernetes、Docker Swarm以及Mesos外，去年底連AWS也推出了自家的調度工具Blox。而Google看上有8成企業在Linux環境中運行Java應用程式，或是Windows環境執行.NET應用程式，更在Kubernetes 1.5版大舉支援Windows Server Container以及Hyper-V Container，使它成為目前唯一通吃Linux、Windows容器調度的利器。挾如此優勢，Kubernetes應會穩坐2017年容器調度工具的龍頭。



",https://www.ithome.com.tw/news/111019,"新聞,Container,Docker"
110708,19,2016-12-31,IT月報｜雲端IT焦點回顧 (2016/12),Google加入Cloud Foundry Foundation（CFF），將與CFF聯手推動企業採用開放技術以實現雲端上的高品質軟體遞送。IBM繼揭露Serverless技術後，終於開始在IBM Bluemix雲端平臺推出OpenWhisk服務，同時將OpenWhisk開源釋出," SAP將製造業MES搬上HANA企業雲
全球商業軟體應用公司SAP將製造執行系統（Manufacturing Execution System，MES）搬上HANA企業雲（HANA Enterprise Cloud），以作為工業4.0解決方案的一部分。SAP在HANA企業雲上推出一個製造執行系統（MES）App，供企業統合各項操作流程，以整合商業和製造程序，並且可以搜集物聯網中所有感應器和裝置中所產生的資料。SAP資深副總裁Hans Thalbauer指出，現今無論公司規模大小都需要更快地調整，以回應市場需求，並藉以調整產品製造方向，SAP透過將製造業MES搬上HANA企業雲，能夠協助企業回應快速變動的市場需求，以加快製造流程。（詳全文）
 
Google加入基金會，加入PaaS開放平臺卡位戰
Google宣布加入Cloud Foundry Foundation（CFF），成為該基金會的黃金會員，將與該基金會聯手推動企業採用開放技術以實現雲端上的高品質軟體遞送。而CFF的任務在於，推動全球認識及採納Cloud Foundry，同時鼓勵社群的貢獻，迄今已經凝聚了超過60家會員，包括EMC、 VMware、IBM及思科等白金會員，以及華為、NTT與Verizon等黃金會員。（詳全文）
 
IBM加入Serverless戰局，推出OpenWhisk

IBM繼今年初揭露Serverless技術後，12月12日終於開始在IBM Bluemix雲端平臺推出OpenWhisk服務，同時將OpenWhisk以開放原始碼模式釋出，提供企業自建Serverless架構。Serverless可謂最輕量級的雲端應用程式，也可說是事件驅動型的應用程式，目前IBM以兩種方式提供OpenWhisk，其一是在Bluemix雲端平臺提供OpenWhisk服務，另外將OpenWhisk以開源方式提供企業自建，OpenWhisk目前亦是Apache基金會的育成專案之一。IBM於2016年初已公開OpenWhisk測試版，12月推出後增加多項功能，包括支援Java、Node v6、Python等更多程式語言，增加NodeJS、Python及Swift的即時除錯，並整合Bluemix的Kafka訊息處理服務，與增加Visual Studio Code支援。（詳全文）
 
雲端競爭失利，思科公有雲服務明年3月關閉
思科（Cisco）宣布2017年3月關閉網際雲服務（Cisco Intercloud Services，CIS），網際雲於2014年3月發表，此服務為基於OpenStack的多租戶代管平臺，目的在於協助客戶建立混合雲端環境，同時具備運算、網路與儲存等公有雲業者所供應的服務。思科雲端平臺暨服務副總裁Kip Compton指出，過去兩年雲端市場的變化劇烈，在企業用戶要求思科協助發展數位轉型的雲端策略下，思科開始將雲端策略重心從連結不同雲端資源轉移，轉向到協助客戶建置及管理混合雲端環境。而思科預計於2017年3月31日關閉思科網際雲服務，並且遷移到其它的雲端平臺，包括OpenStack等。（詳全文）
 
AWS EC2大擴張，GPU、VPS虛擬主機、FPGA通包

AWS EC2一口氣推出7種新的虛擬機方案，從訴求只要3個按鍵就啟用的VPS虛擬主機，到全新推出的FPGA運算服務皆有。AWS新推出的7款EC2虛擬機方案，包括全新的Amazon EC2 Elastic GPU、Lightsail與F1，以及虛擬機規格提升的T2、R4、I3及C5。Amazon EC2 Elastic GPU是首度EC2虛擬機可添加GPU運算能力，如同為電腦加上GPU繪圖加速卡。另一個新推出的運算方案是F1，其為在EC2平臺執行FPGA，使用者可將FPGA程式碼封裝成映像檔，上傳至F1執行，或是採用AWS市集上的FPGA映像檔。（詳全文）
 
Google雲端開始支援IBM軟體
Google宣布旗下的Google雲端平臺（GCP）已經正式成為合格的IBM公有雲（IBM Eligible Public Cloud），能夠用來部署各種IBM軟體。IBM的合格公有雲名單早已囊括其他雲端供應商，除了IBM自己的Softlayer與Bluemix外，還包括亞馬遜EC2及微軟Azure，而Google為主要雲端供應商中最晚進榜的。根據IBM的自帶軟體授權（Bring Your Own Software License，BYOSL）政策，已經或打算利用Passport Advantage或從代理商取得IBM軟體授權的客戶現在已可在Compute Engine上執行相關軟體，此一政策適用於多數IBM軟體，從中介軟體、DevOps產品到資料與分析工具等。Google亦鼓勵客戶提出IBM軟體執行於Compute Engine上所需進行的調整。（詳全文）
 
亞馬遜新推3項雲端AI服務，力爭AI大餅

亞馬遜在AWS re:Invent大會宣布推出3項雲端AI服務，將亞馬遜內部採用的機器學習與深度學習技術，以雲端服務的型式提供給所有非機器學習專家的開發人員使用，包括圖像辨識、文字轉真人語音，以及如同Amazon Alexa的對話式應用服務，亞馬遜終於加入由微軟與Google領先的雲端AI服務市場。AWS推出雲端AI服務所訴求是，讓非機器學習專家的軟體開發人員也能使用機器學習與深度學習技術。整個流程中的資料處理、整理、演算法、機器學習模型，以及類神經網路架構的擴充性等，都由AWS在雲端架構中完成，而以API型式提供機器學習功能，讓軟體開發人員可以輕易呼叫使用圖像辨識、自然語言處理等機器學習與深度學習的功能。（詳全文）
 
IBM在華生雲端平臺上新增3項功能，新增上萬個視覺辨識圖庫
IBM宣布在華生雲端平臺（Watson Cloud platform）上新增3項新功能，分別是即時說話者自動分段標記（Speaker Diarization）測試版、視覺辨識（Visual Recognition）和華生偵測服務（Watson Discovery Service）。透過這些新功能，開發人員能夠增加智慧視覺辨識服務，和在網頁和手機應用程式上進行語音文字辨識。IBM指出，在視覺辨識功能上，已新增了上萬個視覺辨識標籤，供開發者辨識各式各樣的情況，如辨識人類、地點、活動與場景等。而華生偵測服務則進一步整合Watson APIs，包含Alchemy Language API和Document Conversion API。（詳全文）
 
Google、英特爾聯手強化企業雲端，著眼AI、容器、物聯網與安全4大領域研發
Google與英特爾宣布企業雲端平臺合作，著眼機器學習、開源碼容器叢集平臺Kubernetes、物聯網及安全等領域的共同開發，以提升與亞馬遜、微軟Azure、IBM與甲骨文競爭企業客戶的實力。英特爾與Google原本即在資料中心處理器的開發與驗證上合作多年，這次則將觸角延伸到企業雲端服務上，藉此吸引用戶將系統由傳統資料中心環境轉移到雲端。雙方合作首先包括針對多種工作負載，Google將連結英特爾物聯網裝置與Google雲端平臺以進行資料分析，作為零售與製造業決策分析之用，一則藉由深化英特爾硬體和GCP之間的安全整合，以確保企業雲端的安全性。此外雙方也將共同投入技術訓練及市場開發。（詳全文）
",https://www.ithome.com.tw/news/110708,"新聞,Cloud,雲端應用"
109876,19,2016-12-26,最夯容器技術Docker安全機制大剖析,Docker Swarm核心維護者孫宏亮表示，Docker並不為安全而生，其價值並非與虛擬機器一拼安全性，而是以滿足資源及流程標準化、易用性，以及表現極好效能的前提，將安全性提升到最好," 「各位在使用Docker的時候，是否有了解它是否安全？」著有《Docker源碼分析》，現任職於中國容器雲平臺服務商DaoCloud，同時也是Docker Swarm核心維護者的孫宏亮表示，在Docker問世之後，許多傳統虛擬化技術的擁護者紛紛開始議論它的安全性，例如共享作業系統核心，一旦單臺機器收到外部攻擊，傷害範圍也會波及至作業系統核心上運作的Container。
誠然，傳統VM廠商對Container的安全顧慮有其理由，而在Docker官方宣稱其容器技術是絕對安全（Secure by default）的同時，孫宏亮卻拋出了一個令人玩味，表面看似相當矛盾的解讀：「Docker既安全，也不安全。」
究竟為何他會給出這樣曖昧不清的解讀，必須先從Docker Container技術的本質作為切入點開始探討：在任何環境，建置、派送及運行任何應用程式。
在常見的企業級IT架構中，最基本的結構，從底層的伺服器，到最上層的應用程式，中間總共包含了5層大架構。最下層是由Intel x86或是IBM Power組成的實體機器，在這些裸機之上，企業則導入vSphere、KVM、Hyper-V或是Xen等傳統虛擬化技術。利用VM技術，企業則可在虛擬機中運作Linux、Windows等異質作業系統。
第四層則是讓系統軟體與應用程式相互連線的中介軟體，最後才是開發團隊每天接觸的應用程式，「單是支撐一支應用程式運作，底層就得需要如此多的元件在支援。」
Docker可消弭開發、維運團隊間的鴻溝
對於開發者，每日首要目的就是關心應用程式。但是，底層的伺服器、虛擬化平臺、中介軟體等都是由維運團隊在支撐。但是仍然不免因為業務上衝突，導致團隊工作不順利。孫宏亮舉例，像是開發者往往宣稱程式可以在開發環境的機器上運行，但是交付到測試人員手中時就漏洞百出，甚至到了部署階段，維運人員更是不停抱怨部署失敗率極高。
雖然孫宏亮一直提倡開發團隊與維運團隊得要好好攜手合作的觀念，但經常事與願違，「但是在Docker誕生之後，我認為此事的契機到了。」例如任何企業在交付軟體的過程中，勢必得要經過開發、測試及上限部署、維運等過程。利用Docker推出軟體封裝標準的概念，除了各部門能夠友好相處外，也能讓交付應用程式的過程更順利。
然而，開發者在享受Docker快速部署、建置特點，常常被它的易用性所蒙蔽，進而忽略背後隱含的資安問題。孫宏亮表示，在中國開發圈內經常流傳著一句話：「資安永遠是IT架構的遮羞布。」當企業關注資安議題時，其重要性不在話下，反之，當企業輕忽了必要的資安問題，就得為捅出的簍子付出巨大成本。
Docker並非為安全而生
Docker這樣技術具備具有許多優點，Docker問世後，其官方一直所堅守的立場：在任何環境，建置、派送及運行任何應用程式。雖然Docker社群也不停加強此技術的安全性，但是對於資安議題的考量，其實不是Docker的初衷，「Docker並不為安全而生」，孫宏亮表示，其價值並非與虛擬機器一拼安全性，而是建立起資源及流程標準化、易用性，以及表現極好的效能，「在滿足這些前提之下，把安全性做到最好。」
孫宏亮表示，任何新興技術在進入企業級市場時，都會檢視確定其是否滿足資安需求，「一旦有安全疑慮，根本無法進入企業級市場。」
Docker有哪些安全性疑慮?
目前使用者對於Docker安全性的檢討不再少數，其中最為明顯的質疑是與host主機共用作業系統可能引起的資安問題，再者是Docker為了提高效能表現，進而降低安全性。想要拉高企業採納容器虛擬化的比例，Docker也得加強其容器技術的安全性。
孫宏亮認為，Docker安全發展總共可歸納為四大面向，第一是資料通訊安全，包含客戶端至Docker引擎，以及Docker引擎至儲存庫間傳輸映像檔的安全考量。第二則是映像檔本身的安全性，透過縮小尺寸提升其安全性。
再者是Docker Container的安全，孫宏亮企業業務系統都掛載於映像檔，但是仍然是透過Container交付服務，「如果容器出現問題，整個企業就無法正常運作。」
最後則是網路安全，他解釋，許多企業在使用Docker前，就已經對於內部資料中心網路架構有所規畫，如果選擇導入Docker，其架構勢必得要進行調整，「這時網路安全就變成重要議題。」
孫宏亮也觀察，在中國與Docker相關的新創公司都會建立自家的公共容器映像檔儲存庫，而不法人士只要能取得上傳、下載映像檔權限，便可以暗自修改組成映像檔地各層Layer，「污染儲存庫中全部的映像檔。」但為何Docker會引發如此資安疑慮，是這門技術注定無法迴避的缺陷嗎？「是因為大家使用Docker缺乏好的規範，才會導致如此多問題。」他說。
利用Linux Kernel機制，加強Docker安全性
一夕紅遍全球IT界的Docker，走出一條與VM不同的路。不過孫宏亮強調，雖然Docker是理念的創新，「但真正厲害的還是Linux Kernel，Docker借助了許多Linux內建的機制」，例如隔離機制nampspace及cgroup，還有拆分root權限的Capabilities等。
Docker借用了cgroup、namespace實現了資源及程序隔離，孫宏亮比喻，一般人生活在社會中都得保有一定程度的隱私，但突然碰上有心人士的探查，隱私權就會受到侵犯，「而在Linux的世界中，namespace就可以保護各別Container的隱私，防止被人探查。」
而cgroup則是控制系統所使用的資源分配，像是儲存、CPU、硬碟I/O，以及設備權限，「cgroup分配資源的機制為上限分配。」
他解釋，假設系統所有可用的資源數量為X，只要各應用程式索求的資源數目總和不超過X，此時系統資源的分配就不存在問題，「在涉及資源劃分時，也要有一個控制器，確保機器上的資源應用正常。」

在開發軟體的流程中，開發者往往宣稱程式往往可以在開發環境的機器上運行，但是交付到測試人員手中時就漏洞百出，甚至到了部署階段，維運人員更是不停抱怨部署失敗率極高。圖片來源／孫宏亮

需要更細緻的權限控管，可以用Capabilities拆分root權限
再者，在Linux Kernel中內建的安全機制Capabilities則用於拆分root權限，「權限很重要，一旦越級會非常嚴重。」在Linux中，root握有最大的系統執行權限，若遇到Container使用root權限來執行時，將可能發生許多危險，此時就可以利用Capabilities機制，將root權限進行拆分。
孫宏亮舉例，假設原本root權限可以執行50項程序，在重新劃分後，可執行事務只剩20項，「此時root的安全性就提高。」但是使用Capabilities機制也會替使用者帶來不便，孫宏亮表示，由於Linux Kernel將root權限進一步細分，「這時候就會造成Container內root權限受到限制。」
他表示，理想狀況下，容器內的root權限得跟host主機上root權限相等，並且不為使用者帶來使用上的不便，「這就是使用者命名空間的任務，讓Container擁有很大的執行權限，但是不受host主機產生影響。」
最後則是Linux Kernel內建的安全運算模式（Secure Computing Mode，Seccomp），Docker借助此機制，協助Docker Container與Linux Kernel溝通，「使用者利用系統呼叫，透過作業系統核心滿足其需求。」不過，
孫宏亮認為，一旦某個Container可以任意呼叫Linux Kernel也會存在許多危險，例如，透過Container呼叫Kernel，要求重新啟動系統，或是在Linux Kernel內任意插入新模組，「都相當危險。」
而Container所誕生的目的，本身就非要如VM般一樣運作基礎架構，「而是要如應用程式一樣，負責運行上層服務，「因此就必須利用Seccomp機制，禁止不需要的系統呼叫權限。」
企業擁抱Docker也得留意安全問題
透過這些機制，使用Docker仍然可以獲得一定程度的保障，「本可避免很多資安問題，但使用者卻自己暴露出漏洞。」孫宏亮認為，許多人認為Docker不安全，其實追本溯源，都可發現是出自於人為因素，「使用者沒有重視安全議題。」
共用作業系統核心的確是Docker目前不安全的弱點，但是在Docker逐漸加強資安的同時，Linux Kernel也不停在進步，「兩者一同發展，所擁有的優勢相當多。」
孫宏亮也直言，企業想要使用Docker，仍然是存在一定門檻。操作妥善，資安並不會讓使用者頭痛，「但是使用不當，一旦內部資料被偷光，使用者可能還渾然不查。」

在開發軟體的流程中，開發者往往宣稱程式往往可以在開發環境的機器上運行，但是交付到測試人員手中時就漏洞百出，甚至到了部署階段，維運人員更是不停抱怨部署失敗率極高。圖片來源／孫宏亮

",https://www.ithome.com.tw/news/109876,"新聞,Docker,孫宏亮,Container"
109872,19,2016-12-25,HITCON創辦人教你三大容器安全術加強網頁安全,即便使用者眾多、砸重金打造的安全防護不亞於他人的網站，都能夠被駭客找到遠端執行的漏洞，代表全球網站都暴露在被攻擊的高風險下," 作為一名資安工作者，臺灣資安技術社群 CHROOT 、臺灣駭客年會 HITCON 創辦人，目前任職於美商 vArmour 資深工程師的徐千洋，已經養成習慣，經常在各大網站瀏覽，檢查是否有該站管理者沒有察覺的漏洞存在。他表示，位居Alexa網站評比全球網路流量第61名的色情網站Pornhub，由於使用者人數眾多，自然是吸引駭客攻擊的大目標。為此，Pornhub也發起一個漏洞懸賞計畫，歡迎資安高手回報該網站存在的任何漏洞及弱點，成功入侵者也能獲得豐厚的獎賞。
Pornhub懸賞最高金額的前兩名漏洞，都是歸類在遠端命令執行漏洞，總計金額高達2萬5千美元，「而最高金額的獎金已經被人領走。」
即便如Pornhub，使用者眾多、營收規模如此大，更用砸重金打造的安全防護不亞於他人的網站，都能夠被駭客找到遠端執行的漏洞，「這意味著全球更多網站都暴露在類似風險之下。」
讓駭客領取Pornhub最高懸賞金的遠端命令執行漏洞，不僅是駭客常見的攻擊手法，一旦執行成功也相當具有威力，網站中各類的設定檔、原始碼，或是儲存在SQL資料庫的使用者帳號密碼，全部都在攻擊者的掌握，更讓管理者近乎喪失網站的主導權。徐千洋也直言，許多大型網站一旦使用者帳號密碼外洩，往往並非是單純SQL injection攻擊事件，「很可能該網站已被徹底地入侵、掌控了。」這不禁讓徐千洋思考，一名網站管理員有無可能阻絕這些攻擊，即便駭客找到零時差漏洞，也無法成功的入侵？
市面常見的網站，大多都會透過網頁伺服器如Httpd執行連線服務，串連到程式語言直譯器，最後透過PHP等程式語言執行網頁應用程式。但是這段常見的運作流程，從一開始接通網路連線後，就已經暴露在遠端執行的風險中，徐千洋表示，若中間任何一環存在漏洞，就可能導致駭客入侵，例如執行Shell等命令。他觀察，目前網頁服伺服器而言，想找到漏洞並非易事，風險最高的遠端命令執行漏洞數量更是稀少。不過程式語言、網頁應用程式則不乏高風險漏洞，像是通用漏洞平臺CVE的資料庫中，PHP存在漏洞的漏洞，範圍涵括6至10等高風險，「網頁應用程式的漏洞更是多如牛毛。」
徐千洋也歸納駭客經常使用的遠端執行攻擊手法，像某網站經常性的遭入侵，很可能是該網站存在遠端攻擊漏洞，比方說熱門開發套件Wordpress如果突然爆出來不及修補的零時差漏洞，就很可能遭致駭客攻擊。或該網站開放上傳外部資料的功能，如傳送大頭貼、文件等檔案。這類允許外部程式執行寫入權限是高風險行為，一旦使用者疏忽，攻擊就可以將檔案寫入特定目錄，留下後門作為發動攻擊的入口。在成功拿下Webshell後，也能植入簡單的PHP後門一句話木馬，下達攻擊指令。乍聽之下，網站管理者只能成為駭客的待宰羔羊，徐千洋表示，解法就是利用容器技術強化網站安全。
徐千洋表示，過去利用Unix運行網頁伺服器的時代，避免使用root權限執行系統服務是基本的安全守則，碰上非用root權限不可的情況，使用者執行完服務後，也一定要執行權限降低為一般使用者。再者，搭配chroot環境運作網頁伺服器也能提高整體安全性，「就像是加上了一把鎖」，即便遭受攻擊也能將損害限縮在此環鏡，而利用Container建立網站，其中安全觀念與Unix的操作不謀而合，「容器是chroot的強化版本，照理來講安全性會更高。」他說。
容器3大安全強化術
徐千洋表示，使用者可透過Docker中內建的3個原生機制，加強使用容器的安全性。第一個安全術是善用命名空間（Username Space），讓Container不再使用root權限執行。在去年推出的Docker 1.9.0版本中，Docker就將此機制納入其中，「即使在Container用root權限執行服務，也並非host主機握有的root權限。」
當Container在運作程式時，位在使用者命名空間的執行環境，系統會透過host主機取得其執行身份。即使在Container中，某使用ID利用root權限執行程式也不會有影響，「因為Username space中，系統會以該使用者真正握有root權限」，但是在Container底下有root權限的帳號，僅是host主機底下的一般權限帳號，「從host主機的角度來看，所有容器下執行的程序都只是一般權限執行而已。」
第二是善用安全機制Capabilities，劃分特權帳號所能能執行的數十個程序，一一給予控制。徐千洋表示，雖然此機制早在Linux中就能使用，但是礙於使用者必須要熟悉Unix底層操作，並且具備Linux Kernel的相關之至，「因此一直無法普及。」
利用Capabilities機制，使用者可以將root權限所能執行的功能，向下切割成數十個，讓無root權限的使用者也能執行某些程序。舉例，在Unix的設計中，使用者如果想要啟用數字小於1024的port，必須取得root權限。但是利用Capabilities，不需要透過root權限，就可以讓某些服務開啟低於1024的port。
最後一招則是Linux內建的安全模組AppArmor，掌管某程式在執行的當下，對於其他檔案的操作。例如，如果某檔案被限定只能讀取，即使使用者取得可以任意讀寫的root權限，也會被AppArmor所阻擋。
徐千洋也歸納，使用者可以利用3個基本法則，加強網站服務的安全性。第一原則就是避免使用root權限運作服務，「即便使用Container也盡量不要使用root權限。」
再者，不得將網頁程式、設定檔寫入納入服務執行的權限。他表示，許多開發者會因為使用者群組的設定而輕忽此事。例如網站管理者、網頁應用程式擁有者都給予相通的權限，當駭客成功利用遠端攻擊打入網站時，就可以將許多惡意程式植入其中。但是，要防範此事，「只要讓網頁應用程式擁有者的權限，跟網站伺服器擁有者的權限不一致即可。」最後則是服務程序具有寫入權限的檔案不可以被執行。
使用習慣也影響網站安全
但是，除了技術面問題，使用者習慣也是安全的一大考驗，「有些使用者就是不信邪，非得要用root權限運作服務」，一旦駭客取得最高權限，不管系統管理者如何搶救都是徒勞無功。
所以針對Container安全強化，徐千洋也提出了幾個建議。例如，如果不了解Capabilities機制如何運作，「就將它所有的權限去除」，發現某些程序無法執行，再依序地加回原有的權限。
而容器映像檔也是能增進安全的施力點，像是移除不需要的檔案及程式，「像是運行微服務、網站伺服器，根本不會用到GCC編譯器」，多餘的檔案只是徒增駭客所能攻擊的範圍。也因此，開發環境、正式環境中，應要使用不同的容器映像檔。再者，如果網站開發使用者上傳檔案的功能，也必須做出相關管制。偵測到Container中新增了檔案，也可呼叫外部防毒系統掃描。一旦偵測到攻擊事件，產生Log的記錄也要傳送到資安監控中心SOC及資安事件管理平臺SIEM，「不只是阻擋攻擊，還要知道攻擊來源為何，以及使用何種攻擊手法，這樣就可以找到系統內可能存在的漏洞。」
",https://www.ithome.com.tw/news/109872,"新聞,網頁安全,Container,容器,徐千洋"
110407,19,2016-12-19,瞄準容器混搭平臺，Kubernetes 1.5新版釋出，竟然開始支援Windows Server自家容器,它是目前主流容器調度工具中，除了微軟自家產品外，唯一通吃Linux，Docker又能支援Windows Server Container的平臺，可以甚至單一叢集可以同時調度這兩類容器節點," 暨9月Gogole釋出Kubernetes 1.4版本，靠2指令就能部署一套容器叢集，以及新增跨叢集、跨雲環境部署後，近日也推出了1.5版，其中的重要亮點在於，它是目前唯一市面上能支援Windows Container的容器調度工具。Google表示，根據使用者的回饋，他們發現企業不僅想要在容器中，運行保存狀態（Stateful）的應用程式，「最終還想要透過Kubernetes運作所有的應用程式。」因此在此版本中，Kubernetes 1.5版除了支援分散式資料庫系統的運作，對於保存狀態、無狀態（Stateless）的應用程式，確保它能維持一定的中斷服務目標（Disruption Service Level Objective）。
在新版本中，Kubernetes總共新增了2組Beta功能：StatefulSet以及PodDisruptionBudget。Google表示，StatefulSet是一組控制器，用於辨別叢集中，不同節點（Pod）的身份，「透過它來安排系統部署、水平擴充的順序。」
而運行在Kubernetes上的應用程式，只要是負責持久儲存（Persistance Storage），或是具備一組持久身份辨識碼（Persistent identity），都可以透過StatefulSet，執行創建、擴充、刪除，以及儲存等功能。不過由於目前此功能還處於Beta版，並不支援1.5版前的Kubernetes。
第二個Beta功能則是PodDisruptionBudget。Google表示，它是一組API物件，在系統運行時，此功能會確保叢集維持運作一定數目、比例的複本（replica），「在叢集維運上，應用程式部署者可以確保系統不會同時關閉過多節點，導致遺失資料的狀況發生。」
Kubernetes 1.5版除了2個重要的新Beta功能外，也推出了不少Alpha版功能。第一個是命令程式列工具Kubefed，開發者能透利用此工具管理叢集聯邦（Federated Cluster），例如在現有的聯邦中，移除、新增叢集。再者是容器Runtime介面（Container runtime Interface，CRI），允許開發者選擇不同的容器Runtime（Pluggable container runtimes）。
Kubernetes會讓Windows、Linux世界變得更加混亂
雖然新版Kubernetes的功能都是位於測試階段，但是其中有一個重要亮點在於，它是目前主流容器調度工具中，唯一有支援Windows Server Container的一者，甚至還相容於Windows Server 2016平臺。
過往的既定印象中，Linux與Windows是互不相容的環境，Windows程式不會運作在Linux平臺上，反之，Linux應用程式也無法在微軟平臺上運行，「如今，Kubernetes 1.5出來後，一切都變了。」Mirantis技術暨行銷內容總監Nick Chase表示，此版的Kubernetes支援了Windows Server Container。
他解釋，單一Kubernetes叢集中，將可同時包含運行Linux Container的Linux節點，以及執行Windows Container的Windows節點，也因此「提供真正的容器混合使用體驗。」
",https://www.ithome.com.tw/news/110407,"新聞,容器調度工具,Kubernetes,Container,容器技術,分散式系統,Windows Server Container"
110370,19,2016-12-16,不惜放棄自家調度工具，3件事讓紅帽PaaS決定換Kubernetes,紅帽PaaS平臺OpenShift原本也有內建自家的容器調度工具，但為了這三個理由，紅帽決定改用Google的Kuberentes," 為管理大規模容器應用，企業在導入容器技術時，勢必要考量究竟在容器調度工具上，要選擇Kubernetes、Docker Swarm，還是Mesos。然而，紅帽則不惜捨棄過去自己開發的容器調度工具，決定在OpenShift上導入Kuberentes。為何做出此決定？紅帽全球雲端產品策略總經理Bryan Che解釋，選擇Kubernetes有三大理由。
Bryan Che解釋，第一個理由是，參與Kubernetes開發的社群最為廣大。Bryan Che表示，紅帽相信技術是由社群所推動，「而Kubernetes的使用者、貢獻者都是最多的，規模比其他容器調度工具社群都還大。」
第二是從技術架構的考量出發。他解釋，Kubernetes是由Google開源釋出，「而Google運作全世界最大規模的容器叢集，這是市場所看重的。」早在2012年OpenShift釋出時，紅帽就已經在中內建自家的容器調度工具，但是在OpenShift第三版釋出後，便將其更換為Kubernetes，「因為它比我們的工具更為進步。」
最後則是考量各工具的背後，是否被某特定廠商所控制、把持。雖然Docker Swarm、Mesos都是標榜開源專案，但Bryan Che認為：「它們的發展，其實都被單一廠商所主導。」而Kubernetes主要都是靠著社群、第三方廠商的貢獻而茁壯，「這才是真正的開放平臺。」他表示，目前紅帽也是Kubernetes專案的第二大貢獻者。
目前，紅帽在公有雲的戰略上，是利用OpenShift部署於AWS及Google GCP上運作。在私有雲上則是利用開源IaaS OpenStack，推出自家的Red Hat OpenStack Platform。但在今年4月時，在搶攻福斯OpenStack私有雲建案的競爭上，卻輸給了OpenStack廠商Mirantis。
針對紅帽在此的失利，Bryan Che認為：「我不認為這是失敗」，他表示，今年在巴賽隆納舉辦的OpenStack高峰會上，與其他OpenStack廠商相比，「紅帽OpenStack使用者的數量遙遙領先」。而撇除此失敗的案例，紅帽還有許多成功的導入案例，像是電信商Verizon、瑞士電信，或是NEC、日立等企業。
他表示，紅帽在OpenStack技術領域的著墨上，「希望能跟在Linux領域一樣，取得領先地位。」他解釋，回顧15年前，當時Linux才剛開進入企業級市場時，市面上有各式各樣的Linux作業系統廠商，但是經過數年的競爭，Linux市場已經相當成熟，業者數量也減少很多。
「在OpenStack市場上，我們看到一樣的趨勢。」他表示，近年OpenStack的業者已經大幅減少，但是由於技術開始成熟，「OpenStack的使用者、社群貢獻人數也增加許多。」
",https://www.ithome.com.tw/news/110370,"新聞,紅帽,OpenShift,Docker,Container,容器調度工具"
110352,20,2016-12-16,容器標準化關鍵一步，Docker開源containerd元件，4大雲端龍頭將參與開發,Docker釋出容器基礎元件containerd之後，業者更容易打造出一個彼此技術互通的容器管理軟體，AWS、Google、IBM及微軟四大雲端龍頭和阿里雲都承諾會參與貢獻和維護," Docker於本周宣布，將Docker Engine中的核心元件containerd獨立為新的開放源碼專案，包括Alibaba Cloud、AWS、Google、IBM及微軟都已承諾願意成為該專案的貢獻者及維護者。此外，明年初containerd將進一步成為中立的基礎，以讓業者可在共通的基礎上打造自己的容器管理軟體。
containerd提供了建立容器runtime所需的最基本元件，它能下載、儲存與執行容器映像檔，也能連結儲存及網路。
Docker創辦人暨技術長Solomon Hykes說明，各界對Docker的厚愛讓它快速成長為一個完整的平台，仰賴它建置、遞送與執行分散式應用，功能從調度到基礎架構，核心的容器runtime只是其中的一小部份。對於數百萬的開發人員或IT專家而言，他們想要的就是一個完整的平台，但許多平台建置商或營運商卻只需要一個最基本的元件，以讓他們能在自己的系統中透過穩定的介面執行容器，而containerd即符合此一需求。
自從Docker在今年4月釋出的Docker 1.11中納入containerd之後，containerd已被部署在數百萬台的機器上，此次的宣布將進一步擴展containerd。Docker亦承諾會陸續添增Docker Engine功能到containerd上。
支援Linux及Windows的containerd 1.0將提供用來管理容器的各種核心功能，包括容器執行與監督、映像檔的遞送、網路介面管理、本地儲存、原生管道水平的API，以及對Open Container Initiative（OCI）的完整支援等。
根據Docker的規畫，containerd 1.0預計會在明年第二季出爐，屆時不論是Doker或其他容器系統業者都可利用containerd作為核心的容器runtime。
",https://www.ithome.com.tw/news/110352,"新聞,Docker,容器,Container,Containerd,runtime,Solomon Hykes"
110350,20,2016-12-16,Docker與阿里雲、AWS、Google、IBM和微軟結盟，開源Docker Engine核心元件Containerd,Docker與阿里雲、AWS、Google、IBM和微軟結盟，著重於Container Runtime開源計畫的研發，且開源釋出容器平臺Docker Engine的核心元件Containerd，預計在2017年第一季捐獻給獨立基金會。," Docker於本周四（12/15）開源釋出旗下容器平臺Docker Engine的核心元件Containerd，是用來執行容器（Container）的基本元件，Docker表示，Containerd預計在2017年第一季捐獻給獨立基金會。另外，阿里雲、Amazon Web Service（AWS）、Google、IBM和微軟也與Docker結盟，專注於Container Runtime開源計畫的研發。
Containerd可以於Linux和Windows環境下在背景執行（Daemon），能夠管理完整的容器生命週期，包含了傳輸容器映像檔、容器的執行和監控等。根據Docker在Github上的解釋，Containerd可以嵌入在更大的系統，而不是讓開發者或終端使用者（End-User）直接使用。
另外，Containerd也支援OCI映像檔規格（Open Container Initiative Image Spec）、OCI Runtime規格（OCI Runtime Spec）、容器Runtime和生命週期、管理容器的網路命名空間以連接既存的命名空間等。
分析公司RedMonk產業分析師Fintan Ryan表示，Docker開源旗下Containerd至容器生態系統，這意味著Docker提供容器社群開發者標準核心元件，且此標準核心元件技術確保開發者開發時，在跨基礎建設環境下的穩定性和相容性。
",https://www.ithome.com.tw/news/110350,"新聞,Docker,Containerd,Docker Engine,Container,開源計畫"
109801,20,2016-11-27,IT月報｜雲端IT焦點回顧 (2016/11),IT龍頭大搶雲端商機，微軟正式加入Linux基金會，成為最高等級白金會員，而Google則將GPU運算搬上雲端," 為搶雲端商機，微軟加入Linux基金會，而Google則加入.NET基金會
微軟不只擁抱Linux，現在還要進一步加入同一陣線。微軟今天在紐約Connect()開發者大會上宣布，正式加入Linux基金會，成為第11個最高等級的白金會員，每年要付50萬美元會費。微軟Azure首席架構師John Gossman也成為了Linux基金會董事會的16名董事之一。這是微軟繼今年3月加入Eclipse基金會之後，所加入了的另一個指標性的開源組織。「產業已經轉型到雲端和行動的世界，要讓開發者能發揮新境界的威力，只有和社群合作，才能提供開放、彈性和更聰明的工具和雲端服務。」率領微軟開發工具團隊的Scott Guthrie，揭開了微軟擁抱開源、擁抱Linux的最大原因。（詳全文）
 
搶攻深度學習、AI商機！Google明年也要推出GPU運算雲端服務

企業選用GPU雲端服務將有新選擇，Google宣布明年將推出GPU運算雲端服務了，將針對需要大量GPU平行運算能力的深度學習、AI等應用，提供用戶3種伺服器專用的GPU加速器VM來租用，未來收費方式也將按分鐘來計價。Google將透過VM來提供3種伺服器專用的GPU加速器運算服務，來提供全球雲端用戶租用。Nvidia Tesla P100是其中一個用戶能選擇租用的GPU加速器服務，這是Nvidia今年新發布一款能用於深度學習訓練的GPU加速器，採用新一代Pascal架構設計，核心數高達3,584個CUDA，其內含的電晶體數更超過了150億顆，雙精度浮點運算能力則達到5.3 TFLOPs。（詳全文）
 
Google東京雲端營運中心上線
雲端大廠如Google、AWS與微軟等，紛紛強化基礎架構建資料中心，來支援企業調度跨國雲端運算資源的能力，而Google於11月8日宣布啟用位於東京的雲端營運中心，其內建有3個Zone，其伺服器採用英特爾最新推出的Broadwell處理器。東京雲端營運中心為Google全球第6座雲端營運中心（Region），代號為asia-northeast1，且是除了臺灣Google彰化營運中心以外的亞太區第2座，也就是說，如今Google在亞洲設有雙營運中心，來搶攻欲建置跨國雲端服務與備援的企業。繼Google東京雲端平臺營運中心啟用之後，預計於2017年再新建立8座Region，分別位於英國倫敦、新加坡、澳洲雪梨、芬蘭哈米納、德國法蘭克福、巴西聖保羅、印度孟買及美國北維吉尼亞州等。（詳全文）
 
雲端開發工具Nitrous決定收攤，改將開源讓大家任意用
集結舊金山及新加坡的開發人員、甫於2012年創立的雲端整合開發環境Nitrous.io宣布，今年11月14日關閉Nitrous開發平臺與Cloud IDE，並預計會在幾周後釋出產品原始碼。Nitrous.io近日會寄出信件通知既有客戶，同時提供可下載資料備份的連結，兩周後將會把資料刪除。不過，今年4月才開始向用戶收費的Nitrous.io，並未說明結束營業的原因，只表示即日起不再接受新的註冊，也會退還10月16日之後付費的款項。此外，Nitrous.io也打算釋出Nitrous IDE的開放源碼版本「Nitrous Solo」，讓用戶能夠在其他的雲端服務中，來管理基於Nitrous IDE的實例。（詳全文）
 
阿里雲年底前再啟用4座雲端機房，全球達14座
阿里巴巴宣布今年底前將啟用4座雲端機房，分別位於杜拜、法蘭克福、雪梨與日本，提供資料儲存、大數據分析、企業級中間層（Middleware）與雲端安全等服務，以搶攻希望打造跨國雲端服務與備援的企業。阿里雲表示，加上今年底前啟用的4座雲端機房後，阿里雲全球已建14座雲端營運中心。目前阿里雲已是中國最大的雲端服務商，全球有約230萬客戶，為進一步搶攻跨國企業，去年陸續啟用位於香港、新加坡與美國矽谷的雲端資料中心。（詳全文）
 
Google、英特爾聯手強化企業雲端，著眼AI、容器、物聯網與安全4大領域研發
Google與英特爾宣布企業雲端平臺合作，著眼機器學習、開源碼容器叢集平臺Kubernetes、物聯網及安全等領域的共同開發，以提升與亞馬遜、微軟Azure、IBM與甲骨文競爭企業客戶的實力。英特爾與Google這次合作將觸角延伸到企業雲端服務上，藉此吸引用戶將系統由傳統資料中心環境轉移到雲端。雙方合作首先包括針對多種工作負載，Google將連結英特爾物聯網裝置與Google雲端平臺以進行資料分析，作為零售與製造業決策分析之用，一則藉由深化英特爾硬體和GCP之間的安全整合，以確保企業雲端的安全性。此外雙方也將共同投入技術訓練及市場開發。（詳全文）
 
IBM新推資料移轉工具Bluemix Lift與商業分析工具Decision Optimization

IBM在Bluemix平臺上推出新的資料移轉工具Bluemix Lift，供企業更容易地將資料搬上雲端。而Bluemix Lift為在華生資料平臺上的資料搬移工具，IBM表示，在使用者利用Bluemix Lift傳輸資料時，能夠進行資料加密，且傳輸速度最高達每小時225 GB，且IBM宣稱，在資料傳輸過程中，若電腦突然中斷或斷線，資料傳輸不受影響仍能夠照常傳輸。此外，IBM也同時推出商業分析工具Decision Optimization的測試版，提供企業挖掘與分析非結構性資料，如交易資料、業務目標等。（詳全文）
 
微軟新推雲端檢測工具Azure Advisor公開預覽版
由於使用者要人為檢測不符合資安規章的設定等，經常要耗費大量的時間，微軟指出，為了解決相關的問題，推出雲端檢測工具Azure Advisor，此工具會先分析使用者在IaaS平臺上資源配置與使用情況，以偵測其存在的風險與潛在問題，供使用者修復在設定上的錯誤，與提高資訊安全程度等，而此工具為微軟於去年推出的Troubleshooting Engine的延伸服務，並非僅能夠用於資料庫叢集，而是供使用者檢測整體的雲端環境。（詳全文）
 
AWS推出雲端伺服器搬遷服務（SMS），目前僅支援VMware虛擬機
為了讓使用者更容易將虛擬機與就地部署基礎架構搬上AWS，AWS宣布推出雲端伺服器搬遷服務（Server Migration Service，SMS）。AWS指出，目前企業已經能夠在AWS管理主控臺中點選SMS服務，以將VMware虛擬機搬遷到AWS，而其他的Hypervisor和實體伺服器未來將會進一步提供支援，且企業也可以利用SMS建立並管理大規模遷移伺服器所需的複寫排程，與在SMS儀表板上查看複寫的狀態。目前SMS已上線，且在由AWS北維吉尼亞州、愛爾蘭與雪梨3座雲端營運中心提供服務。（詳全文）
",https://www.ithome.com.tw/news/109801,"新聞,Cloud,雲端"
109484,20,2016-11-11,Container雙周報第21期：Mesos釋出年度使用調查報告，6成用戶在正式環境導入Container,Mesos表示，總共有85%的使用者利用容器運行微服務，超過6成用戶則是在正式環境中運作Container," 重點新聞（10月29日-11月11日）
·Mesos 2016年年度使用者調處報告出爐，6成用戶在正式環境導入Container
Mesos在官方釋出了2016年使用調查報告結果，總共收集了來自全世界各地500份的用戶回饋。有將近半數（44%）的使用者才接觸Mesos不到半年，再來才是超過一年（37％）及介於7至12個月（19％）的使用者，更有43％的使用者是來自人數低於200人的小型企業。此外，大多開發者運行的Mesos節點都不超過100個。
在容器技術的導入率方面，總共有85%的使用者利用容器運行微服務，超過6成用戶在正式環境中運作Container。
Mesos表示，此份調查結果顯示Mesos社群成長快速，並且加速當代應用程式如大資料服務、容器調度的採用率。更多資訊
·Tectonic 1.4版推出，新增叢集自動執行功能、加強角色模式管理機制
CoreOS旗下的商業化Kubernetes平臺Tectonic推出了1.4新版本，除了新增叢集自動執行功能（Self-hosted Cluster），也整合了角色模式管理機制（RBAC）。CoreOS表示，新版本中，Tectonic新增了TLS加密解決方案，並且利用開源監控系統Prometheus，讓使用者可以利用圖像化界面，看到各節點的使用情況。
此版本中，叢集自動執行功能為其中一個亮點，讓開發者可簡化安裝、管理以及升級Kubernetes的困擾。此外，整合Prometheus後，企業也能以利用UI介面，一覽CPU、RAM、節點、網路I/O，以及文件系統的使用情形。更多資訊
·容器監控廠商Sysdig釋出監控工具Falco 0.4.0版
容器監控工具廠商Sysding旗下的監控工具Falco近日釋出0.4.0版本，Sysdig表示，此版本與0.3.0版最大的差異在於，新版提高對容器、調度工具的可見度，例如，使用者可以監控特權容器（Privileged Container）中所發生的事件。
此外新版本的Falco也將支援容器調度工具如Kubernetes以及Marathon，開發者可以了解容器部署、節點、應用框架等資訊。更多資訊
·為何紅帽選Kubernetes作為OpenShift上的容器調度工具
市面上容器調度工具不在少數，像是Docker Swarm、Kubernetes及Mesos等工具，然而為紅帽卻獨選Kubernetes進行標準化？紅帽資深產品總監Joe Fernandes表示，在2013年Docker爆紅之時，紅帽迅速的決定要開始支援Docker。
然而Joe Fernandes也清楚，真實世界中，應用程式不可能只靠一個容器就能運行，而正式環境更不可能靠單一主機就能支撐，因此在2013、2014年時，紅帽就開始調查市面上各類的容器調度方案，「最後我們找上了Kubernetes。」
Joe Fernandes認為，Kubernetes總共有下列數項技術優點
1.Kuberenets節點的設計，讓開發者可以在單一Atomic主機上，部署1個以上的Container
2.每個進入節點存取的服務都有一組固定地址，而以DNS為基礎的服務探查，可以串連此些服務
3.複本控制器（Replication Controller）可以確保節點維持一定數量
4.同時可在容器中運作無狀態（Stateless），或是需要保存狀態（Stateful）的服務
5.簡單易懂的調度模型更多資訊
·RancherOS推出0.7.0版本
輕量級容器作業系統RancherOS近日推出了0.7.0版本，此版本也加強對於Docker引擎的支援。最初RancherOS就是為運作Docker Container而生的容器作業系統，一旦RancherOS開啟，就會開啟兩個Container，第一個稱為系統Docker，負責管理系統服務，第二則是用戶Docker，僅僅負責運行容器。
新版本中，Rancher讓使用者更容易切換不同版本的Docker引擎，並且更容易對Docker deamon參數進行組態設定。更多資訊
·數位政委唐鳳用Container平臺自建服務
上任不久的行政院政務委員唐鳳表示，目前其辦公所使用的雲端服務，是建立在Sandstorm平臺上，而此平臺後端所用的技術則是Linux Container。
唐鳳也將各類的開源服務，例如開源檔案分享平臺ownCloud、線上文件工具Etherpad、多人即時協作試算表EtherCalc等工具， 利用Linux Container打包。
她表示，如此部署的好處在於，任何符合Linux Container標準所開發的應用程式，都能直接相容於此容器。此外，此這些服務由於架設在國發會的政府雲端中心上，行政院內各部會也能串接使用。更多資訊
·遊戲開發商CrowdStar導入OpenStack及容器
主打女性手機遊戲的遊戲開發商CrowdStar成立於2008年，當時臉書正是當紅的遊戲平臺，靠著臉書，CrowdStar也累積了3億使用者。
CrowdStar工程部門副總裁Jose Avila表示，CrowdStar利用OpenStack的裸機部署套件Ironic，在實體機器上裸機部署了一套IaaS，「我們團隊原本就使用了很多OpenStack API，只要修改幾行程式碼，幾分鐘就可以部署一臺裸機伺服器。」Jose Avila更表示，靠著Ironic套件，系統初次部署成本下降了60％，也因為使用裸機，讓服務系統的延遲減低了40ms。
除了OpenStack，CrowdStar也導入了Container，一舉降低內部服務的數量，「過去服務對於作業系統、函式庫的依賴性很強。」Jose Avila也舉例，過去開發團隊經常向維運團隊提出修改運行中服務、安裝新函式庫等要求，使得維運團隊受到干擾。在導入容器後，開發者就可以自行修改系統元件、映像檔，維運團隊也不需要花費太多心力檢查，「將控制權還給開發者。」更多報導
·紅帽第4代KVM支援OpenStack及Container
Red Hat過去曾基於KVM專案推出Enteprise Virtualization（RHEV） ，直到今年3月發表的3.6版，產品名稱都維持不變。而在8月底下旬，該公司簡化為Red Hat Virtualization（RHV），並發布4.0新版。
在OpenStack部署的部分，則是針對Red Hat OpenStack Platform（RHOSP）的Neutron網路套件，提供原生支援（內建Open vSwitch ML2代理程式），同樣是為了卸載虛擬機器網路的組態及資料平臺的控管。若要建置橫跨傳統（RHV），以及雲端環境（RHOSP）工作負載的應用系統，可藉Neutron的整合，提升兩種環境之間的網路連線品質。
RHV 4也強化支援Linux Container的工作負載。例如，RHV可將Red Hat Enterprise Linux Atomic Host的主機，視為可設定組態的Guest系統——當中可執行RHV的Guest代理程式，而且，因為它具有容器感知能力，因此能向RHVM指出正在執行Container的特定虛擬機器，方便管理者從整體虛擬化基礎架構的角度，掌握系統資源是以此種方式來耗用。更多報導
更多產品動態
·開源專案coldbrew-cli讓AWS上部署Docker容器自動化 更多資訊 
·Docker映像檔AWS Tools打包常用工具，開發者可透過它與AWS API互動更多資訊  
·Azure容器服務開始支援DC/OS 1.8.4版本更多資訊  
·虛擬化工具VirtualBox推出5.1.8版本更多資訊  
·微軟開源Azure容器服務引擎更多資訊  
·微軟Auzre上也可以運作resin.io更多資訊  
·Joyent推出Triton Container命名服務，可紀錄實例名稱及標籤更多資訊  
·容器新創Kontena宣布與IBM Softlayer、Splunk合作，擴大生態系夥伴更多資訊  
·微軟推出Nano Server映像檔建置工具更多資訊  
Container資源
※知識：Docker官方釋出設計參考架構
※知識：簡介Docker容器服務的儲存解決方案
※知識：你該知道的Docker資安議題
※知識：Uber怎麼將MySQL資料庫Docker化
※影片：結合Jenkins及Docker Swarm搞定持續部署
※投影片：了解Docker Swarm
※How-To：視覺化樹梅派上運作的容器
※How-To：用TLS加密保護Windows Server 2016上的Docker引擎
",https://www.ithome.com.tw/news/109484,"新聞,Docker,Azure,Container,容器服務,Rancher,紅帽,Mesos,IT周報"
109288,20,2016-10-29,IT月報｜雲端IT焦點回顧 (10月),AWS與Vmware破天荒合推VMWare Cloud on AWS，而第14版OpenStack正式釋出，一套API能通管裸機、VM和容器," AWS和VMware化敵為友，公布混合雲策略合作
雲端服務的宿敵AWS與VMware聯手推出VMWare Cloud on AWS，讓客戶可以在結合VMWare私有雲及AWS公有雲的混合雲基礎架構上執行應用。VMware Cloud on AWS的技術底層是VMware軟體定義資料中心（SDDC）的VMware Cloud Foundation，包括 vSphere、VSAN 和NSX，使VMWare為基礎的私有雲跑在AWS裸機基礎架構上，讓客戶在原有VMware軟體及工具外，使用多項AWS服務，包括儲存、資料中心、分析等。在VMWare Cloud on AWS上，客戶將可以透過既有VMware合約購買VMWare的軟體服務，VMware on AWS預計2017年中推出，至於價格預計在即將上線時公布。（詳全文）
 
第14版OpenStack正式釋出，一套API能通管裸機、VM和容器

為了簡化部署與操作友善性，開源雲端作業系統OpenStack剛推出第14版Newton，將OpenStack定位整合引擎，主打企業能夠透過單一API來管理裸機、虛擬機器與容器調度架構（Container Orchestration Framework），並強化擴充性與提高容易使用度等。（詳全文）
 
微軟混合雲平臺Azure Stack明年中正式上市
微軟宣布混合雲Azure Stack一體機預計明年中正式上市，涵蓋IaaS、PaaS、資料庫與容器等服務，近期推出Azure Stack技術預覽版第2版，主要增加Azure Portal中的運算、儲存、網路與安全功能、並支援iDNS，以協助使用者註冊內部虛擬網路名稱，與解決外部網域名稱系統（Domain Name System，DNS）的問題等，預計於明年2或3月再推技術預覽版第3版。（詳全文）
 
Google開源網域名稱註冊雲端平臺Nomulus，推動域名產業開放標準
Google在GitHub上釋出旗下網域名稱註冊雲端平臺Nomulus，進一步推動網域名稱產業的互通性和開放標準，免費提供網域名稱註冊平臺給所有人使用。（詳全文）
 
IBM Cloud Object Storage新推混合雲儲存服務
IBM宣布雲端物件儲存服務IBM Cloud Object Storage（COS）新推混合雲儲存，IBM指出，此服務可以供利用此企業混和雲儲存服務，來儲存大量的非結構化資料，包括影片、照片和人體基因順序等，而COS背後的技術就是基於IBM去年併購的物件儲存系統廠商Cleversafe。IBM雲端資深副總裁Robert LeBlanc指出，當企業客戶經常需要搬移大量的工作負載至混合雲時，就需要提供企業用更快、更安全和更節省成本的方式，來儲存與管理大量的數位資料。（詳全文）
 
瞄準企業冷儲存需求，Google新推雲端資料儲存服務Coldline
Google在雲端儲存服務上進行多項更新，其中相當重要的是針對儲存檔案資料（Archival Data），也就是針對備份或歸檔等不常用的資料新推冷儲存（Cold Storage）服務Coldline。Google繼去年3月因應企業儲存大量資料需求，推出雲端儲存服務Google Cloud Storage Nearline測試版之後，近日再推出Coldline，Google發言人指出，和Google Cloud Storage Nearlin相比，Coldline主要降低資料儲存費用與延遲時間。而Coldline的收費標準為，一個月傳輸1GB的資料量要價0.007美元，而同樣傳輸量Google Cloud Storage Nearline價錢則為0.01美元。（詳全文）
 
開源PaaS平臺Pivotal Cloud Foundry登上Google雲端平臺
開源PaaS平臺Pivotal Cloud Foundry登上Google雲端平臺（GCP），企業可以在GCP上部署和執行Pivotal，也可以整合多項GCP服務，其中包含了Google Cloud Load Balancing、Google Cloud SQL，與多項API，涵蓋Google Cloud Speech API、Google Cloud Natural Language API、Google Translate API等。Pivotal Cloud Foundry不只支援GCP，也已能夠在AWS和Microsoft Azure上部署。（詳全文）
 
Google推出雲端腳本程式編輯器，可用瀏覽器設定雲端管理環境
Google宣布推出Cloud Shell Editor，也就是在Cloud Shell上，使用Eclipse Orion程式編輯器所打造的程式碼編輯器Code Editor。而Google Cloud Shell為命令列管理介面，供使用者管理GCP資源。Google指出，使用者可以透過Google Cloud Console服務來使用Google Cloud Shell Editor，另外也可以進入Cloud Shell頁面，來使用此Editor服務。（詳全文）
 
微軟上季Azure業績成長翻倍、Office 365用戶達2400萬
微軟公佈截至9月30日的會計年度2017年第1季財報。上一季雲端及軟體業務表現亮眼、公有雲Azure成長116%、彌補了該公司在手機業務高達七成的衰退及Windows業務的零成長。Office 365個人用戶則成長為2400萬。（詳全文）
",https://www.ithome.com.tw/news/109288,"新聞,Cloud,雲端"
109181,20,2016-10-28,Container雙周報第20期：IoT新創要讓各式嵌入式裝置也可以運作Docker容器,在2013年Docker風潮正火紅時，Resin.io就看見其支援多種環境，並且能夠快速部署應用程式的特性，因此也著手讓Docker可以在樹莓派上運作," 重點新聞（10月15日-10月28日）
·IoT新創Resin.io要讓嵌入式裝置跑Docker容器
IoT新創公司Resin.io近日推出resinOS，要讓嵌入式裝置也可以運作Docker Container。在2013年Docker風潮正火紅時，Resin.io就看見其支援多種環境，並且能夠快速部署應用程式的特性，因此也著手讓Docker可以在樹莓派上運作。在開發過程中，他們發現必須有一款專門為嵌入式裝置上運作Container而生的作業系統，「但是現有為雲端而生的Container OS都不符合我們的需求。」為此Resin.io也推出了自家的開源作業系統ResionOS。
Resin.io認為，Container技術對於現代連網裝置的開發、部署占有重要意義，「而VM及Hypervisors缺乏硬體支援、耗費過度資源等問題，注定讓它們在嵌入式裝置應用上出局。」
ResinOS目前支援近20種不同類型的Linux嵌入式裝置上運作標準Docker Container，包含知名的樹莓派、BeagleBone，以及企業等級的嵌入式裝置。更多資訊
·GCP也可以運作Pivotal Cloud Foundry
Google宣布與Pivotal合作，要在雲端平臺GCP上運行Pivotal Cloud Foundry。透過GCP，部署在GCP上的Cloud Foundry應用程式可以透過雲端負載平衡功能，處理數百萬的系統請求，而結合GCP平臺上以分鐘使用的計價方式，企業更可降低雲端環境運行的成本。
除了GCP本身的IaaS服務，Cloud Foundry使用者同時也可Google的數據或是機器學習服務，包含BIgQuery、Cloud SQL，或者串接Goolge自然語言、翻譯API。更多資訊
·雲端相簿Everalbum靠雲端容器服務打造基礎架構
雲端相簿Everalbum從傳統VM架構，開始遷移至多公有雲的容器環境。由於Everalubm得提供使用者穩定的相片儲存服務，勢必要有安全、穩定的分散式後端系統作為基礎，同時也要能快速地水平擴充來應付使用流量。
為了打造這樣的基礎架構，Everalbum結合了AWS及Google容器引擎（GKE），「在一年前我們就開始轉移至容器」，並且利用Kubernetes，在不同環境下調度Container。Everalbum共同創辦人Jon Mumm表示，導入Docker也可以加速新程式碼開發及部署的速度。更多資訊
·容器安全廠商Twistlock加強Container安全監控
致力加強Container安全的Twistlock，近日宣布與雲端大數據分析廠商Sumo Logic合作，加強Container安全性監控。
而此合作內容主要有四大方向，第一提供漏管理服務，讓使用者可以在部署程序前，提早容器映像檔的各組成元件是否含有漏洞。第二則提供符合業界規範的容器組態設定規範，含括CIS Docker標準。再者管理用戶存取控制，像是Docker、Swarm以及Kubernetes API的使用權限。最後則是提供Runtime防禦功能，此服務也結合Twistlock自家的統計分析、機器學習，「能保護大規模容器環境，同時撇除人為管理的干涉。」
Twistlock也看好雙方的合作，由於Sumo Logic具備扎實的維運分析工具，並結合Twistlock至今累積集豐富的容器環境資料，「可說是搭配合宜。」像是Twistlock提供了2種主要的Log記錄，第一是主控臺Log（Console），追蹤角色管理、組態設定變化，以及系統健康等訊息。而防禦者Log（Defender）則記錄個節點的行為，像是認證程序、系統Runtime事件。更多資料
·Google與Mesos合作，GCE上也可以運作DC/OS
Mesos宣布和Google合作，讓使用者可以在Google GCE平臺上運行資料中心作業系統DC/OS。雖然DC/OS目前已可部署在GCE上運作，但Mesos正著手釋出相關的模板，經由雙方合作也可以簡化企業的使用門檻。
Mesos表示，GCE除了是目前三大公有雲服務外，也提供了許多彈性的計價方案。Mesos解釋，DC/OS的賣點就是透過應用程式容器化，以及將硬體資源轉換成資源池，藉此提高資源使用效率。而結合GCE平臺的計價策略，像是使用折扣、低價虛擬機服務Preemptible VM，「企業用戶可以告別過度浪費的基礎架構，隨之而來是恰到好處的使用規模。」
不僅如此，DC/OS也可以支援建立微服務、分散式大數據系統等功能，企業也可以自由地把應用程式遷移至混合雲環境。更多資訊
·Docker結盟阿里雲，布局中國容器市場
今年6月時，CoreOS踏入中國市場，與中國基礎架構服務商世紀互聯合作，而近日Docker與中國最大公有雲廠商阿里雲宣布結盟，也意味Docker也開始進入中國市場。
Docker表示，早在推出Docker 1.0版本前，中國就已經有許多企業開始將它導入正式環境，而Docker與阿里雲的合作，將提供以中國在地的Docker Hub實例，確保當地社群使用Docker映像檔時，能獲得更好的效能，「這也是為何與中國最大公有雲廠商合作如此重要。」
而雙方的合作不僅如此，Docker也要透過阿里雲，讓當地企業可以使用Container，運作企業等級應用程式。Docker引用阿里雲的調查，表示超過80％的企業已經開始計畫或早已導入Container，「雙方的合作，讓不同規模的企業都可以將傳統應用程式容器化，加速內部數位改革，並開始打造新的微服務。」更多資訊
更多產品動態

·更新排程器Sundial支援AWS ECS平臺上Docker化應用程式更新工作更多資訊 
·AWS EC2容器儲存庫新增映像檔後設資料更多資訊  


·紅帽CentOS Atomic Host支援Docker 1.12更多資訊 


·紅帽推出Ansible Container 0.2.0版本更多資訊 
·無伺服器平臺廠商Iron.io結盟Cloud Foundry，提供企業多雲無伺服器服務更多資訊 
·容器託管廠商Hyper.sh推新服務Hyper Service，包含負載平衡及自癒功能更多資訊 
·Docker叢集管理工具Shipyard用Docker Swarm搞定叢集資源排程更多資訊 

Container資源
※知識：專家評比三款主流容器調度工具
※廣播：將傳統應用程式遷移到Docker
※How-To：用Kubernetes打造全球分散式服務
※How-To：結合Windows Server 2016及VirtualBox
※How-To：用Docker InfraKit打造高效能運算基礎架構
",https://www.ithome.com.tw/news/109181,"新聞,Docker,Container,google,Pivotal,紅帽,阿里雲,DC/OS,IT周報"
109278,20,2016-10-27,CrowdStar靠Ironic部署裸機OpenStack，善用實機效能又能數分鐘快速部署,CrowdStar使用了OpenStack裸機部署套件Ironic，現在只要修改幾行程式碼，幾分鐘內就可以部署一套裸機伺服器," 主打女性手機遊戲的遊戲開發商CrowdStar成立於2008年，當時臉書正是當紅的遊戲平臺，靠著臉書，CrowdStar也累積了3億使用者。在2013年時，此家公司決定開發更多鎖定女性使用者的手機遊戲，因此推出了Covet Fashion，使用者可以在此平臺中，購買真實品牌的虛擬物件，如衣服、項鍊等服飾來創造各式各樣的服飾搭配方式，還會設計了票選競賽，來吸引使用者創造更多服裝搭配方式來吸引大家投票。
CrowdStar工程部門副總裁Jose Avila表示，Covet Fashion遊戲玩家每個月上傳的新搭配超過了1.5億種，每天投票次數更超過了5,000萬次。為了應付這樣的使用規模，Covet Fashion在美國境內4個不同的資料中心部署了超過200臺伺服器，並且混合使用者KVM、裸機作為基礎建設，「一天更要處理超過1億個API呼叫。」
Jose Avila表示，起初，CrowdStar在實體伺服器上建置虛擬化平臺，以提供VM來部署後端服務系統，他說，虛擬化後提供的水平擴充速度，雖然可以滿足Covet Fashion的成長速度，但是用量達一定規模之後，營運成本反而相當可觀，Jose Avila更表示，尤其隨著開發團隊推出更多功能，系統變得愈來愈複雜，系統開機時間很長，部署程式也需要建立很多例外規則，導致系統變得脆弱。
再加上「我們是小團隊，必須提升工作效率。」Jose Avila表示，裸機部署方式是一個大變革。一般來說，部署在實體機器的好處是效能快、成本也不貴，但得面臨長期維護合約和耗時很久的實機調度或建置時間。
不過，CrowdStar利用OpenStack的裸機部署套件Ironic，在實體機器上裸機部署了一套IaaS，「我們團隊原本就使用了很多OpenStack API，只要修改幾行程式碼，幾分鐘就可以部署一臺裸機伺服器。」Jose Avila更表示，靠著Ironic套件，系統初次部署成本下降了60％，也因為使用裸機，讓服務系統的延遲減低了40ms。
除了OpenStack，CrowdStar也導入了Container，一舉降低內部服務的數量，「過去服務對於作業系統、函式庫的依賴性很強。」Jose Avila也舉例，過去開發團隊經常向維運團隊提出修改運行中服務、安裝新函式庫等要求，使得維運團隊受到干擾。在導入容器後，開發者就可以自行修改系統元件、映像檔，維運團隊也不需要花費太多心力檢查，「將控制權還給開發者。」
",https://www.ithome.com.tw/news/109278,"新聞,Openstack巴塞隆納,OpenStack,Container,裸機,混合雲"
108885,20,2016-10-16,F1車隊用雲服務迎戰全球賽事,F1賽事不只是賽道上的競速、車手的較量，背後的技術支援與生產力比拼，也足以影響車隊成敗，Renault Sport車隊便採用雲端技術，爭取研發、改進與協作時效," 談到一級方程式賽車F1（Formula One），速度就是一切，就連換胎時間都很寶貴，在這分秒必爭的運動賽事當中，我們常能見到汽車領域中最先進的技術，以及特殊的材料運用。但你可能沒注意過的是，這裡面也牽扯到企業資源管理的學問。
Renault Sport車隊（前身為Lotus車隊）是F1賽車隊伍的其中之一，在引擎、車身、零組件、油耗與輪胎設計開發之外，他們今年也透過微軟眾多雲端技術，試圖提升車隊資源管理、分析與協作的能力。這是因為，在近年F1賽事中，不只是賽道上的競速、車手的較量，背後的技術支援與生產力比拼，也足以影響車隊成敗。

Renault Sport車隊今年大規模藉助微軟雲端之力
今年9月中的新加坡F1賽事期間，Renault Sport車隊總監Cyril Abiteboul分享他們在重視速度比拼的賽車競賽中，車隊今年在IT架構上，開始用了不少的微軟雲端技術，期望帶來更靈活的資源管理與即時分析應用。（圖左為微軟Dynamics AX產品經理Pepijn Richter，圖右為Renault Sport車隊總監Cyril Abiteboul。）

從資源管理與新技術著手，提升與大型車隊的競爭力
近年F1賽事規則的變化大，像是每年技術規則的改變，對於引擎、車身設計、系統、零件與輪胎等項目，都有不同的限制與要求，車隊必須要在較短的周期時間內，設計並製造出符合新規則的賽車。而對於過去的Renault Sport車隊而言，他們自認口袋深度不比Ferrari、Mercedes與Red Bull等大型車隊，為了保持車隊競爭力，在基本的賽車設計之外，也試圖從技術層面加以突破，例如從企業資源管理，以及新技術的應用著手，以獲取更敏捷的工作方式，才能動態依據每年賽事規則調整，設計出對應的比賽車型。
基本上，從賽車本身的關鍵系統設計，以及製造生產效率，加上後續的測試調整，都是他們關注的重點。同時還要能做到良好的品質管控，畢竟在賽車過程中，一旦車況有問題，不僅影響車隊成績，同時也會危及車手本身在這種高危險賽事的安全性。對於這種世界級的職業賽車競賽而言，後端生產力的比拼也不容忽視。
在今年9月15日新加坡F1賽事期間，我們也透過微軟與Renault Sport車隊的安排，進一步瞭解他們的F1車隊，是如何運用雲端新技術，來應用在重視速度的賽車競賽之中。
跟一般汽車製造業相比，Renault Sport車隊總監Cyril Abiteboul表示：「我們一年只打造兩部賽車，而不是數以千計的車」。這句話中也隱隱透露出不少含意，雖然僅僅是製造兩部車子，但賽車背後的設計、生產與戰備比拼，其實並不是一件容易的事。

Renault Sport F1車隊運用商業智慧分析技術，讓團隊能夠即時掌握賽車研發與製造的費用，了解各項目的花費比重，快速提供車隊做好分析與決策的資訊。介面上，他們可看出一輛賽車的總成本，並能檢視這輛車在各項目上的花費，像是最花錢的5個項目，分別是諮詢、原物料、煞車、車身與引擎費用。（圖片來源／微軟）

迎接F1賽事規則多變的挑戰，Renault Sport車隊加速擁抱雲端技術
在企業資源管理（ERP）的軟體產品中，臺灣企業可能較熟知的是SAP、Oracle這類全球知名的系統供應商，而國內本身也有為數眾多的ERP本土廠商，像是頂新、正航等，多數國內中小企業可能沒注意到的是，微軟其實也有對應產品，如Dynamics系列NAV與AX，前者主要對應中小型企業，後者則適用於大型企業。
在Renault Sport車隊的前身Lotus車隊，為了賽車設計、製造與後續測試的資源管理，他們在2012年開始採用了微軟ERP系統Dynamics AX，這是當時他們評估了13家ERP廠商後，在功能需求與成本考量下的決定。
值得注意的是，隨著微軟近年在雲端解決方案的多元性發展，今年Renault Sport也開始進行更多嘗試，試圖利用雲端技術的力量，加速車隊本身的企業生產力。而這也跟F1賽事本身求快的目標，相當一致。
將企業使用的軟體系統遷移至雲端，是Renault Sport車隊今年在IT架構上的最大改變。他們讓原本的ERP系統搬移上雲端，這也是微軟Dynamics AX在今年3月的新進展，提供了SaaS服務形式的Dynamics AX Online。至於他們花了多少時間，才將既有系統轉換至雲端服務之上呢？Cyril Abiteboul也給出了答案，他們大約是花了3個月。而這樣的轉換時程，已經算是相當短暫。
同時，車隊也開始應用搭配更多微軟雲端解決方案，像是Azure Machine Learning、Power BI與Office 365等，讓車隊本身的資源管理、商業分析與內部協作應用，可以更有智慧、有效率的運作。
在應用雲端服務的優勢來看，對於他們這種需要全球到處跑透透的車隊，的確很有幫助。有別於過去他們每年在全球21場賽事進行的同時，後端伺服器系統也要跟著就近在當地部署。現在，不論是在測試或比賽中的所得到的數據，都能利用微軟提供的雲端服務來儲存與快速分析。
如同商場上的情資蒐集與即時反應，對於分秒必爭的賽車競賽來說，一樣重要。為了監測賽車各方面的性能，Renault Sport也應用了200多個感測器於車身內，讓車隊成員都能夠根據這些即時資料了解車體所有部位的狀況，不論是引擎、輪胎等各元件的使用情形，並做出更提早更換的決定。
同時這也帶動了車隊在設計、製造與測試的創新速度。畢竟，車隊比賽的地方，或是引擎設計、車輛製造的工廠，以及賽車訓練測試的場地，都是在不同的地方各自進行。現在，Renault Sport車隊內部各單位都能取得即時資訊的反饋，這將能協助研發單位快速改良賽車系統與零件的設計、製造與後續測試修改。
更重要的是，原本要靠人力整理，花上一個禮拜時間才能得到的分析報告，現在也在幾個小時內就能取得。像這樣能實現人工流程自動化的技術應用，就是車隊要的新技術。
利用雲端技術提升車隊分析能力，不只是在報告方面，今年Renault Sport車隊也將Dynamics AX，與微軟Power BI功能結合應用，能依照過去累積的歷史數據，並透過當中的機器學習與人工智慧技術，得到更好的商業智慧分析，協助車隊進一步解讀即時資料，並做出必要的戰略決策。
Cyril Abiteboul也舉例說明：「每輛F1賽車的造價都很貴，我們會很在意計畫中的每個細節，透過Power BI工具，現在可以讓管理團隊，更容易掌握車隊花錢的比重，知道哪些項目的經費運用最高。並可建立KPI，在儀表板介面上直覺檢視目標達成的進度。」因為，成本管控對於這種中小型車隊來說，也是相當重要的一件事。

Renault Sport F1車隊應用商業智慧分析，即時掌握造車成本並協助決策。透過Power BI的儀表版介面，將車隊蒐集到的大量資料即時分析，並以豐富的視覺效果，讓車隊可以專注於所關切的事項。像是他們可以即時檢視、比較各輛賽車在不同項目上的所有花費。

強化車隊在全球的通訊與協作能力，並簡化基礎系統建置
在商業流程系統之外，個人生產力工具也是Renault Sport車隊今年技術提升的重點，因為他們也一併導入了微軟Office 365方案。
在今年9月底的微軟Ignite大會上，Renault Sport車隊也進一步揭露了他們導入的Office 365版本，是最頂級的E5方案，目的是為強化車隊本身內部溝通、協作與安全性。
舉例來說，在強化車隊通訊功能方面，Renault Sport車隊應用了商務用Skype的Cloud PBX功能，他們的IT管理者能從後臺介面，新增商用分機並指派給使用者，之後撥打時，就能讓受話方以商務用Skype接通，這將能強化車隊本身的溝通聯繫能力。
在檔案交換安全性上，車隊IT也利用Office 365平臺的管控功能，限制檔案分享對象只能位在企業指定的網域，如Renault.com、fia.org等，一旦使用者的檔案分享對象包含外部使用者時，系統就會出現警告提示並限制分享。同時，他們也啟用了ATP進階威脅防護機制，可掃描電子郵件中未知的惡意連結與附件，而管理者在後端管理平臺中，也能檢視威脅偵測的事件記錄。
雖然我們還沒有看到他們車隊在Dynamics AX Online與Office 365的結合應用，但根據微軟之前的說法，將可讓業務人員可以在不離開Outlook使用情況下，就能完成商用流程的資訊修改。不過，若隨著更多深度整合應用的加入，勢必也將讓個人生產力工具，與商業流程有更好的整合。對於企業使用者而言，在系統服務更深度整合的情況下，應該將會獲得更豐富的跨系統溝同協作方式。

車隊導入Office 365方案，響應雲端辦公趨勢
Renault Sport車隊採用微軟ERP方案多年後，今年也順勢導入Office 365，這種基於單一供應商服務的選擇，也算是簡化系統維運要連繫多家廠商的麻煩。意外的是，他們選用的是最頂級的E5方案，主要目的也是增強內部通訊與安全，並方便IT人員能在集中式的後臺進行管控。


機器學習技術也是今年的熱門應用，車隊用以預測未來車況
在雲端新技術的應用上，Renault Sport F1車隊也利用新穎的機器學習功能，透過每次競賽與測試所收集到的資訊，協助車隊預測未來趨勢，像是提早更換零件的時間，以及找出更多致勝的關鍵。

",https://www.ithome.com.tw/news/108885,"新聞,F1,雲端,Cloud,Dynamics 365,Dynamics AX,Power BI"
108969,20,2016-10-12,微軟技術高峰會登場，臺灣為全球第一站，主打混合雲方案、機器學習等,微軟技術高峰會（Microsoft Tech Summit）今明日在臺灣舉辦，微軟的目標是要結合大數據分析、物聯網、雲端服務與資訊安全等，為企業提供全面化的服務。," 微軟技術高峰會（Microsoft Tech Summit）今明兩日在臺北國際會議中心舉行，現場總共吸引了近千名聽眾參加， 臺灣微軟總經理邵光華表示，微軟將在全球舉辦17場微軟技術高峰會，而臺灣是第一站，而雲端為微軟重點發展的項目之一，目前在企業數位轉型甚至是工業4.0的過程中，扮演了關鍵的角色。
微軟總部雲端平臺產品行銷部門總經理Mike Schutz表示，未來數年，全球相當多的企業都需要應用機器學習，來分析自物聯網搜集，對公司營運更有價值的資料，同時資訊安全也是相當關鍵的一環。微軟的目標就是結合大數據分析、物聯網與雲端服務、資訊安全等，為企業提供全面化的服務。 
在雲端方面，混合雲為微軟發展的主力目標，其目標在於加速企業橫跨公有雲和私有雲，並協助企業能夠將Azure放到自家的資料中心，而微軟全球有資料中心有36個Regine，他並宣稱Regine的數量為AWS的兩倍。
下圖為微軟資料中心內部

他也指出，在過去五年，企業面臨資訊過載的問題，而資訊安全問題也是企業面臨的嚴峻挑戰之一。
此外，他指出，科技甚至改變了全球的商業運作模式，富邦金控資訊長李相臣在會中表示，台灣的銀行在面對金融科技的浪潮中，已經落後其他國家許多。
如今很多經濟學家指出，資訊科技將要侵蝕金融市場，但危機就是轉機，銀行應該要引用新科技來改變現有的銀行運作模式。
而富邦金控已經在發展金融科技上，投入大量的時間與資源，包含區塊鏈、利用機器學習來開發理財機器人，也就是透過機器學習技術，發展出對企業更有價值的判斷。不過，他也說，企業創新一直都是條艱困的道路，富邦的業務發展方向，以顧客需求為導向，並利用金融科技朝向數位銀行發展。
微軟於今明天於台北國際會議中心舉辦微軟技術高峰會（Microsoft Tech Summit），在今明兩天中，舉辦了近80場技術講座，其中涵蓋雲端、開發、資訊安全、網路功能、資料、儲存、身份識別、行動、與App平臺等主題。會中也提供實機操作空間，供與會者實地操作Microsoft Azure、Office 365和Windows 10等。
 
",https://www.ithome.com.tw/news/108969,"新聞,微軟,Cloud,大數據"
108943,20,2016-10-12,Docker推出管理工具包Infrakit，要讓基礎架構具備自我恢復能力,在開發雲端版本Docker時，Docker也了解到，必須建立一套管理、布建基礎架構的準則，並且在各類環境通行無阻，無論是相異公有雲廠商，或者是內部私有雲。為此，Docker才開始著手研發Infrakit，「讓提供運作分散式系統的基礎架構，可以具有自癒能力（Self-Healing）功能。」," 今年6月Container技術圈內的重頭戲DockerCon大會中，其中的一大亮點就是推出了Docker 1.12版本，並將調度工具Docker Swarm內建於Docker引擎中，解放開發者原本只能在單機部署Container的限制，讓使用者在多主機環境下得以部署容器化應用程式。
而近日歐洲舉辦的LinuxCon大會上，Docker技術長Solomon Hykes則更近一步，因應基礎架構調度的需求，推出了陳述式管理工具Infrakit。雖然容器調度工具SwarmKit與Infrakit都專注於解決應用程式調度問題，但兩者差異在於，前者鎖定的管理對象、使用情境為大規模容器應用程式管理，後者則是「對基礎架構調度像容器應用程式般依樣畫葫蘆。」Docker表示。
為解決異質環境維運難題，推出Infrakit
不僅如此，在今年DockerCon中，Docker更推出AWS及Azure雲端Beta版的Docker，一腳踏入跨雲市場，「除了能簡化設定Docker外，也能讓異質雲端發揮它們原生的優點。」
在開發雲端版本Docker時，Docker也了解到，必須建立一套管理、布建基礎架構的準則，並且在各類環境通行無阻，無論是相異公有雲廠商，或者是內部私有雲。Docker表示，其中的挑戰在於，各家廠商在營運基礎架構時，都使用相異的IP位址，「IT維運團隊應付的規模不只是有布建5臺伺服器而已」，更重要的是，讓IT人員更簡單地宣告應用程式所需要的伺服器數量、規格，或是對其進行組態設定，並在碰上伺服器故障的狀況中，系統能迅速地重新布建新伺服器，確保符合應用程式運作所需要的機器數量。
為此，Docker才開始著手研發Infrakit，「讓提供運作分散式系統的基礎架構，可以具有自癒能力（Self-Healing）功能。」
Docker也想要利用Infrakit，將基礎架構自動化功能拆分為更細緻、簡單的可插式套件。透過這些元件，系統可以確保基礎架構符合使用者預先設定的狀態。例如，自動檢查基礎架構現有的運行狀況，若發現偏離使用者的設定時，這些套件也能自行採取行動，讓系統恢復至正常狀態。
同時，考量開發者可能使用相異程式語言開發系統介面與套件介接，使用者可利用Docker Container將此些元件打包、封裝及部署，藉此解決異質環境的相容性問題。
Infrakit三大元件：群組、實例（Instances）、調味料（Flavors）
而讓Infrakit實現加強基礎架構自動化功能的幕後功臣，則是Infrakit內所包含的三大元件：群組、實例以及配方。第一是群組元件，Docker表示，透過此元件可以加強底層架構抽象化的程度，「比管理單一實例來得簡單多。」例如，使用者可以利用數臺機器組成1個群組，群組之中的伺服器可以擁有一致抑或相異的組態設定，前者適合部署無狀態（Stateless）的應用程式，後者則可以納入資料庫、永久儲存等應用。
再者則是實例（Instance）元件，「實例是隸屬群組中的成員」，Docker說明，此元件僅管理單一實例的實體資源，並不會介入群組的運作，目前此套件已經相容於軟體工具商Hashicorp所開發的虛擬化工具Vagrant、基礎架構管理工具Terraform，「未來還要為AWS、Azure推出更多套件。」
最後則是調味料（Flavors）元件，透過此套件，協助系統辨別群組中各個相異的實例。此外，它還負責對實體實例進行組態設定，並且對應用程式進行健康檢查。
未來Infrakit將要納入Docker引擎
目前Docker引擎由許多不同的套件所組成，像是調度工具SwarmKit，或者協助Docker與Mac、微軟作業系統環境整合的HyperKit、VPNKit以及DataKit，而Docker也表示，未來Infrakit將成為Docker引擎中的組成元件。
",https://www.ithome.com.tw/news/108943,"新聞,Docker,容器,Container"
108746,20,2016-10-08,為何Orchestration是企業擁抱容器的關鍵？,空中巴士已將40套內部PHP系統容器化、瑞士電信也將400套資料庫搬上了容器平臺，奇異旗下奇異家電靠800個容器撐起350個App的後端架構，越來越多企業擁抱容器技術後，如何管理數百、甚至數千個規模的容器叢集是新挑戰," 掀起容器技術風潮的Docker問世不過才3年，不只掀起了Container應用風潮，帶動了微服務新興IT架構崛起，更讓開發維運一體化的DevOps模式更容易實現。
Docker執行長Ben Golub今年6月在DockerCon年度大會上揭露了最新的Docker使用者調查，有6成Docker使用者，開始在正式環境中使用Container，而不像過去大多用於測試、開發階段。大型企業擁抱Container的腳步也開始改變，他更引用另一個2016年中調查，在超過500人規模的大型企業中，更有73％的企業在正式環境中採用。
而且不只有新創或大型網路公司擁抱Container，電商（如ebay、樂天），媒體（如Netflix、紐約時報、BBC），醫療（如Merck、Abbott）、金融服務（如VISA、ADP、PayPal）、製造業（奇異、空中巴士等），科技公司（如Amadeus、IBM、思科）、電信（例如瑞士電信）等，越來越多的產業都開始導入。
應用情境也不再以開發、測試、DevOps、CI/CD為主，Ben Golub透露，儘管DevOps驅動的CD需求仍是大宗，超過5成應用案例都屬這類，但也有43%的Docker案例用來將老舊系統微服務化進而搬上雲端，另外也有37％的Docker使用案例是將老舊應用容器化。目前Docker容器運用上有43％的容器是用來執行傳統的資料庫系統。
Container成為企業雙頭IT的另一列火車頭
Container不只是科技新創或網路公司愛用的技術，開始成為企業雙頭IT的另一列火車頭，專攻雲端原生應用和App。企業面臨的新架構不只是混合雲的架構，還是雲端原生應用的微服務架構，要和傳統應用程式架構的整合。
舉例來說，IT團隊多達1,300人規模的Airbus，不只希望能在企業內部實現快速開發和部署應用程式，還想要進一步將這個速度力延伸到雲端，並且希望擴充應用程式規模時，可以兼顧資源利用率優化來控管成本，更關鍵是，還要簡化舊有非雲端應用系統的汰換過程。「擁抱DevOps和Container的PaaS平臺，是唯一的選擇。」Airbus公司IT工具服務新創部門首席Nicolas Fanjeau在紅帽大會上透露。
也因此，Airbus採用Docker Container技術，並使用Kubernetes來作為Container叢集的管理平臺。不只在新專案上用Container，「內部採用PHP開發的150套應用系統，超過40套已經準備好要改部署到Container上。」他說。
奇異家電靠800容器執行350個App
美國奇異集團旗下的奇異家電，則是靠800個容器撐起了350個App的後端架構，甚至還能將61年老系統所用的後端資料庫Docker化後，方便搬進私有雲中調度管理。
營收超過50億美元的奇異家電，早在2012年中時開始導入私有雲和敏捷流程，花了一年時間打造了一套自助式IaaS平臺。但是奇異家電後來發現，負責維運IaaS平臺的團隊，成了最大的瓶頸。因為不同應用程式所需的執行環境配置差異太大，而且非常複雜，即使已提供了通用配置的IaaS平臺，連資料庫都建立了DBaaS服務，但奇異家電的IT團隊，仍舊得花很多時間來進行手動微調，才足以滿足業務部門需要的應用環境特殊需求。
直到2014年8月，奇異家電在當年Dockercon上看到了Docker和Mesosphere後決定導入，一方面用Docker建立高彈性的AP可移植性，降低部署到多種環境時的配置門檻，另一方面則利用Mesosphere來管理容器、建立自動化排程、擴充等需求，來簡化資料中心維運和管理。
奇異家電還自己打造了一個自助式Web版管理平臺，稱為Voyager，作為應用系統管理者的管理之用，避免直接連線到容器內應用提高安全性和政策控管。經過一年，奇異家電至少已將350個內部應用App轉移到Docker環境上正式提供服務，使用了超過800個容器。可以說奇異家電大多數的關鍵應用系統都已經Docker化了，甚至連用了61年老系統後端搭配的資料庫也容器化放到IaaS上管理。原本奇異家電評估，得花上好幾年才能轉移老舊系統到雲端環境，但後來只用了4個月，就將45％的應用系統轉移到新架構上。
下一步，奇異家電給自己設定的新挑戰是，要盡可能提高容器執行密度，希望能做到在單一刀鋒伺服器上能跑1,000個容器，也希望能將核心的Oracle ERP搬上Docker環境。但這些挑戰都不只是Docker技術本身的考驗，更是大規模容器叢集的維運難題。
容器正式應用越多，Orchestration機制越顯得重要
越來越多企業擁抱容器技術後，新挑戰也接踵而來，不只是數個或數十個容器，企業要面對的是成千上百個容器的維運，如何管理超大規模容器叢集，正是Container平臺的下一個新挑戰。Docker叢集專案Swarmkit負責人陳東洛表示，越來越多人想在生產環境上使用Container，Orchestration（調度）機制更顯得重要。

Docker叢集專案Swarmkit負責人陳東洛表示：「企業要回到調度需求本身來看，而不只是看應用規模就決定導入Orchestration工具，要找出調度需求的痛點，而不是容器需求的痛點。」

過去企業建置大規模叢集時，最常用來管理叢集內伺服器調度的做法，前Mesosphere分散式系統首席工程師Timothy Chen打趣的說，其實是靠Excel。在Excel表單上列出每一臺伺服器的IP和用途，每有異動就更新這張Excel表單，來建立一份叢集節點調度清單，但隨著微服務（Microservices）架構開始盛行、容器技術走向正式環境，單靠Excel已經很難管理複雜的大規模容器調度問題。
容器叢集的考驗是得管理上千個生命周期
CoreOS分布式項目主管李響更直指，容器叢集的挑戰是，企業不僅要管理一個應用程式的生命周期，而是要管理成百上千個容器的生命周期。
尤其在大規模容器叢集的管理上，有三大問題，李響解釋，第一是如何部署容器叢集、其次是如何從中找到特定一個容器，以及如何連結或存取到這個特定的容器。
管理容器叢集常見工具之一就是排程工具（Scheduler），作用就像是過去管理叢集常用的Excel檔，但更自動化也能更聰明。李響表示，Scheduler的作用時將實體資源都抽象成一個資源池，讓開發者只需要向Scheduler提出應用程式需要的資源，再由Scheduler來安排如何提供。換句話說，「對應用程式開發者而言，細節都被Scheduler 抽象化了。」其他可用來管理大規模容器叢集的關鍵的是，李響表示，最新作法是開始採用「服務」（Service）的概念來管理容器叢集，透過「服務」概念來抽象化，多個容器之間的溝通。例如透過服務概念來部署應用程式，做到如滾動升級、自動擴充、副本控制的效果，也比直接調度容器更簡單。
李響提到的Scheduler，只是調度層工具的其中一環，Timothy Chen補充，虛擬化時代，是在一個基礎架構上，管理多個VM內的單一應用，但是使用容器和微服務架構之後，往往得在基礎架構上，提供多個VM，執行多個Container，來提供不同的微服務，組合成各式各樣的應用系統。
因為每一個微服務都得像過去一個應用程式那樣來管理生命周期，「導致開發者在正式環境中運作應用程式所花的時間，比思考程式業務邏輯的時間還要多得多。」Timothy Chen說。
也因此，許多大型網路公司都各使用了不同的Orchestration工具來管理大規模的叢集，如Facebook的Tupperware、Google則有Borg和Omega、Yahoo則利用了Hadoop專案中的YARN，Twitter則是使用了Mesos和Aurora。

CoreOS分布式項目主管李響直言:「容器叢集的挑戰是，企業不僅要管理一個應用程式的生命周期，而是要管理成百上千個（容器）的生命周期。」

Orchestration工具三大功能
Timothy Chen歸納Orchestration工具一般涵蓋了三大類功能，包括了服務管理機制、排程機制和資源管理機制，Orchestration工具可以將Web應用和各類服務和Container Runtime層隔離，來簡化複雜的容器叢集管理難題。
更進一步的功能細節，排程工具要做到置換、擴充／複製、重新排程、升級、降級、資源蒐集等。而資源管理機制則要能管CPU、記憶體、GPU、儲存（Volumes）、網路埠、IP位址等資源，而服務管理機制則要做到如標記（Labels）、命名空間或群組（Groups/Namespaces）、相依性（Dependencies）、負載平衡（Load Balancing）、可讀性檢查（Readiness Checking）等。另外，Orchestration工具最好還要能實作出非功能性的能力，例如擴充性、可用性、彈性、使用友善、移植性、安全性等。「最終就是要用Orchestration工具來建立一個高度可程式化的基礎架構（Programmable Infrastructure）。」Timothy Chen說。
像CoreOS想要實現的目標也類似，李響表示，CoreOS的目標是，開發者只需使用一套叢集管理平臺，就能執行任何自己的分散式應用，甚至可以具備有Google級架構的基礎架構資源池，也就是擁有了GIFEE架構（Google's Infrastructure for Everyone Else，任何人都可用的Google架構）可以使用。
不讓各家Orchestration平臺專美於前，Docker也在今年6月的DockerCon大會上宣布進軍Orchestration平臺的競爭，從Docker 1.12新版開始內建Swarm叢集管理工具，將Orchestration變成Docker引擎的核心機制之一。
陳東洛是Swarm叢集專案開發的負責人，他解釋，其實Docker一直在研究容器調度工具，在1.12版之前，Docker透過Swarm、Compose、Machine等部署工具來實現容器調度，Swarm功能內建後，Docker新的叢集與調度工具是Swarmkit。

前Mesosphere分散式系統首席工程師Timothy Chen認為:「不同企業需要的網路、儲存、資安的差異很大，Orchestration平臺想要設計一套符合所有需求的通用架構，目前還是一大挑戰。」


Docker內建叢集管理新架構
新版Docker 1.12將調度功能內建，提供了新的叢集與調度工具Swarmkit，使用了Docker的Service API來管理服務，要做到服務包含任務，而任務由容器來實現，並內建服務生命周期管理，還要將系統狀態保存在內建的raft store上，所有服務的負載平衡機制也內建，不需像過去得由外部工具提供。所有容器間的通訊皆預設加密。

Docker為何要內建叢集調度
陳東洛想要透過Swarmkit解決的容器Orchestration需求，包括了如何將任務分配到對應的運算、網路和儲存資源上來執行、如何管理系統資源和系統變化（如新增節點或離線）、如何調度任務島的節點、管理任務的生命周期、協助使用者使用調度工具、實現端到端到安全性確保、另外還要滿足公有雲、私有雲和混合雲部署的需求。
因此，新版Docker 1.12所新增Swarmkit，使用了Docker的Service API來管理服務，要做到服務包含任務，而任務由容器來實現，並將服務生命周期管理內建，另外還要能將系統狀態保存在內建的raft store上，所有服務的負載平衡機制也內建，不需像過去得由外部工具提供。整個容器叢集內建CA，所有容器間的通訊皆預設加密。
Orchestration才剛起步，導入得先評估需求
儘管用Orchestration來管理大規模容器叢集已經成了Container圈的熱門話題，但是，目前這類工具還處於發展初期。上海道客網路科技技術合夥人孫宏亮就坦言，儘管Orchestration確定是主流趨勢，但目前才剛在起步階段，企業類型差異很大，若沒有大型企業的人力資源，中小企業導入調度工具前，反而應先將基礎做的更踏實，例如改變資源管理方式、強化容器安全管理等。

上海道客網路科技技術合夥人孫宏亮坦言:「儘管Orchestration確定是主流趨勢，但目前才剛在起步階段，若沒有足夠人力，中小企業導入調度工具前，反而應先將容器管理做得更踏實。」

李響也認為，Orchestration是一個新的領域，目前還缺乏一個共同的抽象層，可供不同的Orchestration平臺來遵循。甚至，Timothy Chen認為，目前Orchestration平臺大多來自大型網路業者的經驗所發展出來的架構，Google的Kubernetes就是最典型的例子，但是每一家企業需要的網路架構、儲存需求、資安需求的差異很大，Orchestration平臺想要設計一套符合所有需求的通用架構，目前還是一大挑戰。
陳東洛表示，在不同應用框架中，各家調度工具的設計有其各自的目標情境，例如網路模式、儲存模式、鎖定機制上的作法仍有不同，儘管大家都希望能適用更多業務情境，但可能還要1-2年後，出現更常見的使用者模式後，才會出現主流的Orchestration設計模式。
這正意味著，如何選對合乎需求的調度平臺，以及上手這些調度工具的門檻成了企業得付出的代價。在Orchestration工具發展初期，企業到底應該等待技術更成熟再採用，還是現在就要一步到位擁抱Orchestration，這成了企業擁抱Container之後的新難題。
陳東洛則建議，企業要回到「調度」需求本身來看，而不只是看規模或數量來決定是否導入Orchestration，他就曾遇過Docker建置規模很大的企業，卻不需要使用調度工具，因為他們可能只在一臺VM上跑一個容器。調度可解決的需求例如複雜問題，有各種依賴關係，資源大小需求不統一，資源相互競爭時需要保障特定情境的使用等。「這些都是業務面的痛點，找出調度需求的痛點，而不是容器需求的痛點，」他建議，首先該做的是提高對自身業務的了解，妥善監測自家業務的使用情況，再從數據來決定，是不是真有調度需求。
李響則建議可以從Dev和Ops的角度來評估，對開發者而言，產品發布流程卡在維運因素，導致長達2、3個月才能發布一次改版，就可以導入調度，「因為調度工具可以將維運流程自動化，將維運時間縮短到2,3天，不只是讓開發者高興，更可以提高收益。」而對維運團隊而言，每次新服務上線後，監控新服務的資源利用率是不是一大難題，若這也是企業維運的痛點，也可以成為一股導入調度工具的動力。若開發或維運都沒有遇到這類困難，「第一步是先容器化，而不要一次就導入調度工具。」
打造過維運10萬容器PaaS平臺的百度資深工程師段兵建議，企業得評估容器化的目的，不一定所有應用都需要容器化，以無狀態服務或Web類應用比較適合。百度先從PHP應用開始，結合有迭代改版需求的大型服務，如百度貼吧來降低難度，直到最近才開始將複雜應用遷移到容器環境中，儘管遷移過程問題不少，但對比於未來幾年可預期的研發效率提升，還是值得投入。尤其需要深思的是，段兵認為：「擁抱容器和調度平臺，不只是技術問題，更是架構變革，連帶也會引起組織變革，這是一條長路，得從技術和管理雙管齊下。」

百度資深工程師段兵表示：「擁抱容器和調度平臺，不只是技術問題，更是架構變革，連帶也會引起組織變革，這是一條長路，得從技術和管理雙管齊下。」

 相關報導  Container平臺新挑戰：超大規模容器叢集怎麼管？
",https://www.ithome.com.tw/news/108746,"新聞,Container,容器,Orchestration"
108748,20,2016-10-08,【大規模容器叢集實例】雷亞遊戲借助Kubernetes，3人搞定百萬玩家App底層維運,雷亞旗下熱門App遊戲VOEZ每日活躍使用者達到100萬人，需用到100個4核心VM組成後端容器叢集才夠，借助Kubernetes，只靠3個後端工程師就能撐起所有維運," 席捲IT業界的Container技術，雖然聽起來高不可攀，貌似只有具備扎實技術的大公司開發團隊才能使用，而位在臺灣的雷亞遊戲，員工數只有130人，其中30人的開發團隊大多數都是電腦圖像工程師，後端工程師的數量一隻手就能數完。雷亞遊戲技術長鐘志遠卻大膽地在正式環境中導入Docker及Kubernetes，更證明使用新技術並非大公司的專利。
成立於2012年的雷亞遊戲，截至現今已經推出了5款遊戲，在Google Play平臺上累積下載次數超過2,300萬，其遊戲已在23個國家中拿下付費排行榜的第一名。在2012年年底，雷亞遊戲推出音樂遊戲Mandora，鐘志遠表示，別於過去推出的產品，Mandora必須經由網路與後端系統連線，但是當時包含鐘志遠在內的8人工程團隊，全部都是專精影像處理，對於底層Linux、資料庫、負載平衡、系統狀況監控，以及網路架構等技術皆不精熟。
碰上如此多技術障礙，「我們決定盡可能使用手上有的資源，不要自己土法煉鋼。」在調查多方PaaS平臺解決方案後，鐘志遠決定選用AWS Elastic Beanstalk在Python環境進行遊戲開發，並且使用第三方資料庫服務商提供的服務，在拼湊各家現有現成服務後，也順利地完成此專案，「幸好當時使用流量並不高，讓伺服器能繼續順利運作。」他笑說。
鐘志遠表示，隨著公司成長，雷亞遊戲的企圖心越來越大，例如企畫團隊將會提出更多需要工程團隊實作的功能，未來也要成立專屬雷亞自家的帳號系統。同時，因為開發者規模增加，雷亞遊戲未來也需要更多遊戲發布商（Publisher）的支援，「所以遊戲伺服器不能依賴於任何PaaS平臺之上，當產品交付給發布商後，得要靠他們自行部署。」最後，鐘志遠還計畫推出更多透過網路連線的產品，因此雷亞遊戲也希望將系統拆解為許多微服務，藉此減低開發成本。
但即便到了2015年，包含鐘志遠在內，工程團隊仍然只有3位後端工程師，而這3人手上也肩負了兩個專案，「人力吃緊的狀況仍然存在。」如此情況讓他下定決心，必須用更少人力，在一定時間內開發出可以支撐雷亞遊戲營運的後端平臺，而此平臺必須完成三大目標：程式錯誤最小化，部署成本最低化，並讓系統累積的技術層（Technology Stack）降到最低。鐘志遠解釋，只要系統結構越簡單，越不需要花費心思研究新技術，讓團隊心力集中花費在寫程式以及思考遊戲邏輯，才能提升工作效率，「而Container便是讓我們完成這些目標的關鍵角色。」

雷亞遊戲技術長鐘志遠表示，在過去使用AWS PaaS平臺的經驗中，也讓他了解到PaaS平臺就像是黑盒子，但是在Container環境中，而應用程式運作所需要的底層技術都被封裝在容器中，「可以輕易了解程式結構，像是系統發布要求到結束的完整流程。」

每個後端工程師必學撰寫Dockerfile
在使用Docker Container前，第一步得先撰寫Dockerfile建置容器映像檔。鐘志遠認為，透過Dockerfile，開發者可以了解應用程式運作所需要的資源，以及該如何部署開發環鏡。因此他要求每一個參與後端系統開發的工程師，都必須具備撰寫Dockerfile的能力，「讓不同工程師自行開發的程式，也都能在他人電腦上運作。」在Dockerfile撰寫完成後，開發者只要將程式碼掛載於某執行目錄下，便能很快速地布建開發環境。
除了能快速建置開發環境，鐘志遠也在持續整合（Continuous Integration，CI）流程中導入了Container。他表示，在開發者存取GitLab儲存庫時，首先得要完成CI腳本，讓程式碼部署、測速流程盡量自動化。而利用Container將程式運作環境、程式碼一同封裝的特性，「測試時，不僅是測試程式碼，同時也可以測試運作環境。」
他也歸納雷亞遊戲CI流程的四大步驟：建制映像檔、測試映像檔、映像檔上傳至遠端環境，以及將部署在主幹（Master）環境、預備（Staging）環境或是開發環境。
第一步是利用Docker建置容器映像檔，只要映像檔名稱命名完成後，只要利用一行程式碼就可以將映像檔上傳至本地端容器儲存庫。第二步驟測試映像檔中，透過Container可以快速開啟、關閉，隨需即用的特性，快速建置測試環境。鐘志遠表示，此特性讓開發團隊不需要特別維護專門測試環境，例如，開發者只要利用過去CI流程中建制的腳本，就可以建置起資料庫，立即進行資料庫環境測試，「完成後再將資料庫清理完即可。」
再者則是將映像檔上傳至遠端環境，由於雷亞遊戲使用的Google公有雲服務中，有提供儲存Container映像檔的儲存庫，開發者只要對映像檔簡單地進行標註（tag），就可以將映像檔從本地端儲存庫中，上傳至雲端儲存庫中。
最後則是將映像檔部署於不同環境，例如主幹、預備以及開發環境。由於Google容器引擎（Container Engine，GKE）背後底層平臺為Kubernetes，也只需透過一行程式碼，就可以將應用程式部署於Kubernetes，「我們的CI過程相當簡單，利用Container建立CI流程是非常簡單的事情。」鐘志遠說。
這也是鐘志遠相當中意Container技術的原因，他認為，容器技術很適合整合在CI流程中，「藉此確保映像檔的運行環境一定經過測試才會上線，並且可以在異質基礎架構上進行部署。」
不過在決定程式碼部署於何種環境時，雷亞遊戲也有一定的內部控制流程，例如，工程團隊就替每一個環境都建立Git分支，當A開發者想要將程式碼部署開發環境時，就必須發出合併需求，並且請鐘志遠檢核程式碼品質，同時A開發者的合併請求，也必須另外的B開發者簽呈。完成這些控管流程後，鐘志遠便會同意將合併開發者提交的程式碼，10分鐘之後，Kubernetes就會將容器部署完畢，「現在所有程式碼得必須經過這樣的CI流程測試才可以上線。」
Kubernetes可免手動管VM，環境也不如PaaS受限
然而，究竟是哪些因素，讓鐘志遠決定從既有PaaS環境，轉移到Kubernetes、Container環境？他比喻，若Google GCE、AWS EC2這類的IaaS環境，和Google GAE、AWS EBS此類型的PaaS環境，分別處於光譜兩極端，最底層為IaaS，而最上層為PaaS時，Kubernetes則位於中間偏上的光譜地帶，「介於PaaS及IaaS之間，不過它比較類似PaaS。」鐘志遠近一步解釋，Kubernetes不如IaaS的操作，必須深入至VM層級手動建置服務，但是也不受限於PaaS環境的局限，可以在Container環境中選擇偏好的技術建置開發環境。
「我們希望能有一個具備PaaS環境特色的環境運行Container，讓程式碼可以在異質環境中運作。」鐘志遠表示，在過去使用AWS PaaS平臺的經驗中，也讓他了解到PaaS平臺就像是黑盒子，例如，常常應用程式部署到一半便發生錯誤，由於團隊中並沒有熟悉Linux的後端人才，也沒有太多時間研究系統Log檔案，礙於對PaaS平臺掌握不足，也對開發團隊帶來很大的負擔。在導入Kubernetes環境之後，開發團隊也擁有較大的自由。鐘志遠認為，Kubernetes是一套容器調度工具，並且將系統需求引導至Container環境中，而應用程式運作所需要的底層技術都被封裝在容器中，「可以輕易了解程式結構，像是系統要求發布到結束的完整流程。」
導入Kubernetes也可以延續PaaS平臺的使用習慣，開發者不需要自動管理VM，同時它也具備自動彈性擴充（Auto-Scaling）、負載平衡、Log記錄，以及系統監控等基礎建設功能。

Kubernetes中也有一支背景程式專門蒐集各個節點的運作狀況，只要透過第三方雲端服務供應商，開發者即可以將系統Log資訊連接至監控系統，像是觀測每個節點的CPU使用量，將資料進行視覺化。

使用Kubernetes的三大優點
除了技術決策的原因，鐘志遠也歸納其他Kubernetes的使用優點。第一是其開源的性質，只要使用上碰到任何異常，只要開啟它在GitHub專案的頁面，就可以了解其運作原理且進行除錯。
第二則是Kubernetes支援多區（Multi-zone）部署功能，在其1.2.4版本中，開發者可以在資料中心內建置叢集外，叢集還可以分布在不同區間(Zone)內，藉此提升應用程式的可用性。
最後則是其運行環境很容易開發者進行除錯。鐘志遠舉例，當開發者想要利用本機電腦連線至遠端環境除錯時，開發者不需要透過重重的SSH連線、建立VPN等步驟，只需要一些基本指令，就可以對Container進行存取並且讀取其內部運行資料。
今年開始將Kubernetes導入正式環境
雷亞遊戲今年推出的音樂遊戲VOEZ中，總共包含了三大系統元件：帳號系統、遊戲邏輯系統，以及防作弊系統，而鐘志遠就導入了Kubernetes做為其底層架構，將其VOEZ切割成數個Kubernetes叢集。他解釋，由於帳號系統會與其他遊戲共用，所以自成一個獨立叢集，而由於遊戲邏輯系統與防作弊系統間的互動緊密，因此兩者則整合於統一叢集中，「利用Kubernetes則可以將不同微服務進行串接。」
但是行銷團隊經常構思不同的推廣方案，像是在周六推出免費歌曲，此時系統請求就會暴增5倍，「這對行銷是好事，但是突然暴增的流量對工程師非常有壓力。」鐘志遠表示，由於此專案只有3位工程師負責，並沒有專屬人力時時監控系統流量，因此，系統自動水平擴充是他認為最重要的功能。而在Kubernetes中，只需要一組指令就可以完成水平擴充功能。他舉例，開發者可以自行設定參數，例如當CPU使用率達到70％時，系統會自行產生新節點（Pod）。同時，也必須要對底層VM進行類似設定，讓系統在自動產生新節點時，提前產生可以容納節點的VM，「藉此就可以透過Kubernetes實現水平擴充的功能。」

Auto-scaling
雷亞遊戲行銷團隊經常構思不同的推廣方案，像是在周六推出免費歌曲，此時系統請求就會暴增5倍。因此，系統自動水平擴展是鐘志遠認為最重要的功能。

除了水平擴充，還能進行流量測試、系統監控
除了部署服務、自動水平擴充外，Kubernetes還可以進行流量測試、系統監控。鐘志遠表示，單臺電腦可以發出請求有限，而開發者可以在Kubernetes平臺上部署分散式流量測試工具Locust，「過去我們就曾使用30臺VM，像系統發布每秒5,000至6,000次的請求次數（RPS，Request per second）。」
而Kubernetes中也有一支背景程式專門蒐集各個節點的運作狀況，只要透過第三方雲端服務供應商，開發者即可以將系統Log資訊連接至監控系統，像是觀測每個節點的CPU使用量，將資料進行視覺化。
從今年一月才開始使用Docker及Kubernetes的雷亞遊戲，在短短半年內就成功導入到正式環境。目前VOEZ每日的活躍使用者約有100萬人，必須利用100個4核心VM才能撐起叢集的運作，「而Container及Kubernetes威力之處，就是讓我們在半年內，只靠三個人就完成這樣的系統架構。」
 相關報導  Container平臺新挑戰：超大規模容器叢集怎麼管？
",https://www.ithome.com.tw/news/108748,"新聞,雷亞遊戲,Kubernetes,Container,容器"
108747,21,2016-10-08,【大規模容器叢集實例】百度打造自家PaaS私有雲，1人也能維運10萬臺Container,早在Docker爆紅的2013年前，百度就開始著手利用Container技術，打造自家的PaaS私有雲平臺BOAS，更將貼吧、糯米等核心業務整合至BOAS," 從搜尋引擎起家的百度，除了原有的搜尋服務，近年更跨足於地圖、行動團購服務糯米，並且經營中國最大社群論壇貼吧。負責建置百度PaaS私有雲平臺的百度資深工程師段兵表示，百度內推出任何一個產品，投入研發人數往往超過100人，每周發布新版本次數超過50次，而維運團隊需要更需要管理超過1,000臺伺服器及100個不同的應用程式。
但他表示，在傳統IT架構下，不僅硬體資源的使用效率低落，而且過去應用程式直接部署於裸機的做法，導致各服務與底層作業系統、函式庫的相依性高。面臨結構越來越複雜，以及規模增加的業務，「如何支撐系統運作，並且進行快速地更新、迭代，是百度所面臨的挑戰。」因此，早在Docker爆紅的2013年之前，百度就開始著手利用Container技術，打造自家PaaS私有雲平臺BOAS（Baidu Open Application Service）。
BOAS五大階段發展
誕生於2012年的BOAS平臺，源自於百度對於PHP地依賴，在2010年時，百度將從過去C語言開發，大量轉為使用PHP開發應用程式。段兵解釋，由於PHP是一種無狀態（Stateless）的腳本語言，除了能快速實作應用程式邏輯外，相比過去使用C語言，一周只能發布10次新版本的速度，使用PHP進行開發的發布次數則大大增加，但是同時，「維運成本同時也大幅增加。」此時，百度便萌生開始利用Container架構內部私有PaaS平臺BOAS的想法。次年，百度則替BOAS平臺進行深度PHP客製化，並且將貼吧的前端業務系統整合至BOAS，「對於BOAS穩定性是相當大的肯定。」
在整合百度貼吧前端系統獲得成功後，2014年百度更大舉將百度錢包、糯米等核心業務整合至BOAS，同時將大部分使用Java開發的Web服務也移轉至BOAS平臺。在這兩年中，貼吧後端系統更一併整合至BOAS中。
然而，為何百度陸續地將核心產品整併至BOAS中？「主要是源自我們對迭代速度提升的要求」，段兵表示，目前BOAS僅需要1名維運人員，就可以管理2萬臺伺服器及超過10萬個Container，除了維運效率提升5倍之多外，「硬體資源使用率總共提升了20％，服務穩定度也超過99.99％。」
沒有BOAS前，開發過程繁複而且緩慢
在過去還沒有BOAS平臺中，在研發團隊拿到需求設定文件後，得開始布建開發環境，並且編寫基礎函式庫以及應用程式碼。在完成開發流程後，開發團隊則將程式碼提交給測試工程師。此時，測試團隊也得要自行建構測試環境。
結束測試階段後，則進入產品發布階段。這階段中，維運團隊得要採購伺服器、建置正式環境，並且負責部署應用程式等繁瑣工作。在服務成功上線後，則會生成許多系統Log資料，維運團隊也得根據營運狀況，進行系統性能分析並產出報告，「過去的流程不僅角色多，過程也複雜，導致研發速度緩慢。」
因此，在導入BOAS後，不僅簡化了流程，也減輕各角色間負責的工作。段兵表示，現今研發團隊拿到需求開發後，只要專注心力在開發程式碼即可，「BOAS會提供開發環境、測試環境。」在完成測試階段後，BOAS則可讓開發者建置正式環境，提供程式碼部署、引進使用者流量等服務。
當產品已經進入正式環境後，BOAS也能提供資料收集服務，讓維運團隊不再需要手動收集系統資料，就能提供系統性能分析、監控警報，並根據這些系統資訊產生維運報告，「這就是BOAS能達到的效果。」段兵表示。
BOAS的三層架構：IaaS、PaaS，以及SaaS
不過，究竟BOAS是何種PaaS平臺？段兵給了一個定義：「可以讓使用者靈活地管理應用程式生命周期，並採開放形式管理的PaaS服務。」他認為，BOAS總共包含三大特色：靈活、明確規範，並且橫跨應用程式的生命周期。第一特色為靈活，使用者可以透過UI介面、API操作BOAS，並且根據不同需求，提供客製化解決方案。
第二，BOAS平臺有訂定明確使用流程，必須符合百度內部的開發模式。像是整併於BOAS的百度貼吧、糯米、百度雲等產品，「我們不是針對各產品提供相異服務，而是使用統一的PaaS平臺。」最後，在應用程式的開發、測試，到上線階段中，都可以透過BOAS執行。
而BOAS的結構，則包含了三大層：底層IaaS、中間層PaaS，及最上層的SaaS。最底層的IaaS層，由伺服器、網路、儲存等元件組成，並且利用百度自家開發的Matrix叢集作業系統，可對大規模Container進行調度。在中間的PaaS層中，則建構了許多模組化服務，包含資源管理、變更發布、流量引入、監控警報、映像檔服務。最上層的SaaS，則是運作了貼吧、糯米、地圖等服務。

百度資深工程師段兵認為，效能對建置私有雲有相當重要的影響，因此「快速啟動、高性能是我們選擇Container的主要原因。」

效能是百度採用容器的首要理由
段兵比較了VM和Container這兩個虛擬化技術間的優缺點。相比於Container，VM的隔離性、資源限制機制都更好，但是運作性能方面，VM約會耗損20％的CPU效能，而Container僅耗損5％，性能直逼裸機。在啟動速度上，Container更是以毫秒為單位計算。他認為，效能對建置私有雲是相當重要的考量因素，「快速啟動、高性能是我們選擇Container的主要原因。」
在決定選用Container作為BOAS底層架構後，管理方式也會與VM相當不同，「IT架構發生極大變化，底層不再是由單機的CPU、網卡、儲存設備構成，而是許多分散式叢集組成。」段兵表示，百度也分別在北京、上海及香港等地設置IDC機房，而使用此些機房為基礎，結合分散式作業系統，將硬體資源整合成統一資源池。
針對單一Container，百度也設計了相關機制，進行資源進行隔離、限制。段兵表示，百度自製的Container引擎也仿效Docker的設計，支援資源限制cgroup，以及PID程序隔離機制，但是在單一容器能取用的資源上，則設計了兩個參數Quota及Limit，前者保障Container使用的硬體資源，後者則定義了資源使用上限。段兵舉例，像是針對單一容器，使用者可就可以限制其儲存參數Quota為4GB，Limit則為6GB，其實際用量可以介在兩者之間。此外，使用者甚至可以設定為-1GB，來降低其優先程度。
除了單一Container設定和優化機制，更關鍵的是在大規模容器調度的設計，百度也做了特別的考量，而BOAS平臺的設計概念總共從四大維度為出發點。第一是離散度，段兵解釋，離散度是釐清運行某服務可分配到的實例（Instance）數目，此舉有利於將服務平均分配在不同機櫃、伺服器中，減低硬體故障對服務造成的影響。第二是服務依賴程度，部署於同一主機中相異服務間的溝通、聯繫。
再者是副本控制，BOAS平臺同時支援水平擴充（Scale-out）以及垂直擴充（Scale-up），前者是控制Container副本的數量，後者則是重新調整Container中Quota、Limit參數的大小，「因為業務剛開始上線營運時，很難評估資源的需求為何。」
為了實現自動化及減少維運成本，百度得讓BOAS具備自動擴充（Auto-scaling）功能，段兵認為，此功能解決的核心問題是「對容量的評估不夠準確」，即便對系統進行監控、分析，也很估算出特定時間內服務所需要的容量為何，「自動彈性伸縮機制就是要解決此問題。」
在建置自動擴充功能時，段兵歸納出數個導入前的評估指標，像是必須事先計算應用程式的CPU利用率、使用者流量，推估未來服務的容量是否足夠。再者，使用者也得計算未來需要擴增多少實例，比較推算結果是否與符合預期數字。此外，每次新增的實例數目都得有所限制，「因為彈性擴充必須設定冷卻時間，即下次進行水平擴充所需的最短時間」，如果實例數量擴張過多也必須進行移除。
然而，除了系統自動動態擴張，針對未來可預期的爆增流量，也必須事先進行準備。段兵舉例，像是中國各大電商促銷日往往來帶爆量人潮，如京東618大型促銷活動、百度糯米517吃貨節，或是阿里巴巴雙11特賣，「可預期這些期間流量會大幅成長，得預先計畫在某些時段進行擴充。」

BOAS平臺提供了服務實例視覺化圖表，可呈現容器實例進行水平擴充後，資源池可調用的總資源也下降的關係。

系統監控帶來維運視覺化、自動化
BOAS平臺掌管了超過10萬個Container ，自然不可能單靠人力手動維護，自動化監控系統也就成為重要功能，「監控的核心價值在於，讓維運工作視覺化、自動化。」段兵解釋，系統資料視覺化讓維運團隊、開發團隊可以觀察某服務在正式環境的運作狀況，並且利用視覺化介面，改變應用程式的狀態，而系統自動水平擴充，不需藉由人力新增伺服器紓解流量。
監控系統得蒐集的資料除CPU、記憶體、硬碟等硬體運作資訊外，也會從業務日誌統計程式碼錯誤、每秒查詢率等數據。在備齊了這些資料後，也得進行資訊整合，所以BOAS可供使用者不同資料尺度進行檢視，大至IDC機房、叢集，小至各服務、實例。
利用這些數據，BOAS系統還能對開發者進行預警，例如，當某應用程式CPU使用率過高，導致伺服器過載時，就必須進行水平擴充，或是發現服務發出HTTP 503、500等錯誤訊息時，就得要重啟服務，或是將服務搬遷至他處。

聚合：App監控
BOAS平臺蒐集系統運作資訊，並透過視覺化方式呈現，例如展示應用程式當前的運作情況，針對狀態異常的服務，維運團隊也可重新啟動。


Container監控
使用者可以利用BOAS平臺的監控系統，觀測Container每段時間記憶體、CPU的使用比例。

建置BOAS平臺三大心得
在建置BOAS過程中，段兵也歸納出3大心得。第一是利用背景程式（Daemon）啟動Container，即便資源管理、部署管理系統皆發生異常，仍然不能影響Container內執行的程序。第二則是技術架構革新對組織帶來的影響，「雲端化是一個技術變革，而技術架構的變化，也等同於組織架構的變化」，必須逐步地革新。
最後是Container共用作業系統核心的特性，使其先天隔離不如VM的弱點。對此，百度也設計一些機制，藉以補強其弱點，像是對每個服務設定SLA，對於每個業務使用資源設定預期值，「一旦超過，可以透過第三方外掛程式進行處理。」段兵表示。
 相關報導  Container平臺新挑戰：超大規模容器叢集怎麼管？
",https://www.ithome.com.tw/news/108747,"新聞,Container,百度,PaaS,容器,BOAS"
108904,21,2016-10-07,Container雙周報第19期：資料中心作業系統DC/OS 1.8版本釋出，加強Container安全及容器調度,新版本DC/OS除改善認證、安全功能，也強化DC/OS處理大數據以及Container網路功能," 重點新聞（9月24日-10月7日）
·DC/OS 1.8版釋出，加強Container安全及容器調度
資料中心作業系統DC/OS釋出1.8版，Mesosphere表示，新版本除改善認證、安全功能，也強化DC/OS處理大數據以及Container網路功能。而此版本中的亮點就是調度工具Marathon被整合為DC/OS中的內建服務。Mesosphere表示，未來開發者可以透過DC/OS的UI介面或儀表板，直接管理服務或是進行容器調度。
Mesosphere也表示，新版本也提供企業更進階的容器基礎架構安全措施。例如利用SSL加密機制，封裝跨叢集的資訊傳輸。
在大數據方面的應用，新版本則開始支援Hadoop分散式檔案系統（HDFS），透過DC/OS Universe的UI介面或是一行指令，使用者即可完成HDFS的安裝程序。而DC/OS Cassandra服務開始支援跨資料中心遠端複製（Cross data center replication）功能，藉此提供服務可用性，並降低跨區使用者存取系統的延遲。更多資訊
·內建Docker引擎的Windows Server 2016正式出爐
微軟在Ignite大會中推出Windows Server 2016時，更在其中內建Docker引擎，並且提供商業支援版本的Docker Engine，除了原生支援Docker外，Windows Sever 2016也提供企業2種部署應用程式的方式，包含Windows Server Container以及Hyper-V Container。
Docker也揭露一些與微軟商業合作的細節，第一是推出經由Docker認證、測試的商業支援Docker引擎（Commercial Supported Docker Engine）。Docker表示，此引擎將會免費提供給Windows Server 2016的用戶。再者Docker資料中心也可以用於管理容器化的Windows Sever工作流程。
對於開發者，Docker與微軟也整合了開發工具Visual Studio for Docker以及Windows版Docker，提供使用者完整的桌面開發環境，撰寫Docker化的ASP.NET Core應用程式。更多報導

·Docker推Infrakit專案，讓基礎架構具備自癒能力
Docker推出Infrakit專案，讓分散式系統能建置自癒能力（Self-healing）的基礎架構。在整合AWS及Azure環境時，Docker了解到，必須想出一套管理基礎架構的方式，同時能夠適用於各類異質環境。
Docker表示，Infrakit專案將基礎架構自動化功能切割成簡單、可插式元件，而這些套件也一同運作，確保系統狀態符合使用者最初訂定的規範，未來Docker也會將Infrakit整合至Docker引擎中。更多資訊
·Kubernetes 1.4版釋出，2個指令就能布建容器叢集
暨7月Kubernetes釋出1.3版，讓叢集規模提升2倍後，近日Google再次宣布推出Kubernetes 1.4版，降低開發者在各種環境運作Kubernetes的難度。此版本的更大亮點便是加強叢集聯邦功能（Cluster Federation），讓開發者可以在跨雲、跨叢集環境中直接部署Kubernetes。
新版本中，開發只需要輸入兩個指令就可以建立叢集，此功能支援範圍也橫跨公有雲、私有雲，以及裸機等環境。在安裝程序中，Google也將Kubernetes與Linux作業系統的程式相依性一同打包，讓使用者能透過熟悉的工具安裝Kubernetes，目前支援的Linux作業系統包含Red Hat以及Unbutu Xenial。

Google同時也強化對於Container安全的支援，像是新增的節點安全措施（Pod Security Policy），讓系統管理者根據不同帳號、群組或使用者，替Container或節點設定相異的資安規則（Security Context）。更多報導

·Niantic用Kubernetes解決寶可夢爆量問題
今年7月，Pokémon GO遊戲剛在澳洲和紐西蘭正式上線不到15分鐘，玩家流量就遠遠超過了開發者Niantic公司的預期，尤其是儲存所有玩家資料的Cloud Datastore資料庫服務流量暴增，很快達到事先預估最大值的5倍量，Niantic也連忙尋求Google CRE團隊的尋求。
Pokémon GO遊戲使用了十多項Google Cloud服務，並建置了一個超大規模的Kubernetes叢集來支撐後端運算。Luke Stone表示，Pokémon GO所用的容器叢集，是GCE平臺推出後有史以來最大規模的叢集。在爆量出現後，Google也緊急調度了許多套核心數破萬的容器叢集，來分擔Pokémon GO遊戲的流量。
而遊戲後端系統則布建在Container應用環境中。遊戲核心程式都用部署在Google容器服務GKE上的Kubernetes叢集中。Niantic利用GKE來打造一個全球性架構（planetary-scale）的容器叢集，讓他們的開發團隊可以專心於部署各項玩家需要的即時更新功能。更多報導
·OpenStack第14版釋出，靠一套API管裸機、VM及Container
為了簡化部署與操作友善性，OpenStack剛推出第14版Newton，將OpenStack定位整合引擎，主打企業能夠透過單一API來管理裸機、虛擬機器與容器調度架構（Container Orchestration Framework），並強化擴充性與提高容易使用度等。
OpenStack基金會執行長Jonathan Bryce表示，OpenStack持續致力於降低使用門檻，讓一般的企業也能夠容易操作，在剛推出的第14版Newton中，已增加裸機服務，並可用單一的API來管理裸機、VM與容器，也同時強化了安全控管機制，與支援如GPU等硬體。
 新版本Newton，也釋出許多新功能，包括在Liberty版亮相的Container流程管理服務Magnum套件正式版，現新出爐安裝指南（Install Guide）、與在實體機上支援Kubernetes叢集與建立非同步叢集等。另外，用來解決Container在OpenStack環境執行時，所產生網路互通問題的Kuryr專案，在Newton版本中，能進一步管理Container的網路，並整合Swarm及Kubernetes。更多報導
更多產品動態
·亞馬遜Amazon CloudWatch支援Contaienr監控、問題排解更多資訊

·靠開源專案Image2Docker，將Hyper-V容器映像檔轉成Dockerfile更多資訊

·DC/OS也支援GitLab部署更多資訊
·CoreOS商業服務Tectonic開始支援RHEL 7.2及CentOS 7.2 更多資訊
·CoreOS釋出開源專案Minikube，可在本地端運行單一節點Kubernetes叢集更多資訊

Container資源
※知識：比較微服務與SOA架構
※影片：在微軟環境中靠Docker發揮DevOps的力量
※How-To：開始使用Docker Cloud
※How-To：增進Docker工作環境效率的4個小訣竅
",https://www.ithome.com.tw/news/108904,"新聞,Docker,Container,Windows Server,OpenStack,Kubernetes,DC/OS,IT周報"
108745,21,2016-09-30,Windows Server 2016正式出爐，Docker終於可以在Windows上用了,Docker執行長Ben Golub認為，此一戰略合作對於Docker抱持「應用程式只需寫一次，便可在各處運作」的理念是關鍵一步," 微軟在Ignite大會中推出Windows Server 2016時，同時也和Docker合作，在Windows Server 2016中內建Docker引擎，並且提供商業支援版本的Docker Engine。微軟表示，Docker目前為市場公認容器調度、Container技術的領先廠商，「我們和Docker合作，想讓Windows Server 2016成為最適合運作Container的平臺」，除了原生支援Docker外，Windows Sever 2016也提供企業2種部署應用程式的方式，包含Windows Server Container以及Hyper-V Contaier。
透過與微軟合作，延伸Docker生態系
Docker也引用產業分析報告，顯示Windows Server在x86伺服器中的市占率高達6成，同時Azure也是成長最快的公有雲服務。因此，Docker宣布與微軟合作的戰略，除了將Docker帶入廣大的Windows Server市場，同時還能擴大既有的Docker生態系版圖。而Docker執行長Ben Golub認為，此一戰略合作對於Docker抱持「應用程式只需寫一次，便可在各處運作」的理念是關鍵一步，讓企業無論是在跨雲、內部私有雲，或是混合環境都能部署應用程式。
提供Docker引擎商業支援服務
Docker也揭露一些與微軟商業合作的細節，第一是推出經由Docker認證、測試的商業支援Docker引擎（Commercial Supported Docker Engine）。Docker表示，此引擎將會免費提供給Windows Server 2016的用戶。再者，Docker與微軟將會一同推廣Docker資料中心，除確保Windows Server應用程式的安全，還可以用於管理容器化的Windows Sever工作流程，「無論是在公有雲、內部，或是混合環境。」對於開發者，Docker與微軟也整合了開發工具Visual Studio for Docker以及Windows版Docker，提供使用者完整的桌面開發環境，撰寫Docker化的Windows應用程式。
微軟Windows Server總經理Erin Chapple認為，隨著數位轉型加速，企業內部的應用程式都必須進行改變。她表示，對於傳統、雲端原生應用程式，Windows Server 2016也提供了新型的運作、部署方式，例如，Windows Server Container，或輕量的Nano Server等部署選項。同時，微軟也讓企業可以選擇在Azure或是私有環境運作應用程式。

Docker與微軟也整合了開發工具Visual Studio for Docker以及Windows版Docker，提供使用者完整的桌面開發環境，撰寫Docker化的Windows應用程式。圖片來源：Docker

",https://www.ithome.com.tw/news/108745,"新聞,Docker,容器,Windows Server,Container"
108732,21,2016-09-30,Kubernetes 1.4版本釋出，只用2個指令就能布建一套容器叢集,除了降低使用門檻之外，此版本的更大亮點便是加強叢集聯邦功能（Cluster Federation），讓開發者可以在跨雲、跨叢集環境中直接部署Kubernetes," 暨7月Kubernetes釋出1.3版，讓叢集規模提升2倍後，近日Google再次宣布推出Kubernetes 1.4版，降低開發者在各種環境運作Kubernetes的難度。
除了降低使用門檻之外，此版本的更大亮點便是加強叢集聯邦功能（Cluster Federation），讓開發者可以在跨雲、跨叢集環境中直接部署Kubernetes。
簡化使用、部署門檻
Google表示，在Kubernetes推出正式版的一年多以來，使用者範圍已經遍布不同行業，從新創公司到大企業皆有導入。而Google也表示，在聽取某一大規模用戶的反應後，透過各社群協作，將新版Kubernetes變得更易於使用、安裝，改善範圍更橫跨了安裝、啟動、認證、網路，以及部署等程序。
例如，新版本中，開發只需要輸入兩個指令就可以建立叢集，此功能支援範圍也橫跨公有雲、私有雲，以及裸機等環境。在安裝程序中，Google也將Kubernetes與Linux作業系統的程式相依性一同打包，讓使用者能透過熟悉的工具安裝Kubernetes，目前支援的Linux作業系統包含Red Hat以及Unbutu Xenial。
強化Container、節點安全
在新版中，Google同時也強化對於Container安全的支援，像是新增的節點安全措施（Pod Security Policy），讓系統管理者根據不同帳號、群組或使用者，替Container或節點設定相異的資安規則（Security Context）。
另外，Kubernetes也支援Linux Kernel安全模組AppArmor，管理員可以強化部署過程安全，使用者也可以利用AppArmor，對Container進行組態設定，限制容器對於系統的操作權限。
延伸支援紀錄狀態的應用程式（Stafeful Application）
Google表示，現今雖然雲端原生應用程式都內建Container，但是許多暨有應用程式需要額外功能，加強對Container的支援。像是許多記錄狀態的應用程式（Stateful Application），如資料庫、軟體更新工具。
而Kubernetes 1.4版也新增了一些功能，簡化這些應用程式的部署難度，像是排程工具（Scheduled Job），使用者可以設定時間區間，讓系統執行批次任務。
",https://www.ithome.com.tw/news/108732,"新聞,google,Kubernetes,容器調度,Container"
108719,21,2016-09-30,迎戰50倍爆量夢魘！Pokémon遊戲打造GCE史上最大Kubernetes叢集,Niantic用Google的Cloud Datastore資料庫服務來儲存所有玩家資料，這是架構起Pokémon遊戲世界最主要的資料庫。但在遊戲上線第一天，不到15分鐘，Cloud Datastore每秒存取次數迅速從5倍、10倍，增加到了比預期多50倍的爆量流量。," Niantic一點都沒想到Pokémon GO遊戲會這樣爆紅。7月6日，Pokémon GO遊戲剛在澳洲和紐西蘭正式上線不到15分鐘，玩家流量就遠遠超過了開發者Niantic公司的預期，尤其是儲存所有玩家資料的Cloud Datastore資料庫服務流量暴增，很快達到事先預估最大值的5倍量，甚至不久後，Niantic技術長Phil Keslin坦言，還增加到了50倍爆量流量，比他預估最壞的情況還要慘10倍。Niantic團隊嚇壞了，連忙打電話給Google CRE團隊尋求協助，因為隔天，Pokémon GO就要正式在美國上線。
Google內部一手包辦各項全球性服務維運的是SRE（Site Reliability Engineering）團隊，隨著雲端服務大舉進軍企業市場，Google正打算將自家SRE經驗，轉變成協助企業維運雲端服務的CRE（Customer Reliability Engineering）服務團隊，Niantic就成了Google CRE服務的第一號顧客，第一個任務就是確保Pokemon遊戲不被50倍爆量流量衝垮。
Google新的CRE服務部門總監Luke Stone是協助Niantic解決Pokémon GO爆量夢魘的關鍵人物，9月29日時，他在Google雲端平臺部落格上，公開了他們如何對抗爆量夢魘的幕後故事。他還特別發布了一張Pokémon GO遊戲所用Cloud Datastore每秒交易流量的變化，Pokémon GO使用了大量Google Cloud上的服務，其中用來儲存遊戲所有玩家資料的Cloud Datastore資料庫服務，是架構起Pokémon遊戲世界最主要的資料庫。遊戲上線當天，Cloud Datastore每秒存取交易次數迅速從5倍、10倍，增加到了50倍的爆量。

不斷湧入的玩家流量，衝垮了原先所有預期的設計，Niantic和Google Cloud旗下CRE、SRE、開發者、產品人員、技術支援團隊紛紛出動聯手來解決這個難題。Google工程師開始設法調度更多額外資源來支撐服務，不過，只是擴充資源還不夠，超大流量已經衍生了不少遊戲穩定性的問題。
為了讓上百萬名新玩家可以繼續登入遊戲，工程師一方面先拆解這些衍生問題的發生順序，來找出不同階段問題的對策，另一方面，Google CRE團隊手把手和Niantic一起重新檢視遊戲架構的每一個環節，甚至找來開發Google Cloud平臺的核心工程師和產品經理幫忙。Pokémon GO遊戲後端其實是布建在Container應用環境中。遊戲核心程式都用部署在Google容器服務GKE上的Kubernetes叢集中。Niantic利用GKE來打造一個全球性架構（planetary-scale）的容器叢集，讓他們的開發團隊可以專心於部署各項玩家需要的即時更新功能。Niantic還利用Google Cloud來建立Pokémon GO的後端單一服務平臺，可以提供持續部署和改善。
Pokémon GO遊戲使用了十多項Google Cloud服務，並建置了一個超大規模的Kubernetes叢集來支撐後端運算。Luke Stone表示，Pokémon GO所用的容器叢集，是GCE平臺推出後有史以來最大規模的叢集。在爆量出現後，Google也緊急調度了許多套核心數破萬的容器叢集，來分擔Pokémon GO遊戲的流量。
因為在Niantic中主導Pokémon GO遊戲決策的團隊才不過6個人，其中負責開發的人更只有4個人，因此Niantic得仰賴許多來自Google底層雲端平臺開發團隊，尤其是擅長架構和維運的工程師，來協助打造這個全球性遊戲的底層架構。
甚至，Niantic做出了一個更大膽的決定，要在遊戲不停機的情況下進行平臺升級，將Pokémon GO容器叢集所用的GKE，升級到下一個有能力提供一次擴充1千個節點的新版本。這個升級就像是在飛機飛行中同步更換引擎一樣的困難。不過，在升級之前，Niantic和Google先更換了新的網路負載平衡機制，改用Google的新版HTTP/S負載平衡服務來取代。這個服務可以提供一套全球架構的HTTPS流量管理系統，也提供了更多控制機制、更快的使用者連線速度，以及更高的整體吞吐量。
搭配大量運算資源擴充、新版GKE的架構升級、新一代負載平衡機制後，2周後，Pokémon GO登陸日本時，新玩家人數比美國玩家多3倍的情況下，還能順利運作。Google事後也將這些在Pokémon GO爆量事件中所修補的臭蟲，都提報到Kubernetes開源專案中改善。
不過，單靠Google加持還不夠，Pokémon GO爆紅之後，不止湧進大量玩家，也開始出現非人玩家的爆量存取，包括了大量第三方程式、軟體機器人等各式各樣的資料爬蟲程式，尤其8月初在南美洲、巴西等國推出時，非官方程式的爆量存取，更讓Pokémon GO被迫延後上市時間，因為服務幾乎快撐不住了，後來，Pokémon GO決定在8月3日開始封鎖那些「非人」的特殊查詢流量，才讓遊戲服務恢復正常。Niantic執行長也在8月4日時在Pokémon GO官網解釋了南美洲上市延後的原因。如下圖所示，在8月3日啟用封鎖機制後，特殊查詢的流量瞬間減少了6、7成。

Pokémon GO遊戲已遍及全球90個國家，遊戲推出2個月時，全球玩家所累積的移動距離，就達到29億英里之遠，大約是從地球到冥王星的距離，目前Pokémon GO App累計下載數量也達到5億次。
 
 
",https://www.ithome.com.tw/news/108719,"新聞,Pokemon Go,Kubernetes,容器,GCP,GKE,Container,寶可夢"
108576,21,2016-09-21,臺灣Container Summit 2016首日開跑，Docker、CoreOS及Mesos官方專家皆來臺參與,高峰會也找來Docker、CoreOS及Mesos等官方專家分享一手經驗，例如來自Docker的陳東洛，目前是Docker 開發分散式系統和叢集解決方案，同時也是調度工具Swarm和Engine-api的管理員，還有CoreOS分散式項目主管李響，在CoreOS負責Kubernetes等分散式系統相關的開發。," 臺灣Container Summit今日在臺大集思會議中心舉行，此次高峰會也找來Docker、CoreOS及Mesos等官方專家分享一手經驗，例如來自Docker的陳東洛，目前是Docker 開發分散式系統和叢集解決方案，同時也是調度工具Swarm和Engine-api的管理員，還有CoreOS分散式項目主管李響，在CoreOS負責Kubernetes等分散式系統相關的開發。

過去任職Mesos分散式系統首席工程師的Timothy Chen表示，容器調度工具總共包含三大元件，第一是服務管理（Service management），主要控制服務的規模，根據需求水平擴展（Scale-out）或者收縮（Scale-in）。第二層是排程器（Scheduling），讓使用者不需要手動安排伺服器得運作哪些應用程式，讓系統自動決定應用程式部署的位置。第三層則是資源管理（Resource management），分配應用程式運作需要的硬體資源，例如CPU、記憶體。

《Docker源碼分析》作者孫宏亮，目前任職中國PaaS服務商上海道客網路科技，同時也Docker Swarm核心維護者。他表示，Docker並不是為了安全而生，其價值在於易用，提供標準化環境，以及相當高的性能表現，但是企業運作必須追求安全，「如果無法解決資安問題，企業不會願意使用Docker。」他也笑說，中國IT業界流傳一句話：「資安是IT架構的遮羞布」，一旦架構設計瑕疵影響企業正常運作時，就得付出巨大的代價。

雷亞遊戲技術長鐘志遠揭露為何雷亞遊戲從PaaS平臺，轉向Kubernetes環境的原因。他表示，過去使用PaaS平臺AWS Elastic Beanstalk 的經驗中發現，PaaS的運作對開發團隊像是黑盒子，「我們對PaaS了解甚少，造成許大的負擔。」而轉為使用偏向PaaS性質的Kubernetes時，使用者不需要管理底層VM，只需要管理Container環境，同時所有的基礎的技術層（Technology Stack）都被封裝在Container中時，開發人員也比較容易了解程式的架構。此外，使用Kubernetes也可以確保環境已經過測試後無異常後，才會進入線上環境。


臺灣駭客年會HITCON創辦人，目前任職資安公司vArmour 資深工程師的徐千洋表示，強化Docker Container有三大基本方法。第一是設定使用命名空間（User Namespace），確保服務不透過root權限運作。第二則是利用Linux內的Capabilities功能拆分權限，將特權帳號可以執行的功能細分成不同權限進行控制。最後則是利用AppArmor功能，針對不同程序進行存取控制。

",https://www.ithome.com.tw/news/108576,"新聞,Container,容器技術,容器安全,CoreOS,Docker,Kubernetes"
107938,21,2016-09-17,靠雲端搶救人命再早一步，救護車變行動急診室,新北市消防局利用雲端技術建立行動急診室救護雲，可以提前在救護車上啟動急診室的醫療急救流程," 每年消防急救案件超過上百萬件，就算全臺上千輛救護車投入，從通報、派遣救護車，到患者送達醫院就醫，平均還是得花上半小時。多數患者可以等待，但對心肺功能停止或腦中風等重症患者，這短短30分鐘卻是救命的關鍵黃金時間，救護車越早一步到達醫院，急診室團隊就能越快接手救治。
每年得出動18萬次緊急救護的新北市的救護作法卻很不一樣，光是去年，就有1,387車次的病患，不用等到抵達醫院，只需6分鐘等待救護車抵達後，直接在前往醫院的救護車上接受診療。光是今年前8個月，就有148位心肺功能停止的危急患者，因為早一步救助而成功救回一命。
過去很多地方的消防救護人員，在患者到院前，只能消極採取輔助急救處置，而無法直接採用更有效的急救手段，因為，救護人員不是醫師，所以患者往往到院後才能由急診醫師搶救，而容易喪失黃金搶救時間。但是新北市的醫師早在救護車抵達現場第一時間，就能透過遠端線上參與病患急救，即便人不在現場，也能做到立即線上指導，甚至到院前，醫院已經召集好醫療人員，準備接手治療。
靠雲端建行動急診室救護雲
為何新北市的緊急救護作法特別不同？他們可以將急診室系統提前延伸到院前啟動，在救護車上就能早一步地展開搶救，這背後的關鍵IT技術，新北市消防局緊急救護科科長張冠吾自豪地說，「靠的正是利用雲端技術建立的一個行動急診室救護雲，可以提前在救護車上啟動急診室的醫療急救流程，來實現新北市的雲端救護。」
新北市消防局早從4年前開始推動這項雲端救護行動急診室（Mobile EMS Room，MER）專案計畫，開始利用雲端技術打造一個救護雲環境，目的是希望以心肺功能停止、急性心肌梗塞、急性腦中風和嚴重創傷這4種特殊時間急症患者為對象，提前啟動院前搶救機制，以提高他們存活和身體癒後康復的機率。因為這4種會危及患者生命的急症，醫學上皆屬於會隨時間消逝造成身體永久性傷害的重症，嚴重甚至讓患者可能喪命，所以要成功搶救就得跟時間賽跑，一旦錯失救命時間，即使之後送到醫院後有在技術高超的醫療團隊也回天乏術。
張冠吾表示，每件行動急診室案件的救護流程都是從派遣端開始，由指揮中心專責人員依據每一個救護案件不同的病症描述，事先來鑒別是不是屬於這4種急重症類型，藉此決定要不要派遣行動急診室救護車輛前往現場救護。
目前新北市消防局採用2階段派遣模式，來針對這4種重症患者進行救護，新北市消防局也是目前全臺唯一有採取雙軌派遣的消防單位。
在第一階段，指揮中心會先派遣離現場最近的救護單位到場進行緊急處置，再由專門派遣人員判斷是屬於4大急重症後，啟動第2階段，也就是加派具備行動急診室功能的救護車到場接手搶救，來縮短急症患者等待急救的時間，「從2013年開始運作至今，從派遣到達現場接觸病患只須約6分鐘完成。」他說。

不像傳統救護人員只能幫危急患者做一些輔助緊急處置，如提供氧氣罩呼吸、施行心肺復甦術等，相較之下，行動急診室救護員能在救護車內為患者做到更多到院前的緊急醫療處置，如採取緊急插管、手動電擊等急救手段，也能施打急救藥物，來維持病患生命徵象，增加患者到院治療的黃金救命時間。


新北市消防局利用雲端技術打造一個能和現場救護環境同步的行動急診室雲端平臺，目的是以4種急症患者為對象，提前啟動院前搶救機制，以提高他們存活和身體癒後康復的機率，且此平臺能串聯指揮中心端、分隊端、救護端和醫院急診系統，還加入了遠距醫生指導機制，讓醫院急診值班人員和合作的醫生，即使人不在現場，也能遠端參與現場搶救。圖片來源／新北市消防局

去年救護車行動急診室提前救治1,387件
去年新北市緊急救護案件總共有186,808 件，其中這4大重症案件所占的比例以急性心肌梗塞最高為2.09%，其次則是心肺功能停止的1.69%，而急性腦中風與嚴重創傷各自也有1.47%和0.69%。而屬於行動急診室的急救案件全年約有1,387件，數量雖然只占全市救護次數比例的不到1%，但從新北市開始導入行動急診室系統後，也逐步提高這4類重症患者的存活機率，以心肺驟停患者來說，張冠吾表示，去年多達有145人被成功救活，但還未導入前，2010年只救活了86人，甚至患者康復出院比例也比以前改善不少，從2010年的3.09%，到了2015年提高到6.9%，到今年， 救回人數更向上攀升，8個月內已成功救回148人。
張冠吾表示，新北市行動急診室的緊急救護服務之所以能夠針對這4種重症患者，做到比傳統救護車能救活更多的人，甚至提高患者癒後康復的成功機率，不單單只是有加入更多的急救處置和配備更好的醫療設備，關鍵還是得靠IT協助才有辦法達成。
新北市如何用IT改善傳統緊急救護流程
為了提高這4類重症患者的存活和完全康復機率，新北市消防局4年前開始利用IT來改善傳統緊急救護流程。他們在板橋總部消防大樓機房內，打造了一個行動急診室雲端平臺，建立一個可以和現場救護環境同步的雲端救護環境，能串聯指揮派遣端、救護端和醫院急診系統，還引進了遠距醫生指導機制，讓不論是派遣中心人員、醫院急診執班人員或醫生，即使人不在現場，都能線上觀看現場救護情況，隨時追蹤病患狀況。
以醫院急診端來說，張冠吾表示，傳統救護車到院前一般都會對病患做檢傷分類，這些檢傷記錄可以加快病患到院後的確診時間，以縮短病患診療時程，但過去院前的救護端和院內流程，兩者並無整合，醫院急診人員無法實際看到現場病患狀況，兩端之間也僅能以無線電方式溝通，沒有良好的聯繫管道，使得即使在救護車上已進行患者身體採集或量測，到院後仍得要重新再做一次，張冠吾也以一個心臟科救護案件來舉例，心臟病患者到院後同樣必須經過檢傷、身體撿查後，才會通知心臟科醫師來會診，這段等待時間可能長達半小時，也壓縮病患真正能被治療的時間。
現在，病患到院前，張冠吾表示，醫院急診室系統就能夠經過行動急診室雲端平臺取得所有和病患相關的病情資訊，包括現場救護人員的評估報告及醫療設備記錄下的病患生命徵象，如血壓、心跳變化等，來隨時掌握患者病情，急診執班醫師也能從遠端持續監看救護車上病患的急救狀況，而透過與院前救護端的流程整合，反而能取代院內檢傷流程，甚至針對有危急的病患，提早在後送階段，就能提前啟動院內預警機制，病患還沒到院，醫院內就已召集相關醫療人員準備收置，來加快病患救治。
新北市這項行動急診室專案，目前已經與包含臺北市跟桃園在內的15家大型醫院合作，例如亞東醫院、萬芳醫院、馬偕紀念醫院、三軍總醫院、聯合醫院三重院區和臺北慈濟醫院等。
另外透過行動急診室的救護方式，也有助於改善傳統管控救護品質的作法。張冠吾表示，過去要監看現場施救品質，得要加派護理師跟車，案件量多時，人力成本就是一大問題。
但現在，護理人員直接從線上就能觀看每件救護案件執行過程中所有的醫療處置，不用人到現場，就能做到遠距跟案，控管救護品質，不只是現場救護人員能看到，醫院和合作的指導醫師也都能同步監看現場施救過程，也提升了他們對於現場施救人員的信賴，未來可以更放心授權救護員現場進行更多急救措施，或是開放更多藥物給予使用。

新北市行動急診室救護車配備格外不同，例如車內提供能現場緊急處置的高階醫療設備，還有能輔助病症評估的行動裝置，例如手機等，連救護小組成員的資格，也都必須有高級救護員資格，例如新北市消防局莒光分隊的5名行動急診室隊員全部都是高級急救員，能依法被授予在現場實施進階的緊急醫療手段，也能給予患者施打藥物，來搶救生命。

行動急診室即時回傳救護畫面的關鍵
為了能夠讓現場救護畫面能完整即時呈現，在現場停留階段，行動急診室隊員頭盔上會安裝一組鏡頭，可以即時錄製現場畫面和收音，連在救護車內也都有加裝攝影機， 一旦救護員離開現場後，畫面就會自動切換到車上來顯示，而每輛行動急診室救護車上也配有多臺醫療急救設備，比傳統救護車能做到更完善的急救處置，例如裝有一臺高階心電圖測量儀器，能量測12導程心電圖，就比只提供初步心電圖檢測的傳統救護車的設備，能得到患者更多方位的生理資訊，甚至可以做為患者病情診斷的使用。「行動急診室的醫療設備幾乎已經貼近急診專用等級。」張冠吾說。
平時出勤時，這些醫療器材則是被放進救護員隨身攜帶的一個紅顏色的急救醫療包內，這些醫療儀器可以記錄下患者的生理資訊，如血氧、血壓等，也具備連網功能。這些從鏡頭拍下的現場影音畫面和儀器量測到的病患生理資訊，能夠透過Wi-Fi，連上一臺4G無線分享器，再將各項資訊透過4G行動網路，傳送到後端的行動急診室雲端平臺上，若是遇到沒有網路的地方，這些病患生理資訊則會先儲存在另一臺工業平板裝置中，等到恢復網路後再傳送。

新北市消防局緊急救護科科長張冠吾說：「如何將醫院內的急救流程，提前到院前啟動，背後關鍵不是人力也不是設備投資，而是得靠雲端技術，才有辦法實現，這正是行動急診室的技術核心價值所在。」

雲端平臺靠行動裝置整合緊急救護流程
即時呈現現場施救過程外，透過行動急診室的雲端平臺，也能讓緊急救護流程可以與行動裝置更密切整合，來加快救護進行。救護車在現場停留階段，行動急診室急救員開始接觸病患時，能利用手機上開啟他們自行開發的專屬App，來進行案件的評估，急救員可以依據現場病患生理狀況，來填寫評估指標，例如傷心指數、有無服用藥物、昏迷指數幾分，來判斷是屬於4大重症的哪一類，同時也能夠依據目前的救護進度，例如到場、離場、到院等階段，來啟動相對應的的處置，如當現場急救人員接觸到病患之後，該時段執班指導醫師的手機即會接收到行動急診室案件的發送通知，而醫師能夠利用手機App，以迅速查看該病患案件的現場評估指標，並立即線上下達指示；而離開現場前，救護員利用手機App選定後送醫院後，負責接收病患的急診室也會收到該案件的通知，以從急診系統螢幕觀看案件進行的情況和患者病理資訊。
救護車也有特殊設計強化派遣效率
不只是能將合作醫師和醫院端及早加入，變成緊急救護流程的一環，連救護車前座還配備有一個專為救護開發的車用導航平板（俗稱車機）也能與後端的派遣系統串接，可以即時顯示收到的派遣案件資訊，該車機內也具備GPS定位功能，當所屬分隊接收到派遣令後，可以自動在地圖上顯示急救患者的所在地點，派遣中心也能隨時追蹤車子位置，掌控案件進度。另外車機下方還有一排按鈕，可以詳細記錄各個救護時間點，例如出勤、到場、離場、到院等，救護員下車後也能改透過手機來接續記錄，透過後端的行動急診室雲端平臺，能做到救護人員跨手機和平板裝置，來無縫完成救護作業。
目前新北市管轄的29個行政區內，共有64個消防分隊總共配置有100多臺的救護車輛，來提供現場緊急救助服務，截至今年，一共有22個小隊已進駐有行動急診室的救護車輛，現場隨時待命，來搶救這4種重症患者，張冠吾表示，目前全市共有28輛行動急診室救護車，今年底更將擴編增加到38輛。
張冠吾表示，通常每輛行動急診室救護車輛配給有2到3名的緊急救護技術員，全部都是具備有高級救護資格的急救員，目前全新北市有424位高級救護員，被分派到配有行動急診室救護車的分隊。
不像一般救護員多屬於中級或初級救護資格，只能給予病患基本的緊急處置，如提供氧氣罩呼吸、施行心肺復甦術或是給予患者心理支持，並且也無法給予患者施打藥物。
相較之下，行動急診室的救護員可以獲得較多的授權，能依法在急救現場採取如插管、手動電擊等進階緊急醫療處置，也可以給予患者施打藥物，目前能允許為患者施打的急救藥物多達6種，例如支氣管擴張劑、胺碘酮等與心肺方面有關的急救藥物，這些都是在做為維持病患生命徵象，增加救命機會的重要手段。
張冠吾表示，今年開始，將會在原本6種藥物外新增加另外5種藥物，例如和心臟急症有關的藥劑，像是硝化甘油含片和雙重抗血小板的抑制藥物，還有呼吸道方面的藥物治療等 。
不過畢竟緊急救護員並不是醫院急診醫生，即使有高級救護能力，事後仍須醫師授權在救護記錄上簽名，以確保急救處置符合醫療規範。目前新北市也聘任一批急診專科醫師群提供線上指導，共有54人，採排班制，8小時為一班，每班有一個正班，2個備班。每位負責該時段的指導醫師執勤不用待在醫院，也不用親自到場，只要手機有開就能接案，隨時能查看病患案件的現場處置情況，在送醫期間也能即時監看病患生命徵兆，還能同步利用手機給予現場人員指導，甚至現場救護人員面臨醫囑授權外的危急狀況，而非得要靠非常緊急措施才能救命時，例如施打還未開放的藥物等，急救員也能迅速線上取得指導醫師授權，來搶救生命。 
 新北市消防局今年也計畫要將心臟科和神經科醫師加入指導醫師團隊，來提高重症患者存活和完全康復的機率。張冠吾表示，目前擔任行動急診室救護的遠距醫生全都是急診專科醫師，但有時，針對一些需專門科別醫師才能授權的緊急救護處置，急診醫師並沒決定權限，例如，靜脈血栓溶解劑是目前用來治療急性缺血性腦中風的有效方法，但要下達靜脈血栓溶解劑的注射命令 ，必須經得神經科醫師的同意才能執行，但許多時候，等到神經科醫師來到急診室後，病患已經延誤不少救治時間，甚至，這類的緊急醫療處置，因為伴隨高風險，即使患者到院後，醫院還得另外花時間說服家屬，等到同意書簽署後才能為患者施打，以致於容易錯失3小時內施打血栓溶解劑的黃金搶救時間，而失去救治的機會。
未來，透過將心臟科和神經科醫師納入線上指導醫師團隊，張冠吾也表示，行動急診室救護員到達現場後，一旦判斷為腦中風患者，直接在院外就能叫回執班的神經科醫師，而不是等到患者送醫後才通知醫生回院。
在送醫途中，醫師也能邊利用遠距方式，透過車上螢幕跟救護車上的病患家屬對話，提前說服他們簽署手術同意書，來縮短病患到院後施打藥劑的等待時間。
張冠吾更計畫明年把更多急診醫療設備搬上救護車上來使用，早一步為患者採用更多進階緊急處置，例如針對胸部外傷而造成張力性氣胸的患者，可以緊急予以胸腔減壓等，加快到院前的病患搶救時間。
 

 新北市行動急診室救護車6大特色 
行動急診室特色1：即時回傳救護車現場畫面

不只是急救員戴的頭盔，連救護車內也都裝有攝影機，可以立即錄製現場影像和聲音，將畫面即時回傳雲端，讓醫院急診室和指導醫師，能隨時監看救護車現場救護過程。

 
行動急診室特色2：配備進階急救醫療設備

救護車上醫療設備等級更高，甚至能診斷患者病情，如上圖的紅色醫療急救包內，配備一臺比一般救護車還能取得更多患者生理資訊的12導程心電圖儀器，協助病症判斷。

 
行動急診室特色3：靠行動App輔助病症評估

急救員接觸患者後，能用行動App事先設好的評估指標來輔助評估患者病症，如傷心指數、有無服用藥物、昏迷指數等，並將評估結果回傳雲端，讓醫院或醫師等可即時查看。

 
行動急診室特色4：配備救護專用導航平板

每臺救護車前座配備專為救護開發的車用導航平板，能與後端派遣系統串接即時顯示派遣資訊，也能迅速找出患者位置，縮短派遣反應時間，提高車輛靈活調度和派遣的能力。

 
行動急診室特色5：急診室提前接收即時病症情報

救護人員用手機App完成病情初步評估後，只要點選將送往的醫院後，被選擇的醫院急診室就能透過急診室系統，接獲患者病情的各種資訊，例如用App判斷的病症評估等。

 
行動急診室特色6：遠端醫生用手機提供救護指導

除醫院外，另有一群線上醫師，不用到救護車現場，也能用手機觀看現場救護畫面，還能線上下達治療指示，遇到醫囑授權外的危急狀況，也能迅速線上授權，搶救患者性命。


",https://www.ithome.com.tw/news/107938,"新聞,新北市消防局,雲端,Cloud"
108374,21,2016-09-16,新一代SDDC管理平臺支援VIC，VMware要讓Container管理像管VM一樣,隨著新一代SDDC管理平臺支援VIC，Container也能像管理VM一樣透過視覺化網頁來調度，VMware還要建立自家Container生態系，一線容器業者Mesosphere、CoreOS、Rancher都會加入," 在今年4月時，VMware執行長Pat Gelsinger曾說：「我們將Container視為VMware基礎架構中的一等公民（First Class Citizen）。」當時，除了在去年釋出的輕量級作業系統Photon OS，以及開源專案vSphere Integrated Container（VIC）外，還無法摸清楚VMware究竟要如何延伸勢力，踏入新興Container世界。但是在今年VMworld大會中，VMware則揭開未來對於容器市場的布局：讓企業能在SDDC架構中管理Container應用程式。對於維運人員，能夠複製既有vSphere平臺使用經驗，管理大規模容器應用，而開發者則可以在現有環境下，享受容器技術的敏捷、快速部署等特性。
在大會上，VMware原生雲端應用副總裁暨技術長Kit Colbert問到：「到底是誰在用Container？」他打趣地說，文青（hipster）工程師、新創公司是最積極擁抱這些新技術的族群。「不過現在容器也開始要進入企業了。」
被視為可能顛覆VM架構的Container、OpenStack等開源技術，在近年四處竄紅。讓VMware執行長Pat Gelsinger在2014年VMworld時，也得積極地擁抱這兩個潛在對手。而Kit Colbert認為，雖然容器對VMware帶來挑戰，卻同樣也是個機會，例如，利用容器技術打造雲端原生應用程式的趨勢逐漸增加，同時，容器技術也能夠縮短軟體開發周期、加快交付速度。
雖然Container目前多半使用於開發環境，「但是在正式環境中導入容器時，必須達到企業等級的要求。」Kit Colbert舉例，最近他與一個想要在正式環境中導入容器的企業相談，卻得知「他們沒有對容器運作進行監控」，讓他感到非常驚訝。

新增容器管理入口網站
開發團隊透過VIC新增的容器管理入口功能，可以一覽開發所使用到容器化應用程式。

讓容器整合至既有SDDC架構
Kit Colbert表示，當今許多企業都已經長期在SDDC、虛擬基礎架構下利用VM運作應用程式。因此，VMware要讓Container也能走進企業，「利用Container打造企業基礎架構。」在去年VMworld中，VMware就發布了兩個容器基礎架構產品，分別是開源專案vSphere Integrated Container（VIC）以及雲端原生基礎架構Photon Platform。
vSphere Integrated Container將Container runtime嵌入vSphere平臺中，讓vSPhere平臺管理者可以用開啟VM的方式，如法炮製地創制Container。而Photon Platform則鎖定開發雲端原生應用程式的團隊，同時支援Docker Swarm、Kubernetes、Mesos等容器調度工具。
Kit Colbert表示，VIC的目標是要整合開發者、維運者這兩個不同世界。讓開發者可以在vSphere環境中，延續既有開發習慣及使用熟悉開發工具，同時，維運者也能繼續使用vSphere平臺進行管理。

可預先建立Ap的容器組成範本
開發者可建立Ap的容器組成範本，如圖中的VMwareApp範本，透過管理網頁就預先新增這類Ap需啟用哪些容器和相關參數設定。

 
VIC新增容器儲存庫及容器管理平臺入口
而VMware為了讓企業能夠在正式環境中導入Container，分別在VIC中新增了容器儲存庫（Container Registry），以及容器管理入口（Container Management Portal）兩個新功能。Kit Colbert表示，企業用戶與VMware反應，想要安全地儲存容器映像檔。而這次新加入的容器儲存庫功能中，則具備角色模式管理機制（RBAC，Role-Based Access Control）以及映像檔複製（Image replication）功能。
此外，應用程式開發團隊可以利用容器管理入口，管理映像檔、儲存庫、容器主機，並且透過它開啟Container執行實例（instance）。Kit Colbert也說，藉此，應用程式開發團隊不需要透過vSphere平臺，就可以對Container進行存取。因此，容器管理入口讓開發、維運團隊可以各自享有獨立的工作環境。
在今年VMware也宣布要建立VIC生態系，並且將超過1,250個合作夥伴的技術整併至VIC，除了納入容器技術廠商Mesosphere、CoreOS、Rancher外，本機虛擬化平臺Vagrant、映像檔打包工具Packer開發商Hashicorp，以及軟體管理、發布開發工具商Jfrog也成為VIC生態系中的一環。
VMware執行副總裁暨技術長Ray O'Farrell表示，當企業開始引入雲端原生應用程式時，「得要擁抱Container這類的新技術。」他認為，Container快速地改變既有的業界生態系，為了將雲端原生應用程式帶入正式環境，必須讓它達到企業級的可靠度、擴充性以及安全性。

容器儲存庫新增RBAC角色控管
容器儲存庫功能中，具備角色模式管理機制（RBAC，Role-Based Access Control），可以設定使用者權限，例如開發者、專案管理者，以及訪客。

 

快速監看Ap所用容器的啟動進度
管理介面還提供了一個容器啟用進度表，可以看到這支Ap所需使用的所有容器啟動進度和失敗情況。

",https://www.ithome.com.tw/news/108374,"新聞,VMware,VMworld,SDDC,VIC,Container"
108336,21,2016-09-15,IBM雲端新戰略將聚焦產業雲,不只發展公有雲，IBM要發展特定產業應用的雲端服務，推出MES製造雲或金融雲等應用," 近日IBM全球雲端戰略有新目標，不只是發展公有雲，現在更要聚焦特定產業應用的產業雲（Industry Cloud），如MES製造雲或金融雲等，而不是一般通用的公有雲服務。IBM大中華區雲端運算事業部技術長陳谷近日來臺時也揭露了未來IBM發展產業雲的新戰略布局。
IBM要發展特定產業應用的雲服務
陳谷表示，雲端服務早期是以提供伺服器、網路、儲存等基礎IT服務居多，但現在，有越來越多的雲端廠商開始在雲端基礎服務之上堆疊更多的應用或服務，例如IBM近年來的雲端發展，逐漸轉往雲端PaaS服務為重心，如提供Watson認知運算服務等， 不過他也表示，接下來IBM的雲端戰略，更將從原有的混合雲、公有雲架構，逐步邁向產業雲前進，來提供特定產業應用的新雲端服務。
陳谷指出，他們想要打造的產業雲，其實和資料運用息息相關，其目的要讓不同產業的企業，能透過IoT設備上的感測器來蒐集大量資料，並將這些資料回傳雲端做為大量資料分析，甚至是進行認知分析運算，從中挖掘出更多的加值應用。這類的產業雲應用也開始吹入臺灣，例如在物流業方面，來自臺灣的五達電通，就提供一套農產品的物流即時監控機制，能透過閘道器將資料傳送到IBM的Bluemix雲端平臺進行分析，來掌握蔬果品質，以達到農產品運輸和銷售流程的即時監控。

產業雲應用也開始吹入臺灣。例如來自臺灣的五達電通，就提供一套農產品的物流即時監控機制，能透過閘道器將資料傳送到IBM的Bluemix雲端平臺分析，來即時監控掌握蔬果的熟成程度。

不只是要讓企業可以將設備資料上雲端來分析，陳谷表示，未來的產業雲更進一步要做的是，能依照產業別的不同，來提供企業客戶特定產業應用的雲端服務，例如將一些企業原本就地部署（On Premise）共通的重要核心服務，重新經過優化後，也變成是一種公有雲服務，讓新加入特定產業的企業可以很快速地拿來套用。
陳谷也以製造的產業雲來舉例，他表示，每個產業都會各自共通的模組，以製造雲來說，則是將製造業通用的重要系統，如MES等，變成是可以提供製造業共通使用的一種雲服務，這麼做的目的，可以讓屬於中小型規模的製造業者跨入製造行業時，可以很快地租用這些經過雲端化的製造核心系統，來加快開發、生產，以及推出新產品的時程，甚至還可以依據不同產業雲來細分，例如將金融雲畫分成個人網銀和企業網銀等，「這即是我們所要朝向的產業雲的方向。」陳谷說。
不過陳谷也坦言，僅靠著一家雲端廠商並無法真正建立一個產業雲環境，他表示，不同產業都有各自的專門知識，例如車聯網、工業4.0、智慧家庭等，這些產業專門知識只有長年待在這個產業領域的廠商最清楚，因此他認為，要建立一個完整的產業雲，就得要有不同產業的廠商共同加入，才能打造一個產業雲的生態系統。
陳谷也表示，目前公司雲端部門的產品，主要分為3類，包括雲端平臺、混合雲及影音服務，以及雲端管理服務與儲存，接下來也將依照不同產業應用重新進行人員配置，目前已在北美市場開始推動這項產業雲計畫，並也將和廠商攜手合作，逐步地推動產業雲的生態系成形。
過去臺灣也有一些系統廠商想成立自己的產業雲，或也有一群製造業者想要打造專屬的製造雲，儘管他們有足夠專業知識和技術能力，但最終還是失敗收場。臺灣IBM雲端運算事業部副總經理許仲言則表示，產業雲能不能成功的關鍵，不僅僅是需要產業的專門知識，更重要的是技術堆疊是不是足夠完備，能夠協助產業進行整合。
許仲言指出，以前，一些產業想要建立產業雲而失敗的原因，主要是來自缺乏產業整合的技術，例如資料格式無法有效整合等，但近年來，這些技術已經越來越純熟，如API技術的演進，讓不同系統的資料或應用的介接變得更容易多了，甚至各產業具備的專門知識也越來越趨於一致性，而使得發展產業雲變得更容易成功。
「除了發展產業雲技術已經完備外，還有另一個原因是氛圍到了。」許仲言說，大數據從概念成立到目前已經發展將近21年，但直到通訊、行動、API、穿戴式裝置技術應用成熟後，才讓外界普遍認為IoT真的落地了，而當技術成熟帶動了物聯網的孕育而生，現在也將跟著帶動產業雲的熱潮到來。
",https://www.ithome.com.tw/news/108336,"新聞,IBM,雲端,Cloud,產業雲"
108355,21,2016-09-09,Container雙周報第17期：VMware要讓Container管理如管VM一樣,VMware為了讓企業能夠在正式環境中導入Container，分別在VIC（vSphere Integrated Containers）中新增了容器儲存庫，以及容器管理入口（Container Management Portal）兩個新功能，讓開發、維運團隊都能以vSphere環境為基礎，並擁有獨立自主的工作空間," 重點新聞（8月20日-9月9日）
·VMware要讓管理Container如管理VM一樣
VMware原生雲端應用副總裁暨技術長Kit Colbert表示，當今許多企業都已經長期在SDDC、虛擬基礎架構下利用VM運作應用程式。因此，VMware要讓Container也能走進企業，「利用Container打造企業基礎架構。」
而VMware為了讓企業能夠在正式環境中導入Container，分別在VIC（vSphere Integrated Containers）中新增了容器儲存庫，以及容器管理入口（Container Management Portal）兩個新功能。新加入的容器儲存庫功能中，則具備角色模式管理機制（RBAC，Role-Based Access Control）以及映像檔複製（Image replication）功能。
此外，應用程式開發團隊可以利用容器管理入口，管理映像檔、儲存庫、容器主機，並且透過它開啟Container執行實例（instance）。藉此，應用程式開發團隊不需要透過vSphere平臺，就可以對Container進行存取。因此，容器管理入口讓開發團隊、維運團隊可以各自享有獨立的工作環境。更多報導
·NSX新掌門人揭露VMware如何通吃非vSphere及容器環境
未來邁向跨雲戰略的VMware，未來得要靠NSX通吃異質Hypervisor環境。現任NSX掌門人的VMware網路與安全性事業部執行副總裁兼總經理Rajiv Ramaswami舉例，像AWS底層就是非vSphere環境，而NSX之所以能做到跨雲運作，其中有一個關鍵元件叫做Open vSwitch，讓VMware不需要經過AWS許可，也可以自行開啟VM，在裡面運作Open vSwitch。
而VMware客戶在AWS上所運行的VM，都會連結至Open vSwitch。因此，企業可以在公有雲上使用NSX的自動化功能，並且設定相關資安規則。
Rajiv Ramaswami也表示，未來還要擴大支援至Container環境，像是Mesos、Kubernetes。藉由開源網路套件，VMware可以設定一組Open vSwitch端點（Endpoint）與Container連接，每個容器內部都會部署Open vSwitch端點。想要使用容器技術的企業，可以利用NSX確保Container運作的安全性，同時還能串接起所有的Container。
·思科併購容器即服務新創ContainerX
思科準備併購專門開發供資料中心使用的虛擬容器服務供應商ContainerX。成立不到兩年的ContainerX標榜適用於裸機、虛擬機器、Linux、Windows、 私有雲或公有雲透過單一的管理介面就能檢視所有的容器架構，以協助企業管理眾多資料中心所使用的容器。
ContainerX為思科首家併購的內容服務供應商，思科表示，容器提供了一個簡單又具彈性的管道來建置、 測試及部署程式，還可讓程式在不同的環境中遷移，對於大型企業來說，新興的容器領域尚處實驗室的採用階段，同時需要搭配安全、管理及互動能力。更多報導
·VMware推統合式SDDC架構VMwrare Cloud Foundation，通管VM、容器及PaaS
VMware在VMworld大會中推出了VMware Cloud Foundation，除了現有VI、VDI環境，未來也規畫延伸管理能力至其他異質環境，包括了可用來建立OpenStack叢集環境的VIO（VMware Integrated OpenStack）工作領域、可建立VIC容器執行環境（vSphere Integrated Containers）的Photon工作領域。
最後一種PaaS工作領域。PaaS工作領域可用來建立一個使用Docker、Kubernetes或Cloud Foundry等平臺，在其他IaaS公有雲上建立PaaS應用。
·容器安全廠商Twistlock推出Twistlock 1.5版，強化Container runtime安全
容器安全廠商Twistlock釋出了Twistlock 1.5版，Twistlock策略長Chenxi Wang表示，新版Twistlock加強了網路防護以及掃描等功能。
其中一個重大新功能是應用程式網路防禦（App-specific network defense），針對特定應用程式，Twistlock可以保護其網路連線。
Chenxi Wang舉例，當Twistlock偵測到某映像檔試圖運作Apache應用程式，Twistlock將會從Dockerflie中取得runtime資訊，同時比對該應用程式的行為是否與組態設定檔一致。當偵測到runtime異常的容器，Twistlock也會停止其運作，或是給予使用者警示。
此外，Twistlock過去也有提供Jenkins、TeamCity等CI工具的相容套件，讓開發者在建置過程就能提前偵測，避免上傳至儲存庫的映像檔含有漏洞。而反映用戶需求，Twistlock在新版本中，將掃瞄功能獨立出來，讓開發者可以在CI之外的工作流程，也能夠整合漏洞掃描功能。
Twistlock也表示，掃描功能可以在任何Linux主機上運作，而掃描結果也會利用JSON格式輸出。更多資訊
·Mesosphere結盟無伺服器平臺廠商Iron.io，加強資料中心內微服務架構及無伺服器運算
Mesosphere與提供多雲無伺服器平臺廠商Iron.io宣布合作，而Iron.io表示，Iron.io所專攻的混合微服務架構做法，很適合與Mesosphere推出的資料中心作業系統DC/OS結合。Iron.io認為，同時使用DC/OS及Iron.io後，企業可以在異質環境中處理分散式工作程序，藉此可以朝向混合雲策略前進。
Iron.io也列出兩家廠商結盟後，企業能享受的好處：
1.由於Mesosphere、Iron.io同時能橫跨公有雲、私有雲運作，讓企業用戶可以部署混合式微服務（Hybrid Microservices），在挑選廠商服務的效能、安全性、價格時，能擁有較高彈性
2.綜合Iron.io支援多程式語言、Mesosphere運行大資料分析平臺的能力
3.提供企業容器即服務（Container as a Service，CaaS），不限於先天誕生於雲端SaaS時代的企業
更多資訊

更多產品動態
·華為推出自家雲端容器引擎CCE 1.0版更多資訊
·DevOps自動化服務商Stelligent在AWS提供容器化CI服務更多資訊
·紅帽CentOS Atomic Host支援分層打包（Package Layering）更多資訊
Container資源
※知識：容器資料中心的平臺架構
※How-To：在AWS上用Rancher運作Kubernetes
※How-To：用Docker儲存庫、Rancher部署服務軟體層
※How-To：透過Rancher，在Kubernetes上部署微服務

",https://www.ithome.com.tw/news/108355,"新聞,VMware,VIC,Container,容器,Docker,樹莓派,IT周報"
108107,21,2016-08-31,【現場直擊VMworld 2016】容器不是新創公司、文青工程師的專利，VMware要讓企業正式環境也能用Container,VMware為了要在環境中導入Container，分別在VIC中新增了容器儲存庫（Container Registry），以及容器管理入口（Container Management Portal）。," 「到底是誰在用Container？」VMware原生雲端應用副總裁暨技術長Kit Colbert打趣地說，文青（hipster）工程師、新創公司才最積極擁抱這些新技術的族群。「不過這是刻板印象，現在容器也開始要進入企業了。」
被視為可能顛覆VM架構的Container、OpenStack等開源技術，在近年四處竄紅。讓VMware執行長Pat Gelsinger在2014年VMworld時，也得積極地擁抱這兩個潛在對手。而Kit Colbert認為，雖然容器對VMware帶來挑戰，卻同樣也是個機會，例如，利用容器技術打造雲端原生應用程式的趨勢逐漸增加，同時，容器技術也能夠縮短軟體開發周期、加快交付速度。
雖然Container目前多半使用於開發環境，「但是在正式環境中導入容器時，必須達到企業等級的要求。」Kit Colbert舉例，最近他與一個想要在正式環境中導入容器的企業相談，卻得知「他們沒有對容器運作進行監控」，讓他感到非常驚訝。
讓容器整合至既有SDDC架構
Kit Colbert表示，當今許多企業都已經長期在SDDC、虛擬基礎架構下利用VM運作應用程式。因此，VMware要讓Container也能走進企業，「利用Container打造企業基礎架構。」在去年VMworld中，VMware就發布了兩個容器基礎架構產品，分別是vSphere Integrated Container（VIC）以及Photon Platform。
他表示，VIC的目標是要整合開發者、維運者這兩個不同世界。讓開發者可以在vSphere環境中，延續既有開發習慣及使用熟悉開發工具，同時，維運者也能繼續使用vSphere平臺進行管理。
VIC新增容器儲存庫及容器管理平臺入口
而VMware為了讓企業能夠在正式環境中導入Container，分別在VIC中新增了容器儲存庫（Container Registry），以及容器管理入口（Container Management Portal）兩個新功能。Kit Colbert表示，企業用戶與VMware反應，想要安全地儲存容器映像檔。而這次新加入的容器儲存庫功能中，則具備角色模式管理機制（RBAC，Role-Based Access Control）以及映像檔複製（Image replication）功能。
此外，應用程式開發團隊可以利用容器管理入口，管理映像檔、儲存庫、容器主機，並且透過它開啟Container執行實例（instance）。Kit Colbert也說，藉此，應用程式開發團隊不需要透過vSphere平臺，就可以對Container進行存取。因此，容器管理入口讓開發團隊、維運團隊可以各自享有獨立的工作環境。VMware也宣布，要將超過1,250個合作夥伴的技術整併至VIC，其中包含了Mesosphere、CoreOS、Rancher及JFrog等開源廠商。
VMware執行副總裁暨技術長Ray O’Farrell 表示，當企業開始引入雲端原生應用程式時，「得要擁抱Container這類的新技術。」他認為，Container快速地改變既有的業界生態系，為了將雲端原生應用程式帶入正式環境，必須讓它達到企業級的可靠度、擴充性以及安全性。

而VMware也為了要讓企業在正式環境中導入Container，分別在VIC中新增了容器儲存庫（Container Registry），以及容器管理入口（Container Management Portal）


VMware宣布，要將超過1,250個合作夥伴的技術整併至VIC，其中包含了Mesosphere、CoreOS、Rancher及JFrog等開源廠商。

 
",https://www.ithome.com.tw/news/108107,"新聞,VMware,Container,VIC,容器技術"
107936,21,2016-08-27,IT月報｜雲端IT焦點回顧 (2016/08),Google Cloud Platform（GCP）正式推出3款企業級資料庫服務，並收購雲軟體商務平臺Orbitera， 擴大GCP服務內容,"  Google Cloud Platform   Orbitera 
Google收購多雲軟體商務平臺Orbitera，擴大GCP服務內容
Google宣布收購商務平臺Orbitera，以便提供開發人員採購與部署跨多種雲端的應用程式及服務。Orbitera的商務平臺為獨立軟體開發商、服務供應商及IT通路業者提供付費、包裝和訂價的自動化作業平臺，以銷售及部署跨多雲環境的軟體及服務。
Google全球技術合作夥伴方案主管Nan Boden指出，企業用戶或ISV都使用一家以上的雲端供應商，並且正式系統上線前，都會在信賴的系統整合商、經銷商合作下進行產品測試及概念驗證。Google未說明Orbitera將如何整合進GCP，但表示仍將維持Orbitera多雲商務的中立平臺角色。（詳全文）
 
 AWS   Kinesis Analytics 
亞馬遜推出分析工具Kinesis Analytics，用SQL指令就能分析即時串流資料

亞馬遜在2015年的re:Invent大會上已預告串流資料分析工具Kinesis Analytics將在今年上市，亞馬遜終於正式釋出Kinesis Analytics工具，提供開發者可使用標準SQL查詢來分析即時串流資料。但Kinesis Analytics工具目前僅開放愛爾蘭、美國北維吉尼亞州和奧勒岡地區AWS資料中心的用戶使用。
Kinesis Analytics分析工具是AWS即時串流資料平臺Amazon Kinesis上的服務之一，可以分析新傳入資料庫的記錄，並提供一個合適的資料架構（Schema），或使用者也可以自己微調資料架構。在使用者完成資料架構的定義後，就可以使用Kinesis Analytics工具中內建的SQL編輯器，來檢查SQL語法的正確性、編輯SQL語法、測試即時串流資料分析等。（詳全文）
 
 Google Cloud Platform   MySQL 
Google Cloud Platform正式推出3款企業級資料庫服務
Google Cloud Platform正式推出3款企業資料庫服務，分別是Cloud SQL、Cloud Bigtable及Cloud Datastore，上述服務先前已上線測試，正式版的問世意謂著它們開始受到「服務水準協議」（Service Level Agreement，SLA）保障。其中的Cloud SQL為第二代產品，專供MySQL實例使用，Google說它的處理效能是AWS Relational Database Service（RDS）的2倍，每筆交易的延遲時間則只有RDS的一半。
Cloud Bigtable則屬NoSQL資料庫服務，這是個專為大型任務所設計的資料庫，也是Google內部所使用的資料庫服務，支撐Google Search、Google Analytics、Google Maps、Gmail與其他Google服務。Cloud Datastore亦為NoSQL資料庫服務，但鎖定較小型的數據集處理，類似Amazon DynamoDB與Microsoft DocumentDB。（詳全文）
 
 Mirantis   OpenStack 
Mirantis聯手SUSE，提供OpenStack用戶主流Linux發行版技術支援服務
OpenStack服務商Mirantis日前宣布與SUSE合作，提供Mirantis版OpenStack用戶SLES（SUSE Linux Enterprise Server）、REHL（Red Hat Enterprise Linux）和CentOS等主流Linux的技術支援服務。Mirantis為開源雲端平臺OpenStack的系統整合商，提供OpenStack的相關技術與服務，涵蓋評估、參考架構、教育訓練，及協助部署等。Mirantis創辦人暨行銷長Boris Renski表示，許多Mirantis的大型用戶通常會執行2～3種版本的Linux作業系統，而現在Mirantis將提供OpenStack使用者主流Linux發行版的技術支援，此外，Mirantis OpenStack將採用SLES作為開發平臺。（詳全文）
 
 HPE   Helion OpenStack 
HPE組織再度大調整，Helion雲端團隊改由硬體主管接手
HP Enterprise（HPE）揭露組織改革細節，繼HPE技術長暨HP實驗室執行長Martin Fink在6月底時宣布計畫於今年底退休後，HPE又宣布了3位高階主管即將離開HPE公司。同時，HPE也表示，未來將聚焦於混合式IT、全球銷售和儲存業務的發展。另外，HPE也計畫以Helion OpenStack（HOS）和HelionCloudSystem團隊為基礎，建立全新軟體定義暨雲端事業群（Software-Defined & Cloud Group，SDCG），並任命現任HPE資深副總裁暨融合式資料中心基礎建設總經理Ric Lewis為SDCG事業群負責人。（詳全文）
 
 Salesforce   BeyondCore 
強化分析雲業務，Salesforce買下商業智慧新創業者BeyondCore

Salesforce宣布將併購新創商業智慧與分析應用業者BeyondCore，以力求加碼該公司的分析雲業務。BeyondCore執行長Arijit Sengupta表示，Salesforce已經簽約併購該公司，BeyondCore現有的產品將併入Salesforce的Analytics Cloud服務中，而併購案的財務條件則未被公布。BeyondCore是主攻將商業智慧與分析應用採行到企業的所有面向的新創公司，該公司近來積極將自家產品與Salesforce的雲端應用平臺結合，強化後者服務的分析功能，雙方在緊密合作一段時間後，Salesforce決定出手併購。（詳全文）
 
 Azure RemoteApp   Citrix 
微軟宣布Azure RemoteApp一年內終止，改與Citrix結盟
微軟宣布，將逐漸讓其應用軟體虛擬化產品Azure RemoteApp退場，並鼓勵用戶改用Citrix的相關產品與服務。微軟遠端桌面團隊在官方部落格發表了將在未來1年內逐步終止Azure RemoteApp的決策，但強調將會協助現有用戶平順轉移至其他解決方案。Azure RemoteApp將持續銷售至今年10月1日為止，相關技術支援則將於2017年8月底結束。關閉產品的同時，微軟亦宣布與虛擬化軟體業者Citrix加強在遠端桌面與應用和Azure方面的合作，儘管對於新產品提及不多，但微軟表示XenApp ""express""將結合應用遞送的簡便性與Azure雲端平臺的可擴充性、安全性、管理與效能優勢，將Windows相關應用透過XenApp ""express""與Azure遞送到任何形式的終端裝置之上。（詳全文）
 
 IDC   公有雲 
IDC：今年公有雲市場規模約965億美元，2020年將倍增至1,950億美元
市場調查研究機構IDC發表公有雲服務市場支出半年報，該市場規模將由2016年的965億美元，倍增至2020年的1,950億美元。IDC資深分析師Benjamin McGrath表示，未來5年，雲端軟體的成長將會是整體軟體市場平均成長速度的近3倍之多，同時也將會是個別不同功能性軟體子市場的主要成長動能來源，而領導公有雲服務市場前進的主要用戶產業類別，為離散製造業、銀行與專業服務，在2016年占達該市場總支出的三分之一強，不過，未來5年，成長最快的採用產業別則為媒體、電信與零售業，但不論是哪一個產業別，至2020年的成長率都會超過100%。（詳全文）
",https://www.ithome.com.tw/news/107936,"新聞,Cloud,雲端"
107855,22,2016-08-22,Container雙周報第16期：RancherOS推出 v0.5.0版，換主機免重開機,在近日，Rancher也推出了RancherOS v0.5.0版本，以後換主機（Console Switching）免重開機，目前支援的作業系統有Ubuntu、Debian、Fedora以及CentOS," 重點新聞（8月6日-8月19日）
·輕量級作業系統RancherOS推出v0.5.0版本，換主機可免重開
以執行Docker Container而生的RancherOS，在VMware Photon 、CoreOS、Snappy Ubuntu Core等容器作業系統中屬極為輕量的一者，在近日，Rancher也推出了RancherOS v0.5.0版本。
Rancher表示，自從0.4.0版本後，RancherOS已經擺脫Alpha版狀態，開始增進系統穩定性、改善使用者體驗，以及修復與Docker 1.11版本的相容問題。Rancher也整理新版本的4大特色：
1.提供正式版本的樹莓派映像檔（Raspberry Pi Image），包含支援Raspberry Pi 2以及Raspberry Pi 3
2.改善建置流程，目前已經可以支援ARM以及ARM64的裝置
3.換機（Console Switching）免重開，支援的作業系統包含Ubuntu、Debian、Fedora以及CentOS
4.新增組態設定指令
Rancher表示，RancherOS仍然會堅守一開始的設計理念，「只擁有讓Docker運作的必要元件。」更多資訊
·CoreOS自家OpenStack Tectonic 1.3版本釋出，新增角色模式存取管理機制
繼去年11月CoreOS推出自家版本的OpenStack Tectonic後，近日也邁入了1.3版本。CoreOS表示，1.3版本除了提供企業級工具，也為Kubernetes加入了些新功能。Tectonic 1.3版本總共具有5大新特色：
1.新增角色模式存取管理機制（RBAC，Role-based Access Control），藉此管理使用者在叢集中的權限
2.企業級認證功能，使用者可以更有效利用現有的認證基礎設施
3.增加擴展規模
4.簡化安裝程序，為AWS、裸機環境使用者提供圖像化安裝工具
5.利用開源監控工具Prometheus，加強叢集監控管理
更多資訊
·容器安全廠商Twistlock用機器學習了解容器運作行為
容器安全廠商Twistlock表示，在Docker 1.12版釋出正式版後，為了跟上Docker的開發步調，Twistlock也更新了自家的產品。Twistlock認為，企業使用者主要相中新版Docker的容器調路、叢集功能。在Docker推出1.12前，若使用者想要建立可以運作容器的多節點、高可用叢集，通常得靠第三方容器廠商的幫忙。現在企業想要實作這些功能則簡單許多，「因為這些功能都已經內建在Docker引擎中。」
Twistlock預告，將在下次產品釋出時，針對容器部署增加保護，同時，目前Twistlock已經在在產品中導入了機器學習，藉此了解容器的運作模式。Twistlock表示，目前自家機器學習模型總共可以分為三大功能。
第一是靜態映像檔分析（Static image analysis），Twistlock表示，利用此功能可以了解容器運作行為的核心特徵，例如Container進行連接所使用的網路。再者則是自主學習功能，在容器完成部署後，自動觀察容器運作過程，並且建立容器的行為模型。
最後則是進階網路學習功能，Twistlock表示，目前已經把容器可連接的覆蓋網路（Overlay Network）納入此功能範圍中。更多資訊
·Rancher推Convoy專案，解Docker跨主機檔案存取問題
Rancher表示，使用Docker的開發者，在跨主機存取檔案、共用資料時常碰上難題，即使隨著Docker生態系逐漸成熟，「跨環境持久性儲存對許多人仍然造成困擾。」
在聽取社群建議後，Rancher推出了Convoy專案，試圖解決開發者在使用Docker的痛點。Rancher表示，Convoy是一個儲存套件，同時能支援AWS區塊儲存（EBS）、S3儲存服務、虛擬檔案系統（VFS），以及網路檔案系統（NFS），「讓使用者能有更多布建共用儲存的選擇。」更多資訊
·澳洲非營利政府組織Healthdirect用Docker Swarm解決部署問題
澳洲政府成立非營利組織Healthdirect，讓澳洲公民無論何時、何地，都能透過系統存取健康資訊、康護諮詢，並且協助使用者找到距離最近的服務提供地點。
Healthdirect解決方案架構師Scott Coulton表示，在Docker推出的初期，Healthdirect就已經開始導入，並且自行打造解決基礎建設、應用程式部署的工具。在近期，Healthdirect則開始使用Docker資料中心、Docker認證儲存庫（DTR），以及通用控制平臺（UCP）。
Healthdirect使用組態設定工具Puppet部署Docker Swarm叢集，並且利用本地端的儲存庫下載Docker映像檔。Soctt Coulton表示，透過自建內部儲存庫，可以拉近映像檔初始儲存及最終部署位置兩者間的距離，藉此加快作業程序。
Scott Coulton表示，Docker所提供的解決方案，包含整套的點對點平臺的管理、套件，「是我們使用Docker的決定性因素。」他表示，Docker資料中心提供開發團隊穩固的應用程式環境，讓IT人員可以花更多時間專於在建置、部署應用程式。更多資訊
·牛津大學出版社靠Docker Compose管理容器開發環境
牛津大學出版社（Oxford University Press）是全球規模最大的的大學教課書出版社，每年出版書刊超過4,000種外，也雇用了近6,000名員工。牛津大學出版社平臺技術總監Sandro Cirulli表示，目前世界上有許多語言還未被轉譯至網路世界中，主要原因大部分的語言資源尚未被數位化，「這也是未來10年我們最大的計畫。」他表示，此計畫的推動，部份得要靠Docker，藉由它使用上的彈性、可攜性，「讓我們更容易遷移到效能更強的伺服器，或是雲端環境中。」
Sandro Cirulli也表示，牛津大學出版社希望可以加強T運作自動化，而Docker讓版本控制、組態設定的程序變得較為簡單。其中，Sandro Cirulli認為，Docker Compose更是其中關鍵，目前牛進大學出版社的IT開發環境有超過10至15個容器，必須透過Docker Compose進行調度作業，「在我們重啟容器時，容器不會失去彼此間的溝通。」更多資訊
·Docker Hub映像檔下載次數破50億
問世三年多的Docker，官方儲存庫Docker Hub映像檔的下載次數在近日已經超過50億。比起今年2月宣布的20億次，成長到2.5倍。
Docker表示，50億次下載次數意味著，官方儲存庫上65萬的使用者，每分鐘總共下載超過1萬3千次映像檔。此外，單是官方映像檔的下載次數就超過了10億次。更多資訊

更多產品動態
·CoreOS線上驗證器開始支援Ignition更多資訊
·OpenShift容器平臺整合AppDynamics更多資訊
·紅帽推出Vagrant服務管理者1.3.0版本更多資訊
·紅帽釋出Atomic Docker更新檔更多資訊
Container資源
※知識：容器資料中心的平臺架構
※知識：Unikernel成員談單緒核心
※How-To：在OpenShift平臺運作CI/CD
※How-To：用Docker實現自動擴增規模

※How-To：在Windows Server 2016中設定Docker
※How-To：利用Docker在Mac上運作Linux應用程式
",https://www.ithome.com.tw/news/107855,"新聞,Rancher,Docker,Container,容器技術,Docker Compose,CI/CD,IT周報"
107828,22,2016-08-21,樂天、日本雅虎都愛用的敏捷教練DevOps練成術,日本雅虎敏捷教練伊藤宏幸認為，DevOps要成功， 必須改變企業文化，而要實現這個目標的關鍵，得依靠IT自動化以及持續整合," 不同於美國雅虎在網路市場的撤退，以日系股東為首的日本雅虎向來是日本入口網站龍頭，單月瀏覽人次超過650億次，近幾年為了擴大行動布局，日本雅虎更是積極擁抱多項IT自動化新策略，來加速服務推出的腳步，也找來不少業界DevOps或敏捷專家加入。曾在日本樂天一手重建了大規模自動化CI團隊的關鍵人物伊藤宏幸，也在去年底加入了日本雅虎，擔任敏捷教練（Agile Coach）以及自動化教練（Automation Coach）的職務。
不同於一般導入DevOps常按CALMS五大策略（文化、自動化、精實、測量及分享）來進行的作法。
伊藤宏幸認為，DevOps要成功，必須改變企業文化，而要實現這個目標的關鍵，「得依靠IT自動化以及持續整合。」他進一步解釋，DevOps必須以IT自動化以及持續整合（CI）、持續部署（CD）為基礎，來優化程式開發、測試、系統維運等所有程序。
進入日本雅虎後，伊藤宏幸的任務是幫助產品團隊引進自動化、持續整合等作法，來培養雅虎團隊具備DevOps的體質。他負責先幫4個團隊導入DevOps。
不過，伊藤宏幸只有3個月的時間，他計畫以1個月為單位分階段來改革。
他表示，第1個月是準備階段，首先要了解這些雅虎團隊開發的產品，並且開始撰寫簡單的腳本程式。第2個月時，他則開始進行授課、開設工作坊讓團隊了解CI相關知識和觀念，並且以2名開發者為單位，兩人共用一部電腦共同開發（Pair Programming）。最後，則是開始嘗試移除系統架構設計瓶頸，從源頭來排除IT自動化的障礙。
他觀察到，這幾個團隊除了有不少開發經驗不夠老練的成員外，程式碼整合也發生過不少問題，另外他們也鮮少利用自動化測試。
伊藤宏幸解釋，經驗不足的工程師常常無法釐清工作的重點，例如，不了解工作自動化的重要性，或是不懂得如何撰寫測試腳本。
另外一個問題是，這些團隊中的前端工程師、API工程師，或是資料庫工程師，也都抱持被動態度，等待主管指示。
不僅如此，負責各系統元件的團隊各自為政，也引發了企業界中常見的穀倉效應（Silo Effect）：團隊間缺乏溝通，導致多頭馬車的狀況，「這些都是文化上的問題。」他說。
除此之外，日本雅虎仍有許多缺乏測試腳本程式的老舊程式碼，伊藤宏幸比喻，這些老舊程式就像是那些被稱為棕地（Brownfield）的市郊老舊工業區一樣，必須更有效的利用。
雅虎開發團隊並沒有撰寫測試腳本的習慣，「是我們碰到最大的挑戰。」
因此，伊藤宏幸認為，導入自動化測試是首要之務。當開發團隊將自動化測試視為技術的基礎，才能逃離一再反覆修改程式碼的輪迴，也能改善設計流程和程式碼，甚至可以進行重構。
單元測試是自動化的關鍵
不過程式碼測試的作法很多，例如涵蓋了效能測試、接受度測試（Acceptance Testing）、安全性測試等，伊藤宏幸則是直接鎖定單元測試，作為幫助雅虎團隊導入自動化測試的關鍵。他解釋，單元測試除了執行簡單之外，也可以很有效率地改善軟體開發的品質。
為了讓團隊習慣自動化單元測試，伊藤宏幸提出了5個作法。第一，讓團隊成員從簡單的測試腳本開始著手，等待習慣自動化流程後，伊藤宏幸再正式導入測試驅動開發（Test Driven Development，TDD）。
不過，想要說服開發者習慣測試驅動開發不大容易，所以，伊藤宏幸反其道而行，他直接使用隨機破壞程式功能的猴子測試，來考驗團隊的開發成果，要求團隊快速找出問題點，藉此向團隊證明測試腳本的重要性。「若沒有事先撰寫測試腳本，就很難快速找出問題。」他認為，為了團隊習慣TDD理念，給予他們震撼教育也是個好方法。此外，伊藤宏幸也推薦了一個線上學習網站Cyber Dojo，幫助成員有效學習單元測試和TDD。
接著，使用測試替身（Test Double）來進行Mock單元測試，第四步是在必要時撰寫特徵測試（Characterization Test）。最後一步則是進行軟體程式碼和架構的重構。

伊藤宏幸將CI流程化簡，從過去複雜、不清楚的作業流程，利用版本控制系統作為開發流程的核心樞紐，讓組態設定檔透過版本控制系統，部署至網頁伺服器、資料庫伺服器或是應用程式伺服器。（圖片來源／伊藤宏幸）

三大步驟導入CI
在團隊養成在開發中進行測試的習慣後，接著伊藤宏幸要開始導入持續整合（CI）。導入CI的過程中，伊藤宏幸也碰上了不少問題，例如程式碼雖然可成功部署至Staging階段，但是正式環境階段中卻失敗。
而伊藤宏幸依序採取3個行動，讓團隊開始導入CI。第一，讓敏捷教練與開發者一同用樣本程式碼進行練習。
同時，他也借鏡共同開發（Pair Programming）的想法，兩人一起對CI伺服器進行組態設定。再者，伊藤宏幸也再三教育開發者，CI程序中加入自動化測試的重要性。
伊藤宏幸導入CI的最後一步是簡化部署流程。伊藤宏幸則是大刀闊斧地把原有複雜、部署動線多軌且不清楚的交付流程，改為以版本控制系統作為開發流程的核心，所有組態設定檔，只能透過版本控制系統來派送到網頁伺服器、資料庫伺服器或是應用程式伺服器，來簡化架構造成的發布瓶頸。
團隊開始發展自己習慣的CI、CD程序
伊藤宏幸表示，截至今年3月底，也就是導入CI後的2個月，這四個日本雅虎團隊，總共新增了27個單元測試項目，並因此在測試階段發現了10個軟體臭蟲和24個基礎架構的配置錯誤，甚至找出了3個未來可能發生的問題。
但伊藤宏幸表示，看似成效不是很好，但這些都是「扎扎實實的成果。」他認為，如果企業要改善開發流程，或是導入敏捷開發，必須循序漸進地進步。
幾個月過去，這幾個原先不諳CI、自動化測試的團隊，也開始出現轉變。
伊藤宏幸表示，團隊不只建立了自己習慣的一套測試規則，以及自己的CI和CD策略，甚至，團隊開始自動自發地撰寫單元測試。而產品負責人（Product Owner，PO）也了解測試的重要性，將完成單元測試視為產品完成度的重要指標，「自動化測試和CI真的改變了這四個雅虎團隊的開發文化。」他說。
",https://www.ithome.com.tw/news/107828,"新聞,伊藤宏幸,DevOps,敏捷開發,Agile"
107613,22,2016-08-08,Container雙周報第15期：Mesosphere執行長：歡迎來到容器2.0時代,Mesosphere執行長Florian Leibert表示，在容器2.0時代中，除了企業可以在開始看見容器技術的價值，維運人員可將任一應用程式、服務，視為可部署物件（Deployable Object）。," 重點新聞（7月23日-8月5日）
·Mesosphere執行長：歡迎來到容器2.0時代
瞄準大量容器調度的Mesoshpere，其執行長暨共同創辦人Florian Leibert喊出了有意思的口號：「歡迎進入容器2.0時代。」
他表示，在容器1.0時代中，大多人關心的是Container技術如何重新改善應用程式開發，例如，開發者如何使用Docker、appc等通用格式打包其程式碼，或是如何利用輕量化調度工具協作Container。但他表示：「現在我們得開始討論Container技術所蘊含的可能性了。」
Florian Leibert表示，在容器2.0時代中，Container技術意味著，可設定狀態（Stateful）或是無狀態（Stateless）服務，可以利用同一組資源，同時一起運作，「這才是我們打造、運作現代應用程式的方式。」他表示，如果企業無法打通應用程式及基礎架構間的隔閡，再強大的資料分析技術、再快速的應用程式部署速度，也無法完全發揮其效用。
他也認為，在容器2.0中，除了企業可以在開始看見容器技術的價值，維運人員可將任一應用程式、服務，視為可部署物件（Deployable Object）。開發者也能使用新方法打造應用程式，例如利用無伺服器運作的概念，開發者只需要關注應用程式本身的運作邏輯即可。更多資料
·叢集管理系統Mesos正式推出1.0版本
歷經3年，叢集管理系統Mesos從最初的0.12.1版本，近日正式邁入1.0版本。除Apple將Mesos用於Siri，包含Twitter以及Mesosphere自家的資料中心作業系統DC/OS，也使用Mesos進行叢集管理。Mesos整理了新版8大特色：
1.推出新版HTTP API，相容可支援HTTP協定的程式語言，使開發者可以更簡單地撰寫Mesos框架
2.提供統一容器化工具（Containerizer），除了常見的Docker daemon，使用者現在可以自己選用習慣的映像檔格式

3.相容容器網路介面（CNI）標準，藉此Mesos可以將網路命名空間（Network namespace）分配給容器
4.支援GPU資源管理，目前還是beta版功能
5.細質認證（Fine-grained Authorization）
6.推出beta版本Windows版Mesos
7.使用代理人制度（Agent），取消Slave角色
8.推出API版本管理功能，使用者可看到版本間的改變，以及是否相容舊版本的API更多資料

·內建調度功能的Docker 1.12正式版釋出
繼DockerCon上推出內建調度功能的Docker 1.12版後，近日可部署於線上環境的正式版也已經釋出。Docker表示，經由外部社群的貢獻、協力開發，相比最早內建調度功能的Docker，「目前調度規模已經成長了1倍。」此版本也引入管理者節點（Manager）、工作節點（Worker）設計，讓企業在建立Docker叢集時，能夠更細緻地分類各節點，藉以建立更複雜、分工更細的叢集架構。
而開發者可以利用Docker叢集，建構可程式化拓樸（Programmable Topology）架構。企業可以自行指定Docker節點的角色為管理者節點或是工作節點，例如，在資料中心內跨區部署不同的管理者節點。同時，開發者也可以透過API、命令程式介面，動態地更改不同節點的角色。更多資訊及更多報導
‧Airbus空中巴士40套內部系統都用Container
Airbus原本大量仰賴傳統IT架構，每年光是內部SAP系統上的交易次數就多達150億次，也大量使用大型主機和高效能運算伺服器，但是開始大幅度地導入開源軟體及Container技術。
Airbus公司IT工具服務新創部門首席Nicolas Fanjeau表示，除了擁抱開源技術及DevOps外，為了要達到快速開發和部署應用程式的步調，「擁抱DevOps和Container的PaaS平臺，是唯一的選擇。」他強調。
Airbus導入了紅帽新版OpenShift 3企業版，採用Docker Container技術，並使用Kubernetes來作為Container叢集的管理平臺。Nicolas Fanjeau表示：「Container產品更成熟了，可以用來部署重要的企業系統，Airbus不只將Openshift用於新專案，連內部採用PHP開發的150套應用系統，超過40套已經準備好要改部署到Container上，「在各種開源技術中，Airbus更是壓寶Container，因為Container是PaaS的未來。」他表示。更多報導
‧容器安全廠商Twistlock與資安研究公司合作，加強防護針對容器的進階威脅

容器廠商Twistlock與專攻零時差漏洞的資安研究Exodus Intelligence宣布一同合作，在確保容器能有防禦進階威脅的能力。
Twistlock首席策略長Chenxi Wang表示，Twistlock將要結合Exodus Intelligence的研究成果，以及Twistlock自家的漏洞掃描、runtime防護功能。因此，現在企業除可以掃描容器現有的漏洞，還可以進一步尋找零時差漏洞。更多資訊
‧為何Google認為OpenStack擁抱Kubernetes是雙贏？
近日Mirantis宣布，將要重新架構其私有雲平臺，並且使用Kubernetes作為其調度引擎。而Google表示，此舉讓雙方社群都前進了一大步。Google解釋，OpenStack社群可以享受Kubernetes的調度、管理能力。而Kubernetes社群也可以在同一平臺內，同時管理以Container、VM架構為基礎的應用程式。更多資訊


更多產品動態


·紅帽推出Atomic App 0.6.2版，新增Index命令程式列 更多資訊
·叢集管理工具Mesos正式邁入1.0版 更多資訊
·容器監控廠商Sysdig推出應用程式活動監控工具Falco 0.3.0版 更多資訊
·Docker 1.12版推出，叢集內節點分工更細緻 更多資訊
·Mirantis選用Kuberentes作為調度引擎 更多資訊
·.NET核心1.0版登上OpenShift平臺 更多資訊
Container資源
※觀點：改變Container遊戲規則的Docker 1.12
※觀點：比較Swarm、Swarm Kit及Swarm Mode
※How-To：用Docker Swarm整合Proxy
※How-To：結合Docker Compose實作服務探查
※How-To：用Docker實現自動擴增規模

",https://www.ithome.com.tw/news/107613,"新聞,Container,Docker,容器技術,Mesos,DC/OS,OpenStack,IT周報"
107459,22,2016-08-01,內建調度功能的Docker 1.12正式版釋出，叢集內節點分工更細緻,此版本也引入管理者節點（Manager）、工作者節點（Worker）設計，讓企業在建立Docker叢集時，能夠更細緻地分類各節點，藉以建立更複雜、分工更細的叢集架構。," 繼DockerCon上推出內建調度功能的Docker 1.12版後，近日可部署於線上環境的正式版也已經釋出。Docker表示，經由外部社群的貢獻、協力開發，相比最早內建調度功能的Docker，「目前調度規模已經成長了1倍。」此版本也引入管理者節點（Manager）、工作節點（Worker）設計，讓企業在建立Docker叢集時，能夠更細緻地分類各節點，藉以建立更複雜、分工更細的叢集架構。
在新版本Docker中，使用者可自行決定是否開啟內建調度功能Swarm模式，Docker Swarm則由數個分散式、高可用性的Docker節點所組成。每個Docker節點都自成調度子系統（Orchestration subsystem），可以建立共享資源池，對Docker化服務進行排程。
這樣的設計思維，使開發者可以利用Docker叢集，建構可程式化拓樸（Programmable Topology）架構，因此，企業可以自行指定Docker節點的角色為管理者節點或是工作節點，例如，在資料中心內跨區部署不同的管理者節點。同時，開發者也可以透過API、命令程式介面，動態地更改不同節點的角色。
Docker表示，管理者節點執行的工作為調度叢集、協調容器工作排程、檢查運作狀況不佳的容器，以及提供服務API運作等。而工作節點負責的工作則相對簡單，例如創建容器，或將資料傳送至指定容器中。
同時，Docker也建議在正式環境中導入Docker的使用者，將節點角色指定為管理者節點或是工作節點。Docker解釋，藉此，管理者節點就不需運行容器，除了可以降低管理節點的工作負載。同時，將節點角色畫分更細緻，亦能減少攻擊面（Attack Surface）。此外，企業可以設定工作節點的操作權限，讓其無法存取服務API、資料倉儲內資料，僅能接受工作指派，或是回報系統狀況。萬一有攻擊者奪取工作節點的控制權，也能讓減少系統遭攻擊後影響的範圍。考量不同節點間溝通對於速度、容量的需求，Docker也使用不同的技術協定，橋接各節點間的溝通。此外，每個節點間的資料傳輸一律預設採取MTLS加密。
例如，為了滿足管理者節點間傳輸一致性（Consistency）需求，Docker會將管理者節點納入Raft一致性群組（Raft Consensus Group）， 進行資訊分享。在Raft群組中的一個管理者節點，會被推派為指揮者（Leader），掌握節點名單、任務，或是進行排程調度。
而管理者節點則是使用gPRC協定，與工作節點溝通。Docker表示，gRPC協定除了能允許以HTTP/2為基礎的連線外，也內建版本管理功能（Versioning），讓運行不同Docker引擎的工作節點，也能夠跟統一的管理者節點溝通。除了管理者節點會發派任務至工作節點，工作節點也會回報任務狀態等資訊。
最後，工作節點之間則使利用Gossip網路（Gossip Network）互相連結。Docker解釋，Gossip網路包含P2P、高容量的特點，適用於大規模的應用情境。當工作節點接收任務後，除了會開啟容器外，此節點亦會通知其餘節點，此容器位在的覆蓋網路（Overlay Network）。Docker表示，透過Gossip網路，訊息僅會在特定節點內傳送。
此外，Windows版Docker及Mac版Docker也推出了正式版本。
",https://www.ithome.com.tw/news/107459,"新聞,Docker,容器調度,容器技術,Container"
107411,22,2016-07-31,IT月報｜雲端IT焦點回顧 (2016/7),臺灣OpenStack Day登場，基金會四巨頭也親自來臺參加；AWS擴展資料庫移轉工具功能，開始支援持續性資料複製；微軟秋天將推出結合ERP及CRM的Dynamics 365,"  OpenStack Day   財政雲 
臺灣OpenStack Day登場，基金會四巨頭也親自來臺參加
臺灣OpenStack Day 2016在臺北國際會議中心舉行，現場總共吸引將近2,000名聽眾報名參加，同時，OpenStack基金會的四巨頭，包含OpenStack基金會主席Alan Clark、執行長Jonathan Bryce、創辦人兼營運長Mark Collier，以及行銷暨社群副總裁Lauren Sell及也親自到場。
Jonathan Bryce揭露了目前臺灣開始試用OpenStack的案例，例如是方電訊的公有雲服務、104人力銀行及中華電信的企業私有雲。甚至連財政部財政資訊中心也開始用OpenStack作為雲端運算基礎架構，建置財政雲測試平臺，成為第一個使用OpenStack架構的政府雲，他歸納成功擁抱OpenStack的關鍵為，使用者大多都選擇標準平臺，除了OpenStack外，還結合了其他元件。他表示，OpenStack提供底層的運算、儲存及網路功能，「只要有這些為基礎，就可以創造許多新東西。」（詳全文）
 
 AWS   SAP ASE 
AWS擴展資料庫移轉工具功能，開始支援持續性資料複製

亞馬遜宣布擴展DMS工具的功能，開始支援持續性資料複製、SSL加密傳輸終端設備，以及前身是SAP Sybase ASE的ASE資料庫。AWS資料庫移轉工具提供用戶移轉TB規模的資料庫至Amazon Relational Database Service或是Amazon EC2上的資料庫，目前支援Oracle、SQL Server、MySQL、MariaDB及PostgreSQL等資料庫的移轉。（詳全文）
 
 Azure   Office 365 
微軟財報出爐：Azure成長102%，手機營收下滑70%
微軟公布了該公司截至今年6月30日的2016財年第四季財報，該季創下了226億美元的營收與0.69美元的每股盈餘，超越了分析師期待，股價在盤後交易漲上55.34美元，上漲幅度為4.24%。觀察微軟該季的產品表現，在成長的部份涵蓋：Office商用產品及雲端服務的營收成長了5%；Office消費者產品及雲端服務營收成長19%，且Office 365訂閱用戶數已達到2,310萬。（詳全文）
 
 Dynamics ERP   Dynamics CRM 
微軟今年秋天將推出結合ERP及CRM的Dynamics 365

微軟宣布，將把Dynamics AX online企業資源規畫及Dynamics CRM online客戶關係管理等兩項雲端解決方案合而為一，在今年秋天推出Dynamics 365。Dynamics 365將供應各種獨立的程式供企業根據需求使用，包括金融、現場服務、銷售、操作、行銷、專案服務自動化及客戶服務。上述程式皆可獨立部署，並依照使用量計價。
Dynamics 365內建了Power BI及Cortana Intelligence等商業智慧分析功能。例如Cortana可提出交叉銷售建議以讓業務預測客戶所需的產品及服務；或者是利用現場服務存取物聯網資料時可透過資產監控及異常偵測主動在故障發生前採取行動。（詳全文）
 
 奇異   工業物聯網平臺 
微軟聯手GE，發展工業物聯網平臺Predix on Azure

微軟進一步擴展旗下Azure雲端平臺的服務範圍，日前在全球合作夥伴大會（Worldwide Partner Conference）上宣布與奇異公司（GE）合作，推出Azure版Predix平臺（Predix on Azure），提供工業企業用戶能在Azure雲端服務中存取GE旗下的工業PaaS平臺Predix，而Predix on Azure開發者預覽版預計在今年年終釋出，商用版則預計在2017年第2季上市。（詳全文）
 
 SoftLayer   Ubuntu 
IBM SoftLayer雲端服務支援Canonical認證Ubuntu映像檔，加速Ubuntu更新

日前Canonical宣布，IBM成為Ubuntu認證的公共雲合作夥伴，IBM旗下的SoftLayer雲端服務開始支援經Canonical認證的Ubuntu Linux伺服器作業系統映像檔，而用戶可以使用Ubuntu映像檔來測試和調校SoftLayer雲端環境，以確保SoftLayer的虛擬機器或裸機伺服器能提供更好的工作負載。（詳全文）
 
 混合雲   Azure Stack 
微軟混合雲平臺Azure Stack明年第一季正式上市

微軟宣布混合雲平臺Azure Stack預計明年第一季正式上市，會涵蓋IaaS、PaaS與SQL Database等服務，微軟也同時宣布，Windows Server 2016將於今年10月正式推出。微軟營運暨行銷事業群資深平臺策略經理馮立偉表示，Azure Stack主要的使用者聚焦於大型公司，如銀行與電信業者，其硬體規模，以戴爾推出的Azure混合雲機櫃為例，至少需具備八臺機櫃以上，而微軟預計於今年10月推出Azure Stack的企業導入計畫。（詳全文）
 
 IDC   公有雲 
IDC：2020年，企業雲端支出將占全球總體IT基礎架構支出近50%

市場調查研究機構IDC指出，和2015年相比，2016年全球雲端IT基礎建設的總支出成長了15.5%，達371億美元，而預期2020年，全球整體的雲端IT基礎架構支出規模達到595億美元，占整體IT基礎架構的48.7%，成長率為13.1%，顯見雲端基礎架構在企業IT建置中的重要性。而2016年全球企業雲端IT基礎建設，企業投資在公有雲的支出將比私有雲來得高，成長也比較快速，其中私有雲IT基礎建設的支出相較於2015年成長了10.3%，達138億美元，而公有雲IT基礎建設的支出則成長18.8%，來到233億美元。（詳全文）
 
 Skype   P2P 
Skype今年內完成雲端化，終止支援舊版Windows Phone與Android
微軟在2011年以85億美元併購了Skype之後，便積極將Skype架構從P2P轉移到雲端，預期今年內將可完成轉移，同時微軟也宣布準備終止Skype對Windows Phone及舊版Android的支援。現在Skype的許多新功能都是基於雲端架構，從語音通訊、視訊、檔案分享、離線存取、翻譯到機器人等。根據微軟的規畫，Skype將在今年的10月終止對舊版Windows Phone的支援，包括Windows Phone 8與Windows Phone 8.1，但仍會繼續支援Windows 10 Mobile。（詳全文）
",https://www.ithome.com.tw/news/107411,"新聞,Cloud,雲端,OpenStack Day"
107410,22,2016-07-29,為搶雲端市佔大砸93億美元，甲骨文決定買下NetSuite,買下NetSuite後，有助於甲骨文補齊其雲端服務在製造、零售、商務與專業服務等產業的缺口，目前甲骨文在這些產業仍以傳統on-premise模式銷售其軟體產品。," 著眼雲端市佔，甲骨文大砸93億美元買下NetSuite軟體大廠甲骨文（Oracle）宣布，以93億美元（約合新台幣2,976億元）現金收購線上應用軟體服務供應商NetSuite，藉以助其強化雲端業務發展一臂之力。
甲骨文執行長Mark Hurd表示，兩家公司的雲端應用能夠互補，並會持續在市場永遠存在，甲骨文會持續同時投資雙邊產品的研發與銷售。甲骨文另一位執行長Safra Catz則表示期待該併購能立刻增加甲骨文財報的營利，凸顯甲骨文過去幾年來一直努力增加雲端業務在整體營收所佔的比例。
甲骨文與NetSuite兩家公司其實淵源頗深。其執行長Zach Nelson在1990年代曾在甲骨文擔任全球行銷副總，並是甲骨文當時最年輕的副總，而甲骨文創辦人Larry Ellison亦是NetSuite的最大個人股東，兩家公司都在企業資源規劃（ERP）軟體市場頗多建樹，只是NetSuite打從創立起便提供web-based會計軟體服務，其起源便與當今最熱門的雲端服務模式相同。
NetSuitet創辦人暨技術長Evan Goldberg表示，該公司18年來一直都在研發在雲端協助企業營運的單一系統，與甲骨文結合有助創造客戶、員工與合作夥伴的多贏局面。Zach Nelson則補充，甲骨文的全球營運規模有助NetSuite加速將其服務延伸並擴充到更多產業別與國家。
購入NetSuite將有助於甲骨文補齊其雲端服務在製造、零售、商務與專業服務等產業的缺口，目前甲骨文在這些產業仍以傳統on-premise模式銷售其軟體產品。
甲骨文將以每股109美元現金收購NetSuite，後者股票在消息發布後上漲18%達108.07美元。該併購案預計將在2016年底前完成。
 
",https://www.ithome.com.tw/news/107410,"新聞,Oracle,Cloud,NetSuite,雲端應用平臺,甲骨文"
107198,22,2016-07-24,空中巴士40套內部系統為何要用Container？,為了管理全球80萬個資訊設備，Airbus公司展開擁抱開源大作戰，不僅關鍵系統改用開源產品，今年更積極把開發維運流程導入DevOps，準備上雲端，這是他們強迫IT一定要懂的開放工作術," 「你猜一臺空中巴士A380飛機上，要安裝多少臺伺服器？」全球兩大飛機製造商之一Airbus公司IT工具服務新創部門首席Nicolas Fanjeau在今年紅帽大會分享Airbus為何轉而擁抱開源技術時，他一開場就問了這個問題。「答案是500公斤，在飛機上的計算單位是公斤，而不是臺。」他打趣著說，但這卻是Airbus資訊部門必須熟悉的數據，因為這類資訊設備也歸IT部門所管。
全球飛機訂單市占5成的空中巴士，每年要出貨上千臺飛機，光是2014年就高達1,456架， IT部門要在飛機上部署的伺服器超過50公噸，手上還未完成的飛機訂單還有多達6千多架，訂單交期往往長達9年，IT部門的伺服器部署規畫，往往得考慮到好幾年後要交貨的飛機。
階段1：導開源資產管理ERP，管理80萬件IT設備
再加上Airbus全球400個據點共有5萬5千名員工，前端辦公室有7萬臺PC、6,000臺印表機和4萬臺手機，後端各處機房合計部署了12,500臺伺服器和15PB的儲存系統。即使Airbus全球資訊人員高達1,300人，但要高達80萬件的相關資訊基礎設備，仍是一大挑戰。
為了建立一套集中管理的IT基礎架構資產管理系統，還能自己客制，Airbus決定導入號稱是基礎架構ERP的開源ITSM管理系統iTop。開源軟體iTop所提供的外掛套件，可以提供開放的API，搭配開源開發工具Eclipse、開源AP伺服器和REHL Linux作業系統，Airbus資訊部門在這套系統上，一口氣採用了全套開源環境。Nicolas Fanjeau解釋，不只是為了建置單一平臺，更大目的是要強迫自己擁抱創新科技。
2015年9月啟動iTop專案後，3個月內先完成了CMDB變動管理系統，陸續在今年2到5月間進一步導入了倉儲管理、租用管理等系統。這套供2千名員工使用的系統，讓Airbus平均每周可以發布一次更新小改版。
階段2：用開源EIP打造客服系統，服務10萬顧客
不只這項專案採用開源技術，今年1月，Airbus展開了另一個更大的開源計畫，要打造一套能夠服務10萬人的使用者中心設計的IT客服系統。Airbus業務不只是製造大型客機，還有企業用小型飛機和貨機，還會提供各式飛機的交易買賣，往來顧客多達13萬人。
為了串接後端系統，Airbus資訊部門使用開源CMS系統LifeRay來建立服務前臺，再透過一套標準化的API來存取多套後端系統，甚至得要存取大型主機上的資料。整套系統同樣採用開源技術，搭配底層RHEL和開源應用伺服器Tomcat。
只花了一個月，Airbus資訊部門就推出了第一版IT服務系統，但是10萬人使用規模是一大挑戰，3月時先開放給400人試用，穩定後在擴大規模到4千人，今年6月時全面上線，開放給全球10萬名顧客使用。
但因IT客服系統得串接多套後端系統，改版開發難度較高，Airbus只能每兩周改版一次。可是，超過6成Airbus顧客使用手機瀏覽，為了更快反應業務端提出的新需求或修改，Airbus決定進一步擁抱DevOps，在12套內部的整合型應用系統上，導入持續交付（Continuous Delivery）。「減少了修補問題的時間，等於是增加了開發新功能的時間。」Nicolas Fanjeau表示：「更大好處是，透過DevOps來增加團隊溝通、協作和整合，可以強迫IT擁抱開放的工作方法（Open Way of  Working）。」
階段3：導入持續交付和容器PaaS，加速開發兼顧舊系統汰換
但是，Airbus資訊部門變革的腳步還不僅如此。Nicolas Fanjeau表示：Airbus希望快速開發和部署應用程式的步調，不只在企業內部實現，還要進一步延伸到雲端，在擴充應用程式規模時還能優化資源利用率，另一方便也希望能簡化舊有非雲端應用系統的汰換過程。「擁抱DevOps和Container的PaaS平臺，是唯一的選擇。」他強調。
不過，考量要能支援原有開發語言、資料庫系統的Container技術，Airbus導入了紅帽新版OpenShift 3企業版，採用Docker Container技術，並使用Kubernetes來作為Container叢集的管理平臺。Nicolas Fanjeau表示：「Container產品更成熟了，可以用來部署重要的企業系統，Airbus不只將Openshift用於新專案，「內部採用PHP開發的150套應用系統，超過40套已經準備好要改部署到Container上。」
對Airbus這家原本大量仰賴傳統IT架構，每年光是內部SAP系統上的交易次數就多達150億次，也大量使用大型主機和高效能運算伺服器，建置超過5年還沒更新的內部系統更是比比皆是。
但是，Airbus想盡辦法透過各項開源技術的導入，就是要讓全球1,300人的IT團隊，學會這套來自開源社群衍生的「開放工作術」。為何非這麼做不可？
「擁抱開源和DevOps，的確能減少大量重複工作，也能讓IT變成大受使用者肯定的快手」但是，更重要的是開源和DevOps是促進協同合作的加速器，」Nicolas Fanjeau表示：「在各種開源技術中，Airbus更是壓寶Container，因為Container是PaaS的未來。」
 

 Airbus千人IT團隊3階段導入開放工作術 
階段1 從一個關鍵專案開始
●時間：2015年9月~2016年6月
●作法：採用開源ITSM軟體建置資產管理ERP，解決80萬件IT設備管理難題。
●目標：強迫IT團隊接觸新興科技和開源技術
●應用規模：2千人使用者，管理80萬件IT設備，每周更新一次。
●關鍵軟體：Eclipse開發工具、iTop開源ITSM軟體、HTTP應用伺服器、RHEL。
 
階段2 促進開源軟體使用
●時間：2016年1月~2016年6月
●作法：採用開源CMS軟體打造客服前臺以利擴充，建立標準化API串接多套後端系統。
●目標：使用更多開源軟體，善用開源優勢（低成本、快速導入）、減少對傳統軟體商的依賴、促進創新
●應用規模：10萬名顧客，每2周更新一次。
●關鍵軟體：Eclipse開發工具、LifeRay開源CMS軟體、Tomcat應用伺服器、RHEL。
 
階段3 擁抱開放工作術
●時間：2016年持續進行
●作法：擁抱DevOps和容器PaaS，12套整合型應用系統導入持續交付，40套PHP應用準備容器化。
●目標：提高團隊動機和效率，讓IT更加透明化。
●應用規模：10萬名顧客，每2周更新一次。
●關鍵軟體：Eclipse開發工具、LifeRay開源CMS軟體、Tomcat應用伺服器、RHEL。

 
【相關報導請參考「Container商業化起步」專題】
",https://www.ithome.com.tw/news/107198,"新聞,Container,容器,空中巴士,Airbus"
107197,22,2016-07-24,通吃容器、VM和實體機，紅帽企業級容器生命周期管理平臺OpenShift登場,紅帽要用OpenShift來提供一個介於PaaS層和IaaS層之間的CaaS（Container as a service）層，來提供Container生命周期管理所需的機制," 紅帽的PaaS產品OpenShift不是唯一一套瞄準通用型混合雲架構的容器平臺，如IBM的Bluemix也有意成為通吃實體、虛擬和容器的混合雲平臺，而OpenStack也想往這個方向邁進。但OpenShift卻是第一個主攻Container ALM（應用程式生命周期管理）軟體的商用PaaS產品。這也意味著Container應用的管理，從以Container取代VM的布建管理層次，拉高到以應用程式為中心的管理思維
在今年6月紅帽大會中，紅帽最新揭露的產品戰略目標，就是要提供一套企業級的開源Container產品，而不只是Container技術而已。
紅帽產品和技術部門總裁Paul Cormier表示，紅帽終於可以提供一個完整的Container解決產品，給想要轉換基礎架構的企業。
打從Docker發表之後，以Linux作業系統和中介軟體為重的紅帽，很快就決定緊跟主流Container技術而非另行發展自家技術。因應今年開始進入搶市場的容器競爭態勢，紅帽Container新戰略是，先擴大OpenShift容器產品線，其次再利用去年併購的Ansible自動化工具，將容器帶入標準化的企業工作流程中。
打造單一容器平臺通吃實體、VM和混合雲
Paul Cormier表示，紅帽希望透過自家企業級Linux產品作為基礎，來提供Linux容器技術、支援開放容器聯盟的容器格式、利用Kubernetes實現資源調度（Orchestration），並提供儲存庫來提供容器探索服務，「最終要能打造出一個通吃實體伺服器、VM、私有雲和公有雲環境的標準化容器應用環境。」Paul Cormier表示。
所以，就在紅帽高峰會第一天，紅帽就先宣布， OpenShift軟體推出3.2版，搭載最新Kubernetes 1.2版，可提供動態應用程式配置、強化擴充性和新的排程功能。紅帽也將原有OpenShift企業版軟體直接更名為OpenShift Container平臺軟體，並推出一個免費下載的OpenShift Container Local版軟體。
Local版軟體是一個能安裝於本地端的容器應用平臺軟體，內含Red Hat容器開發包，可供開發者建立一個和雲端OpenShift（包括Online版服務和Dedicated版服務）一致的本地端容器開發和測試環境。另外還推出了OpenShift Container Lab版本，這是一個供企業評估和測試容器應用的版本。Paul Cormier表示，Online版、Local版和Lab版這3個版本都是同一套OpenShift軟體，只是針對不同需求而提出的不同銷售方式。
在紅帽的Container產品布局中，試圖透過OpenShift提供一個介於PaaS層（如商業自動化、資料服務、網頁應用、第三方開發框架）和IaaS層之間的CaaS（Container as a service）層，來提供如Container生命周期自動化（自助服務、CI/CD、Image檔串流）、Container管理（監控、容量控管、政策管理）、容器基礎架構服務（調度、排程、儲存、Registry、資安、網路）。紅帽的中介軟體JBoss則主攻PaaS層需求，而RHEL和Atomic Host則攻IaaS需求。

從生命周期產品布局來看，OpenShift不只要看開發者生態系的工具串接（如圖左的IDE、CDK，Ansible自動化），也要和各式各樣的雲端管理平臺和套裝服務生態系整合（圖右）
（圖片來源／紅帽）

整合Jenkins 2.0，將提供視覺化容器CD流程管理
紅帽預告，下一版OpenShift 3.3版也很快將在今年底推出，將搭載Kubernetes 1.3版，計畫能提供多叢集聯邦機制（Multi-cluster federation），讓企業可以透過單一平臺來管理不同配置的叢集，甚至是不同資料中心內的容器叢集。3.3版不只內建企業級容器儲存庫（Registry）功能，還將整合新一代Jenkins 2.0版，可提供一個視覺化介面的容器持續交付工作流程（CD Pipelines），能涵蓋開發到生產環境的容器建立和部署流程。
紅帽宣布，會將自家中介軟體產品整合到容器架構中，預計近期就會釋出容器化的JBoss EAP映象檔提供企業測試，來蒐集中介軟體容器化後的使用需求和意見，做為未來大規模將中介軟體整合到OpenShift容器平臺的參考。

下一版OpenShift 3.3版整合新一代Jenkins 2.0版，可提供一個視覺化介面的容器持續交付工作流程（CD Pipelines），能涵蓋開發到生產環境的容器建立和部署流程。（圖片來源／紅帽）

推出容器原生的企業級儲存機制
另外，紅帽也推出了Red Hat儲存產品Gluster的容器原生儲存機制，要在Container叢集內提供持續性企業級儲存能力，紅帽解釋，先前容器叢集是透過Kubernetes Volume驅動程式來存取外部儲存系統，現在紅帽則利用Kubernetes Volume框架，可將控制Gluster儲存程式放入容器內，成為容器內的功能，等於讓封裝在容器內的應用程式，可以直接將檔案資料存放到同在容器內的儲存系統，紅帽的Gluster儲存程式再自動將資料存放到外部儲存系統上，來實現容器原生企業級儲存的功能。
另外在容器安全上，原本用於掃描 OpenShift映象檔儲存庫的Black Duck掃描引擎，也內建到Red Hat Enterprise Linux Atomic Host中，等於可以在最新版RHEL中使用容器安全掃描功能。
紅帽還釋出了OpenSCAP預覽版，這是一個用於回報容器內軟體弱點的開源協定，可供第三方資安工具來檢查容器內的軟體。
【相關報導請參考「Container商業化起步」專題】
",https://www.ithome.com.tw/news/107197,"新聞,Container,容器,OpenShift,紅帽,Red Hat"
107196,22,2016-07-24,容器風潮轉向，Container搶市場大戰一觸即發,跨主機多容器調度更容易，安全議題成新焦點，不只混合雲架構積極擁抱，生命周期管理軟體也現身，容器廠商競爭態勢更加明顯，開始進入積極搶市場的階段了," 一手掀起Container狂潮的Docker技術長Solomon Hykes，竟然在2016年DockerCon年度大會中大喊：「現在沒人關心Container了，因為Application才要緊」，不少人會心一笑，不覺得這只是一句玩笑話，因為Container技術競賽已經漸趨明朗，新一輪的競爭是群雄競逐的Container市占大戰。
紅帽產品和技術部門總裁Paul Cormier觀察，Container市場從2013年Docker問世至今，經過了4階段的轉變。在2013年的技術導入初期，標準化的容器封裝和生態系開始萌芽，眾人驚艷於Docker找到了改良Container使用體驗的關鍵，Linux作業系統業者如紅帽開始支援，甚至還出現了專為執行Container而生的專用輕量級Linux作業系統CoreOS。
2014年，Container風潮更加火紅，進入了快速擴張期。
不只更多Linux作業系統支援，雲端作業系統OpenStack也來助陣，連被視為競爭對手的虛擬化技術龍頭VMware也宣布擁抱Docker。大勢所趨之下，向來是Linux對手陣營的微軟，也在2014年10月宣布，要在Windows Server中支援Docker，並積極投入Container研發，加入技術競賽。不過，Container技術開始出現分歧，Docker盟友CoreOS推出了自家容器技術Rocket互別苗頭。
而大讚Docker好用的Google，也決定大力支持Docker，但不是切入容器技術競賽，而將自家大規模管理容器的經驗，用來打造出管理Container叢集的開源計畫Kubernetes。從大數據分析技術竄起的叢集管理平臺Mesos也推出Marathon容器調度計畫，Container研發進入新的競爭階段：叢集管理。
另一方面，雲端龍頭業者也紛紛在IaaS服務上支援Docker，尤其是雲端Container叢集服務的支援，Google率先發表了可部署和管理大量Container叢集的GKE。而Amazon也推出了號稱可以管理任何規模數量Container叢集的ECS服務。
隔年， Container市場進入積極投入階段，2015年時出現了多可用於大規模建置Container的輕量級容器OS亮相，連VMware都推出自家輕量級Linux，搶進Container技術戰爭。不過，開放容器組織OCI和原生雲端運算基金會的成立，結束了容器技術的戰爭，掀起容器標準化的趨勢，大型廠商如微軟和VMware更加積極支援，紅帽也推出了容器認證來吸引ISV加入容器生態系。
而到了2016年，Paul Cormier認為，Container生態系更加快速成長，甚至全面地影響了幾乎所有的Linux供應者，不管是Linux開發者、傳統Linux商軟或PaaS業者、Linux新創或是公有雲業者。
Container市場開始轉型
容器市場也因此開始轉型，Paul Cormier提出幾項證據，容器市場正從技術，開始成為應用市場的轉變，包括如容器相關創投資金達到17億美元、容器安全開始成為主要議題、容器廠商開始出現競爭關係，例如Mesosphere將旗下容器軟體DC/OS開源，要來打造自家的容器生態系。而Docker更是早在3月時揭露了進軍容器即服務（Container as a Service）布局雲端市場的戰略。
企業對混合雲需求的竄起，更是帶動了Container市場的競爭。開放Container標準的普及，讓Container比VM更容易在公有雲和私有雲、甚至是多個公有雲間移動，各大IaaS和PaaS平臺或軟體業者，也紛紛加碼進入容器技術和平臺的競爭，更多競爭勢力的加入，讓Container市場的戰局日益複雜。
Container廠商競爭態勢日益明顯，Docker更是在今年6月DockerCon大會中，大舉跨出核心技術研發的範疇，積極布局各類Container應用市場。Solomon Hykes一句話，正暗示了Docker產品策略的轉變，從專注Container技術，開始轉向以應用程式為中心的產品研發思維。
新版Docker內建調度工具就是最典型的例子，讓Docker從容器技術引擎，跨進了叢集管理平臺的戰場，讓開發者更容易在多主機中部署複雜架構的多容器應用系統，打破原本只能在單一主機上部署的侷限，等於是直接和調度工具廠商如Mesosphere打對臺。
廣達雲端運算事業群資深副總經理楊晴華認為：「從應用程式角度來看，Container才是對的技術。」因為從底層實體伺服器開始，中間不管是實體主機，VM或是容器技術或是任何技術，最重要的還是如何實現商業邏輯從中獲利才是關鍵，那就是應用程式的任務，而現在「Container已經是可以用的軟體了。」他說。
甚至Docker還反過來跨足線上公有雲市場，推出了AWS和Azure版的雲端Docker，來簡化企業上雲端自建Container環境的門檻，同時也推出Mac OS和Windows桌機版Docker，要讓開發者從，桌機開發測試環境、企業內部私有雲到公有雲的Container都能一以貫之，用同一套Docker就能通吃，大有邁向混合雲架構Container平臺的意味。
原本多用於開發和測試環境之用的Container，新一代微服務（Microservices）架構思維的竄起，讓應用程式容器化工具更加成熟，也帶動了正式環境部署Container應用的需求，更進一步將Container備受質疑的安全問題推到前臺成為重要焦點，促使Docker決定強化安全機制，不只在1.2新版中預設啟用安全機制，亙新增了相互認證TLS加密，來確保在容器叢集內跨節點傳輸資料時的安全。
Container叢集平臺競爭帶動商用容器軟體更成熟
不過，Docker要進軍混合雲架構和容器叢集市場，最大競爭技術是Google的Kubernetes。
Google不只是為了推廣Container而力推Kubernetes，更將其視為吸引更多開發者和企業使用Google雲端平臺的關鍵中介平臺，因此改版速度飛快，想要快速補齊各種功能。
Kubernetes今年接連2次改版中，大幅提高了單一Container叢集的擴充能力，3月1.2版可以支援1千個節點，部署3萬個Container，並且增加了叢集自動化工具來提供跨區資源排程和跨區出錯備援機制。
到了6月底剛發布的1.3版，不只再度提高部署規模上線，到可用2千個節點組成容器叢集，也新增了跨叢集聯邦服務（Cross-Cluster Federated Services），讓Container上的服務可以跨叢集內外持續執行，來維持應用服務不中斷，並能支援混合雲和多雲的運作環境。另外，除了也開始支援狀態保存機制，有助於企業利用Container來部署，需要記錄狀態的應用服務（Stateful application），如資料庫系統。另外也增加了新指令來簡化本地端的Kubernetes叢集部署，且讓本地端叢集API和雲端完全相容，讓在本地端測試開發的容器化應用，可以直接上傳到雲端部署。
Google在Kubernetes的布局也和Docker新版布局方向有不少相似，都是朝混合雲架構發展。這也讓使用Kubernetes為核心的PaaS產品，更容易發展成能通吃傳統實體、VM和Container的通用型容器平臺，Red Hat新推出的OpenShift就是這類的容器PaaS平臺產品。
但不管如何，Container新創、雲端龍頭、主流作業系統廠商、虛擬化技術業者都紛紛積極擴大Container市場的布局，「容器軟體業開始進入搶市場的階段了。」Paul Cormier說。
【相關報導請參考「Container商業化起步」專題】
",https://www.ithome.com.tw/news/107196,"新聞,Container,容器,Docker"
107301,22,2016-07-24,Container雙周報第14期：DC/OS推出Gestalt框架，要讓使用者自建無伺服器運算架構,Mesos認為無伺服器架構將在未來占有一席之地，因此成立了Galactic Fog團隊，並且推出Gestalt架構，讓使用者也能自建無伺服器服務," 重點新聞（7月9日-7月22日）
·資料中心作業系統DC/OS推出Gestalt框架，要讓使用者自建無伺服器運算架構
以Container技術為設計核心的Mesos，想要利用DC/OS簡化資料中心管理，而在近日Mesos也宣布推出Gestalt框架，要讓使用者能夠自建無伺服器運算架構。
從大型主機、伺服器、VM到近期的Container，Mesos指出，許多人皆認為無伺服器將會是下一代的IT架構，就如AWS現有提供的Lambda服務。Mesos也直言：「無伺服器架構將在未來占有一席之地」，因此Mesos也成立了Galactic Fog團隊，並且推出Gestalt框架，讓DC/OS的使用者也能擁有無伺服器運算的能力。
Mesos表示，Gestalt的概念類似於Lambda，當特定事情發生時，才會驅動應用程式執行，而使用Lambda的開發者，也不需思考究竟應用程式是透過哪些容器、VM中運作，「因為Lambda會自動開啟Container，並且在工作結束後，自動關閉Container。」Mesos表示。
此外，Gestalt也採取雙層調度（Two-level scheduling）的架構設計。Mesos解釋，在不超過分配資源的條件下，Gestalt可以自由地調度系統工作排程。除了支援無伺服器運算功能外，Gestalt還能支援其他功能，例如部署Container，或是讓使用者跨叢集管理資源。目前在Mesos也在應用程式市集中釋出了Gestalt。更多資訊
·CI/CD服務商Wercker結合Kubernetes，打造自動化平臺
提供使用者持續部署、持續整合服務的Wercker，使用容器技術打造自動平臺。Wercker支援數個不同工作流程，包含程式碼建置、API測試等工作，而每個工作流程都是在Docker Container中執行。
目前Wercker總共得運作數百萬個容器，才能支撐現有應用規模。Wercker技術長Andy Smith表示，在平臺中執行測試、部署、建置的容器，生命周期都相當短，同時，Wercker也在跨節點環境中運作容器，因此「我們需要具備高度擴展性的排程工具，所以決定導入Kubernetes。」
Andy Smith表示，Kubernetes讓Wercker省下在跨節點環境中，管理大量Container的複雜工作，而Kubernetes也提供不同的API、工具，讓使用者可對容器進行監控、除錯等工作。更多資料
·Citrix與Google合作，整合應用程式發布控制器NetScaler與Kubernetes
Citrix產品管理總監Mikko Disini表示，Citrix最近與Google合作，結合NetScaler Docker負載平衡器，以及Kubernetes，解決企業用戶工作流程的遷移需求。
Mikko Disini也說明，Citrix為何整合NetScaler、Kuberenetes的三大理由：
1.企業在遷移至雲端環境中，用戶希望NetScaler依舊能提供Layer 4到Layer 7的服務，同時，企業也可以利用Kubernetes，部署微服務架構及Container
2.Kuberentes讓基礎建設可以同時運行VM及Container，並且提供自動化運作
3.NetScaler CPX提供Layer 4到Layer 7的服務外，也可以提供NetScaler分析平臺等遠端監測資料更多資訊
·為何紅帽押寶Kubernetes？紅帽OpenShift架構師告訴你
紅帽OpenShift架構師Clayton Coleman表示，兩年前Google推出Kubernetes專案時，紅帽就決定押寶它。他解釋，因為憑藉開源社群，才能在未來打造出最好的應用程式調度工具，同時，也唯有開源社群才能夠整合多方人士的開發能力，讓專案成功發展。
而紅帽押寶Kubernetes的決策是否正確？Clayton Coleman表示，可以藉由某一應用程式的使用人數，衡量它是否成功，「而Kubernetes的成功超乎我們預期。」
他解釋，目前有許多企業，透過OpenShift平臺，在正式環境中部署Kubernetes。而這些使用者也表示，無論是交付時間、應用程式生命周期，或是資源利用都有所進步。更多資料
·印第安納大學捨棄VM架構，轉用Docker

印第安納大學雖為學術機構，但是其服務對象，除了分散在印第安納州的8個分校外，服務規模更有超過11萬名學生及2萬名員工。
在過去，印第安納大學採用紅帽RHEL 6，並且將應用程式部署在VM之上，為了提供學生、員工更好的使用經驗，印第安納大學得要將超過150個應用程式通通翻新，包含人力資源、選課及財務等系統。此外，印第安納大學也需要能在多主機、跨資料中心的環境中，更快地部署應用程式。
印第安納大學企業軟體架構師Eric Westfall表示，印第安納大學很希望能將IT架構，轉為以Docker為主的容器環境，讓應用程式交付的速度能提升。因此，印第安納大學開始使用Docker所提供的商業解決方案Docker資料中心（Docker Data Center，DDC），提供提供容器即服務（Container as a Service，CaaS）、通用控制平臺（UCP），以及Docker認證儲存庫等功能。
導入Docker解決方案後，印第安納大學可使用UCP，管理橫跨資料中心的6個節點，同時，也可以利用現有的Docker API、Docker容器，加速交付應用程式的速度。而維運團隊也可以透過UCP，在伺服器上部署應用程式，不需要手動設定其基礎架構。更多資料
·華盛頓郵報在正式環境中導入Docker
美國華盛頓郵報首席技術架構師Patrick Cullen表示，華盛頓郵報目前有超過4,600萬名讀者。除了運作許多不同的應用程式是Patrick Cullen目前面臨的挑戰外，他還希望能建立一套持續部署（CD）系統，能支援多種程式語言，以及不同的應用程式。
目前華盛頓郵報有許多專案團隊，同時開發不同的小型應用程式，「因為使用Docker的開發成本相當低」，Patrick Cullen也表示，華盛頓郵報也能利用Docker，繼續運作既有的傳統應用程式。
Patrick Cullen表示，除了使用Docker Engine外，其中他們特別中意Docker Compose所提供的功能。他解釋，Docker Compose可以應用在叢集管理系統中，作為Runtime組態設定，「讓開發者很容易指定應用程式要如何在叢集中運作。」除此之外，華盛頓郵報也使用Docker打造新聞分析系統、個人化新聞服務。
他認為，目前IT團隊可以將心力專注在開發應用程式，而非管理基礎架構，而透過Docker，除了讓開發者能推出更多應用程式外，應用程式部署的時間也越來越快。更多資料
更多產品動態


·監控系統Prometheus推出1.0版，未來系統更新不需要改變既有部署或重新初始化系統更多資訊
·紅帽Openshift平臺整合監控系統Prometheus更多資訊
·紅帽釋出新版CentOS Atomic主機更多資訊
·容器安全廠商Twistlock提供AWS EC2、ECR容器安全服務更多資訊
·紅帽推出Linux管理介面Cockpit 0.113，使用者可指定Container使用的記憶體、CPU資源更多資源
Container資源
※知識：概略Docker 1.12網路模型
※How-To：結合.NET、Docker及PostgreSQL建立微服務
※How-To：用Docker Swarm部署服務
※How-To：在Docker 1.12中建立Swarm叢集
※How-To：在Rancher中使用DataDog
※How-To：用Jet打造原生Docker CI服務

",https://www.ithome.com.tw/news/107301,"新聞,Container,Docker,容器技術,Rancher,Mesos,Kubernetes,IT周報"
107011,22,2016-07-07,Container雙周報第13期：紅帽推OpenShift Container平臺，目標加速企業導入容器技術,紅帽推出OpenShift容器平臺，想讓企業盡快在正式環境中導入Container，目前西班牙對外銀行（BBVA）、蘇格蘭皇家銀行，都已經選擇OpenShift進行數位轉型，「並利用紅帽容器平臺作為核心。」," 重點新聞（6月25日-7月8日）
·紅帽推OpenShift Container平臺，目標加速企業導入容器技術
上月的紅帽高峰會中，紅帽推出了OpenShift容器平臺，想讓企業盡快在正式環境中導入Container。紅帽表示，目前西班牙對外銀行（BBVA）、蘇格蘭皇家銀行，都已經選擇OpenShift進行數位轉型，「並利用紅帽容器平臺作為核心。」
紅帽表示，此容器平臺可以讓開發者繼續使用熟悉的工作流程、CI/CD工具，進行程式開發。除了開發者外，「一個穩定的容器平臺，對維運人員很重要」，紅帽解釋，由於維運團隊得同時管理傳統應用程式、新型微服務架構應用程式，因此從最底層的軟體、虛擬化層，到最上層的應用程層，「要提供他們完全的能見度。」目前紅帽總共提供3種版本的OpenShift，包括OpenShift線上版、OpenShift專用版及OpenShift容器平臺。更多資訊
·Kubernetes 1.3版釋出，瞄準雲端原生應用
近日Google釋出開源容器調度工具Kubernetes 1.3版，Google表示，目前許多企業、開發者開始在正式環境導入Kubernetes，「加入了這波雲端原生應用的革命中。」Kubernetes的使用者反應，除希望能跨區（Zone）、叢集及雲端環境部署服務外，也想在Container中運作更多工作，「在此版本中，我們試圖解決這兩個問題，同時，也讓企業在大規模分散式系統中，更簡單地使用Kubernetes。」新版有6大特色：
1.加強應用規模及自動化功能
2.新增跨叢集聯邦服務（Cross-Cluster Federated Services）
3.支援需要保存狀態的應用（Stateful application），如更容易利用Container執行資料庫等應用
4.容易在桌機建立本地端叢集
5.支援rkt runtime和OCI及CNI等容器標準
6.更新Kubernetes儀表板UI介面
目前Kuberenetes獲得多家廠商支持，例如CoreOS結合OpenStack，要在Kubernetes上運作OpenStack，連紅帽也想利用Kubernetes，打造標準的容器化應用環境。更多資訊

·紅帽在高峰會上揭露未來Container新戰略
今年紅帽高峰會最新揭露的產品戰略目標，要提供一套企業級的開源Container產品，而不只是Container技術而已。紅帽產品和技術部門總裁Paul Cormier表示，因應新的容器市場競爭態勢，Paul Cormier表示，紅帽的Container新戰略是，第一是擴大OpenShift容器產品線，其次是利用去年併購的Ansible自動化工具，將容器帶入標準化的企業工作流程中。
紅帽希望透過自家企業級Linux產品作為基礎，來提供Linux容器技術、支援開放容器聯盟的容器格式、利用Kubernetes實現資源調度（Orchestration），並提供儲存庫來提供容器探索服務，「最終要能打造出一個通吃實體伺服器、VM、私有雲和公有雲環境的標準化容器應用環境。」Paul Cormier表示。更多報導

·Rancher 1.1正式推出，開始支援AWS EBS及Google GCE持久儲存
Rancher近日正式推出1.1版，Rancher共同創辦人暨工程副總裁Will Chan列舉了新版4大特色：
1.支援Docker 1.11的以上版本
2.使用者可以選擇Mesos做為容器調度工具
3.加強對Kubernetes的支援，例如支援AWS EBS及Google GCE持久儲存、私人儲存庫
4.新增機器目錄（Machine Catalog），讓使用者可以利用客製UI介面，新增Docker主機
Will Chan透露，Rancher團隊正在整合內建調度功能的新版Docker 1.12，預計在Rancher 1.2.0預覽版本中開始支援。更多資訊
·百度DevOps經驗大公開，1萬臺伺服器全部容器化
蔚為中國最大社群論壇的百度貼吧（簡稱貼吧），每天瀏覽次數30億人次，累積13年的貼文數量已經高達930億則。百度資深研發工程師陳建森表示，百度採用LNMP架構（Linux、Nginx、MySQL、PHP），將系統拆分為微服務架構（Microservices），服務之間則透過HTTP協定互相溝通。
不僅如此，貼吧更將1萬臺伺服器內的系統全部容器化，總共達到5萬個Container的使用規模，而容器化不僅提升部署效率，「也讓系統水平擴展變得更加簡單。」他表示，微服務化也能讓各團隊維運系統的責任分工更明確，「業務開發速度能更快。」更多報導
·CoreOS推出etcd 3.0.0正式版本
日前CoreOS推出etcd v3.0.0 beta版本，除了降低延遲性、提升吞吐量外，也提供自動化的TLS加密組態設定，在近日CoreOS則釋出etcd 3.0.0正式版本。CoreOS表示，etcd目前已經與大規模容器調度工具Kubernetes整合，並確保etcd 3.0.0的API具備足夠彈性，能支援不同的應用程式。
CoreOS表示，etcd一開始是用來解决CoreOS的升級問題，但現在則使用在組態管理、分散式網路、負載平衡等服務上。雖然舊版的etcd2足以擔負調度機器的功能，但在微服務基礎架構的趨勢下，「etcd得在單一叢集內，完成數百萬項的操作。」因此，CoreOS將基礎伺服器介面（Server Interface），由JSON改換至gRPC協定，「藉以增加效率。」更多資訊
·未來Azure容器服務也要支援Windows Server Container
微軟近日推出可運作Windows Server Container的Azure容器服務的封閉測試版，Azure Linux專案經理Saurya Das表示，Azure容器服務讓使用者可以使用開源的容器調度工具，例如DC/OS或是Docker Swarm。
不過目前推出的封閉測試版本，使用者僅能透過Docker Swarm，調度Windows Server Container。更多資料
更多產品動態

·紅帽推出儲存產品Gluster，在Container叢集內提供持續性企業級儲存能力更多資訊 
·紅帽整合OpenShift及容器監控工具Sysdig更多資訊
·DC/OS整合容器監控工具Sysdig更多資訊
Container資源
※影片：15分鐘上手Docker Swarm
※影片：DockerCon 2016的影片清單
※知識：介紹Docker 1.12儲存功能
※知識：概略Docker 1.12網路功能
※How-To：如何監控容器運作
※How-To：用Docker 1.12執行服務

",https://www.ithome.com.tw/news/107011,"新聞,紅帽,Kubernetes,Container,Rancher,Docker,IT周報"
106967,22,2016-07-05,【DevOps Summit焦點】百度貼吧DevOps經驗大公開，撐住每日30億拜訪次數的關鍵,蔚為中國最大社群論壇的百度貼吧（簡稱貼吧），每天訪問次數30億人次，累積13年的貼文數量更達930億則，同時，因應行動裝置的發展，百度開始經營影像直播、電影及遊戲等服務，每天交付至正式環境的程式碼變更高達100次，對於工程團隊也是相當龐大的壓力," 蔚為中國最大社群論壇的百度貼吧（簡稱貼吧），每天訪問次數30億人次、API呼叫百億次，一日新增的貼文有4千萬則，累積13年的貼文數量已經高達930億則，百度資深研發工程師陳建森在今年DevOps Summit大會上透露，必須靠超過1萬臺伺服器，才能應付如此龐大的業務需求。
同時，因應行動裝置的發展，百度開始推出影像直播、電影及遊戲等服務，每天交付至正式環境的程式碼上傳次數，也高達100次，對於工程團隊產生相當大的壓力。貼吧已經從最原始的論壇，變成「功能複雜的產品。」
陳建森表示，為了應付龐大的業務需求，百度在北京、廣州及南京分別架設IDC機房，假如北京機房故障，可以將服務遷移至他處，「對容災、容錯都有幫助。」但只靠硬體建置還不夠，在軟體架構上還得配合才行，陳建森表示，百度採用LNMP架構（Linux、Nginx、MySQL、PHP），將系統拆分為微服務架構（Microservices），服務之間則透過HTTP協定互相溝通。最後，貼吧更將1萬臺伺服器內的系統全部容器化，總共達到5萬個Container的使用規模，而容器化不僅提升部署效率，「也讓系統水平擴展變得更加簡單。」他表示，微服務化也能讓各團隊維運系統的責任分工更明確，「業務開發速度能更快。」
但是，即使大幅導入微服務、Container技術及異地備援等機制，貼吧服務的穩定性仍然是個痛點。在2015年時，貼吧2015年核心服務穩定性為99%，每天出現的系統異常總共超過200次，而精準定位系統故障問題，也往往超過了30分鐘才能恢復正常。
陳建森解釋，因為伺服器規模過於龐大，只要幾臺機器出現異常，就足以讓百度的服務受到影響。再者，由於貼吧論壇的服務越來越龐雜，當系統出現異常狀況時，光是找出問題也相當耗時，只靠工程師「逐一排除異常的作法，還是會讓同樣的問題層出不窮。」百度想辦法找出新的作法才行。
建置線上服務自動保障系統，確保服務維持高可用性
加上貼吧底層子系統超過200套，也分散部署在三地的IDC機房，即使用光纖連線，還是會因距離過遠，而產生傳輸延遲的問題。
所以，為了讓系統更加穩定，百度著手建置線上服務自動保障系統，陳建森解釋，此系統的目標是確保服務維持高可用性，同時，也要讓維運作業盡可能自動化，具備排除系統異常的能力。不只如此，百度還希望打造貫穿兩者的一站式平臺，「讓這樣的系統也能變得更易用。」
而且這套自動保障系統，不只是用來排除故障，也因自動化，所以能快速解決問題，這套系統的設計核心是「在有限資源下，達到最佳的服務品質」，陳建森表示，百度用系統反應時間的數據，來定義這套自動保障系統所要維護的服務品質指標，所以，連帶也解決另一個百度最關心的系統反應時間延遲問題。
針對不同伺服器規模，訂定相異保護策略
陳建森歸納，系統發生異常時，往往從小部分模組開始，進而才擴散到整體架構中，因此，確保服務品質最關鍵的一環就是「確保系統模組的穩定性。」因此，貼吧鎖定了三大方向，藉以落實服務高可用性：資源調度、服務降級，以及過載保護。同時，百度也會針對問題規模大小，來提供不一樣的保護策略。
例如單臺伺服器上，線上系統會分配每個網頁請求的反應時間，萬一某模組回應請求的反應時間過慢、等待時間過長，「該請求會停止，系統會自動降級，確保系統不會發生故障。」同時，由於貼吧採取LNMP架構的設計，團隊也為Nginx、HHVM兩大核心元件，開發遠端程序呼叫（Remote Procedure Call，RPC）負載平衡模組，確保系統的穩定性。
萬一故障從單一伺服器逐漸擴散，進而影響了整體服務品質，貼吧也訂定了不同的對策因應。第一種方式是利用百度異地機房的備援架構，分散單一機房的流量壓力，藉此維持使用者的用戶體驗。
再者，當系統資源不足以應付用戶流量需求時，貼吧則透過頁面快取（pagecache）及業務降級解決。陳建森解釋，貼吧在使用者進行訪問介接層中，實作可水平擴展的Nginx模組，並且在json文件中，告知系統哪些頁面要存入快取。
當使用者的需求得到系統回應時，系統會將請求結果儲存在快取叢集中（cache cluster）。一旦請求失敗、後端系統失靈，Nginx模組則會從快取叢集中，讀取先儲存的內容，並且轉給使用者，「即使後端失靈，我們仍然可以提供服務給用戶」。另外，瀏覽次數較高的頁面，由於儲存快取的頻率高，讀取成功的機率也比較大。
同時，系統也會開始進行服務降級，限縮可以進行訪問的系統模組，降低資源消耗。最後，為避免過載，系統也開始針對異常流量，進行限流管理。
儘管自動化能大量減少異常發生，不過仍無法100%避免，面對龐大的系統，萬一每個系統問題都必須被排除，勢必會浪費大量的人力及時間。因此陳建森表示：「必須精簡問題，不將所有異常列入考慮」，已維持服務穩定性為最高優先。例如，某臺伺服器失靈，但是沒有對服務造成傷害，此時便不需要特別排除其故障問題。
架構革新讓系統異常次數陡降8成
透過一連串的架構革新，陳建森表示，目前，整體服務穩定度達到了99.95％，每天系統異常次數從200次，下降到30次，而定位系統異常的時間從30分鐘，更減少到10分鐘。在百度貼吧的經驗中，陳建森也得出了兩大心得。他表示，如果想要實現自動化，標準化、規範化是關鍵。此外，自動化系統也要能因應技術演進，持續發展，「確保業務不斷發展的同時，自動化系統仍然可繼續沿用。」
",https://www.ithome.com.tw/news/106967,"新聞,百度,Nginx,DevOps,高可用性,DevOps Summit"
106698,23,2016-06-27,Container雙周報第12期：新版Docker產品戰略大升級，發展重心從容器技術發展轉往應用程式,Docker技術長Solomon Hykes強調：「現在沒人關心Container，應用程式才要緊」，正點出了Docker從起初專注於Container技術的強化，到今年的DockerCon，則開始以應用程式為中心來思考需要的新功能," 重點新聞（6月11日-6月24日）
·Docker產品戰略大升級，DockerCon大會重點回顧
Container圈的年度技術大會DockerCon近日在西雅圖登場，吸引了超過4,000人參與，Docker技術長Solomon Hykes的一句話，更暗示了Docker產品策略的改變，從專注Container技術，開始邁向以應用程式為中心的研發思維，發表重點如下：

發展重心從容器技術轉往應用程式


Docker 1.12版推出，內建容器調度功能


新版Docker結合TLS加密技機制，確保Docker Swarm叢集跨節點資料傳輸的安全


搶進公有雲市場，Docker推出AWS、Azure雲端版Docker


Docker也推出實驗性的開放檔案格式，稱為分散應用程式包（DAB）

更多報導
·容器軟體市集Docker Store邁入封閉測試
Docker宣布展開容器軟體市集Docker Store的封閉測試，與代管超過10萬種的免費及開放源碼的Docker應用映像檔的Docker Hub相比，最大的差別在於，Docker Store將同時提供開源與商用工具，且所有的內容都需經過審核，且將鼓勵獨立軟體開發商出版可靠的內容，而且必須通過安全掃描、元件庫存、開源碼授權的使用等軟體品質的驗證，並具備完整的分類與搜尋功能。更多報導
·三星收購雲端基礎架構業者Joyent，強化行動及物聯網服務
三星併購公、私有雲軟體業者Joyent，藉此為其行動、雲端及物聯網（IoT）服務提供後端基礎架構。Joyent旗下擁有容器即服務平台Triton、Manta物件儲存技術、無伺服器運算及Node.js等技術。更多報導
·容器儲存供應商ClusterHQ發布調查，近8成企業在正式環境中使用容器技術
Container儲存供應商ClusterHQ發布2016年容器採用率調查報告，全球共有310位IT專業人士參與這次的調查，容器採用率報告顯示，有近8成（79％）的企業有使用Container技術，而在正式環境中採用容器技術的企業有76％，比起2015年的38％，容器採用率成長了近一倍。更多報導
更多產品動態

·CoreOS聯手微軟，在中國正式登陸 更多資訊
·Apache Mesos推出0.28.2版本 更多資訊

·Docker推出Mac、Windows本機端公開Beta版Docker 更多資訊
·Container監控解決方案提供商Sysdig推出企業級容器監控、問題排除解決方案 更多資訊

Container資源
※知識：介紹Docker SwarmKit
※影片：南非房貸業者SA Home Loan怎麼用Docker資料中心
※How-To：如何Hyper-V主機上使用Docker及Visual Studio
※How-To：Ubuntu平臺中用Docker運作.NET核心
※官方教學：如何在AWS、Azure上部署Docker資料中心
※官方教學：用Docker打造無伺服器應用程式

",https://www.ithome.com.tw/news/106698,"新聞,DockerCon,Joyent,Container,容器技術,IT周報"
106667,23,2016-06-22,2016年Container採用率翻倍成長，有近8成企業在正式環境中使用容器技術,根據Container儲存供應商ClusterHQ的年度容器採用率調查報告，有76％的企業在正式環境中採用Container，相較於去年的採用率（38％）幾乎翻倍成長，而Kubernetes則是企業最受歡迎也最常使用的容器調度工具。另外，今年企業部署Container時最大的挑戰是持續性儲存問題。," Container儲存供應商ClusterHQ日前發布2016年容器採用率調查報告（Container Adoption Survey），全球共有310位IT專業人士參與這次的調查，容器採用率報告顯示，有近8成（79％）的企業有使用Container技術，而在正式環境中採用容器技術的企業有76％，比起2015年的38％，容器採用率成長了近一倍。
而Docker仍是最多企業使用的容器技術，根據ClusterHQ的調查報告，有94％的企業採用Docker，其次是Linux Container（LXC）占15％。另外，在今年最受歡迎也是企業最常使用的容器調度工具是Kubernetes，Docker Swarm則是企業其次最常使用的容器調度工具。

（資料來源／ClusterHQ）
在基礎建設方面，調查報告顯示，有6成企業在亞馬遜（Amazon）AWS雲端平臺上部署Container，其次則是在自家資料中心部署Container，占了4成，而有2成企業表示採用Google Compute Engine平臺。
ClusterHQ也調查了企業投資Container技術的狀況，根據調查結果，了解企業IT預算的受訪者中有5成表態企業現在有投資Container技術，且每年投資在容器技術的授權費用破百萬美元的企業占4％，而分配預算在Container相關的人事費用破百萬美元的企業有6.5％，不過企業在Container的預算分配上，仍多落在1萬美元的區間。
而今年容器採用率調查報告也揭露了企業部署Contianer時面臨的困難的轉變，在2015年，有61％的受訪者表示安全性是企業採用Container的最大顧慮，其次是管理和網路問題。不過，今年的調查報告指出，持續性儲存是現在企業用戶部署Contianer時所面臨的最大挑戰。而未採用Container的受訪企業則表示，主要是因為不夠了解容器技術，以至於沒有投入資源在容器領域的發展。

（資料來源／ClusterHQ）
此外，ClusterHQ還調查了企業採用Container技術的原因，最多企業表示採用Container是為了增加開發效能，其次則是為了支援微服務架構（Microservices Architecture）。
",https://www.ithome.com.tw/news/106667,"新聞,ClusterHQ,Container,年度企業容器採用率調查報告"
106487,23,2016-06-13,Container雙周報第11期：Rancher也開始支援Mesos,"Rancher也宣布開始支援Mesos，CoreOS發布容器分散式儲存開源專案Torus,新版Ansilbe 2.1版則增加了docker-service新模組"," 重點新聞（5月28日-6月10日）
·Rancher也開始支援Mesos
基於社群、使用者對Rancher提出的要求，Rancher宣布開始支援Mesos，也讓Rancher支援的調度平臺（Orchestration platform）變得更為豐富，目前總共包含Mesos、Kubernetes及Docker Swarm。
Rancher表示，發布此次更新後，使用者可以讓Mesos基礎架構的更新、設定自動化，包含Mesos Master、Mesos Slaves及Marathon等。當使用者部署新版本的Rancher，現有的Mesos叢集同時也會進行更新，同時不會對正在運行的工作造成影響。此外，Mesos框架也能受惠於自動更新功能，例如現有的Hadoop、Kafka、Cronos、Elasticsearch等框架。更多資訊
·Google容器引擎新功能，終於可用不同規格VM組成叢集
Google近日在Google Container Engine（GKE）上正式推出節點池（node pools）功能，現在企業在架設叢集時，單一叢集內可以使用不同規格（如CPU數、記憶體容量不同）的虛擬機器了，不用再像過去，雖然可以自選機器的硬體規格，但是叢集內的伺服器就必須採用統一規格。更多報導
·CoreOS發布容器分散式儲存開源專案Torus，提供容器叢集持久性儲存

容器作業系統CoreOS公司揭露新開源專案Torus，Torus是容器分散式儲存系統，專為Container和叢集調度平臺設計，如Kubernetes，目的在於提供容器叢集基礎建設一個具備擴展性與持久性的儲存系統。Torus使用etcd分散式鍵值資料庫（Distributed Key-Value Database）來儲存和檢索檔案或物件的中繼資料。目前Torus原型版本也已經在GitHub上釋出。更多報導
·Ansible 2.1版登場，重新編寫現有Docker模組
紅帽（Red Hat）釋出Ansilbe 2.1版，除了加強對Windows及Azure平臺的支援外，也提供docker-service新模組，並且重新編寫Ansible現有的Docker模組。例如docker_serivce，可讓開發者可以使用Docker Compose，並且管理、擴增容器化應用程式。
紅帽也表示，docker-service模組可將Docker Compose內嵌至Ansible組態設定檔（Playbooks），設定網路、作業系統和在容器環境外部署基礎架構。更多資訊
·持續整合雲端服務商Semaphore也開始支援Docker
提供CI/CD雲端服務的Semaphore開始支援Docker，Semaphore網頁工程師Nikola Đuza表示，在此版本的更新，使用者可以開始利用Docker減輕CI/CD的工作流程。目前，Semaphore所支援的容器儲存庫總共有AWS ECR、Google GCR、Docker Hub等。更多資訊

·容器安全服務商Twistlock加強Azure平臺容器化應用程式安全
容器安全服務商Twistlock與微軟合作，加強企業部署在Azure平臺上容器化應用程式的安全。
Twistlock技術長John Morello表示，Azure容器服務（Azure Container Service）讓企業可以使用DC/OS、Docker Swarm等開源框架，管理、水平擴展容器化應用程式。更多資訊


 ·雲端POS系統商iChef搭配Docker及AWS容器服務解部署難題 
​雲端POS系統商iChef技術長何明政表示，由於系統不斷加入新功能，開發團隊不只頻繁地修改程式碼，甚至還經常改變資料架構（Data Schema），但這也讓程式部署變得越來越困難。例如，iChef用使用資料分析函式庫Pandas及Python擴充程式庫NumPy來設計報表功能，但這兩個函式庫需同時部署許多相依元件，使用EC2虛擬機器來部署報表功能的後端系統時相當費工，若遇上程式碼或Schema有異動時，維運負擔則更是雪上加霜。
所以，iChef進一步改用EC2容器服務（ECS），將所有需要的映像檔打包成Docker映像檔來簡化部署，「部署時，就不需要擔心程式的相依性問題。」何明政表示。更多報導

更多產品動態
·vSphere釋出Docker Volume驅動程式，可在vSphere環境建立Docker容器可用的長期儲存空間。更多資訊
·Docker和HPE聯手，要推出提供完整商用Docker支援的x86伺服器產品。更多資訊
·NetApp宣布更多快閃產品支援Docker，包括去年併購的SolidFire。更多資訊
·Joyent支援思科容器化微服務平臺Mantl 更多資訊
Container資源
※影片：開始認識Docker
※影片：結合Python、Docker部署及水平擴展應用程式
※知識：介紹Docker信任儲存庫（Docker Trusted Registry）
※詳細教學：怎麼學會Docker？先打造一個微服務吧
※How-To：在Docker資料中心上打造微服務應用程式
※How-To：用Docker運作ELK（Elasticsearch、Logstash、Kibana）
※How-To：在Docker資料中心上打造微服務應用程式
※How-To：在Docker資料中心上實作Docker多主機網路架構

",https://www.ithome.com.tw/news/106487,"新聞,Rancher,Docker,CoreOS,容器,Container,IT周報"
106167,23,2016-05-28,化整為零，IT架構要能動態組合,企業身負維運傳統IT重擔，提供穩定可靠的系統環境，同時要推動新興雲端應用，持續提供服務，使得自動化需求大增，促成軟體定義IT，下一步則是邁入API層級的系統管理新作法," 回顧2015年的新興IT技術當中，OpenStack、Container、DevOps，絕對是名列前茅的熱門議題，各家IT廠商在後續的產品藍圖上，無不把這些技術的應用與整合列為重點項目，而它們之所以炙手可熱，主要是能夠協助推動軟體應用服務的持續整合（Continuous Integration）、持續提供（Continuous Delivery）、持續部署（Continuous Deployment）。
不過，這一波風潮似乎在公有雲服務的環境上最為興盛，一到了私有雲環境上，企業可能就必須設法自行建置，由於這些功能是源自開放原始碼的多種系統與應用軟體套件，因此，對於習於使用套裝產品的企業而言，技術門檻相當高；在此同時，從軟體底層的硬體角度而言，也並未隨著這一波應用風潮而有所調整，例如，效能與資源管理效率可能無法針對上層Container應用的特性，而做到最佳化；或是並未提供API，讓軟體或程式碼能夠更直接地呼叫、執行，因此還是必須仰賴手動的方式來操作。
所幸，從去年起，已經有越來越多IT廠商注意到其中的商機，而開始投入這塊市場，陸續推出了相關的產品，來回應這方面的需求。例如，強化可由軟體來定義（Software Defined）的特性，並且支援Docker container應用，以及Chef、Ansible、Puppet等自動化組態管理平臺，也有公司進一步延伸到DevOps平臺的建立。
面對這股即將興起的IT風潮，我們看到已經有一些伺服器廠商加入支援行列，也意味著相關的整合應用將會變得更普及。
其中，支援動作最為顯著的是Cisco和HPE，兩家公司異口同聲提出了新的產品類型：「組合式基礎架構（Composable Infrastructure）」，藉此與現行的IT基礎架構快速建置套件產品區隔，例如融合式基礎架構（Converged Infrastructure），以及超融合基礎架構（Hyper Converged Infrastructure）。
以目前來看，組合式基礎架構的產品定位上，主要的訴求對象是想要大規模採用DevOps環境的企業，協助他們實現「基礎架構即程式碼（Infrastructure as Code）」的理想。
軟體先行，Red Hat與VMware將產品應用擴及DevOps領域
想要提升IT架構的建置速度與靈活度，我們都知道可運用伺服器虛擬化技術來做到，不過，隨著這幾年Container、OpenStack與自動化管理應用當紅，幾家企業級的系統軟體廠商首當其衝。
有些公司把心力花在自身經營的雲端服務上，像是微軟專注在Azure，IBM則是主推SoftLayer與Bluemix，但也還是持續發展Container，以及IaaS平臺
有些公司則正面回應，推出相關產品來應戰，例如Red Hat和VMware都是很典型的例子。
Red Hat
Container開始受到廣泛應用，主要是與Docker崛起有關，Linux作業系統平臺對於各種Container的支援也非常積極。
以Red Hat為例，可由Red Hat Enterprise Linux 7，以及Atomic Enterprise Platform、OpenShift等產品，來提供Container。若要管理Container架構與工作負載，則搭配Red Hat CloudForms。
值得一提的是，該公司在今年4月新推出的基礎架構套件Red Hat OpenStack Platform 8，以及Red Hat Cloud Suite，也都結合了上述產品的應用，顯然是為了協助企業建置雲服務等級的DevOps平臺而來。
此外，去年10月，該公司也併購自動化組態管理軟體廠商Ansible，今年推出2.0版，可擴及OpenStack的管理，強化支援AWS雲服務、VMware虛擬化與管理軟體、微軟Windows等環境，並改良Docker與網路自動化機制——隔1個月後，Re Hat又宣布Ansible支援Arista、Cisco、Cumulus、OpenSwitch、Juniper等網路設備作業系統。Ansible這些新特色與改進，也都是為了DevOps而來。
VMware
當前DevOps的風潮之大，也影響了企業伺服器虛擬化平臺大廠VMware。去年他們推出了vSphere Integrated Containers環境，用於混合環境（vSphere可同時執行Container與VM），以及Photon Platform，用於雲服務原生應用（Cloud-Native App）。
就基礎架構的管理而言，VMware從2014年起，對於企業需同時管理傳統IT與雲服務原生應用的需求，也開始正視。他們也積極推動進階的產品技術，希望從伺服器虛擬化環境的管理，逐步提升到智慧型維運管理、自動化IT環境、基礎架構即服務，最終達到DevOps就緒的IT環境。
而在這個轉型的過程當中，VMware借助的旗下產品主要是vRealize Suite，並透過不同版本來對應各自的情境。今年2月，該公司透過新推出的vRealize Suite 7，對於既有用戶如何從單純的虛擬化環境跨足到DevOps，就提出了一套很完整的階段規畫。
硬體整合在即，Cisco、HPE、VCE提出對策
談到Container、DevOps、Cloud Native，通常就會提到Infrastructure as Code（IAC），這個稱呼乍看令人摸不著頭緒，但說穿了，其實，就是透過程式碼與預先定義好的組態檔，自動產生（provision）與管理IT基礎架構。
而且，這裡的IT基礎架構，並不只是針對虛擬機器，還包含Container，甚至是裸機（實體伺服器）的管理與部署。
很多人都在關注IAC的進展，就連《重構：改善既有程式的設計》作者Martin Fowler，在今年3月，也特地於自己的網站上，發表了一篇〈InfrastructureAsCode〉探討。
對於多數企業IT人員而言，所謂的IAC，也許用軟體定義式IT架構來稱呼，會比較習慣一點。因為這股技術風潮已經持續好幾年了，從個人電腦、伺服器能夠被虛擬化之後，IAC的應用就已經一點一滴地浮現，只是現在可操控的系統層級更為細緻，而且更多元。
關於DevOps的應用推廣，過去硬體廠商在這個領域的著墨不多。這幾年來，他們除了定期跟著Intel Xeon處理器改朝換代而推出新機型，以及持續提供整合型系統／融合式基礎架構的產品，也發展出提供高密度運算或儲存資源的機型，希望針對高效能運算（HPC）應用，以及雲端服務業者的需求，達到以最小空間獲得最大IT資源的目的。
對於軟體定義風潮的接軌，主要還是跟近期大數據應用爆發，促使基於通用伺服器架構、可橫向擴展規模的軟體定義儲存系統，開始風行。隨後，對於緊密整合伺服器虛擬化平臺與軟體定義儲存的超融合基礎架構，由於可節省無需外接專屬儲存設備的成本，企業接受這類整合型方案的意願也跟著大增。
以目前的發展進度來看，下一個軟體定義IT的關鍵時刻，可能是網路虛擬化的整合，同時，企業也在熟悉動態調度運算資源與儲存資源，而廠商的軟硬體平臺也將增添更多自動處理的機制。當這些因素逐漸成熟之後，應用IAC的障礙可望日漸消解。
不過，要支援主流伺服器虛擬化平臺的好處很明顯，，要投入更高階的軟體定義、OpenStack、Contianer、DevOps環境，由於需求並不明確，可能就讓不少伺服器廠商為之卻步了。所幸，有些廠商已經決定要突圍，打算搶下這個新領域的發言權，從這幾年來看，Cisco最先提組合式基礎架構，接著是HPE，最近VCE也在新的產品當中開始觸及DevOps議題。
Cisco
2015年下半，Cisco開始介紹組合式基礎架構的概念，並以旗下的UCS M系列模組化伺服器，以及UCS C3160機架伺服器，作為應用這類架構的代表產品。
有趣的是，根據新聞稿發布時間來看，Cisco是在2014年9月向市場介紹這兩款產品，當時是用「Cloud-Scale Computing」作為號召。不知為何，隔年，他們改以「Composable Infrastructure」作為新的訴求。
對於這個新架構，Cisco認為，若為了進一步縮減維運成本與提高彈性，IT運算資源與儲存資源，應該從傳統的手動組裝、現行的整合式組裝，進化到動態組裝的境界，而UCS M系列和UCS C3160各自要對應的IT場景，分別是運算密集與儲存密集的環境。
HPE
第二個我們看到主打Composable Infrastructure的廠商是HPE，他們在去年12月宣布推出Synergy的伺服器，不過產品真正上市的時間是今年3月底，與Intel Xeon E5-2600 v4系列處理器平臺推出的時間一致。
Synergy採用與刀鋒伺服器相似的模組化設計，企業可搭配運算模組、儲存模組與網路模組，而且還有Composer與Image Streamer等兩套管理模組，取得監控與映像部署的機制，讓用戶能夠做到更快速的應用系統建置。
在這套系統裡面，HPE強調能提供動態的IT基礎架構共用資源配置，並能支援軟體定義應用，同時也提供統一的API介面
VCE
除了Cisco和HPE之外，在5月舉行的EMC全球用戶大會上，身為整合式系統龍頭的VCE，也發表了跟DevOps應用有關的超融合基礎架構產品——該公司基於去年推出的VxRack System 1000系統，新提供了一套名為Neutrino Nodes的伺服器節點，當中整合了OpenStack，可協助企業快速建置IaaS服務。
接下來，VxRack System with Neutrino Nodes還將推出VMware Photon Platform，以及Apahe Haddoop的版本，支援Container與大數據應用。
目前，VxRack System還可搭配兩種模組：SDDC Nodes和Flex Nodes。以VxRack System with SDDC Nodes來說，其實就是去年VxRack System 1000，是基於VMware EVO SDDC軟體平臺，當中整合vSphere、Virtual SAN、NSX、vRealize Operations、vRealize Log Insight，以及EVO SDDC Manager，用戶還可選搭VMware桌面虛擬化軟體Hoizon。
另一套VxRack System with Flex Nodes則是今年4月推出的，所採用的系統軟體是EMC ScaleIO的軟體定義儲存系統與VMware vSphere。
化整為零，IT架構要能動態組合
從目前市面上所能看到的商用等級軟硬體產品來看，不論是Container、DevOps或組合式基礎架構，在技術發展和普及度方面，都還有很大的發展空間，我們難以預知何時會成熟，對於想要拓展市場的廠商，以及無法確定本身有需求的用戶來說，也許在短期之內都處於觀望的角度。
然而，在IT系統持續不斷整合的狀態下，簡化IT資源提供與加速系統部署之路，是非走不可，因為對於前端使用者來說，除了無法容忍應用服務停擺之外，也不能接受一成不變的功能，當上層的應用系統面臨持續整合、持續提供、持續部署的狀態時，有賴於可動態因應的IT基礎架構，接下來的IT，必須能做到能自動化隨需供給系統執行環境，以及自動化管理，能否做到以軟體來定義，以程式化的方式來動態控制，將是關鍵。

組合式基礎架構演進三部曲
IT基礎架構經過長久的演變，在軟硬體配置上，最早需仰賴手動組裝，後來則進步到由廠商預先驗證、組裝，到了現在，已經發展到動態組裝的階段。（圖片來源／Cisco）

 

分秒必爭！組合式基礎架構贏在速度
企業目前的IT基礎架構可分為4種：在傳統架構下，系統是各自獨立，若要建置起來，需要花上好幾個月；接著出現的融合式基礎架構，系統之間的資源能夠共享，建置所需時間縮短到以天為單位；到了超融合基礎架構，由於整合度高，資源管理變得簡單，若要建置IT基礎架構僅需幾個小時。而近期新推出的組合式基礎架構，對於IT資源的使用更為動態，而且由於搭配自動化與可程式化機制，建置時間能在幾秒內完成。（圖片來源／HPE）

 

組合式基礎架構的4大階層
當企業想要評估組合式基礎架構的導入，對於IT架構需依序考量幾個因素。首先，IT基礎架構需支援由軟體或程式碼的方式來配置，而且要能橫向擴展使用規模；接著，IT資源必須能夠支援動態組合與調度指揮；在第三個層級，IT基礎架構需支援自動化管理；最後，要能達到以應用為中心的完美目標。（圖片來源／Moor Insights & Strategy）

 

組合式基礎架構與現行基礎架構比一比
相較於傳統架構、融合架構、超融合架構，組合式架構的特點，是希望進一步簡化IaaS服務的建置，更徹底完成軟體定義IT的理想，並且支援超大量的工作負載，以及涵蓋實體、虛擬與容器化的工作負載。（圖片來源／HPE）

 

VMware從管理軟體的角度支援DevOps應用
伺服器虛擬化是當前企業IT基礎架構的重要平臺，上面承載了許多應用系統，包含傳統應用系統，以及新興雲端應用，針對整體環境的管理，VMware是透過自身的vRealize Suite這套軟體來協助。（圖片來源／VMware）

 

組合式基礎架構的重要精神
在Container、DevOps的IT架構管理上，最常提及基礎架構即程式碼（Infrastructure as Code）的概念，而這也是實現組合式基礎架構的關鍵。例如，要有彈性的API、IT必須更貼近DevOps的管理，我們也要學著把硬體當軟體來看待，以及資源耗用是變化多端，而非一成不變。（圖片來源／EMC）

【相關報導請參考「組合式基礎架構興起，重新定義伺服器應用」專題】
",https://www.ithome.com.tw/tech/106167,"DevOps,Infrastructure as Code,Composable Infrastructure"
105965,23,2016-05-19,微軟開發平臺掌門人剖析競爭關鍵 傳統企業如何面對新創來勢洶洶,用線上真實資料驅動開發  4個「持續」落實DevOps," 傳統企業面臨新創公司異軍突起，不擁有任何一臺計程車的Uber，市值破600億美元；沒有任何一間客房的Airbnb，以255億美元的市值，成為全球前三大私人公司。獨角獸新創崛起，大者恆大不再是市場鐵則，規模更不是唯一優勢，服務交付速度成了另一個決勝關鍵。
執掌微軟全球開發平臺事業部資深副總裁潘正磊指出，在傳統企業彼此互相學習商業模式下，「最後考驗的是發布速度」，碰上新創公司，交付服務的速度以每小時為單位，「如果傳統企業的交付速度不夠快，怎麼跟新創競爭？」
Visual Studio將3年開發時程縮為一半
她以Visual Studio為例，來解釋微軟如何面對競爭加速的考驗，過去微軟以3年為單位，對Visual Studio進行大翻新，所以產品編號分別為2002、2005到2008。但是在Visual Studio 2012釋出後，微軟開始體會到，3年更新一次的步調，無法跟上IT技術推陳出新的速度，若繼續守著過去的工作方法，在更緊縮的時間資源、限制下，絕對沒辦法推出新版本。而帶領微軟.NET、Visual Studio等開發平臺團隊的潘正磊，深知微軟必須有一套新工作流程，縮短開發過程並且增加產品交付頻率。
這也逼得微軟必須大改開發流程，轉為每3周為單位的衝刺期（sprint），每到2至4個月，就必須釋出1次更新；而12個月至18個月，就必須要發布一次大版本。
相比傳統公司，在網路時代誕生的新創公司，人力編制較為吃緊，一開始開發團隊、維運團隊的分工，就不如傳統企業劃分清楚，不過，這樣限制，卻讓新創公司，先天具備較優良的DevOps體質。
不僅如此，新創公司的背負包袱也不如傳統企業。例如，中國近年的網路新創公司，首要目標是將新服務交付給用戶，即便系統中存在漏洞，只要能在短時間內修復，也不會構成大問題。
反之，傳統企業若出了紕漏，經營長達20年、30年的招牌可能就毀於一旦，潘正磊也坦言，新創公司因為沒有品牌包袱，不需要花太多時間保護商譽。而產品線完備的大企業，漏洞對於產品造成的衝擊很大，「就會不敢踏出去。」
但傳統企業若遲遲不敢加速交付速度，也會眼看既有市占率逐漸下滑。企業面臨這樣的矛盾處境，「要敢跨出第一步」，潘正磊表示，「關鍵做法是，循序漸進地改變」，像微軟的核心功能一開始也不敢加快交付速度，因此得先從周邊的功能開始改革。
從非核心功能開始改變工作流程，除了能降低砸掉自家招牌的風險外，也能讓開發團隊較快速熟悉新工作流程。再者，在核心功能都趨於成熟、穩定之下，市場的競爭點，大多是在角逐新功能推出的速度。因此潘正磊認為，傳統企業也可以拆分核心功能及非核心功能，並且在後者導入模組化開發，讓周邊功能的開發步調快於骨幹功能。
因應如此轉變，微軟產品的結構，勢必得必須大幅度調整，從過去單套式（monolithic）結構，改為各自單獨的元件。潘正磊比喻，傳統企業發布產品的方式，「就像每3年發布一套編號從Ａ至Z的百科全書」，但是要因應市場需求快速轉變的步調，企業要具備能力，可以針對百科全書中的某一本，甚至其中一段進行修改。
她表示，Visual Studio 2015架構經過修改後，其中功能模組例如TypeScript、Apache Cordova及Andriod模擬器，也都可以達到每3周交付一次的速度。
在微軟開發平臺大規模導入DevOps幾年下來，潘正磊總結DevOps導入關鍵在於「4個Continue」的不間斷過程，從Continuous Development為起頭，再來是Continuous Deployment（持續部署），並且透過Continuous Monitoring（持續監控），監控正式環境的運作，並且收集相關資料。最後，則將核心資料回饋給下一次的規畫，達到Continuous Planning。在4個Continue中，她認為持續部署是其中最重要的部分，必須有足夠的自動化測試流程，確保程式碼品質。
一手維運資料才能精準反映用戶行為
除了持續開發、持續部署能加快交付速度，如果要快速規畫開發方向，必須靠持續監控，從營運環境中取得系統及使用者的一手資料，而非透過社群平臺、使用者意見回饋，得知用戶心得。因此，更延伸出了資料驅動開發（Data-Driven Development）的概念，「幾乎所有的新創網路公司都在關注。」
潘正磊指出，資料驅動開發最核心的概念，是集結用戶操作時產生的資料，觀察使用者行為，藉此「真正理解使用者」，而非透過費時、不準確的問卷調查收集資料。她笑說，目前現在遊戲公司是資料驅動開發的佼佼者，能在玩家玩遊戲的同時，後端系統同步分析資料。
更高段的遊戲公司，甚至還能根據使用者資料，即時修正遊戲的難易度。
不僅遊戲公司，她也指出，目前美國的一些金融公司所開發的App，也能做到根據使用者身份，調整用戶體驗。例如，投資人觀察某支股票許久，卻遲遲沒有下單。因此，如果App觀察到有此狀況，就可以發布通知給投資人，給予建議或詢問是否需要協助。或是App介面，也會根據投資人的資產、投資能力有所區隔，讓企業「對用戶精細區分，提供客製化的體驗。」
但資料驅動開發的威力不只如此，它也是促使物聯網發展的推力引擎。潘正磊舉例，如冷氣空調設備，每個用戶的使用量、使用頻率都不一樣，也讓每臺空調設備的壽命都不一樣。如果廠商能知道各別設備的使用情形況，就能提前維修、更換設備。
而潘正磊所提的概念，也已經有廠商著手進行。像是濾水器廠商Brita在過濾器中裝置感測器，當水流量超過一定程度，便會透過AWS Dash補給服務，自動訂購過濾器。因此，廠商、使用者及產品也能建立更為緊密的關係。
過去，商品經販售後，就與生產者脫離關係。在廠商不熟悉使用者習慣下，往往都是產品損毀或故障，廠商才會接到使用者的抱怨。不僅客戶體驗不佳，企業也較難根據用戶回饋，更新產品設計。
因此，在資料驅動開發的新模式下，企業在收集使用者資料後，除了能提早得知是否有維修需要外，也能歸納各種使用情境，根據用戶的需求，推出不同的商品款式，「對我來說，這也才真正實現了物聯網服務的精神。」潘正磊說。
AI是IT業界下個未開發之地
潘正磊說到：「AI是另一種形式的資料驅動開發」，同時，微軟執行長Satya Nadella在今年微軟Build大會中也提到：「軟體機器人（Bots）會是新一代的App」，也暗示出AI是微軟要卡位的新世代技術。潘正磊認為，IT世界從大型主機，發展到當今的行動設備，「AI是下一個未開發領域，它不會被單一設備所局限，而是一個全方位體驗。」
潘正磊以自己的生活經驗為例，每年的滑雪旅行前，她都會使用App，檢視天氣預報及滑雪場的開放狀況，提前進行規畫。
而從AI的角度出發，她認為，如果Bot能蒐集App、通訊軟體的資料，便能主動發覺「我要規畫滑雪旅行」，便可以主動提交相關的旅遊資訊。使用Bot，也可以讓App的能力、性能獲得提升，「甚至也不需要再安裝App」，她表示，Bot可以鎖定使用者意圖（User Intent），並且將使用者意圖包裝為服務，直接提供給用戶。
Bot不僅能讓App性能提升，也能讓App變得更為簡潔。但是，當今的食衣住行都有成千上萬的App，對於電腦操作不熟悉的使用者，每個新的App，都代表著另一個學習門檻。因此，Bot的興起，也能促使交談即平臺（Conversation as a Platform）的發展，透過語音形式的人機互動，直接提供服務給使用者。

企業間的競爭，最後的考驗是比較發布的速度。只有比對手快，才能贏得這場戰爭。——微軟全球開發平臺事業部資深副總裁潘正磊

",https://www.ithome.com.tw/news/105965,"新聞,微軟,潘正磊,DevOps,4個Continue"
105836,23,2016-05-14,獨家專訪VMware執行長Pat Gelsinger（下）：OpenStack是VMware對手還是朋友？,VMware執行長Pat Gelsinger暢談網路虛擬化平臺NSX、開放原始碼IaaS平臺OpenStack，並觸及Dell1併購EMC對其的可能影響,"  Q9  目前NSX有多少用戶？
 Pat  目前全球已有超過1,400家企業採用NSX，其中超過一半都為了微切分功能而導入。有些用NSX來保護內部環境，或用NSX建造自家DMZ，也有企業用來建立一道圍牆以隔離內部最有價值的資產，像是信用卡資料庫。同時，NSX也開始整合其他廠商的產品。
例如和Palo Alto Networks合作，提供了單一政策整合機制（Single Policy Integration），只要設定一次防火牆政策，就會自動套用在NSX微切分機制和Palo Alto Networks的次世代防火牆（NGFW）產品上同時生效。
由於NSX的分散式防火牆只是輕量級的防火牆，遇到特殊情況時，會改將網路封包交給更完善的次世代防火牆做進一步的檢查，這樣的配套也大多能自動進行。目前已有許多企業同時運用這兩類產品。
 
 Q10  網路虛擬化之父Martin Casado的離職，將會對NSX有什麼影響？
 Pat  Martin仍繼續以顧問身分在VMware兼職。NSX去年就能創造出6億美元的生意，VMware網路及資安部門也會交由來自博通的Rajiv Ramaswami帶領，而這比Martin Casado曾經帶領的團隊都還要大上10倍。
 
 Q11  Martin Casado曾承諾NSX會支援所有廠牌的Hypervisor，但為何目前只支援vSphere？
 Pat  不對，NSX目前有兩種版本，一種是與VMware自家產品vSphere高度整合的版本，另一種則能可支援多種Hypervisor。因為技術原因，目前這兩個版本仍有不同，但未來，VMware會把這兩個產品整合到同一個產品線中，屆時就可以同時支援vShpere和非vSphere的環境，甚至可以支援其他的雲端環境。
我認為，NSX會將成為真正的網路虛擬層，可以橫跨所有雲端平臺、網路技術及所有的Hypervisor，即使是微軟的產品。目前NSX已可在Azure上運作。
 
 Q12  相較行動領域的積極，VMware反而在雲端事業上被動，為何？
 Pat  很不幸的，我們無法完成Virtustream合資計畫（編按：VMware於去年12月宣布退出與EMC合資經營公有雲服務商Virtustream的計畫。）所以，我們將vCloud Air業務收回來自己做，我仍舊是大老闆。vCloud Air後續策略，將縮小聚焦於特定應用情境，如有超大VM規模、資料中心整併、資料中心災難備援、混合式網路架構、雙資料中心協同運作等需求，或是大量使用VMware產品的企業，這些是vCloud Air擅長之處。美國和歐洲目前是vCloud主要市場。
另一方面，也會提供同樣的產品給vCloud Air Network計畫的經銷體系，目前已有4千家合作夥伴，持續增加中，他們使用VMware產品來打造自家的雲，有大型企業如Rackspace，也有小型新創、醫療、金融產業等。另外最近也與IBM建立新的合作關係。
 
 Q13  聽起來像是將公有雲事業變成附屬品，要如何跟AWS、Azure競爭？
 Pat  VMware的vCloud Air事業雖然是小生意，不過可以透過4千家合作夥伴來擴大。從全局來看，vCloud Air加上vCloud Air Network，就是一個很大的事業了。另外，像IBM這類合作夥伴，有能力實現完整的VMware軟體架構來向企業展示。同時也會在AWS和Azure上提供更多VMware的服務，像是NSX或用vRealize管理平臺。因此，我相信這是一個正確的策略，幫助企業打造私有雲或管理託管雲，或是在其他雲端環境中提供服務。我認為，未來將是一個多雲世界（Multi-Cloud World）。
最近，我剛跟某一家車廠的CIO談過，他們大量使用VMware產品來運作一套更有效率的私有雲，他們也找來vCloud Air合作的委外供應商，想要打造混合雲架構，但是這位CIO也同時租用了AWS提供網頁應用，並在微軟Azure上使用Office 365打造協同工作環境，這其實是一個非常典型的企業，他來問我，能不能幫助他管理這樣的異質環境。
因此，我不相信有任何一家雲端廠商會單獨勝出。企業會擁有多種雲端環境，因此會具備管理多雲的技術。不管是搭配哪一家的硬體，VMware都能夠提供不受限於硬體廠牌的運算資源。我認為，雲端就是新的硬體，足以承載企業需要的應用系統。不論是私有雲、託管雲、AWS、Azure，VMware都會提供跨雲環境的管理、安全和網路功能，那是我們想要傳遞給客戶的價值。
 
 Q14  曾是VMware重度用戶的福斯要用OpenStack翻新架構，外界認為這是警訊。OpenStack是VMware的對手還是朋友？
 Pat  市場很多人討論OpenStack。但VMware對於OpenStack的策略是，擁抱它的API，並整併到VMware的技術中。已有一些企業利用這樣的方法來建立很不錯的營運規模。例如NIKE就是結合VMware與OpenStack的成功案例。
不過，一般來說，開源的OpenStack並不是非常成功，大部分的OpenStack新創公司都已經歇業，沒有剩下幾間。
 
 Q15  但WalMart、eBay都導入了OpenStack？
 Pat  沒錯，可是有能力達到像他們這樣應用規模的企業很少，而且必須大量投資工程團隊，並不是所有企業都具備技術高強的團隊，可以大規模導入OpenStack。
的確，有些客戶會想嘗試不一樣的路，VMware也不會得到所有的客戶。不過，我也看到很多企業無法成功執行OpenStack，像是有些VMware客戶自行嘗試導入OpenStack後，轉而向VMware尋求整合兩者的的API及技術支援。而VMware可以很快介入，協助這些企業建立VIO（Vmware-integrated OpenStack）架構。
 
 Q16  有企業擔心依賴VMware越多成本越高而改用OpenStack，你會因此考慮降價嗎？
 Pat  針對大量使用的企業級顧客，VMware已有提供vSphere永久使用的授權方式，不需要付更多的費用。因此，這類用戶可以在現有基礎上導入OpenStack及Open API，並且加入NSX和VSAN。我們在NSX和OpenStack市場得到很好的回應，即使他們不是使用vSphere的用戶。例如eBay和PayPal就是NSX用量很大的客戶。有些企業也有很多舊有系統，仍然持續使用vSphere，或是在重要建設上使用VMware，次要系統則使用其他解決方案，再使用NSX來橫跨這些不同的環境。雖然有些企業為了追求更便宜的成本而使用開源解決方案，但是，這些企業反而必須配上50個工程師，再花上2、3年投入，這也是很高的成本。
 
 Q17  Dell併購EMC後會如何影響VMware？
 Pat  整體來說，影響並不大。VMware目前主要股東是EMC，等到交易完成後，主要股東就變成Dell。不論是VMware的董事會、客戶以及生態系，基本上不會有什麼改變。透過這項併購案，Dell承諾會加速VMware的成長。過去EMC主要鎖定企業級的高階用戶，並非鎖定中階市場。熟諳中階市場的Dell可以協助VMware推廣更多的產品、解決方案。
所以，這並不會改變VMware，反而是加速VMware的成長。
 
 Q18  可以透露更多細節嗎？
 Pat  目前有兩大方向，不過在併購案完成前，我不能提前偷跑透露太多。第一項是在VMware現有與Dell的合作項目中，加速VMware營運。例如，Dell 目前是VSAN和vSphere的經銷商，未來可以幫忙賣更多。
另一個方向是將會擬定新的協議，來從事VMware還未跟Dell合作過的計畫。不過，得等到併購案完成後，我們才可以著手擬訂這些新合約。
 
 Q19  你認為，未來每一家公司都會變成軟體公司嗎？
 Pat  我不這麼認為。像台積電會變成一家軟體公司嗎？不會，他們仍是半導體公司。
但是台積電需要學習更多軟體開發技巧嗎？答案是肯定的。
例如未來台積電的客戶，可能會希望使用行動裝置更快確認訂單是否延遲，而不希望透過銷售人員告知。台積電仍然是半導體公司，但是可能得使用不一樣的方式與客戶互動，這是一個例子。
或像是BMW，他們是軟體公司還是汽車公司？當然是汽車公司。但我現在就可以透過手機，立刻檢查我遠在美國家中的BMW，是不是完成了充電，或是油箱中還剩下多少汽油。BMW仍然是間汽車公司，但需要學習更多的軟體技術。
每個產業都一定會面臨數位轉型。企業中不論是哪一種事業群，都要學會如何透過資訊技術接觸客戶，或是延伸自身的價值。也因此會導致，某些企業的消失。
在休士頓時，我與一家能源公司碰面。他們透過自家的智慧電網更有效率地管理能源傳輸的網路，也開始輸出自家智慧電網的技術給其他能源公司，開始真正成為了一家軟體公司，販售自家的技術。不過，他們的事業核心仍然是能源管理。
我相信，所有公司都要開始接觸軟體技術、應用程式技術，用新方式與客戶互動，並且將既有資產現代化。這才是我認為的軟體吃掉全世界的方式。

我相信，所有公司都要開始接觸軟體技術、應用程式技術，用新方式與客戶互動，並且將既有資產現代化。這才是我認為的軟體吃掉全世界的方式。——VMware執行長 Pat Gelsinger

【相關報導請參考「VMware的挑戰」專題】
",https://www.ithome.com.tw/news/105836,"新聞,VMware,VM,Container"
105833,23,2016-05-14,獨家專訪VMware執行長Pat Gelsinger：VM對戰Container如何勝出？（上）,不論是無伺服器架構的全雲端IT，或是以NoOps、Container和微服務設計為主的Next IT架構，都試圖要挑戰或顛覆虛擬化技術主導IT架構多年的地位，這位一手影響兩世代IT架構的VMware掌門人，會如何出招因應？," 這位執掌虛擬化軟體VMware不到5年的執行長，卻有大半輩子的時間花在硬體事業上。Pat Gelsinger從Intel的工程師做起，卻成為了Intel第一位技術長，甚至掌管了Intel處理器和伺服器事業部門長達30年。Pat Gelsinger對軟體領域並不陌生，因為Intel開發者論壇就是他一手所創。Pat Gelsinger率領Intel團隊所打造每一代PC處理器和伺服器，造就了第二代IT架構（PC加上主從式架構的伺服器），而他現在所領導的虛擬化技術龍頭VMware，更奠定了第三代IT架構（雲端、大數據、社群）的基礎。
但是，不論是AWS或是Google所勾勒的未來IT願景，不論是無伺服器架構的全雲端IT，或是以NoOps、Container和微服務設計為主的Next IT架構，都是要挑戰甚至要顛覆現有的IT架構，這位一手影響兩世代IT架構的技術人，如何看待新一代IT架構的變革和虛擬化技術未來得面對的挑戰，日前趁他旋風來臺之際，我們向他提出了這19問。
 Q1  你認為下一代的IT架構是什麼模樣？
 Pat  IT架構正從專屬主從式伺服器世代，開始邁向行動-雲端（Mobile/Cloud）世代。網際網路串連了近乎無窮盡規模的雲端資源，讓應用程式、服務可以普及各式各樣的行動裝置、IoT裝置、機器對機器的溝通型態等，這是我們當前所處的階段，也是IT史上最重大的轉換。
這一波轉換，比從大型主機踏入迷你電腦，迷你電腦到主從式架構，甚至是跨入網際網路的變革都更大。但我認為，至少還需20年才能完成這樣的轉型，儘管仍有一段長路要走，但明顯出現一些早期模式，讓我們略知IT在行動-雲端環境的模樣。
所謂的無伺服器架構，其實伺服器依舊存在，只是感覺上像是沒有伺服器而已。但是，隨著應用程式逐漸變成一群服務的集合，應用程式也變成了一套網路系統。這些服務連結著更多微服務，來存取資料庫上的既有資料，或是即時更新的資料。現在來看下一代IT，就像是30年前看人工智慧，距離成熟的時機還早的很，AI可是直到現在，才變得具體可行。
我認為，未來IT結合了大量資料、令人驚奇的運算能力，來自嵌入式IoT或個人裝置的即時遠端感測技術，以及演算法的躍進，具備機器學習或AI能力的應用系統將會是可預期的未來，這些使用AI的應用程式，未來都將建置在行動＋雲端（Mobile/Cloud）所架構的網際網路上。
 
 Q2  在新一代IT架構中，Container會取代VM嗎？
 Pat  不會。VM的價值在於封裝了應用程式及作業系統環境，讓應用程式可以更有效率地在IT基礎架構上運作。VM不是改變應用程式的開發方式，而是改變應用程式的運作模式。
那Container呢？VMware相信，Container真正的價值是更有效率的開發、管理、部署、更新以及生命周期控制，這是Container在開發上所帶來的非凡價值。但是，我們仍然需要一個運作Container的環境，能夠提供管理、確保安全、建立網路連結，而這正是VM可以帶給Container的價值。
所以，VMware的策略是，在VM之中運作Container，同時開發新的VMware軟體層（VMware Stack），專為Container優化，我稱之為VMware-Integrated Container，讓企業得以在今日的基礎架構上運作Container。同時VMware也有一個Photon計畫來擁抱Container技術，在一個特別為Container優化的環境中，提供網路、安全性、管理性和相容性。
目前擁抱Container有兩種作法。第一是自建模式（Construction Approach），使用各式各樣的開源工具來建置和運行Container環境，例如Mesos、Docker以及Kubernetes。第二種是PaaS模式，運用一個更有效的通用型PaaS架構來提供Container環境，像是Pivotal Cloud Foundry、IBM Bluemix。VMware同時支援這兩種作法，目標是讓VMware變成最適合Container運作的基礎架構。
總體來說，Container技術仍舊是處於非常早期還未成熟，但是，VMware積極擁抱它，將Container視為VMware基礎架構中的一等公民（First Class Citizen），因為Container的確可以對開發應用程式帶來革命性的發展，因此，我對它充滿了熱情。
 
 Q3  儘管Photon可讓Guest OS輕量化，但大家都有慣用的OS，不見得會想用Photon，這樣VMware不就還是無法解決VM過肥大的問題嗎？
 Pat  在Photon架構中，VMware提供了一個輕量級的Linux作業系統也就是Photon OS，已獲得Docker和CoreOS的認可，但Photon架構同時也會支援其他Guest OS。Photon推出後反應還不錯，許多人爭論哪種Guest OS比較好，在技術姓和輕量化上，我認為我們贏了。企業級用戶想要一個可以通用的Container運作模式，因此會希望，有一個如VMware般的世界級供應商來照顧Runtime環境。
 
 Q4  如果Container解決安全問題，變得更加成熟，VMware未來的策略會如何？
 Pat  VMware會讓NSX支援Contaienr和Photon架構，而我相信，也將被下一代網路架構所採用。NSX除了支援vSphere外，也支援KVM，最近也宣布支援Amazon及Azure 。即使Container解決應用程式面的問題，在網路功能上，仍然有許多困難未解決，而VMware則解決了網路問題。
我不認為用戶會想要直接跳下懸崖，至少企業不想。因為內部應用系統相當龐大，甚至可能是長達20、30年投資的成果，大多數新開發的應用，仍舊基於現有應用或是新舊應用的綜合體。
企業在新環境下做更多的狀況下，VMware決定採支援（enbaling）新舊環境的策略。這些應用程式環境，通常可能是20、30年的投資。
所以，VMware的策略就是建立一個支援新舊環境的相容架構，對企業來說，這才是更有效率的作法。即使對VMware抱持懷疑態度的企業，也正面看待VMware這個策略。
 
 Q5  新創和雲端原生公司，會是你最想要的顧客？
 Pat  企業用戶才是VMware的第一順位，要讓他們具備Container導向（Container-Oriented）的開發能力，第二順位則是SaaS公司。
 
 Q6  在併購Airwatch前，VMware的策略只鎖定One Cloud，什麼機會讓VMware走入行動市場？
 Pat  在主從式架構中，PC是主要裝置，所以，VMware提供了VDI及View等產品。在Client/Server的世界中，VMware的主力產品是ESX。但是，到了行動-雲端的世界，主要裝置變成了行動裝置，在這領域的主力產品是Workspace，加上VDI、Airwatch等。針對雲端的主力產品則是SDDC（軟體定義資料中心），完全虛擬化的伺服器、網路以及儲存。為了補齊這樣的策略布局，我需要Airwatch，來管理和確保行動裝置的安全。
 
 Q7  這是為何你在2016年RSA會議說，VMware要變成資安公司的原因？
 Pat  對，即使Airwatch或NSX還不是加密類產品，在安全應用上已經很有價值，這也反映出，VMware需要為行動-雲端時代找出新的安全模式。所以，Airwatch產品線將增加更多安全功能，也會和資安公司合作在他們的平臺和框架中支援Airwatch。
 
 Q8  Airwatch目前主要強化的重點是？
 Pat  你記得美國零售業者Target信用卡資料外洩事件嗎？肇因於駭客先入侵了Target的承包商做為跳板，而能入侵Target系統來竊取資料。
Airwatch剛完成了與NSX微切分（Micro-Segmentation）功能的整合，因此透過Airwatch、Workspace和NSX的微切分功能，可以用來管制承包商只能存取特定系統，而無法接近其他系統。更明確的說，幾乎許多零售業者，都因為這種Airwatch、Workspace加上NSX微切分的這種用法而成為了VMware的客戶。企業都害怕變成下一個Target（也是攻擊對象），除了損害商譽、失去客戶，還必須付出大筆賠償金。
【相關報導請參考「VMware的挑戰」專題】
",https://www.ithome.com.tw/news/105833,"新聞,VMware,VM,Container"
105918,23,2016-05-13,翟本喬分析雲端八大趨勢,企業主現在已經跨越最大的心理障礙，資料的雲端儲存逐漸普遍。而雲端之後的應用以及技術，和沛科技CEO翟本喬剖析八大新趨勢。," 近來企業上雲端成了新趨勢，企業主們已經克服了最難的心理障礙，開始大步朝向雲端化邁進。對上雲端的企業來說，和沛科技CEO翟本喬表示，現在有8大新趨勢要注意，包括資料也要上雲端，混合雲的經營、多雲架構、催生新的雲端原生應用、Container技術出現、及超融合架構等
 
第一項 資料也要上雲端
雲端應用在哪裡運算其實不重要，「重點是企業的資料也得要上雲端。」他說。尤其現在有許多勒索軟體（ransomware）的出現，公司的資料一但被挾持，除非付贖金，不然救不回來。翟本喬表示，上雲端儲存資料可以解決勒索問題，例如透過版本控管，或是可以分散備份，甚至能偵測是否遭攻擊。當資料上雲端後，不只可以分散儲存降低風險，偵測到攻擊還能提早防範，這就凸顯出雲端儲存與傳統式儲存的差異。
第二項 混和雲
單將資料放上公有雲或儲存在私有雲都有風險，因此，企業現在傾向於採用混和雲：部份存在私有雲，部份則存在公有雲。考量資料性質、政策、心理因素等，企業仍舊習慣將特定資料放自家的儲存系統中，所幸現在建立私有雲的成本相對便宜，因此，他建議。若是需要常態使用的資料就可以儲存在私有雲。偶爾一次性使用的資料再儲存於公有雲，來控制雲端成本。
第三項 多雲
「現在傾向多雲策略。」翟本喬引述去年統計資料，千人以上的大企業，平均使用了1.8個公有雲平臺，以及1.6套私有雲，同時還繼續試用1.3個公有雲和1.2套私有雲。甚至大企業同時會使用6朵不同的雲，例如Amazon、Google、IBM、微軟、VMware等，也會同時使用多家解決方案，因為每一家各有長處，所以，企業漸漸開始使用多雲混和的方式，來分散風險以落實雲端運算。
第四項 資訊安全與雲端人才
混合多雲，讓資料的保護更顯重要。翟本喬說：「資安有兩個重點：資料會不會壞、會不會被偷走。」他同時也指出2016年的資安問題從第一名退到第二名，因為技術已經可以達到讓企業安心的程度，並且把服務交給外面供應商。
今年企業最關注的是雲端人才的缺乏，不論是私有雲建置、後續的維運問題、多雲管理，都需要專才處理。人才的高需求也顯見企業雲端化的比率增高。
不過翟本喬也補充，基礎建設的複雜度需要由雲端供應商進行簡化與改良，以利企業採用。
第五項 原生雲端應用
為了上雲端，企業以往都是將舊系統改寫成相容於雲端，現在則是直接把程式寫成雲端模式，直接享用雲端的彈性、容錯、高可用度、自動備份等。
翟本喬舉例，現在餐廳都直接將POS系統建在雲端上，從平板點餐，傳到廚房，最後再將帳單印出來結帳。
這項趨勢削弱了如VMware這種透過整合legacy來賺錢的公司。
第六項 Container架構
既然應用都由原生寫起，所以不用綁定在某個作業系統上，這種情形的vm架構就可以做的非常輕量。所以Docker這種container架構最近就開始興起。
Google在做的時候就沒有用到虛擬化的技術，一開始就是用container架構，所以比別人早、快。當然一開始雲端賣得不好，因為不給windows，不給奇奇怪怪的東西，但是現在也慢慢追上。
第七項 超融合架構
以前是不同伺服器做不同的事，但現在可以把所有東西壓到一個盒子裡，同一個盒子做所有的事。我只需要一個盒子，不斷加上去，不用想要買多少compute，多少儲存。
但有個危險是，除非你的使用情境是很平衡，都能平衡的增加，否則會有些空間浪費。
Storage的部分，你會有些optimization，把成本降到最低，效能拉到最高，雖然彈性大，但是效能差，整體成本反而會比較高。少臺的伺服器可以這樣做，但超過二十臺以上，還是要把儲存跟運算的事情分開做。企業用量大，反而不合適超融合架構。

第八項  IoT
物聯網的概念與雲端運算息息相關，因為雲端讓設備都有彈性，資料統統傳輸到雲裡，隨時可以取用，因此不用特別為IoT設計一套網路系統，用雲端即可達成。
 
翟本喬表示上周的某場黑客松，有一組團隊利用政府公開的登革熱資料，發想做了一個名為「靠北蚊子」的App。因為醫院送的都是事後的資料，並沒有任何可預防的機制。
「靠北蚊子」啟動後只做一件事，上傳時間地點氣候：我被蚊子咬。三週後，比對發病資料，就可以知道在溫度、濕度、時間地點的狀況下，哪裡的發病結果最嚴重，並且開始消滅蚊子。
這樣的雲端應用就是在找出原因，找出對策。翟本喬希望可以將類似的概念延伸到各領域，並且繼續催生更棒的解方。他說：「任何系統、資料庫都不能很快的解決問題，而是問題可以怎麼在系統上很有彈性的解決。」
 
",https://www.ithome.com.tw/news/105918,"新聞,Container,Hybrid Cloud,Cloud"
105909,23,2016-05-13,Container雙周報第9期：容器映像檔徹底詳解列出，Docker漏洞掃描工具正式登場,Docker解釋，在使用者部署映像檔前，會先進行安全掃瞄，並且列出組成Docker應映像檔的各層結構及元件，Docker稱之映像檔的BOM表（bills of materials）。之後系統將持續掃瞄新風險，一旦發現新漏洞，隨即通報使用者," 重點新聞（4月30日-5月13日）
·Docker新增漏洞掃描工具，保護使用者映像檔安全

Docker正式推出安全掃瞄功能，Docker同時在Docker Cloud私有儲存庫及Docker官方儲存庫Docker Hub加入此功能。透過安全掃瞄功能，可以保護Docker映像檔，進行主動風險管理。
Docker解釋，在使用者部署映像檔前，會先進行安全掃瞄，並且列出組成Docker應映像檔的各層結構及元件，Docker稱之映像檔的BOM表（bills of materials）。之後系統也持續掃瞄新風險，一旦發現新漏洞，隨即通報使用者。更多資訊

·Docker資料中心軟體更新，加強UI及高可用性
Docker資料中心（DDC）軟體功能大翻新，除了推出通用控制平臺UCP 1.1、Docker認證儲存庫DTR 2.0版外，同時提供訂閱用戶Docker Engine 1.11的商業支援服務。而DDC除了讓企業內部部署容器即服務（Container as a Service，CaaS）外，也能讓開發團隊、維運團隊一同協作，打造、建置應用程式。
Docker表示，這次UCP的更新中，企業可以直接在GUI中，輸入或上傳docker-compose .yml檔案，隨即產生應用程式，並且將Container部署於叢集。之後，企業也可以在GUI中，直接管理、監控Container。
Docker也重新設計DTR HA叢集架構、UCP中的認證管理中心（Certificate Authorities ）及備份／復原機制，加強高可用性。更多資料
·CoreOS推出etcd v.3.0.0 beta版本
近日CoreOS推出etcd v3.0.0 beta版本，並且包含所有3.0版該具備的主要功能，也確定在正式版的API中，也不會進行大幅度修改。此版本中，除了降低延遲性、提升吞吐量外，也提供自動化的TLS加密組態設定。
在去年1月時CoreOS推出etcd v2.0.0，而CoreOS表示，etcd v3版配備新的儲存引擎，解決v2版的擴充方面的問題，而新版API也支援多版本的並行控制（Concurrency Control）。
CoreOS表示，在經過內部測試後，etcd beta版雖然已經可以用於系統之中，但是仍然需要更多使用者測試，才能發布用於正式環境的版本。目前，此beta版也改善了認證程序，並且提供工具、指南，協助使用者從etcd v2遷移到新版本。更多資訊
·CoreOS壓寶開源監控系統Prometheus
線上音樂平臺SoundCloud在2015年開源釋出監控系統Prometheus。CoreOS表示，利用Prometheus，企業可以不需要花費大量資源，對目標進行監控。
Prometheus最初的目的在於監控微服務系統架構，CoreOS則表示，Prometheus的應用範圍，逐漸延伸至原生雲端基礎架中。同時，CoreOS也壓寶Prometheus，並表示Prometheus是CoreOS下一個要支援的開源專案。
同時，為推廣GIFEE（Google Infrastructure for Everyone Else），CoreOS也宣布，未來要加強整合Prometheus與Kubernetes、Tectonic。更多資訊
·EMC推出開源儲存框架Polly，支援多家Container技術
在EMC World大會上，EMC推出開源儲存框架Polly，並且同時支援Docker、Kubernetes及Mesos等容器技術。Polly是一個集中式儲存調度服務，可以與Container排程器進行介接，並且提供排程器所需要的資源。在未來，Polly也會進一步發展，支援新興容器生態系及儲存平臺。
EMC表示，過去Container排程器都專注於運算、網路、內部儲存的資源部署。當Container中的應用程式開始需要後端永久儲存功能時，將儲存作為可調度資源的需求也隨之而生。因此，EMC認為，企業可以使用Polly作為開放儲存框架，整合多家的容器解決方案。
目前Polly支援的儲存平臺，除了EMC自家的ScaleIO、XtremIO、Isilon及VMAX外，在雲端環境則支援AWS EC2、Google GCE、OpenStack及RackSpace。更多資訊
·用Slack也可以監控Container運作狀況
Container監控解決方案提供商Sysdig為容器化基礎設施，提供監控、警示及問題排除的解決方案，目前總共支援的平臺包括Kubernetes、AWS、Google及Azure。日前，Sysdig也整合了Slack，讓使用者可以使用Slack，監控Container的運作狀況。
Sysdig表示，使用者只需要認證Slack網域及頻道，就可以從電子郵件、Slack訊息等管道獲得訊息。此外，Sysdig也提供連結，讓使用者可以直接連回至Sysdig Cloud，查看完整的運行資訊。更多資訊
產品動態
·CoreOS推出etcd v.3.0.0 beta版本更多資訊
·開源監控系統Prometheus更多資訊
·開源儲存框架Polly更多資訊
·開源儲存調度引擎REX-Ray更多資訊
·Docker新增安全掃瞄功能更多資訊
·Sysdig整合Slack至容器監控功能更多資訊
Container資源
※知識：Docker Mac版本介紹
※知識：回顧Docker去年加強的資安功能
※How-To：在Windows Server 2016科技預覽版中使用Docker
※How-To：在Docker中建立節點應用程式
※How-To：在Windows Server 2016中設定Docker
※How-To：將APS.NET核心Docker化
",https://www.ithome.com.tw/news/105909,"新聞,Docker,EMC,Container,容器技術,IT周報"
105789,23,2016-05-09,微軟.NET團隊領導人潘正磊：傳統企業也要和新創競爭，關鍵就是4個Continue,微軟全球資深副總裁潘正磊表示：「由資料驅動的開發模式的速度才夠快」她說：「如果傳統企業的交付速度不夠快，你要怎麼跟新創競爭？」現在的競爭對手已經不是傳統的對手，而是來自網際網路的公司了。," 微軟今天首度在臺大規模介紹年初併購的App開發工具Xamarin，微軟全球資深副總裁潘正磊也再度來臺說明微軟開發平臺開源進展和微軟近年擁抱DevOps加速產品更新的成果。
潘正磊表示，傳統IT專供內部人員使用，使用人數規模變動不大，但現在透過雲端服務顧客，可能明天就會突然暴增上萬人。如何快速交付產品非常重要。

潘正磊表示，尤其有「4個Continue」是關鍵，包括了Continue Development和Continue Deploy（持續部署），另外也還需要Continue Monitoring了解應用系統執行資訊，尤其是蒐集用戶使用資訊，最後要能回饋到Continue Planing來改進下一個版本。
其中，潘正磊認為，又以「持續部署最重要，但這得倚賴許多高度自動化的IT，擁抱DevOps讓開發和維運一體化才能實現，並且能夠實現「Data Driven Development」，「由資料驅動的開發模式的速度才夠快」她說：「如果傳統企業的交付速度不夠快，你要怎麼跟新創競爭？」現在的競爭對手已經不是傳統的對手，而是來自網際網路的公司了。
",https://www.ithome.com.tw/news/105789,"新聞,微軟,潘正磊,Xamarin,DevOps,持續部署"
105675,23,2016-05-02,不合作就等死！OpenStack的LAMP黃金組合是什麼？,即便OpenStack是雲端運算世界的當紅炸子雞，但光靠OpenStack也不足以應付未來企業需要的高擴充度的IT架構。OpenStack勢必要擁抱其他技術，找到早期網際網路的成功方程式－－LAMP一樣的黃金陣容。," 網際網路之所以能興起，大半功勞是Linux等開源軟體適時的助力。更精確的說，是Linux、Apache、MySQL及PHP的組合，適時構成了涵蓋作業系統、網站伺服器、資料庫與程式語言的LAMP架構，而這個堅強的黃金陣容讓為數眾多的網際網路公司快速打造網站基礎建設，因而造就了網際網路的輝煌。
而今網際網路已邁進雲端時代，雲端運算架構的LAMP黃金組合到底是什麼？在OpenStack Summit Austin大會第二天主題演講，OpenStack基金會營運長Mark Collier一開始就拋出這個問題。
Mark Collier表示，IT基礎建設的需求量正在快速增加，根據思科的研究，預計2020年全世界將有超過500億個連結網路的裝置。然而，不論未來快速興起的連網裝置是汽車或健康醫療裝置等等，這一切的背後仍需要運算、資料儲存、移動；所不同的是，隨著連網裝置快速增加至百億以上的規模，對於基礎建設的需求量除了快速增多，也會截然不同。他認為以OpenStack打造IT基礎建設，可以符合物聯網與雲端高速成長所需要的高度擴充（Scale）能力。

2020年全球將有超過500億個連網裝置，據此推估全球的資料中心需要部署超過4億臺伺服器，才有辦法支撐5百億個以上的連網裝置，Mark Collier表示，接下來最大的挑戰是思考怎麼管理如此巨量的伺服器，顯而易見，傳統的管理方法無法應付上億臺伺服器的規模。他指出，進一步與使用者討論未來管理大規模伺服器的架構，發現使用者所需要的不外乎是透過可程式化的軟體，以全盤控制實體機器、虛擬機器與軟體容器。
Mark Collier表示，OpenStack將扮演整合引擎（Integration Engine）的角色，整合相關技術以提供具有高度擴充性的IT基礎建設平臺。顯而易見，未來IT基礎建設需具備大規模擴充的能力，因而OpenStack雲端軟體將有很大的發展機會。
Mark Collier接著訴求OpenStack社群要擁抱其他的開源社群，他說，面對未來只靠OpenStack社群單打獨鬥是不夠的，單靠任一個軟體或開源專案的成功，是無法達成未來IT架構所需要的那種高度擴充性。他指出網際網路早期的成長基石－－開源LAMP架構，就是由Linux、Apache、MySQL及PHP等多項開源軟體所組成的黃金陣容，它們合在一起所形成的影響力，遠超過任何單一軟體。

諸多使用OpenStack的大型企業，如Walmart、AT&T、Volkswagen及中國最大電信公司中國移動等，Mark Collier表示，這些大公司的客戶數量會不斷增長，像是中國移動的用戶已超過8億人，已經不可能只靠OpenStack來支撐未來的成長。
這些企業早已了解「不合作就只能等死」，Mark Collier以此呼籲OpenStack社群也能看齊。既然這些企業為了生存都能跳出舒適圈、比他們的客戶想得更遠大、積極參與開源軟體社群、勇於整合新技術，創造出比過往內部自行開發還要龐大的技術架構，Mark Collier說，我們也必須確定自己不是矇起眼來說OpenStack是唯一重要的技術，事實上未來絕對是OpenStack加上許多其他的技術，這也是OpenStack與其他社群合作的機會。OpenStack應該要效法LAMP架構的成功模式，傾聽使用者的需求，找出成功的模式。OpenStack加上其他的技術，將能造就未來新興IT架構。
Mark Collier接著分別邀請時代華納有線電視（Time Warner Cable）應用服務工程總監Tim Pletcher、即時通訊服務LivePerson雲端工程總監Koby Holzer上臺，討論他們如何以OpenStack搭配其他技術一起使用。Tim Pletcher表示，時代華納有線電視正以4個人的小團隊導入Apache Mesos，藉由Mesos管理實體機器的運算資源，再提供給OpenStack雲端服務使用，這項專案預計在5月會完成。
LivePerson則是在1年半前開始導入軟體容器（Container）技術。LivePerson的IT架構規模為2萬個實體處理器核心，為了要擁有更快的技術反應速度，他們將應用程式改寫成115個微服務（Microservices），並且採用Kubernetes來管理容器架構，以利於他們導入持續整合（Continuous Integration）、持續交付（Continuous Delivery）與其他新興技術。未來，LivePerson的目標是讓Kubernetes架構可以自主擴張，並且利用公眾雲達到混合雲架構。

從OpenStack使用調查發現，使用者已經將OpenStack跟其他新興技術一起搭配使用，其中Kubernetes的使用率最高，不過，這些技術卻也沒有一個使用率是超過5成，顯示新興技術的多樣性。

 
",https://www.ithome.com.tw/news/105675,"新聞,OpenStack,OpenStack Summit Austin,Container,Mesos"
105634,23,2016-04-28,CoreOS推出Stackanetes專案，容器化OpenStack套件簡化部署與升級,容器作業系統CoreOS公司在OpenStack Summit Austin高峰會上發表Stackanetes專案，提供使用者利用容器資源調度服務Kubernetes來管理OpenStack平臺，用戶可將OpenStack套件包裝為容器化應用程式，以簡化OpenStack的部署與升級。," 日前，容器作業系統CoreOS公司在OpenStack Summit Austin高峰會上揭露Stackanetes專案，整合容器（Container）和雲端服務，提供使用者透過容器資源調度服務Kubernetes來管理OpenStack平臺，使用者可以將OpenStack作為容器化（Containerized）應用程式來部署至企業的基礎設施。
另外，Stackanetes可以在Kubernetes服務或容器管理平臺Tectonic上執行。CoreOS執行長Alex Polvi表示，Stackanetes是CoreOS將GIFEE（Google Infrastructure for Everyone Else）推向OpenStack社群的一大步。
Kubernetes原是Google推出的Docker容器管理專案，可以跨叢集管理容器化應用程式，而Stackanetes部署標準OpenStack服務至容器，作為容器化應用程式，並使用Kubernetes的應用程式生命週期管理功能來部署容器化OpenStack套件，以簡化OpenStack在部署和升級過程中的生命週期管理，並提供企業執行OpenStack基礎建設即服務（IaaS）和容器工作量。
此外，Stackanetes還能夠用來交付動態管理、自我修復的部署，以及無痛升級，其中，Stackanetes的自我修復功能是用來確保OpenStack中每個服務維持運作，而Stackanetes也能提升OpenStack IaaS的擴充能力，以加強用戶資料中心環境的應變能力，另外，在Tectonic平臺中使用Stackanetes的用戶還可以透過單一平臺來管理IaaS和容器工作量。
Alex Polvi在示範影片中，用Stackanetes來升級OpenStack的套件，且能夠移轉工作量至新版套件，Alex Polvi示範從舊版硬體資源儀表板套件Horizon節點的工作量移轉至新版本的節點，過程中，Alex Polvi只透過滑鼠點擊就完成了OpenStack套件的設定與升級。而Stackanetes除了可以容器化Horizon套件外，還有如網路管理套件Neutron、運算套件Nova-Compute等也可以包裝成容器化應用程式。
利用Stackanetes在Tectonic平臺執行OpenStack示範影片：
 


 
",https://www.ithome.com.tw/news/105634,"新聞,CoreOS,Stackanetes,Kubernetes,Tectonic,OpenStack,Container,OpenStack Summit Austin"
105597,24,2016-04-27,Jenkins十年首度再改版，老牌CI引擎終於能支援持續交付了,Jenkins 2.0版本，並且強調Pipeline-as-code的概念，讓開發者可以使用程式碼定義工作流程（pipeline）," 問世超過10年的開源持續整合（Continuous Integration，CI）軟體Jenkins，目前已經正式推出Jenkins 2.0版本，並且強調Pipeline-as-code的概念，讓開發者可以使用程式碼定義工作流程（pipeline）。
Jenkins認為，當今使用者所面臨的挑戰在於提交（commit）程式碼以及線上環境的自動化程度規模，已經有了大幅度成長。因此，Jenkins也在2.0版本加入工作流程功能，讓開發者可以定義應用程式的生命周期，並且讓Jenkins支援持續交付（Continuous delivery，CD）工作。
近兩年中，Jenkins試圖讓開發者，能使用文本形式（textual form）的方式描述自動化工作的流程，執行版本控制。同時，Jenkins採用特定領域語言Groovy，即使工作流程變得複雜時，也能較為使用較簡單的的方式進行管理。
發展超過10年的Jenkins，目前已經有1,000個套件，因此讓開發者使用Jenkins時，通常必須額外尋找合用的套件，「但也導致Jenkins的預設安裝過於輕薄、陽春」，進而讓開發者有不好的經驗。
也因此，在2.0版中，Jenkins重新調整策略，目標「解決8成使用者，所面臨的8成問題」，讓工作專注於開發程式、品質測試，而不是「留給使用者自行尋找、使用套件。」
同時，2.0版本也修改了UI介面，例如網路UI介面、工作組態設定頁面等。
",https://www.ithome.com.tw/news/105597,"新聞,Jenkins,DevOps,持續整合,持續交付"
105519,24,2016-04-26,OpenStack執行長呼籲企業勇於擁抱未來IT技術的多樣性,在OpenStack高峰會首日主題演講登場的講者，不論是OpenStack基金會執行長、Gartner分析師，AT&T、Volkswagen福斯集團等全球知名企業，以至紅帽（Red Hat）、SAP、Mirantis等資訊科技廠商，不約而同討論現今企業必須緊追雲端、行動、App、大數據等新興技術帶來的新機會，同時又得維護傳統系統的處境。," OpenStack Summit於今日（4/25）在美國德州奧斯汀（Austin）登場，睽違6年OpenStack高峰會終於重回家鄉奧斯汀，OpenStack基金會執行長Jonathan Bryce指出，第一場在奧斯汀舉辦的OpenStack會議只有75人參加，而今超過7,500人與會，開源雲端軟體OpenStack這幾年成長之快不言可喻。
Jonathan Bryce指出，過半的財經500大企業都採用OpenStack，而且將OpenStack實際用於生產營運的企業也持續增加，據OpenStack基金會最近的調查，65%的OpenStack用戶已在實際的業務系統採用OpenStack，比起去年增加33 %。
在OpenStack高峰會首日主題演講登場的講者，不論是OpenStack基金會執行長、Gartner分析師，AT&T、Volkswagen福斯集團等全球知名企業，以至紅帽（Red Hat）、SAP、Mirantis等資訊科技廠商，不約而同討論現今企業必須緊追雲端、行動、App、大數據等新興技術帶來的新機會，同時又得維護傳統系統的處境。
Jonathan Bryce在演講中指出，2010年推出第一版OpenStack雲端軟體時，他們就意識到這是一項破壞性技術（Disruption），然而，破壞性創新代表著機會，破壞性創新的程度有多大，往往代表未來潛在的機會有多大。
他接著表示，任何一個新技術，最終是必須與既有的技術結合，雲端運算技術也必須與企業既有的傳統IT系統連結，所以企業正處於需要同時掌握新舊技術的階段，他呼籲企業要勇於擁抱資訊科技的多樣性。
對於如何擁抱IT的多樣性，他提出3點建議。首先是標準化的平臺，他認為雲端架構可分成基礎建設、應用程式與雲端原生框架等3層，基礎建設層級就是虛擬機器或軟體容器（Container）等，而雲端原生框架則如同Mesos、CloudFoundry等。他說，對於未來的IT架構，OpenStack不會唯一的答案，但OpenStack能夠充分融入這3層架構。

第二點是，即便是新型態的雲端、行動應用軟體，往往也需要與企業的傳統應用系統整合，例如許多App必須取得交易資料，而交易資料通常是傳統應用程式在處理。所以必須要一個能兼顧新舊應用程式的軟體平臺，Jonathan Bryce指出，OpenStack就具有這樣的特性，企業也可以在OpenStack的環境下同時執行軟體容器、虛擬機器或是傳統應用程式。
最後，他指出破壞性創新要能成功，不是只靠科技，企業的組織文化往往才是成功關鍵。Jonathan Bryce表示，技術確實是驅動創新的重要關鍵，但若缺乏組織文化上的認同，破壞性創新是不可能發生的。他甚至以一個真實案例為例，某一家企業在尚未導入雲端技術前，其系統的部署上線需要44天，該企業期待只要投資導入雲端技術，就能大幅改善系統上線的速度，然而在花了大筆錢導入雲端技術後，該公司的系統上線時間只是縮短為42天，原因就出在企業組織文化並未符合雲端技術的敏捷彈性。最後，該公司對症下藥後，在整個流程線都符合自動測試與派送之後，系統上線時間只要2小時。
Mirantis共同創辦人暨行銷長Boris Renski在接下來的演講也指出，OpenStack導入成功的要素中，技術只占1成，9成都是人員與流程的議題。
即將在明日主題演講登場的CoreOS共同創辦人暨執行長Alex Polvi，在媒體記者會上也指出，許多人以為軟體容器（Container）是要取代虛擬機器（Virtual Machine），這其實是很大的誤解，事實上未來的企業同時都會有這些技術，而OpenStack所扮演的角色，就是動態調配這些技術。
",https://www.ithome.com.tw/news/105519,"新聞,OpenStack,OpenStack Summit,Cloud,Container,Mesos,CloudFoundry"
105474,24,2016-04-25,OpenStack年度高峰會明日登場，臺灣將首度登上OpenStack全球舞臺,開源雲端平臺OpenStack的年度重頭大戲－－OpenStack Summit（OpenStack高峰會），即將在明日（4/25）於美國德州奧斯汀（Austin）登場，今年很特別的是臺灣第一次登上OpenStack高峰會的大會舞臺。," 開源雲端平臺OpenStack的年度重頭大戲－－OpenStack Summit（OpenStack高峰會），即將在明日（4/25）於美國德州奧斯汀（Austin）登場，今年很特別的是臺灣第一次登上OpenStack高峰會的大會舞臺。
OpenStack是近年呼聲最高的開源雲端平臺，也是成長速度最快的開源軟體社群。截至目前為止已有涵蓋178個國家、39,192名開發者投入開發OpenStack，程式碼數量已經超過2千萬行，而支援OpenStack的廠商也有586家之多。
今年OpenStack Summit Austin高峰會的主題是打造未來的雲端運算（Building The Future of Cloud Computing），OpenStack基金會執行長Jonathan Bryce將會在大會首日以「擁抱資料中心的多樣性」為題揭開序幕，緊接著Gartner副總裁Danna Scott會討論雙模IT（Bimodal IT）, 提出現今企業邁向數位的過程必須同時掌握傳統IT架構與雲端，同時，AT&T、福斯汽車也會以OpenStack用戶的角度分享邁向雲端的經驗。

從最近OpenStack釋出第13版OpenStack Mikata所強調的大幅簡化安裝程序與API標準化，以及明日OpenStack高峰會的主題演講內容來看，OpenStack的發展很明顯地朝向企業應用邁進。OpenStack基金會近期針對1千多位用戶的調查，也顯示將OpenStack用於線上應用環境的企業增多了。
OpenStack Austin高峰會第二天的主題演講，將聚焦在物聯網與軟體容器（Container）。物聯網（IoT）應用是促使雲端運算發展的一個重要驅動力，而Container則是雲端應用最熱門的新興技術之一。
此外，第二天的主題演講更特別的是，臺灣將會首度登上OpenStack高峰會的主題演講舞臺。由於OpenStack基金會在3月底於臺灣舉行全球第一場OpenStack應用黑客松（Hackthon），得將的冠軍隊伍－－由工研院服務業科技應用中心健康服務組工程師曹思漢領軍的「LIKA小隊」，除了受邀參加OpenStack Austin高峰會，也將在OpenStack高峰會的大會舞臺上向全球展現黑客松的開發成果－－「Phantom of the LIKA」，一套建立在OpenStack雲端平臺上，能夠透過偵測手腕肌肉來分辨小提琴指法的系統。面對首次臺灣能夠在全球矚目的雲端運算大會上向全世界發聲，LIKA小隊的成員其實很擔心現場示範會出錯，還特別從臺灣帶了兩把小提琴，以備不時之需。
今年3月底在臺灣首度舉辦的OpenStack全球應用黑客松，不僅促成了OpenStack基金會執行長Jonathan Bryce首度來臺灣站臺，就連行政院院長張善政也到場致辭頒獎。張善政在致辭指出，OpenStack是當代開源的趨勢，臺灣必須兼備上游OpenStack人才培養，以及下游的企業界應用。他觀察到OpenStack還不像作業系統被納入主流大學教育，但OpenStack必須是主流課程，因而呼籲大學教授要開始把OpenStack當做一門正式課程教授，並且追蹤OpenStack等開源技術的趨勢。他說：「如果OpenStack沒有學好，臺灣的發展會受到限制。」，因而他也指示工業局要號召業界，教育部要資助教授及學生，一同參與OpenStack高峰會，讓國際看到臺灣未來在雲端軟體上不缺席。
由於OpenStack應用黑客松在臺灣首度舉辦獲得不錯的成績，幾個其他國家的OpenStack用戶社群也開始效法。
此外，今年OpenStack Summit Austin還有一個特別的OpenStack認證考試，也就是去年下半年在OpenStack Tokyo高峰會發表的OpenStack第一個認證「Certified OpenStack Administrator（COA）」。
OpenStack自2010年1月發表第一個版本Austin，就採取每6個月發表一個版本的策略，至今已經正式推出第13版OpenStack Mikata。同時，OpenStack基金會也依照每6個月發行新版的節奏，每年辦兩次OpenStack高峰會，通常上半年高峰會的地點以美洲為主，下半年的高峰會則是全球各個城市。
由於OpenStack基金會非常在意OpenStack是以開放原始碼模式發展的雲端平臺，因此諸多作法皆採取社群模式，例如OpenStack每個版本的名稱即由社群投票決定。其決定方式是以英文字母的順序，再依據下一次OpenStack高峰會的舉辦地點，由社群成員提出該地符合該版本英文順序的地名，再經由社群投票表決。例如，2015年OpenStack高峰會決定在日本舉辦，而第13版OpenStack的英文字母順序是M，因此就以日本地名以M為開頭的來決定新版本名稱，最後是由日本東京都的三鷹市（Mikata）出線。接下來明年的兩個新版本則為Newton（一棟位於奧斯汀被列為國家古蹟的義大利、希臘風格古宅）與Orcata（名列英國衛報全球50知名海灘之一的西班牙巴塞隆納Orcata海灘，因為今年下半年的OpenStack高峰會在西班牙巴塞隆納舉辦）。
",https://www.ithome.com.tw/news/105474,"新聞,OpenStack,OpenStack Summit Austin,Cloud,雲端"
105437,24,2016-04-22,Mesosphere釋出開源資料中心作業系統DC/OS，誓言讓資料中心管理像使用個人電腦,DC/OS除了以Mesosphere為首外，同時還集結了超過60個企業夥伴。除了微軟、思科、HPE等科技大廠外，Puppet、Chef及Datadog等DevOps廠商也沒有缺席," 資料中心作業系統廠商Mesosphere希望可以讓企業在資料中心運作分散式系統時，能夠像運作一臺個人電腦一樣簡單。在近日，Mesosphere也將DC/OS（Data Center Operating System，資料中心作業系統）以開源形式釋出。Mesosphere表示，想要變成軟體定義的企業，可以使用DC/OS作為基礎。DC/OS除了以Mesosphere為首外，同時還集結了超過60個企業夥伴。除了微軟、思科、HPE等科技大廠外，Puppet、Chef及Datadog等DevOps廠商也沒有缺席。
Mesosphere表示，DC/OS是百分之百的開源平臺，讓Spark、Kafka、Cassandra等分散式系統，可以像安裝app般迅速。同時，DC/OS也提供圖像化的監控、管理程序，簡化管理資訊中心管理程序，「讓數千臺機器轉換成一臺電腦」。此外，DC/OS也可以部署於多種環境，例如裸機、VM或是雲端中。
DC/OS以Apache Mesos分散式系統核心為基礎，並且結合容器調度引擎Marathon、Mesos-DNS、調度服務ZooKeeper、Mesos-DNS以及Mesosphere自行開發的開源Nginx組態設定Admin Router，而這些開源元件在DC/OS中則扮演主要節點（master node）的角色。
分散式系統核心Mesos扮演DC/OS的核心，提供系統資源隔離。同時，也將基礎設施化為資源池，根據使用者需求或是政策設定，分配系統資源以及工作排程。而DC/OS則選用Marathon作為容器調度（container-orchestration）引擎，在控制群組cgroups、Docker Container中的微服務，進行控制以及叢集間的啟動程序（init）。
同時，DC/OS也透過Marathon，管理長時間應用程式（long-running application），並在應用程式失效時進行修補；Mesos-DNS具備服務探查（ service-discovery）功能，透過DNS，使運作在Mesos上的服務、應用程式可以發現對方的存在；DC/OS也使用Zookeeper，執行系統間的調度服務。最後，由Mesosphere自行開發的Admin Router，使用者可以在叢集間提供中央認證（ central authentication）。
而應用程式、服務則部署在私有代理人節點（agent node），如果企業有需要，也可以架設公開代理人節點，透過公網，存取DC/OS上的應用程式。而代理人節點由Mesos代理人程序、Mesos Containerizer以及Docker Container所組成。主要節點可透過mesos-slave程序調度所需要的資源；Mesos Containerizer提供輕量級的容器化，以及executor的資源隔離，Docker Container則支援內含Docker映像檔的任務。
 
 
",https://www.ithome.com.tw/news/105437,"新聞,Mesosphere,DCOS,開源,Marathon,Mesos,容器技術,Docker,Container"
105366,24,2016-04-21,Google儲存SRE團隊負責人第一手經驗大公開,在Google負責服務維運工作的工程師稱為SRE（Site Reliability Engineer，網站可靠性工程師），而其中的儲存SRE團隊，負責維運的是Google雲端平臺中與儲存相關的服務," 突然發現Gmail用戶能看到他人信件內容，若你是Gmail維運人員，會怎麼做？通知團隊負責人？立刻打電話詢問公司副總裁？訂披薩準備找問題？還是立刻關掉這個全球10億人使用的郵件服務？Google儲存服務SRE部門總監Melissa Binde說：「正確答案是立刻關掉Gmail。」
在Google負責服務維運工作的這類工程師通通稱為SRE（Site Reliability Engineer，網站可靠性工程師），Melissa Binde表示，不論擔任SRE這類職務的人是實習生，或是剛拿到第一份薪水的新進，只要為了保護Google，SRE維運人員「可以做任何決定的權力，甚至必須關閉整個Google.com網站，公司高層都會支持。」她說，這句話反映出Google對SRE一職的重視和倚賴。
Melissa Binde率領的儲存SRE團隊，負責維運Google雲端平臺中與儲存相關的服務，例如GCS、Bigtable服務、SQL服務等，也包括了Google內部使用的Bigtable、分散式高擴充檔案系統Colossus等多項Google全球性分散式儲存系統。換句話說，SRE團隊正是維持Google每天正常提供各項服務的幕後功臣。
SRE團隊需支援Google全球的雲端業務
但究竟Google所創立的SRE是個什麼樣的職務？Melissa Binde解釋，其實SRE就像是近來火熱的DevOps，但兩者仍然略有不同。
DevOps工程師是為了解決開發團隊和維運團隊的矛盾而出現的新角色，不過，目前各界對DevOps內涵仍眾說紛紜，出現了各式各樣的詮釋或定義，而Melissa Binde表示：「對Google來說，SRE就是由軟體工程師來負責維運工作的設計和執行。」
由熟悉軟體的軟體工程師來負責系統維運，更能掌握軟體、系統間的交互運作關係，更重要的是，Google的SRE團隊，不是照本宣科地執行維運，更要同時負責「設計和優化維運工作。」
Google賦予SRE團隊三大工作目標，包括了確保正式環境的可靠性、水平擴展性及效能表現。為了實現這些目標，SRE得想辦法讓負責系統的運作更自動化與視覺化，也得打造儀表板以時時監控這些系統的效能表現。例如SRE可以更換Google服務底層的資料庫，來改善服務的延遲，或開發許多自動化程式加速系統部署，或是設計軟體機器人（Software robot），來進行跨系統資料傳遞、自動關閉特定機器，甚至是關閉整座資料中心。Google的SRE團隊不會集中在一處，Google全球各地據點都有分配SRE團隊，來支援雲端業務。
找出合適人才，是Google建立SRE團隊的第一步
如何打造出這樣的SRE團隊？Melissa Binde透露，有4件事很重要。
第一是人員組成。她說，所有SRE成員，人人都得通過軟體面試才能加入，尤其必須通過非抽象大型系統（Non-abstract large system）設計的測驗，甚至「SRE要比開發人員還更了解開發。」
擅長開發的SRE參與維運機制的設計後，更能改善維運工作，舉例來說，許多軟體在開發階段常有些過於理想的假設，像是系統呼叫必定不會失敗，但是一旦在正式環境中大規模部署時則幾乎是一定會發生系統呼叫失敗的情況，後者就是SRE要負責解決的問題。
分配固定開發團隊配額給SRE團隊
第二是組織層級。為了讓開發團隊也能對SRE有貢獻，當開發團隊打造出來的服務大受歡迎，導致維運工作超量時， Google的開發團隊可以將自己的人力配額（Headcount）貢獻給SRE團隊，讓SRE團隊可以招募更多人力，來確保服務維運的品質，才能讓開發團隊繼續推出更多新功能。不過，SRE也有權拒絕這樣的配額轉移。
不過，SRE團隊的直屬主管必須和開發團隊分開，SRE團隊的直屬副總和開發團隊直屬副總是兩個人，如此一來，「當線上環境還未備妥前，SRE團隊也能有權拒絕開發團隊的要求。」Melissa Binde表示，因為「SRE不是群隨傳隨到的猴子。」
減少維運人員雜事干擾，專注於手上專案任務
第三是好的工作環境。為了避免SRE受到雜事干擾，Melissa Binde表示，必須讓SRE過半數時間能專注於負責的專案工作，減少SRE受到會議、工單、待命任務等工作的干擾。如果SRE團隊手中有太多的專案要處理，除了可以請求開發團隊提供更多配額外，也可以將手上專案轉給開發團隊接手。
另外，Google也採取12小時的待命（On-Call）輪班制度，而非更長的18小時或24小時待命制度。
另一方面，儘管SRE團隊成員的加入頗有難度，也需經過主管同意，但所有SRE成員都是自願加入而非受指派而成為SRE，SRE團隊成員如果厭倦了從事維運工作，也可隨時轉入開發團隊。正因此，「SRE團隊也一直處在人來人往的狀態，隨時會有新成員加入，舊成員離開。」Melissa Binde表示，這些新血也能帶給SRE團隊新的思維。
守住系統高可靠性，開發團隊也能盡情推新功能
Dev和Ops常見的衝突是，開發團隊想盡可能嘗試新功能，但Ops擔心新功能影響既有服務的穩定性而力阻，雙方經常各執一詞而爭執不下。Melissa Binde表示：「我們用數學來解決這個問題。」Google明確地建立了一個可以兼顧推新功能和服務穩定性的規則，稱為「犯錯預算」（error budget）的概念。
Melissa Binde舉例，若某項服務承諾的SLA可用性是99.9%，那麼開發團隊就等於擁有0.1％的嘗試錯誤空間，「這個0.1％就是開發團隊在這項服務上可用的犯錯預算。」只要整體影響服務中斷的時間沒有超過0.1％，開發團隊可以盡情嘗試新功能。當然，「若開發團隊在開發過程常常失敗，得不斷重啟服務，也會更快地用光這個預算。」Melissa Binde說。
不過，犯錯預算用完了，Google仍提供開發團隊一個緩衝機制，稱為銀色子彈（Silver Bullet）。如果開發團隊耗盡了錯誤預算，但非常希望推出某項新功能，則可以使用銀色子彈來說服VP，放手讓開發團隊進行。Melissa Binde笑說，雖然這樣的儀式看起來很笨，「但其實威力強大。」
出錯後撰寫事後報告，避免錯誤一再重複
明確界定出開發團隊可犯錯的空間，讓開發與維運的爭執點有法可循之外，Google也非常重視出錯後的事後檢討，但不是為了究責，而是為了避免錯誤再度發生。例如若有新人上傳的程式碼導致一項服務中斷時，Melissa Binde認為，更應該檢討的是開發流程的程式碼審核（code review）、測試及快速回復（rollback）工具的問題。她解釋，這些程序應該要有能力阻止開發者上傳錯誤的程式碼，不該讓人為疏失蔓延到正式環境中。
而Google也會要求開發者在事後檢討報告中，除了詳細交待事故原因，更必須提出預防方法，以及發生類似事件時該如何緩和來降低受影響人數的對策。
Melissa Binde表示，這樣的思維正是Google企業文化中的不究責事後檢討（blameless post mortems）。她認為，解決意外最好的方式，就是了解事情始末，如果隨便找人背黑鍋，只會讓情況越來越惡化。
 

 Google SRE團隊維運心法大全 


Google網頁可靠性團隊儲存部門總監Melissa Binde同時也大力推薦這本由Google SRE團隊撰寫的SRE心法大全，裡面匯聚70名SRE團隊成員，總共累積500工作年的一手維運經驗，分享他們如何幫助Google更快完成部署、建置程序，「我對這本厚到不行的書，感到相當興奮。」


 
",https://www.ithome.com.tw/news/105366,"新聞,DevOps,Site Reliability Engineer"
105411,24,2016-04-20,雲端容器又有新選擇，微軟正式推出Azure Container Service,Azure Container Service支援Docker映像，且在指揮調度層採用開放源碼，使得客戶應用可攜至任何雲端或就地部署建置," 微軟的雲端容器服務Azure Container Service在經歷兩個月的預覽之後，於本周二（4/19）正式登場，標榜是在雲端執行容器應用最簡單、最開放也最彈性的管道。
微軟Azure專案經理Ross Gardler表示，談到雲端運算就很難不提及具備可攜性與靈活開發特性的容器生態，但當一個採用容器的企業想擴大容器於生產線上的應用時，就會發現容器的部署與操作是個重要的議題，追蹤與管理大量成長的高密度容器部署，其複雜度讓傳統的手動的管理模式顯得效率不彰。
Azure Container Service即可解決相關問題，它藉由開放源碼的容器指揮調度技術來簡化配置，只需要幾個點擊就能在一個管理框架上部署基於容器的各種應用。
Azure Container Service支援Docker映像，且在指揮調度層採用開放源碼，使得客戶應用可攜至任何雲端或就地部署建置。Gardler強調，由於Azure Container Service是基於100%的開放源碼軟體，因此可最大化其可攜任務，並可選擇受歡迎的DC/OS或Docker Swarm指揮調度引擎。
微軟周二亦宣布已與打造DC/OS的Mesosphere及逾50家業者共同創立了新的「資料中心作業系統」（Datacenter Operating System，DC/OS）開放源碼專案，以提供強大的容器操作能力，並可快速安裝複雜的分散式系統，涵蓋HDFS、Apache Spark、Apache Kafka與Apache Cassandra等。
",https://www.ithome.com.tw/news/105411,"新聞,Container,Azure,微軟,雲端,容器,Docker"
105350,24,2016-04-19,避免廠商綁定，Container技術第一個映像檔格式標準OCI出爐,OCI近日推出開放容器OCI映像檔標準，確立容器映像檔建立、認證、簽署以及命名的方式," 由Google、微軟、IBM及VMware等廠商組成的OCI聯盟，致力於統一各家Container技術標準。OCI除推出OCI runtime標準，讓開發者打包、簽署應用程式，並且可以自由選用不同的Container runtime環境外，在近日則更一步延伸，推出開放容器OCI映像檔標準，由Container技術社群訂定規範，確立容器映像檔建立、認證、簽署以及命名的方式。
CoreOS研發團隊總監Jonathan Boulle表示，未來數個月中，開發者可期待透過共享標準，建立、發布軟體Container。因此，無論開發者是使用appc或是Docker映像檔，也不會受到任何影響，「對於業界承諾『打包一次，各處運行』（package once，run anywhere），也是前進了一大步。」他說。
OCI在去年6月成立時，起初的目標主要瞄準於建立Container執行環境。然而，此次映像檔標準的推出，Jonathan Boulle認為，訂定了Cotnainer標準的最重要基礎元件，「建立起了分散式（distributable）的容器映像檔」，為容器可攜性的目標奠定了基礎。他表示，開發者也只須一次性地建立、打包容器，便可以在不同的雲端業者平臺或是企業就地部署。
OCI映像檔標準目標是避免Container遭廠商或引擎所綁定
訂定OCI映像檔標準的目的在於，讓開發者自由打包應用程式Container，並使用不同的Container引擎運作。因此，Jonathan Boulle表示，使用者也不會被特定廠商的Container技術所綁定。同時，也可以在rkt、Docker、Kubernetes及Amazon ECS等異質runtime中運作，「Container本身也不需要進行修改。」
Jonathan Boulle也透露，在未來數個月中，如Amazon Container Registry、Google Container Registry、Docker Hub及Quay等Container儲存庫，也都將支援OCI映像檔標準。
許多開源容器廠商對於OCI映像檔標準，也紛紛表示看好。如CoreOS技術長Brandon Philips表示，推出OCI映像檔標準，讓使用者逐步在採用現代化基礎架構中導入Container技術。Rancher首席架構施Darren Shepherd則認為，此標準的釋出，不僅讓工作可以在異質雲環境中進行，也可以跨Container runtime環境執行。
",https://www.ithome.com.tw/news/105350,"新聞,Docker,CoreOS,Rancher,容器技術,Container,IBM,google,AWS"
105168,24,2016-04-09,IT月報｜雲端IT焦點回顧 (2016/03),Google終於全力進軍企業雲，機器學習平臺相繼上雲端，OpenStack全球首次黑客松登臺。,"  Google   企業雲 
虛擬化女王帶隊，Google終於全力揮軍雲端
3月23日早上9點多，在舊金山AT&T球場對面的48號碼頭倉庫，超過2千人齊聚，包括各國企業IT主管，近2百位來自全球的媒體記者和分析師，即使已經延遲了半個多小時，人人依舊興致高昂地等待入場。因為這是繼IO以外，Google最大規模的全球活動，也是Google第一次的全球雲端用戶大會Next。
儘管Next大會規模，不論人數或是參展廠商攤位數，都只有公有雲龍頭AWS年度大會 re:Invent的十分之一，但從開發者、企業到IT業者，紛紛給予這次Next不亞於re:Invent的高度重視，因為Google雲端平臺（Google Cloud Platform，簡稱GCP）的新領導人即將揭露Google雲端的新戰略。(詳全文) 
 
 雲端機器學習   混合雲 
Google揭露雲端三大新戰略，新推機器學習雲和混合雲管理工具搶攻企業
Google全球首次雲端平臺用戶大會NEXT，今天在舊金山一連舉辦兩天。超過2千人參加，上百分析師和全球媒體，參展廠商超過35家。這是繼Google IO之外，最大規模的Google活動。
Google執行長Sundar Pichai也親自開場，介紹Google雲端平臺部門的新主管Google 雲端事業資深副總裁Diane Greene出場，她一手創辦了VMware，推動了整個虛擬化產業，「這位女性一手改變了整個IT產業，Sundar Pichai這樣介紹。
Diane Greene表示，Google雲端平臺將聚焦三大重點，包括了安全,機器學習,加速上新一代雲端。(詳全文) 
 
 雲端營運中心   Google 
Google將建10座雲端營運中心，東京和俄勒岡年底先上線

趕在Google首次跨大規模舉辦的雲端平臺用戶大會NEXT舉辦之際，Google宣布了雲端營運中心的全球建置計畫，將在2017年底前新增10個雲端營運中心，來凸顯Google積極進軍企業雲端需求的決心。Google現有8個雲端平臺營運中心，預計明年底可達到18個，不過，目前尚未透露更多設置地點的資訊。(詳全文) 
 
 Azure   機器學習 
HPE與微軟聯手在Azure上推出機器學習雲端服務
HPE和微軟宣布合推代管於Azure雲端平臺的機器學習即服務（machine-learning as a service）Haven OnDemand。
Haven OnDemand為一雲端開發平臺，提供圖片辨識、臉部辨識、索引搜尋、文字分析、預測、格式轉檔、影像分析、聽寫等超過60項進階機器學習API與服務，並可介接Web、Dropbox及SharePoint或檔案系統，協助企業IT、開發人員、與新創公司開發資料導向的行動、桌面及IoT應用程式。HPE表示目前該服務已有12,000多名開發人員註冊。(詳全文) 
 
 AWS   資料庫上雲端 
可協助客戶將資料庫轉至雲端的AWS資料庫移轉工具上線了

Amazon正式推出AWS Database Migration Service，協助客戶將就地部署的各種資料庫轉至AWS，自今年1月開放預覽以來，已有1,000個資料庫成功移轉至AWS。
AWS Database Migration Service可用來移轉多種品牌的資料庫，涵蓋Oracle、SQL Server、MySQL、Maria DB及PostgreSQL等。目前該服務的上線區域為北維吉尼亞、奧勒岡、北加州、愛爾蘭、法蘭克福、新加坡、雪梨及東京等，亦準備擴充至其他市場。(詳全文) 
 
 Azure   Docker 
微軟首席雲端架構師：Docker可用但還不夠，Azure要幫Ap架構最佳化

微軟雲端與企業服務事業群首席架構師Ulrich Homann認為，Docke確實可用但還不夠，因為還沒做到應用程式分散架構的最佳化，而這正是微軟Azure想提供的高階雲端服務。(詳全文) 
 
 IBM   資料雲服務 
IBM資料服務雲端化，25項資料服務一次上雲端

IBM將許多旗下既有的資料分析軟體以及新技術服務搬上雲端，提供訂閱式的雲端版本，並分為資料儲存、資料分析及資料回饋三大類產品，目前一共涵蓋25項雲端服務，IBM軟體事業處協理胡育銘表示，許多過去企業必須就地部署（On-Premise）的軟體與服務，現在都能改在雲端環境中使用。(詳全文) 
 
 OpenStack   黑客松 
OpenStack全球首場黑客松在臺開跑，執行長親自來臺頒獎

OpenStack過去也在世界各地主辦開發者活動及高峰會，此次黑客松的目的是要看產業界、學界及政府機構可以透過OpenStack，做到何種程度的應用。（詳全文) 
 
 張善政   OpenStack 
張善政：OpenStack是未來主流，企業研發不能錯過，大學正式課程也得納入

行政院院長張善政呼籲參加黑客松的業界人士，企業內部必須開始設立OpenStack研發團隊，讓它加值於軟體及硬體上，「如果硬體公司要轉型，雲端技術及OpenStack是重點。」而工研院等法人團體必也須開始輔導尚未導入OpenStack的業者。(詳全文) 
 
 資料中心OS   雲端新創 
微軟和HPE聯手投資雲端新創，加速資料中心OS發展

雲端運算新創公司Mesosphere日前結束了C輪投資，獲取7.35千萬美元，並由HPE主導此輪投資，並與微軟一起成為Mesosphere的新策略投資者，同時Mesosphere也發表2款新產品，容器調度系統Marathon和持續整合與持續部署平臺Velocity。(詳全文) 
 
 語音辨識   Google 
Google限量開放Cloud Speech API，加速語音辨識應用開發
Google將開放自家的語音辨識Cloud Speech API供第三方開發者使用，開發語音辨識相關應用軟體，開放初期將免費供開發者使用，未來則將收費。
Google是在NEXT雲端用戶大會上宣布此一消息。Google的Cloud Speech API支援便是超過80種語言，已經被應用Google的語音搜尋、翻譯、聽寫輸入等功能，未來一旦開放，便可與各種應用軟體結合，增加文字辨識、聽與翻譯等功能。
目前Cloud Speech API為限定預覽(Limited Preview)階段，感興趣的開發者可以登記Google Cloud Platform帳號，獲核准者可免費使用該API，而正式上市與收費的日期與收費方式則尚未公布。(詳全文) 
",https://www.ithome.com.tw/news/105168,"新聞,Cloud,雲端"
105099,24,2016-04-09,【Google雲端新戰略3】機器學習上雲讓人人能用，雲端資料平臺瞄準4大應用,機器學習開始驅動產業新革命，未來甚至將成為競爭力的證明，為了讓人人都能用，Google決定將開源機器學習引擎TendorFlow變成一朵雲，也讓雲端資料平臺布局更上一層," 除了Container技術，Next大會的另一個焦點技術就是機器學習。繼去年Google將機器學習引擎TensorFlow開源之後，現在更進一步，Google推出了機器學習雲端服務。
Google研究團隊資深院士Jeff Dean表示：「如何理解和運用資料的方式，能決定你成功的深度。」這位在Google Brain團隊帶頭研究深度學習技術的專家是Google最重要的研發人才之一。
他是MapReduce技術的發明人之一，這正是大資料分析平臺Hadoop的核心演算法。他也設計了Google五代檢索、索引與搜尋服務系統，還有Google賴以為生的原生廣告與AdSense內容廣告系統，甚至還有分散式運算的基礎架構。現在，Jeff Dean正全力研究大規模分散式系統上的機器學習技術，TensorFlow正是他率領Google Brain團隊打造的其中一項成果。他對機器學習技術發展的看法，最能反映出Google機器學習技術未來的發展方向。
Jeff Dean認為，機器學習技術可以幫助企業，從結構化和非結構化資料中抽取出有價值的趨勢，進而降低維運負擔也能改善商業運作。
Google從2012年初開始在內部專案中使用機器學習技術，2014年擁抱機器學習的專案量更快速成長，至今超過1,500個內部專案採用，除了AlphaGo以外，還有地圖服務、相片服務、Gmail、語音辨識、Android、YouTube、翻譯、機器人研究、自然語言研究、醫藥研發等專案。
Google想要打造的機器學習技術，Jeff Dean表示，想要滿足三類使用者，一種是擁有高度機器學習專業能力的專家，來訓練他們自有的機器學習模型，第二種是服務那些需要簡單易用介面，不需要高度機器學習專業的應用程式開發者，讓他們可以善用那些已經預先訓練好的機器學習模型，來打造出更聰明的應用程式。最後一種是介於兩者之間的角色，也就是資料科學家們，讓他們方便在自己的資料上運用成熟的機器學習模型，進行即時或批次的預測。
去年11月，Google開源釋出了自家第二代機器學習引擎TensorFlow，這是一個可以本地端、雲端或甚至在行動裝置上執行的機器學習引擎，引發了業界震撼，在今年Next大會中，Google更進一步推出了以TensorFlow為核心打造的機器學習雲端服務Cloud Machine Learning（或簡稱Cloud ML）測試版，也釋出了以機器學習技術打造的Cloud Vision API的Beta測試版、雲端語音辨識API的Alpha測試版以及雲端翻譯API正式版。Jeff Dean表示，這只是開始，將會在雲端提供更多機器學習API。
Google雲端平臺產品管理總監Fausto Ibarra表示，機器學習雲並非是一個獨立的Google服務，而是Google雲端資料平臺的一環。
Fausto Ibarra表示，這個資料平臺可以提供從雲端資料庫、儲存服務、資料處裡服務到分析服務、進階分析智慧、探索和協助技術的總和，Cloud ML正是進階分析智慧的關鍵平臺。而當前主要目標，將會鎖定常見的4大雲端資料應用模式，包括了App開發所需、資料儲存與歸檔、大資料分析以及機器學習應用所需，針對開發者、資料科學家和商業分析人員的需求來打造。
 相關報導
【直擊Google首次雲端平臺大會NEXT】Google雲端平臺新戰略
",https://www.ithome.com.tw/news/105099,"新聞,google,NEXT大會,機器學習,TendorFlow,雲端,Cloud"
105098,24,2016-04-09,【Google雲端新戰略2】跨大全球資料中心布局，2年增設10座雲端機房,除了現有的8個雲端平臺營運中心，Google將在2017年底前再新增10個雲端營運中心，其中，日本東京和俄勒岡的營運中心最快於今年年底上線，來凸顯Google積極進軍企業雲端需求的決心," 在Google首次雲端平臺用戶大會NEXT之際，Google也宣布了雲端營運中心（region）的全球建置計畫，將在2017年底前新增10個雲端營運中心，其中，日本東京和俄勒岡的營運中心最快於今年年底上線，來凸顯Google積極進軍企業雲端需求的決心。
Google現有8個雲端平臺營運中心，大多集中於美國，歐洲只有1座，設置在德國。亞洲也同樣只有在臺灣彰化設立了一個Google雲端平臺營運中心。Google全球資料中心副總裁Joe Kava表示，Google擁有全球最大規模的資料中心，光在冷卻技術上就有多項創新，不只使用外部冷空氣來冷卻，也運用了如海水、回收雨水、工業回收廢水、熱儲存機制等。不過，Joe Kava表示，即使是Google，仍會發生人為失誤，但是透過軟體設計，可以讓這些失誤不會造成資料中心任何當機。
日本東京Region設立後，亞太區將出現雙營運中心，來搶攻有意建置跨國備援架構的全球性企業。Google現有8個雲端平臺營運中心，預計明年底至少將達到18個。但Google目前尚未透露更多新資料中心設置地點的資訊。
根據Google網站資料，雲端營運中心（Region）是地理區域上的畫分單位，一個Region下有多個可用空間（Zones），一座資料中心內可能將機器分群成多個Zone，也可能由2個資料中心合組成同一個Zone。例如Google在臺灣的彰濱資料中心就是目前Google亞太雲端營運中心，內有3個Zone。同一個Zone內的機器可說是處於同一個網域中的環境，Zone與Zone間的網路彼此具有隔離性。在收費上，Zone內流量免費，跨Zone間則部分服務計費，部分不收費。但是跨Region的流量則都要計費。Google也建議使用者利用跨Zone機器來建立高可用性架構，或是跨Region來建立跨國備援架構。Google去年才於南卡羅來納州全面啟用一座Region。AWS和微軟Azure同樣也採取Region和Zone的畫分方式。
不只Google，為了搶攻企業雲布局，雲端大廠紛紛強化全球架構，來提供企業跨國運算資源的調度能力。目前AWS全球設有12個Region維運中心，預計未來1年再增加5個，也積極搶進中國天津設置資料中心，來提供中國當地雲端服務。而微軟Azure則有22個Regions，已公布將增加到28個。
IBM雲端服務Bluemix則沒有採取Region和Zone的作法，直接以各地資料中心來供企業選擇，可以直接指定要將雲端服務部署在哪一座資料中心內的伺服器上，Bluemix底層是Softlayer提供的IaaS平臺，目前在全球6大洲共有46座雲端資料中心，去年底在澳洲設置了雪梨資料中心，今年3月最新剛啟用了位於南非的約翰尼斯堡的IBM非洲第一座資料中心。
 相關報導
【直擊Google首次雲端平臺大會NEXT】Google雲端平臺新戰略
",https://www.ithome.com.tw/news/105098,"新聞,google,NEXT大會,資料中心,雲端營運中心,雲端,Cloud"
105097,24,2016-04-09,【Google雲端新戰略1】推廣無伺服器新架構，用Kubernetes加速企業上雲端,Container是史上第一個能將所有應用封裝在標準化環境的技術，這是邁向無伺服器架構的關鍵，Kubernetes就是為實現Container大規模部署而生，能讓Container叢集建置標準化，分散式App的開發更容易," 在NEXT雲端大會前一周，Google先釋出了Kubernetes 的1.2新版本，這個看似Google為了追趕Container及Docker熱潮而生的開源平臺，直到Next大會才揭開了它的真正面紗，其實這個專案源自Google已經用了10年的Container技術。
Alphabet執行董事長Eric Schmidt表示，2003年時，Google已經發展到第三代雲端平臺架構，開始使用Container技術來部署全球架構的雲端服務，因此而能催生了如Gmail這類全球規模的雲端服務。10年前，Google更發明了用來管理全球最大規模叢集的排程和服務管理工具Borg。
2008年，Google推出了App Engine，讓開發者可以快速利用各種雲端API來打造自己的應用，這個底層也是Container，但卻沒有受到開發者的青睞而使用率不佳。因為App Engine平臺出現太早，Eric Schmidt表示，「因為這是我們以為開發者應該需要的地方，卻不是當時開發者真正需要的地方。」後來Google在2010年推出了VM租用服務，這就是GCP雲端平臺的誕生。
不過，Google自家服務仍舊部署在可以提供更高彈性、以Container為主的第三代Google平臺上，而非是採用較舊VM技術的GCP雲端服務（對Google而言）。至今，Google每周啟用的Container數量超過了20億個。
直到現在，Google基礎架構副總裁Eric Brewer表示，以Container封裝應用、可動態維運、微服務架構導向的雲端原生應用風潮開始興起，Google遂將用來管理和部署大規模Container的Borg和Omega等管理平臺的經驗，重新開發成了一套開源容器叢集管理軟體Kubernetes，並推出以Kubernetes打造的Google雲端平臺提供的GKE（Google Container Engine）雲端服務。
不同於Docker要讓Container可用，Eric Brewer表示，Kubernetes的目的是要讓Container能用於Production環境，使Container叢集建置可以標準化，讓分散式App的開發更容易。
在Kubernetes 1.2新版已可做到單一叢集提供3萬個Container的管理能力，也具備了彈性自動化擴充能力。
不過，Eric Brewer認為，更重要的新功能是ConfigMap API。這提供了可程式化和高彈性的部署配置，可以在開發常見的應用部署階段之前，提供一種新的組合式部署方法稱為Construction，在部署階段仍然可以即時變更Config配置，例如由程式自動依據部署環境在測試環境、Stage或Production階段來調整不同資料庫的配置參數，可以提供比腳本程式控制或是DSL配置語言更彈性的自動化配置方法。
如此一來，Google雲端平臺副總裁Brian Stevens表示，開發者只要將容器化後的應用丟上雲端，就能自動部署成為全球架構的服務，甚至不需要管理叢集，也根本看不到伺服器。Container是史上第一個能將所有應用封裝在標準化環境的技術，這是邁向無伺服器架構的關鍵。「儘管目前全球Container使用量不到VM用量的5％，但維運角色（Ops）終究會消失，這是正在發生的事。」

 相關報導 
【直擊Google首次雲端平臺大會NEXT】Google雲端平臺新戰略

",https://www.ithome.com.tw/news/105097,"新聞,google,NEXT大會,Kubernetes,Container,雲端,Cloud"
105095,24,2016-04-05,【Google NEXT大會直擊】虛擬化女王帶隊，Google終於全力揮軍雲端,為了搶進雲端戰局，Google決定將旗下所有雲端產品部門，包括了Google for Work、Cloud Platform及Google Apps在內的雲端業務，從產品、工程開發、行銷到業務都整合起來，通通交給她來領導──VMware創辦人、矽谷創業圈的風雲人物Diane Greene," 【舊金山直擊Next大會】
3月23日早上9點多，在舊金山AT&T球場對面的48號碼頭倉庫，超過2千人齊聚，包括各國企業IT主管，近2百位來自全球的媒體記者和分析師，即使已經延遲了半個多小時，人人依舊興致高昂地等待入場。因為這是繼IO以外，Google最大規模的全球活動，也是Google第一次的全球雲端用戶大會Next。
儘管Next大會規模，不論人數或是參展廠商攤位數，都只有公有雲龍頭AWS年度大會 re:Invent的十分之一，但從開發者、企業到IT業者，紛紛給予這次Next不亞於re:Invent的高度重視，因為Google雲端平臺（Google Cloud Platform，簡稱GCP）的新領導人即將揭露Google雲端的新戰略。
Google執行長Sundar Pichai親自開場，介紹Google雲端平臺部門的新主管Google雲端事業資深副總裁Diane Greene出場，「這位女性深深地改變了整個IT產業。」Sundar Pichai如此描述，在矽谷，她就是一個無須介紹的大人物。
2015年中，Google採取了激烈的組織改組動作，成立了自己的母公司Alphabet，Google兩位創辦人Larry Page與Sergey Brin成了新公司的執行長，而Google則由Sundar Pichai接任成為新任CEO。也將部分新興事業獨立出來成立新公司，如Google生命科學團隊獨立為Verily公司、Google X實驗室獨立成Google X公司，先前收購的智慧家庭設備公司Nest Labs也獨立出來了。
瘦身後的Google更聚焦於網際網路相關的產品，包括了搜尋、YouTube、地圖、Gmail、Android及Chrome，當然還有雲端相關服務。若從營收來看，新Google更像是一家廣告公司，營收大宗來自各式各樣的網路廣告收入。
不過，2015年秋天，Google技術基礎架構資深副總裁Urs Hölzle在一場演講中透露，Google未來將從一家廣告公司，真正變成一家雲端公司。他認為，Google未來營收大宗將來自雲端，而不只是廣告，甚至雲端收入將超過了現有的廣告收入。
儘管Google一舉推動了雲端運算技術的浪潮，讓雲端運算成了IT界的主流技術之一，甚至擁有多項領先全球的雲端技術，但Google雲端服務產品大多仍聚焦在消費端的SaaS服務，企業市場的占比仍遠低於公有雲龍頭AWS，甚至在企業雲端的影響力，後來也漸漸被微軟Azure趕上而遭超越。
VMware創辦人Diane Greene領軍雲端部門
新Google改組後，GCP雲端平臺如何轉型成了眾人關注的新焦點，終於，2015年11月時答案揭曉，Google決定將旗下相關雲端產品部門，Google for Work、Cloud Platform及Google Apps在內的雲端業務，所有產品、工程開發、行銷及業務也都將整合於該部門之下。而誰來擔任這個雲端部門的新主管，誰將是主導Google未來的頭號關鍵人物呢？答案就是Diane Greene，她不只將負責主管Google新的雲端事業部門，也持續擔任Google董事。
儘管在Next開場演講中，Diane Greene上場時間不算長，但她卻宣示了Google雲端平臺接下來最重要的發展方向，「Google現在要全心投入企業需要的雲端了。」她如此宣示。
Diane Greene以她熟悉的航海事物「飛翼船」來比喻，這種不同於傳統航行於海面前進的帆船，能夠藉助船裝有水翼的支架，讓船身飛行在海面藉以提高速度。她說：「要用GCP的雲端擴充力將企業舉起來。」就像是飛翼船可以站立在水面上航行，更高速地前進，而不像傳統帆船只能夠在海面逆浪前進而已。
揭露雲端平臺3大重要方向
Google的雲端技術力，就是Diane Greene認為最能和競爭對手拉開差距的關鍵，在這次Next大會演講中，她先揭露了Google雲端平臺首要聚焦的三大重點，包括了安全、機器學習，以及加速企業上新一代雲端的目標。
強化雲端資訊安全
在資安上，曾以虛擬化技術壟斷企業市場的Diane Greene相當清楚，安全是企業上雲端最在意的關鍵之一。「Google內部用的資安技術，現在提供給顧客。」Diane Greene表示。
「Google雲端平臺採取了九層式資安架構，來提供不同的安全機制。」Google資深工程師Niels Provos表示，從硬體、開機、OS層、儲存層、網路與VPC層到應用層、部署層、維運層到使用層都有各自不同的安全機制。「GCP雲端平臺也採取了同樣的9層式資安架構，但從網路層開始，更提供了公有雲平臺需要的安全機制。」
不只預設全面加密，現在更進一步開放由企業客戶提供加密金鑰的儲存服務和雲端運算服務。另外GCE雲端運算平臺推出了身分識別與存取管理系統IAM for GCE，而App Engine雲端應用平臺則推出了可按角色管理（Role-based）的IAM機制。

Google資深工程師Niels Provos表示，「GCP雲端平臺也採取了Google內部同樣的9層式資安架構，但從網路層開始，更提供了公有雲平臺需要的安全機制。」

推出機器學習雲平臺
第二個焦點是機器學習，Diane Greene認為，機器學習對各產業都帶來了革命，現在已經是企業得向他們的顧客證明，自己也有擁抱機器學習的能力，而Google不只開源機器學習引擎，還將推出機器學習雲，來創造更多訓練資料，以及更多垂直產業的支援。

率領Google深度學習團隊的Google研究團隊資深院士Jeff Dean也上臺展示Cloud Vision API 的威力，透過機器學習可以分辨出照片中多種特徵，例如每個人臉上不同的情緒。

打造NoOps全自動化IT模式
最後一個發展焦點是如何加速上新一代雲端。她表示，Google想要打造一個NoOps的全自動化IT，也就是無伺服器架構（Serverless）的模式，讓開發人員可以像變魔術般的快速將應用程式部署到全球架構之上，「幾行指令就能夠部署上千臺伺服器，就像魔術一樣。」她說。
為了達成此目標，Alphabet公司全集團每年資本門投資高達99億美元，其中大多用於雲端基礎架構，Diane Greene表示：「這更證明了我們有多認真要投入雲端業務。」
除了揭露未來雲端發展方向，Google也在Next上推出多項新服務來回應這三大目標。在機器學習上，Google已經開源釋出了Tensor Flow機器學習平臺，但Google認為應用速度還不夠快，在Next大會中也宣布推出機器學習雲（Cloud Machine Learning）平臺，可供資料科學家或開發者自行建立自己的大規模機器學習模型，可支援Google雲端平臺既有產品，也可利用測試資料建立預測分析模型，這個雲端機器學習平臺，可以涵蓋從資料擷取到結果預測的全程處理。並可提供預先測試機器學習模型（Pretrained Machine Learning models）。
另外在大資料分析服務也有多項更新，包括了長期儲存半價折扣，超過90天可自動減免50%儲存費用。另外推出自動化儲存分區機制（Automatic Table Partitions），透過日期或搜尋時段來自動將資料表分區。另外也新推出了Capacitor儲存引擎，可以提高10倍搜尋速度。也針對公眾資料分析需求，推出了Public Datasets Program計畫來推廣開放資料的分析。
新發表雲端監控管理平臺Stackdriver
在加速上雲端的策略上，Google則發表了新的雲端監控管理平臺Stackdriver，可以用來蒐集跨Google雲端平臺、AWS和私有雲的Log資料，透過單一介面來管理。Google雲端產品總監Greg DeMichillie表示，Stackdriver這套混合雲管理平臺最大特色是，不只能跨多種雲，也要能用同一套指令、相同的API，甚至是同一套後臺系統，就可以管理公私雲。不過，目前Stackdriver還未支援微軟Azure。
在Next大會中，Google沒有揭露太多雲端經銷體系或和合作夥伴的推廣計畫，反倒是在Next大會前一周，舉辦了全球夥伴大會TeamWork，推出了新的合作夥伴計畫拉攏系統整合商和ISV。Google現有合作夥伴大多是全球性的企業，而較少有在地化的SI或ISV來提供當地支援。Google雲端平臺副總裁Brian Stevens坦言，目前仍聚焦在全球性架構的支援，但「包括如當地銷售團隊、本土技術工程師等在地化支援，是Google未來一定會做的事。」
不過，Google揭露多項新雲端平臺服務的同時，仍沒有說明未來的雲端獲利模式，Diane Greene表示，對Google而言，未來雲端事業的營收將成為不亞於廣告收入的營收，但目前仍專注於開發更多公有雲產品，來吸引更多開發者和企業使用，再來考慮獲利方式。

Google新發表的雲端監控和管理平臺Stackdriver，可以蒐集跨Google雲端平臺、AWS和私有雲的Log資料，透過單一介面提供監控。不過，目前Stackdriver還未支援微軟Azure。

 

 傳奇創業女王成Google雲端掌門人 

沒人想得到，這位熱愛大海，40年前奪下全美女子帆船大賽冠軍的女船長，後來成了影響第二代IT架構和全球科技產業的關鍵人物。
1996、1997年時，Diane Greene任職於史丹福教職的先生Mendel Rosenblum，和幾位學生合寫了幾篇如何在單機同時執行多套作業OS的論文，Diane Greene為了幫忙先生將這些論文變成商品，在1998年出面創立了VMware，也同時接下了VMware執行長一職，讓她的先生也是VMware共同創辦人同時擔任技術長，能夠繼續從事技術研發工作。
從1998年開始，Diane Greene連續10年擔任VMware執行長，一手將VMware發展成一家營收估計高達20億美元的上市公司，一手推動了虛擬化產業的蓬勃發展，虛擬化一詞，因此，從此成了CIO與IT人們人人必需了解的基礎知識。
即使到後來Diane Greene離開了她一手所創立的VMware，她仍舊是美國矽谷創業圈的風雲重量級人物。
技術背景出身的Diane Greene，擁有了麻省理工學院造船工程碩士學位以及加州大學柏克萊分校電腦科學碩士學位，而且屢屢都能夠在企業IT新創的投資中拔得頭籌，不僅搶先投資了如Hadoop套裝軟體知名發行商Cloudera、知名SDN新創Cumulus Networks、雲端作業系統Numbula等，她所創辦的VXtreme影音串流技術公司也被微軟相中而收購。
她在2012年就成為Google董事會的成員，如今也仍舊在Google母公司Alphabet公司董事會中，和Google執行長Sundar Pichai一樣擁有一席之地，另外，她也是直覺電腦軟體公司（Intuit）、可汗學院（Khan Academy）以及麻省理工學院的董事會成員。

 
 相關報導 
【直擊Google首次雲端平臺大會NEXT】Google雲端平臺新戰略
",https://www.ithome.com.tw/news/105095,"新聞,google,NEXT大會,Diane Greene,雲端,Cloud"
105022,25,2016-03-30,Rancher正式推出1.0版本，同時可以建構Docker Swarm及Kubernetes叢集,Rancher執行長梁勝表示認為，當企業開始在正式環境中部署Docker Container時，立即會碰到整合大量開源技術的挑戰。而Rancher身為Container管理平臺，必須解決網路、儲存、監控、調度以及排程等問題。," 自從2014年Rancher首次在Amazon re:Invent大會曝光後，在近日正式推出1.0正式版。Rancher執行長梁勝表示，在歷經一年半之的開發後，「Rancher已經達到一定的品質，以及功能完整性，已經可以用於正式環境的部署。」同時他也揭露，目前Rancher已經達到破百萬下載次數。
而Rancher是目前唯一同時支援Kubernetes及Docker Swarm的Container管理平臺，Rancher表示，Rancher環境提供了叢集即服務（Cluster as a Service），能運作不同的叢集管理框架，而開發者除了可以管理Rancher原生的調度引擎（orchestration engine）Cattle外，同時還可以建置Kubernetes叢集及Docker Swarm叢集。
梁勝表示認為，當企業開始在正式環境中部署Docker Container時，立即會碰到整合大量開源技術的挑戰。而Rancher身為Container管理平臺，必須解決網路、儲存、監控、調度以及排程等問題。
「Rancher也針對在正式環境中所需要的技術，進行開發、整合及發送。」梁勝舉例，如Rancher整合了Docker Swarm以及Kubernetes及Mesos此類的Container調度工具。同時，Rancer著手開發應用程式目錄（app catalog）、容器網路、存取控制等技術，「在部署Rancher後，企業可以專注於開發應用程式。」
梁勝也點出，目前企業大多轉移至敏捷式開發流程。不過，他表示，使用者GitHub、Jenkins及Docker Hub等工具，僅僅解決流程中的前半部。而透過部署Rancher，開發者除了可以進行測試、升級、部署等工作外，同時，不論在私有雲、公有雲中，也可以運作容器化應用程式。
",https://www.ithome.com.tw/news/105022,"新聞,Rancher,Docker,Container,容器技術"
104926,25,2016-03-26,【直擊Google NEXT】Google首次全球雲端大會Day2重點：安全，資料中心和容器,Google全球雲端大會NEXT的第二天進一步聚焦在安全，資料中心和Container三大技術上，可說是Google NEXT第二天就是Google雲端技術日。," 【舊金山直擊Google NEXT】
Google舉辦首次全球雲端用戶大會NEXT 2016，第一天由新任Google雲端事業資深副總裁Diane Greene的登場秀，她帶頭揭露Google未來雲端三大方向：安全,機器學習和加速新一代雲端技術之外，就聚焦在機器學習雲端服務、雲端管理平台上。第二天則是更進一步聚焦在安全，資料中心和Container三大技術上，可說是Google NEXT第二天就是Google雲端技術日。

在GCP NEXT第二天上台介紹資料中心的Google主管，來過臺灣好幾次，正是彰化資料中心開幕時的Google高層，Google全球資料中心副總裁Joe Kava，即使是Google，仍會發生人為失誤，但是透過軟體設計，可以讓這些失誤不會造成資料中心任何當機。

Google資料中心如何節省能源？靠冷卻技術的創新


Google全球資料中內也有機器人幫忙

Google也利用機器學習技術來優化資料中心的管理，並將優化結果視覺化


Google雲端平臺安全架構則是在原有Google安全架構的儲存和網路層開始不一樣。

Google負責資安和隱私的資深人員Niels Provos，透明化是建立信任的關鍵，因此，他要來介紹Google的資安架構，從最底層硬體到最上層的使用者，每一層如何確保安全.

最後上台談Container的Google基礎架構副總裁Eric Brewer，他在Google打造了第一個全球架構的運算叢集。他認為，Docker讓Container更容易存取，而Kubernetes的目的是要讓Container更容易應用在真實環境中。而1.2新版Kubernetes最大特色不是速度，而是能夠管理超大叢集的節點，也因此，需要新的部署管理方式。



在部署之前，要先設定叢集，傳統作法有兩種，利用腳本程式，或是用特定領域語言，但各有好壞，Google在Kebernetes提出一個新的概念：用Construction來組裝設定，也將提供快速架構設定的工具




 
",https://www.ithome.com.tw/news/104926,"新聞,GCP,NEXT,google,雲端,資料中心,容器,安全,Container"
104884,25,2016-03-25,Docker奉上生日大禮，推出原生Windows及Mac版Docker,Docker表示，今日推出Beta版本採限量名額，使用者登入Docker後，會被列入等待名單之中。," Docker支援Windows及Mac再進一步！在Docker滿三歲生日時，推出Beta版的原生Windows及Mac版Docker。而Docker表示，今日推出Beta版本採限量名額，使用者登入Docker後，會被列入等待名單之中。
使用者在操作Windows及Mac版的Docker時，不需要仰賴如VirtualBox的虛擬化軟體。Patrick Chanezon表示，透過Mac OS X的xhyve VM，或是Windows的Hyper- V VM，Docker引擎就可以在Alpine Linux之中運作。而VM則是透過Docker應用程式管理，不需要額外的Docker主機運作。
新版本也提供原生Windows及Mac使用者操作介面、及自動更新功能給使用者，而Docker工具組內則包含了Docker命令列、Docker Compose及Docker Notary命令列。
Docker技術團隊成員Patrick Chanezon表示，為了讓使用者在本機網路更容易運作Container，新版本除了內建給Container使用的DNS伺服器外，同時也整合了Mac及Windows的網路系統。他表示，在Mac OS X上，甚至也可以使用Docker連線至公司內嚴密限制的VPN。
Docker表示，Mac版Docker至少需要 OS X 10.10.3以上的版本，以及2010以後的Mac電腦，而Windows版Docker則僅支援Windows 10專業版。
",https://www.ithome.com.tw/news/104884,"新聞,Docker,Container,原生支援,容器技術,Docker Container,Hyper-V,微軟,Windows"
104797,25,2016-03-23,【直擊Google NEXT】Google企業雲新戰略即將揭曉，兩大重點聚焦安全和Container,Google雲端平臺產品總監Greg DeMichillie透露，為了向企業展示Google的雲端產品已經準備妥當，在這次NEXT大會兩大重點將是安全和Container。," 【舊金山直擊Google NEXT】Google即將在23、24日舉辦擴大規模的雲端平臺用戶大會GCP NEXT。趕在活動開始前一天，Google先對媒體透露了會中將聚焦的雲端新戰略。
Google雲端平臺產品總監Greg DeMichillie認為，第三波IT革命將創造出真正具備全球化彈性的雲，核心將是叢集、分散式儲存、分散式運算、機器學習和Container

Greg DeMichillie認為，有四項應用是企業上雲端的第一步，包括了1.資料和分析、2.低成本、低延遲的資料歸檔/備份、3.Dev/Test 開發/測試，以及4.高運算需求的工作量。這也暗示了Google雲端平臺產品未來將優先聚焦的四大應用

Greg DeMichillie透露，為了向企業展示Google的雲端產品已經準備妥當，在這次NEXT大會兩大重點將是安全和Container。Google容器引擎資深產品經理David Aronchick表示，Google所有服務都跑在Container 上面，每週啟用20億個容器來提供各式各樣的Google應用。但是，他說，使用容器最困難的挑戰是如何確保Container的運作穩定。因此，Google創造了一套內部平臺來管理超大量Container，後來也將這套容器管理系統的思維和經驗，重新開發出了Kubernetes容器叢集管理平臺，並開源釋出，已有超過1,200開發者參與開發。最近Google還將Kubernetes程式碼貢獻給了Cloud Native Computing Foundation基金會

Google雲端平台產品總監Fausto Ibarra表示，Google從儲存、資料庫、大資料分析到機器學習四大領域的應用，將組合成Google Cloud Data Platform平臺。
Google大資料產品布局將涵蓋整個大資料分析的生命周期，常見四項大資料應用包括了行銷分析,行動遊戲分析,IoT和感測器資料分析,基因分析。為了保護資料，GCP NEXT明天也將發表新的加密服務，也將有機器學習的相關新宣布



",https://www.ithome.com.tw/news/104797,"新聞,GCP,NEXT,google,企業雲,Container"
104785,25,2016-03-22,CoreOS釋出容器漏洞掃描工具Clair正式版，可提供和更新漏洞修補程式,CoreOS在4個月前推出容器映像檔安全分析引擎Clair測試版，現在宣布Clair也可以在正式環境下執行，新版Clair加強了效能、可用性和彈性，並能提供開發者可用的修補程式來修復漏洞。," 容器作業系統CoreOS公司釋出容器映像檔安全分析引擎Clair 1.0，並宣布可用在正式環境，Clair可用來監控容器（Container）的安全性，而正式版Clair不只能夠揭露漏洞的存在，也能提供可用的修補程式或更新來修復漏洞。另外，Clair 1.0也加強了效能和擴展性，讓開發者可以建置自己的Clair分析服務。
CoreOS在2015年11月推出開源計畫Clair測試版，Clair是CoreOS自家容器安全掃描服務Quay的核心分析引擎，提供API式的分析服務，透過比對公開漏洞資料庫CVE（Common Vulnerabilities and Exposures）的漏洞資料，並發送關於容器潛藏漏洞的有用和可操作資訊，來協助開發人員檢查每個容器中映像檔（Image）的潛在資安威脅或未修補漏洞。
而在正式版Clair中，CoreOS加強Clair 1.0的效能、可用性和彈性，在效能方面，提供了Postgres 9.4資料庫抽象層的操作介面，並利用遞迴查詢來模擬圖形結構，同時維持傳統SQL資料庫的效能，而這也促進了API在正式環境中的回應速度，CoreOS宣稱，API回應3個指令的時間從30秒加速到30毫秒就可以得到回應。
在新版Clair的可用性上，則提供開發者新的RESTful JSON API，與舊版API緊密結合容器儲存庫不同的是，新API可以協助使用者整合Clair與工作流程和系統。而在彈性方面，CoreOS則透過增加子系統來增加Clair使用上的彈性，包含了蒐集公開漏洞資料的抓取工具Fetcher、標出有漏洞的容器映像檔工具Detector、漏洞通知工具Notification Hook等，且支援Docker、ACI等映像檔格式。
此外，新版Clair還包含Feature功能，提供漏洞的名稱和版本，並且會修復存在的漏洞，也有如CVSS（Common Vulnerability Scoring System）的中繼資料（Metadata），可以提供漏洞的基本特徵資料，還有標誌（Flag）功能，則提供用戶在映像檔的特定層可以更容易更新漏洞修補程式。
另外，根據CoreOS分析Quay容器儲存庫（Container Registry）裡的容器發現，70％以上已知的漏洞可以透過更新容器映像檔的修補程式來修復，而80％以上的高風險（High）和重大（Critical）等級漏洞也可以透過更新映像檔的修補程式修復問題。CoreOS表示，許多常見的容器映像檔會因為年齡和大小而潛藏許多漏洞，CoreOS也呼籲使用者更新容器映像檔，以避免資安威脅。
",https://www.ithome.com.tw/news/104785,"新聞,CoreOS,Clair,Container,容器漏洞掃描工具,Quay"
104692,25,2016-03-21,Container雙周報第5期：微軟首席雲端架構師：Docker還不夠好，Azure要幫Ap架構最佳化,微軟雲端與企業服務事業群首席架構師Ulrich Homann來臺揭露Azure發展布局時表示，Docker聚焦於基礎架構資源的管理和應用程式的封裝，確實可用但還不夠，因為還沒做到應用程式分散架構的最佳化，而這正是微軟Azure想要提供的更高階雲端服務。," 重點新聞（3月5日-3月18日）
·微軟首席雲端架構師：Docker可以用但是還不夠，Azure要幫Ap架構最佳化
全球Container熱潮持續發燒，微軟也不會放過，不過，近日，微軟雲端與企業服務事業群首席架構師Ulrich Homann來臺揭露Azure發展布局時表示，Docker聚焦於基礎架構資源的管理和應用程式的封裝，確實可用但還不夠，因為還沒做到應用程式分散架構的最佳化，而這正是微軟Azure想要提供的更高階雲端服務。
負責微軟雲端和企業商用平臺架構規畫的Ulrich Homann表示，當微軟執行長Satya Nadella上任後，將Windows Azure改名為Microsoft Azure之後，Azure產品藍圖就有了截然不同的改變，不再侷限於Windows這單一產品平臺上，而有了更大的格局也更開放，甚至能支援非微軟OS。
·Mesos正式推出Mesosphere DCOS 1.6版
Mesos宣布推出Mesosphere DCOS 1.6版本，除了增加安全性外，同時也整合最新版本的Apache Mesos及Marathon。Mesos表示，新版本讓支援企業使用GUI介面安裝，讓使用者較容易將DCOS部署至叢集，讓組態設定的步驟降到最低。
使用者也可在DCOS企業版本中透過網頁介面，在資料中心中設定單一或是多人使用者權限，以及本機權限或遠端權限。更多資訊
·微軟推出支援Azure檔案儲存的Docker Volume套件
Azure支援Docker再進一步！Azure Linux軟體工程師Ahmet Alp Balkan表示，微軟推出支援Azure檔案儲存的Docker Volume套件。他表示，這個開源的Docker Volume套件，讓Docker Container可以在VM之外，擁有資料儲存空間。因此可以讓Container在主機間的遷移程序變得更加簡單。
Ahmet Alp Balkan表示，標準的Docker Container通常是儲存在Docker主機的目錄中，這樣的設計讓Container必須依賴主機上特定的某些檔案，使得Cotnainer在進行遷移、水平擴展上的難度增加。更多資訊
·Rancher 0.63版開始支援Kubernetes
Rancher在近日宣布推出Rancher 0.63版本，並且開始支援容器調度工具Kubernetes。Rancher執行長梁勝表示，企業使用新版本Rancher建置Kubernetes環境時，只需要單鍵點擊，等待5至10分鐘後就自動完成Kubernetes叢集的部署程序。
梁勝表示，新版本推出所帶來的意義，不僅只是使用者可以在Rancher平臺上創建Kubernetes叢集，「我們將Kubernetes融入，讓它成為Rancher的關鍵元素。」並且同時整合2個工具的能耐，例如使用者可以創建多重的Kubernetes叢集，並且透過Rancher管理使用者存取權限。更多資訊
·Kubernetes推出1.2版本，簡化應用程式部署、管理
Google推出Kubernetes 1.2版本，新版本除了加強效能表現化，也讓應用程式的管理、部署變得更加簡單。Kubernetes資深產品經理David Aronchick表示，目前Kubernetes專案總共有超過680個貢獻者，而1.2版本是目前以來發布最大的版本。
Kubernetes新版本可管理叢集規模總共增加了400％，每一個叢集可以納入3萬個節點（Pod）外，同時也採用動態組態（Dynamic Configuration），當應用程式在運作時下載組態。同時Kubernetes也採用統包部署（Turnkey Deployments），可以自動進行版本管理（versioning）。更多資訊
·Docker技術長揭露Docker進軍容器服務市場戰略
Docker技術長Solomon Hykes與雲端運算服務諮詢商Cloud Technology Partners技術長Mike Kavis對談時，Solomon Hykes也揭露Docker推動容器即服務的市場戰略。
Solomon Hykes表示，Docker推出容器即服務的戰略，原因在於觀察到許多企業用戶偏好集結不同的Container技術，藉以打造自家的PaaS，而不需要受限於單純的PaaS解決方案。
而併購單緒核心技術廠商Unikernel則是長遠的IoT策略布局。單緒核心（Unikernel）在未來會越來越重要，由於感測器、晶片等小型裝置沒有足夠運算資源支撐一個完整的作業系統。更多資訊
產品動態
·Mesos正式推出Mesosphere DCOS 1.6版更多資訊
·微軟推出支援Azure檔案儲存的Docker Volume套件更多資訊
·Rancher推出0.63版本，支援Kubernetes更多資訊
·Virtualboux 5.0.16版本推出更多資訊
·Kubernetes 1.2版本推出更多資訊
·Joyent推出Container命名服務更多資訊
Container資源
※知識：5個小訣竅給Docker Swarm使用者
※影片：如何建立Docker Swarm叢集
※影片：用Kitematic開始上手Docker
※How-To：用樹莓派架構Docker Swarm叢集
※How-To：用Docker Swarm做即時叢集監控
※How-To：運作Windows本地Docker Swarm
※How-To：結合Docker Swarm及Docker Networking部署容器
※How-To：測試Docker Container的訣竅
※How-To：結合Jenkins套件及Docker，打造容器化建置環境
※How-To：在Docker資料中心完成建置、發布及運行程序
",https://www.ithome.com.tw/news/104692,"新聞,Docker,Container,容器,Mesos,Kubernetes,Rancher,Azure,雲端,Joyent,Virtualbox,IT周報"
104610,25,2016-03-19,Walmart開發人員必學的DevOps部署＋混合雲管理利器OneOps,"2013年中，負責研發創新電商平臺技術的WalmartLab團隊，低調買下了一家新創OneOps，如今，Walmart內部3千名開發人員使用OneOps，來部署和管理超過3,500個電商應用，每月透過OneOps發布的程式異動超過3萬次"," 「我們不是要打造Walmart的AWS服務，而是要藉助開源加速內部平臺的進化。」Walmart技術部雲端工程經理Rick Melick這樣回答。
2013年中，負責研發創新電商平臺技術的WalmartLab團隊，低調買下了一家新創OneOps。沒有人清楚真正的原因，只知道這一套自動化應用部署和資料中心維運管理工具，成為了Walmart 大力投入的平臺。
直到2年後，2015年10月初，Walmart突如其來地宣布，將開源釋出OneOps，甚至打造了一個新創網站產品介紹首頁。不只開發人員關注，也引起業界討論，甚至傳出Walmart是為了和Amazon競爭，打算從AWS著墨較少的PaaS層雲端服務切入，來打造一個自家公有雲平臺。而開源，就是為了建立Walmart幫開發人員，布局未來自家雲端生態的第一步。
隔周，東京OpenStack高峰會中WalmartLab（現為技術部）維運主管的演講大爆滿，連講堂兩側走道地板都坐了人，為的就是一睹OneOps為快。
WalmartLab將當初買下的IT自動化管理平臺，進一步發展成了一套用於持續部署雲端應用的生命周期管理軟體，也是一套部署在Walmart自家OpenStack私有雲上的PaaS管理平臺，更是全Walmart內部開發人員，人人必學的一套DevOps工具。
有了可以通吃多種公雲和私雲的OpenStack，為何還需要OneOps？Rick Melick解釋，好處是可以將電商系統的管理高度，從IaaS層級拉高到應用程式層級。負責系統的開發團隊可以全權管理從開發到維運的過程，也更容易對齊業務需求來設計應用系統，完全不用擔心基礎架構層的問題。對內部管理而言，也可以建立一套全公司通用的應用程式部署和管理流程，更容易推動DevOps。
目前Walmart內部3千名開發人員使用OneOps，來部署和管理超過3 ,500個電商應用，每月透過OneOps發布的程式異動超過3萬次。
儘管在Walmart內部以OpenStack為主，但WalmartLab仍決定讓OneOps發展成一個可以跨雲管理的工具，可以用來解決被單一雲端供應商或雲端軟體平臺商綁定的問題，OneOps可以提供跨雲應用的單一部署和管理介面。
簡單來說，OneOps是一個雲端持續整合及應用程式生命周期管理的平臺。支援協作，也提供視覺化操作介面，採取模式驅動（Model-Driven）架構設計，並內建了最佳實務資料庫，也是一個雲端平臺的抽象層，讓企業更容易跨多雲管理應用系統。
Rick Melick表示，OneOps優點是可以提供一個自助式敏捷架構，快速可重複和持續調度App環境，甚至提供App回復服務的平臺，目標是要提供複雜商業核心工作量的管理
OneOps平臺可以讓開發者依據架構或應用的需求來定義應用程式所用的工作量，可管理的資源包括了基礎架構資源（如伺服器、儲存空間）、多種軟體資源（OS套件、SCM儲存庫等），還可以將外部雲端服務整合到客制元件上，再透過OneOps來管理這些客制元件，也就等同可以管理不同的外部雲端服務資源。
目前OneOps已可支援多種私有雲或公有雲平臺，例如OpenStack、Azure、AWS等皆可支援。
2016年1月底OneOps已如期在Github上開源釋出。
 
【相關報導請參考「【雲端企業實例1】電商體質大改造！Walmart上雲端」】
",https://www.ithome.com.tw/news/104610,"新聞,walmart,沃爾瑪,OneOps,DevOps,混合雲,電商,電子商務"
104663,25,2016-03-17,微軟首席雲端架構師：Docker可用但還不夠，Azure要幫Ap架構最佳化,微軟雲端與企業服務事業群首席架構師Ulrich Homann認為，Docke確實可用但還不夠，因為還沒做到應用程式分散架構的最佳化，而這正是微軟Azure想提供的高階雲端服務。," 全球Container熱潮持續發燒，微軟也不會放過，不過，近日，微軟雲端與企業服務事業群首席架構師Ulrich Homann來臺揭露Azure發展布局時表示，Docker聚焦於基礎架構資源的管理和應用程式的封裝，確實可用但還不夠，因為還沒做到應用程式分散架構的最佳化，而這正是微軟Azure想要提供的更高階雲端服務。
負責微軟雲端和企業商用平臺架構規畫的Ulrich Homann表示，當微軟執行長Satya Nadella上任後，將Windows Azure改名為Microsoft Azure之後，Azure產品藍圖就有了截然不同的改變，不再侷限於Windows這單一產品平臺上，而有了更大的格局也更開放，甚至能支援非微軟OS。
根據微軟最新統計，Azure每月訂戶新增9萬名，累計Azure AD帳號數超過5億個，超過150萬個SQL資料庫部署在Azure上、推出一年的Azure IoT平臺每周則要處裡超過2兆則訊息。
不過，全球有能力提供百萬臺伺服器規模的公有雲供應商，Ulrich Homann認為，目前有3家，除了微軟之外，就是AWS和Google。為了和對手競爭，微軟將從超大規模架構、企業實證、混合雲架構三方向來創造自己的差異化。微軟雲端投資將聚焦於三大領域，包括了高階雲端服務、雲端基礎架構以及商用SaaS解決方案。
Azure所要實現的雲端基礎架構包括了5層，Ulrich Homann解釋，由下到上可以分為基礎架構層、IaaS層、叢集協同調度層（Cluster Orchestration）、通用運算PaaS層，以及最上面的垂直應用運算PaaS。

基礎架構層包括了Azure基礎公雲以及微軟內部採用同樣架構的Azure私雲，奠基在這之上的IaaS層則包括了VM、VM套件功能和各種VM延伸機制。接著之上則分成了兩套架構，一個是由開源Orchestration技術，如Mesos、Docker Swarm、SCALR、RightScale等技術組合而成的從叢集協同調度層，也可支援Google的Kubernetes，再搭配Apprenda、CloudFoundry、Jelastic和Marathon等技術所建構的通用運算PaaS層。
但微軟則還有一套自行開發的Service Fabric工具，可以提供叢集協同調度層和通用運算PaaS層的功能，來管理VM和Container的資源。微軟並在Service Fabric上來建置能支援網路應用、行動App、各式雲端服務的垂直應用運算PaaS層。
Ulrich Homann表示，Docker和Container技術可視為一種由外而內的調度機制，主要聚焦於基礎架構資源管理和應用程式封裝，確實可用，但還沒做到應用程式分散架構的最佳化。而Azure的Service Fabric則是從內而外的作法，從AP管理出發，了解需求後才調度資源來部署，因此可以提供運算資源最佳化的效果。目前已可支援Windows應用，未來還將支援Linux應用和Java應用的雲端優化。
 
",https://www.ithome.com.tw/news/104663,"新聞,Azure,Docker,Container,架構師,微軟,雲端,AWS,google"
104414,25,2016-03-13,Kubernetes創辦人談原生雲端運算：捨腳本式部署才能應付網路規模,Kubernetes共同創辦人Craig McLuckie表示，面對高複雜度的應用程式以及龐大資料流量，傳統命令式、腳本式的部署程序是不切實際的作法，得在應用程式架構及整體運作模式中，採取新方法," 「高複雜度的應用程式以及面對大量資料的流量，已經逼得我們得在應用程式架構及整體運作模式中，採取新的方法。」Kubernetes共同創辦人Craig McLuckie表示，業界開始將這種新手段稱為原生雲端運算（Cloud native computing）。
原生雲端應用及傳統系統的三大關鍵差異
Craig McLuckie認為，原生雲端運算與傳統系統相比，總共有三大核心差異，分別是容器化封裝（Container packaged）、動態管理（Dynamically managed）以及微服務導向（Microservices oriented）。
他表示，以封裝形式將應用程式部署在Container中，可以讓部署程序變得更加可預測，「使用傳統命令式、腳本式的部署程序，面對目前我們處理的規模是不切實際的。」
而面對原生雲端運算的規模，Craig McLuckie表示，維運人員也不可能採用人工方式調度、管理Google每周開起多達20億個Container，因此必須依賴智慧化系統根據需求，動態判斷任務需要的Container數量，以及分配Container的運作位置。他表示，藉著動態管理，Google可以仰賴小型維運團隊提供一般服務外，同時還可以讓開發人員專注於開發工作上。另外，他表示，Google全部的系統都採用鬆散耦合（Loosley coupled）架構，可以讓系統變得更敏捷外，也大幅提升程式碼的重複使用率。
除Google外，像Facebook及Twitter等也使用類似的方式應付龐大的營運需求。雖然各廠商在實作細節上有許多差異，但是他表示，在基礎做法上各企業都有高度一致性，因為「只有這種方式能夠處理網路規模的維運。」而他認為，未來會有更多傳統企業被迫面對網路規模帶來的難題。像是物聯網，將給企業帶來過去無法想像的資料流量。
同時Craig McLuckie也發現，許多企業開始發展自家的關鍵技術，無非就是為了能追上轉型成原生雲端運算企業的趨勢。但是他認為，此種發展模式的問題在於，單一廠商必須有能力提出完整解決方案。另外，由於Container技術缺乏調度、服務及runtime相關標準，使得每家廠商互為孤島外，「也僅有少數企業能提供完整解決方案。」
成立原生雲端運算基金會，解決廠商孤島問題
有鑑於此，Craig McLuckie也透露Google將著眼發展Kubernetes。他認為，除了將Kubernetes交由基金會運作是合理作法外，Google也與社群廣泛合作，並且匯集Intel、紅帽、思科、IBM、VMware、Docker、CoreOS以及Mesosphere等，共同建立雲端原生運算基金會（CNCF）。
「CNCF的目標不是成為傳統的標準機構」，Craig McLuckie更希望CNCF是匯聚各家的技術平臺，創造一套配有簡潔API的架構。而企業在建立延伸應用的同時，也必須通過CNCF的審查，確保與其標準相符合。而CNCF也會依循開放性、公平性及一致性等核心價值持續運作。
",https://www.ithome.com.tw/news/104414,"新聞,Kubernetes,Craig McLuckie,Container,原生雲端運算,Cloud native"
104463,25,2016-03-09,MapR大資料融合平臺正式上市，每秒可處理近2千萬筆訊息,MapR更新旗下融合資料平臺（Converged Data Platform），加強容器（Container）、安全性、資料治理等功能，並整合Myriad，打通YARN和Mesos間資源共享的阻礙。," Hadoop企業版發行商MapR於3月8日宣布，旗下融合資料平臺（Converged Data Platform）正式上市，並加強Docker容器（Container）、安全性、資料治理等功能。另外，此平臺現在也包含了開源Hadoop專案Apache Myriad，讓叢集管理工具YARN和Mesos間共享資料中心的資源，並支援多租戶環境。
MapR融合資料平臺將Hadoop和Spark、網路規模（Web-Scale）的儲存、NoSQL、資料串流功能等整合到一個統一的叢集，提供用戶可以部署即時資料應用程式。而該平臺主要由大資料事件串流系統MapR Streams、NoSQL資料庫管理系統MapR DB，以及基於POSIX檔案系統型態的儲存系統MapR FS所組成。
在這次的更新中，MapR透過狀態資料（Stateful Data）來加強Container與持續儲存（Persistent Storage）的互動，而狀態資料就是指資料的背景，舉例來說，顧客的銷售歷史記錄，每個重要資訊構成了歷史記錄，歷史記錄則構成了資料背景，而此資料能供應用程式持續檢索。另外，融合資料平臺之於Docker Container就像資料服務層，提供Container分散式且彈性的儲存，也包含容器化（Containerized）應用程式所需的資料庫和訊息與串流功能。
在安全性方面，融合資料平臺現在利用存取控制運算式（Access Control Expressions，ACE）來描述使用者存取的資料權限，根據MapR，ACE讓系統管理員可用1～2行的程式碼，就能描述指定的存取權限。而除了ACE外，MapR也在MapR Volume多加一層資料檔案的防護，加強多租戶控制，以確保資料僅供指定群組存取。
而在效能的部分，研究機構ESG進行MapR Streams的基準測試，結果顯示在每秒3.5GB的吞吐量下，每秒可處理超過1.8千萬筆訊息。另外，MapR DB現在支援原生JSON文件儲存格式，使用者可在SSD中，透過平行I/O即時存取NoSQL資料。
",https://www.ithome.com.tw/news/104463,"新聞,MapR,Converged Data Platform,Container,大資料平臺"
104342,25,2016-03-05,走向商業應用，Docker推容器資料中心,從工具提供者走向解決方案提供商，Docker推出自家的Container管理平臺Docker Data Center（DDC），能讓企業在虛擬私有雲或是就地部署容器即服務，提供安全的應用程式開發環境，讓開發者自助式地開發、部署應用程式," 不讓雲端供應商AWS、Google及微軟專美於前，Docker也在近日推出了自家的Container管理平臺Docker Data Center（DDC），從工具提供者，逐漸走向解決方案提供商。
過去PaaS跟IaaS是壁壘分明的兩種雲端服務層，但用Container技術來建立的雲端服務層，相當於是IaaS層的上端與PaaS層的下端，形成了一個介於基礎架構及平臺服務間的交集，而這也是目前廠商正在角力的容器即服務（Container as a Service，CaaS）市場。
DDC提供企業就地部署CaaS的能力
Docker新推出的DDC，能讓企業在虛擬私有雲或是就地部署容器即服務，提供安全的應用程式開發環境，讓開發者自助式地開發、部署應用程式。同時，DDC也整合了目前Docker的商業解決方案，如Docker認證儲存庫DTR以及通用控制平臺UCP。
《Docker源碼分析》作者DaoCloud軟體工程師孫宏亮表示，IaaS使用資源的形式，必須按照需求進行分發與管理。而CaaS意味服務可以透過Container的形式進行及管理，而目前公有雲廠商如AWS、Google及微軟也紛紛搶進容器服務的市場。不過，孫宏亮認為，CaaS除了滿足Container所有的需求，例如運算單位的安全性、效能，以及隔離需要考慮外，應用程式主機的認證、負載等需求也必須被滿足。
Docker從工具提供者走向商業應用
孫宏亮認為，Docker推出DDC的策略布局，帶著走入市場的商業意圖。他表示，在過去兩年間，Docker以及Docker生態系提供了許多基礎工具，為企業貢獻許多Container技術以及應用變革的理念。
不過，「Docker走向商業化路線，似乎也是必然。」他表示，Docker眾多的革新工具與想法，唯有通過企業願意用於正式環境的考驗，才能為未來的技術發展鋪下好的基礎。
孫宏亮解釋，Container生態系發展至今，大致有兩大發展方向，第一類是以Docker為首的生態系，目標為發展、開發基礎的Docker原生工具。第二類則是以應用程式調度編排管理為目標的Container調度工具，如Kubernetes、Mesos及Marathon。
而Docker的發展方向，類似於以前VMware的vSphere，試圖從提供工具作為第一步，逐漸走入企業市場。
目前Docker推出的商業解決方案，如Docker認證儲存庫DTR、通用控制平臺UCP及DDC。為了具備提供完整解決方案的能耐，孫宏亮認為，目前Docker還必須補齊對於應用程式的管理及比方說負載平衡及測試管理工具。
而DDC是否為Docker走向商業化的關鍵的一步？孫宏亮認為未必，雖然DDC是較為完整的產品形態。不過畢竟市場還有很多商機，而業界導入Container技術的程度，或是Docker的商業策略，都會影響企業決定是否要採用Docker。但是Docker推出DDC的這步棋，讓其進軍商業市場的方向變得更加清晰。
",https://www.ithome.com.tw/news/104342,"新聞,Docker,Container,Docker Data Center"
104376,25,2016-03-04,Container雙周報第4期：Docker推出容器資料中心，提供企業視覺化介面管理內部容器,重點新聞（2月20日-3月4日）," 重點新聞（2月20日-3月4日）
·Docker推出容器資料中心，提供企業視覺化介面管理內部容器
不讓雲端供應商AWS、Google及微軟專美於前，Docker也在近日推出了自家的Container管理平臺Docker Data Center（DDC），從工具提供者，逐漸走向解決方案提供商。
Docker新推出的DDC，能讓企業在虛擬私有雲或是就地（on-premises ）部署容器即服務，提供開發安全的應用程式環境，讓開發者自助式地開發、部署應用程式。同時，DDC也整合了目前Docker的商業解決方案，如Docker認證儲存庫DTR以及通用控制平臺UCP。更多資訊
·Rancher執行長：CaaS讓企業可以在公有雲或私有雲上部署容器化應用程式
「容器即服務（CaaS）是一個重要的觀念。」Rancher執行長梁勝表示，在過去一年中Rancher持續推行著CaaS。他也認為，CaaS讓企業具備在公有雲、私有雲上部署容化應用程式，「CaaS可以獨立於基礎建設之上，而CaaS也包含了如Swarm及Kubernetes此類強大的容器調度工具。」
梁勝認為，Docker近日推出的容器服務將會迅速的催化市場發展，並且讓Rancher此類的平臺業者得利。他解釋，由於企業會感受到必須得開始部署CaaS，因此會開始尋找像是Rancher此類的開源產品。
·Docker Cloud問市！Docker併購Tutum結果揭曉
Docker去年10月併購容器線上管理服務公司Tutum後，Tutum共同創辦人Borja Brugos近日宣布正式推出Docker Cloud雲端服務。
Docker Cloud是在Tutum原本的服務之上，進一步整合Docker Hub、Docker ID、Docker Repository及商業版Docker引擎（CS Engine），此外亦提供Docker Cloud討論區，提供用戶相關討論服務。
Borja Brugos表示，Docker Cloud讓使用者只要按幾個鍵，在幾秒鐘內就能部署或擴展雲端應用程式，並且提供持續整合、自動組建、測試與部署等自動化流程，而且，不論是開發者或營運者，都能透過REST API或指令介面來管理服務，而視覺化介面亦可讓管理者完整掌握容器基礎架構。
他同時也透露Docker Cloud接下來的發展，他表示下個月應該可以提供企業協同作業所需的功能。為了推廣Docker Cloud服務，Docker公司現在免費提供一個節點與私有Repository，超過一個節點則以每節點每小時0.02美元計價。更多資訊
·《Docker源碼分析》作者：DDC的推出，顯示Docker逐漸進軍商業市場
《Docker源碼分析》作者DaoCloud軟體工程師孫宏亮認為，Docker推出DDC的策略布局，帶著走入市場的商業意圖。他表示，在過去兩年間，Docker以及Docker生態系提供了許多基礎工具，為企業貢獻許多Container技術以及應用變革的理念。而Docker的發展方向，類似於多年前的VMware的vSphere，試圖從提供完整工具作為第一步，逐漸走入企業市場。
「Docker走向商業化路線，似乎也是必然。」他表示，Docker眾多的革新工具與想法，唯有通過企業願意用於正式環境的考驗，才能為未來的技術發展鋪下好的基礎。
孫宏亮解釋，Container生態系發展至今，大致有兩大發展方向，第一類是以Docker為首的生態系，目標為發展、開發基礎的Docker原生工具。第二類則是以應用程式調度編排管理為目標的Container調度工具，如Kubernetes、Mesos及Marathon。
·小蝦米對抗大鯨魚，VMware違反GPL授權案在德國法院召開聽證會
去年VMware遭Linux核心開發者Christoph Hellwig控告，指控VMware旗下產品ESXi沒有遵循GPLv2授權中必須釋出開放源碼的規定，因而侵犯到Christoph Hellwig的著作權。此案也在上周（2/24）於德國法院召開聽證會，知名Linux開發者及GPL推動者Harald Welte也到了現場，記錄他在現場的聽聞。Harald Welte表示，如果未來有任何的相關判決結果出爐，其法律效力則限於德國地區。
Harald Welte表示，法庭上花了許多時間爭論，究竟Christoph Hellwig持有包含著作權素材（copyrighted materials）是否充足。而Harald Welte認為，無論Christoph Hellwig在Linux專案中的貢獻度為何，此案爭議則是Christoph Hellwig的著作權物出現在VMware ESXi中。更多資訊
·NSX部門掌門人換班，SDN之父Martin Casado離開VMware
打造出VMware網路虛擬化平臺NSX的關鍵人物Martin Casado近日離開VMware，準備轉移跑道至創投公司Andreessen Horowitz。在2014年Martin Casado曾表示，網路虛擬化產品至少還要3到4年才會成熟，意即2017或2018年。但是現在NSX還未到Martin Casado所預估的成熟時間，他已經先離開了VMware。 

VMware高層近年離職消息不斷，例如去年8月，VMware聯手EMC創辦的大資料平臺Pivotal執行長Paul Maritz也宣布離職。原本任職VMware執行長的Paul Maritz，但是由於擔負EMC搶進PaaS市場的責任，才轉職於Pivotal，而此次的Martin Casado則是一手催生NSX的關鍵人物。更多資訊 
·Kubernetes創辦人談原生雲端計算
「必須處理大量資料流量的複雜性應用程式，已經迫使我們必須採用新的方法、架構。」Kubernetes共同創辦人Craig McLuckie表示，業界開始稱這類新方法為原生雲端運算（ Cloud native computing）。
Craig McLuckie認為，原生雲端運算與過去的傳統方式總共有三大核心差異：容器化封裝（Container packaged）、動態化管理及微服務導向。更多資訊

產品動態
·Docker推出容器資料中心DDC更多資訊
·Joyent推出應用程式容器化工具Containerbuddy1.0更多資訊
·Docker雲端服務Docker Cloud更多資訊
·讓Docker容器執行更新工作的調度平臺Menagerie更多資訊
Container資源
※知識：Docker Networking介紹
※影片：Docker Compose及Docker Networking功能介紹
※How-To：利用Docker，10個步驟部署Elasticserarch
※How-To：用Windows本地端運作Docker Swarm
※How-To：結合Python及Docker
※How-To：用Puppet安裝Docker通用控制平臺
※How-To：在Docker Cloud上運作應用程式
※How-To：把Rails應用程式遷移至Docker
※How-To：結合Golang及Docker運作測試環境
※How-To：利用Docker快取機制加速Build程序
",https://www.ithome.com.tw/news/104376,"新聞,Container,Rancher,Kubernetes,容器技術,Docker,Pyton,ASP.NET,Joyent,IT周報"
104313,26,2016-03-03,思科技術長Zorawar Biri Singh：容器技術竄起，將迫使公有雲服務量5年內減少3成,思科技術長Zorawar Biri Singh日前出席思科年度合作夥伴高峰會時表示，容器技術的竄起，將掀起新一波公有雲服務出走潮，促使越來越多企業改把原本放置於公有雲的業務，逐漸轉移至企業資料中心內部署，來提供服務。," 近期十分火紅的容器（Container）技術，不只越來越多雲端企業要採用，連網通巨頭思科（Cisco）也都看好未來的容器技術發展。思科技術長Zorawar Biri Singh今日（3/3）參加思科年度合作夥伴高峰會（Cisco Partner Summit 2016）時表示，容器技術的興起將對於傳統就地部署的資料中心具有關鍵性的影響，促使越來越多企業改把原本放置於公有雲的業務，逐漸轉移至企業資料中心內部署，來提供服務。
儘管Zorawar Biri Singh去年8月才正式接下思科技術長一職，上任至今還未屆滿1年。不過他在思科夥伴高峰會上也揭露他對於新興網通技術的最新趨勢觀察。他認為，隨著Container技術竄起，將掀起新一波公有雲服務出走潮，迫使公有雲服務量（public cloud workloads），5年內將大幅減少3成，取而代之的是，越來越多的企業客戶會選擇自建基於容器部署的資料中心，來提供企業內部服務。
因為，他說，靠著如Docker這類以應用為主的容器技術所搭建而成的基礎設施架構，企業將可以小規模的方式很快在資料中心部署所需的應用，當企業能更簡易的利用容器技術在資料中心開發和部署應用時，對於許多企業來說，原本大規模採用部署在公有雲的服務，將會變得越來越不具有經濟效益。
「這對於思科的網通業務來說，某種程度也將帶來更大的營收成長」。不過，Zorawar Biri Singh表示，在傳統網通業務外，思科也正積極朝向更加注重企業IT服務的方向轉型，並也持續和合作夥伴來推出新的產品和服務，包括了安全、儲存和分析等相關產品。
Zorawar Biri Singh認為，這樣的轉變將有助於會促使思科從原先以端點到端點的資料傳輸為主的核心網通業務，開始轉而逐步朝向提供更安全資料處理和資料分析的業務前進。
不過，從現有網通設備市場來看，思科仍然獨佔鰲頭。根據市場研究機構Synergy Research調查顯示，思科2015年仍占有全球將近6成（56%）的交換器與路由器市場，且不論是在企業級的乙太交換器、路由器或是服務供應商路由器的市占也都大幅領先其他對手。
",https://www.ithome.com.tw/news/104313,"新聞,思科,Container"
104151,26,2016-02-29,IT月報｜雲端IT焦點回顧 (2016/2),Google旗下AdWords的Display Network及DoubleClick Digital Marketing將推動100% HTML5政策，6月30日起將不再接受新的Flash格式展示廣告," Google七月起推動100% HTML 5政策，禁止上傳Flash展示廣告
Flash末日再近一步。Google宣佈自7月後，將不再接受Flash展示廣告，所有廣告必須100%使用HTML 5格式。
Google兩年來分階段推動限縮政策。去年初該公司推動將Flash廣告格式自動轉為HTML5，年中時又預設Chrome瀏覽器暫停非於網頁中央的Flash廣告。Google 表示，為了持續改善行動用戶的上網體驗，現在旗下AdWords的Display Network及DoubleClick Digital Marketing兩個廣告通路將推動100% HTML5政策。（詳全文）
 
行動版Skype的群組視訊功能上線了

（圖片來源／Skype）
Skype 2/18宣布，支援Android與iOS等行動平台的群組視訊功能正式上線了，初期將先部署於西歐及北美市場，預計今年3月完成全球部署。
行動版的群組視訊可切換多種操作介面，例如以格狀展示各個與會的人，或是自動對焦正在說話的人，也能鎖定特定與會人士。
Skype兩年前先推出支援桌面的群組視訊功能，在增添對行動平台的支援之後，各方的Skype用戶不論是透過桌機、筆電、手機或平板電腦都能參與群組視訊，而且最多可支援25人同時視訊。（詳全文）
 
無伺服器架構新選擇，Google Functions平臺低調亮相
挑戰AWS的無伺服器（Server-less）雲端服務Lambda，Google也悄悄發布了Google Functions雲端服務預覽版。
開發者不需要使用VM來建立雲端執行環境，也能在雲端部署一支用JavaScrpit寫的小程式或程式函式，等到特定事件發生時再驅動。Google Functions上的任何程式都將在Node.js runtime中執行。（詳全文）
 
紐約市的免費Wi-Fi上網服務LinkNYC正式登場

（圖片來源／NYC）
美國紐約市的免費Wi-Fi網路服務在 2/18正式登場了，此一名為LinkNYC的專案是將紐約舊有的電話亭變身為Wi-Fi服務站（Wi-Fi Kiosk），提供免費的Wi-Fi網路服務、免費的國內電話、2個USB充電埠、一個可聯絡緊急服務的911按鈕，以及一台可用來連網的平板電腦。
LinkNYC專案是由Intersection、Qualcomm與CIVIQ Smartscapes聯手開發及營運，營收全仰賴廣告，提供全紐約市免費的公共Wi-Fi網路，可望造福當地居民及遊客。（詳全文）
 
IBM重砸26億美元併購雲端健康分析平臺

（圖片來源／IBM）
IBM於2月18日宣布，計畫以26億美元（約臺幣780億元）併購雲端醫療保健資料分析公司Truven Health Analytics（簡稱Truven），這將為Watson Health健康事業部門的健康資料儲存庫（Repository）帶來超過8,500家來自醫院、政府、企業雇主、診所、生技公司等的醫療保健資料，IBM打算利用Watson的認知運算能力，來協助專業人士增進醫療成果、保健品質、控制成本等。而IBM預計在今年年底完成這起併購案。（詳全文）
 
紅帽企業級Linux登上微軟Azure市集

（圖片來源／Microsoft-Azure Marketplace）
微軟 2/17宣布，紅帽的企業版Linux（Red Hat Enterprise Linux，RHEL）實例正式登上Azure市集（Azure Marketplace），雲端容器服務Azure Container Service進入公開預覽，亦開始支援WalMart所使用的雲端管理平台OneOps。
微軟在去年11月便宣布與紅帽結盟，準備把RHEL列為Azure企業Linux的首選平台，且由雙方共同提供技術支援，當時雙方已允許用戶將RHEL訂閱轉移到Azure，並於近期直接在Azure市集上供應RHEL。（詳全文）
 
IBM推出區塊鏈雲端服務，並貢獻4.4萬行區塊鏈程式碼

（圖片來源／IBM）
IBM宣佈多項和區塊鏈（blockchain）有關的服務和計畫，包括針對開發人員設計的區塊鏈即服務（Blockchain as a servive），以及為Linux基金會的Hyperledger專案貢獻近4.4萬行程式碼等。
新的區塊鏈即服務是建立在IBM雲平台Bluemix之上的新服務，可讓開發人員建立與管理區塊鏈網路來執行分散式分類帳（ledger）應用，他們可建立數位資產及相應的業務邏輯，並傳送給經許可的區塊鏈測試網路中的成員。（詳全文）
 
Google雲端視覺分析服務Cloud Vision展開公測，3月正式上線

（圖片來源／Google）
Google 2/18宣布旗下的雲端視覺服務（Google Cloud Vision）邁入公開測試，開發人員可利用Google釋出的Cloud Vision API來分析圖片，同時Google也公布了Cloud Vision服務的售價，正式服務預計於3月1日上線。
Cloud Vision結合了各種機器學習模型來理解圖片的內容，它可快速將圖片歸類，並偵測每張圖片中的物件與人臉，或是讀取照片中的文字，開發人員可藉由Cloud Vision API將視覺分析功能整合在各種應用中。（詳全文）
 
Amazon併購義大利高效能運算公司，AWS服務瞄準HPC族群

（圖片來源／Nice）
亞馬遜繼2015年9月併購影片技術公司Elemental Technologies後，日前更宣布，與義大利軟體開發商Nice正式簽署併購協議，而這是亞馬遜近半年來第二起軟體商併購案，預計在3月完成交易。
Nice也是一家雲端運算廠商，提供網格入口網站（Grid Portal）和雲端服務，使用者可以優化且集中化高效能運算（High-Performance Computing，HPC）和視覺化工作量（Visualization Workloads），同時也提供工具讓使用者可以用行動裝置遠端連線作業。（詳全文）
 
微軟IoT Hub雲端服務全面上市

微軟宣布，Azure IoT Hub雲端服務在2月4日全面上市（General Availability，GA），協助企業蒐集、管理和處理從物聯網裝置上所產生的資料。同時，也宣布和研華、Dell、HPE和Libelium合作Azure IoT認證專案。（詳全文）
 
IBM大採購，併購三家公司強化數位行銷、IoT及雲端服務

農曆年前大量採購是華人的節慶習俗，但藍色巨人IBM也巧合在羊年的倒數時刻，宣佈併購兩家數位行銷公司Aperto與Resource/Ammirati，以及天氣風險管理公司The Weather Company的雲端、行動與B2B業務。
IBM在2月2日宣布買下德國數位廣告代理商Aperto，並將整合入IBM近來加碼投入的互動體驗顧問服務部門IBM iX，以求提升在行動App與其他數位產品的相關設計服務水準。（詳全文）
",https://www.ithome.com.tw/news/104151,"新聞,Cloud,雲端"
104029,26,2016-02-22,Google客製化VM正式上線，可改按分鐘計價,使用者可以根據自己需求，搭配VM的vCPU及記憶體，而Google也表示，使用除了Google Compute Engine外，Google Container Engine及Deployment Manager也可以支援客製化VM。," Google客製化VM在近日正式推出，讓使用者可以根據自己需求，搭配VM的vCPU及記憶體。而Google也表示，使用客製化VM的企業平均都節省了19％的運算成本。此外，除了Google Compute Engine外，Google Container Engine及Deployment Manager也可以支援客製化VM。
Google表示，客製化VM將傳統的IaaS變得更為彈性，讓企業得以依照使用資源的多寡進行付費。Google舉例，客製化VM的計費時間以10分鐘起跳，如果只有使用2分鐘，則會被收取使用10分鐘的費用。然而，只要使用超過10分鐘，則開始以分計價。但不滿1分鐘也會自動進位，例如使用時間為11.25分鐘，則會被收取12分鐘的費用。
另外，Google也列出目前客製化VM的收費。在亞洲區的用戶，vCPU及記憶體每小時的費用，分別為0.03841美元及0.00515美元（每GB）。而如果採用預留（preemptible）計價的方案，vCPU及記憶體每小時的費用，則為0.01103美元及0.00172美元。
目前客製化VM每個vCPU最高可以支援至6.5GiB，而每個VM最多支援至32個vCPU。而使用者可以選擇的作業系統則包含CentOS、CoreOS、Debian、OpenSUSE、Ubuntu、Red Hat及Windows作業系統。
Google表示，在去年11月推出Beta版本後，如Wix或是資料平臺商Lytics，分別省下了18%及20％的運算成本。
",https://www.ithome.com.tw/news/104029,"新聞,google,VM,Container,GCE,公有雲"
103823,26,2016-02-20,製造業也要積極上雲端，車王電子高度雲端化的下一步是大資料應用,車王電子在數位轉型上特別積極，不但因應外地使用需求將主要系統都上雲端以方便資料整合，更有高達6成IT平臺皆以行動、雲端、社交、大資料為主，遠高於企業整體平均的1成多," 講到企業數位轉型，製造業普遍被認為是較保守的產業，不過，在本次iThome CIO大調查中，我們也發現幾個起步快且高度雲端化的企業案例，如車王電子。車王電子在數位轉型上特別積極，從產品開發管理到各項簽核表單都已經全面數位化、無紙化，並大量使用雲端基礎架構，下一步則瞄準大資料分析應用。目前，他們有高達6成應用屬於以行動、雲端、社交、大資料為主的第三代IT平臺，遠高於此次CIO大調查其他企業的平均值（17.9％），且只有7.7％企業有過半應用屬於第三代IT平臺。車王電子資訊部經理賴昶予表示，他們的第三代IT平臺占比還會繼續成長。
賴昶予表示，由於車王電子在美國、英國都有子公司，目前他們除了郵件服務，其他所有系統都已經上雲端，包括ERP、BI系統也都只有一套讓所有人共用，這麼做是要讓應用面更單純，不需要每個地方都有一套系統，資料整合也較容易。不過，這麼做也有一定的門檻和風險，賴昶予表示，雲端服務的主要門檻在於雲端環境穩定性是否夠高，且系統回應速度也要在合理範圍內，這樣各地區才會願意把系統放上雲端。而現階段車王電子仍以私有雲為主，賴昶予表示，他們正評估是否採用公有雲，朝混合雲架構邁進，有意將一些備援方案，或是B2B網站服務，放到外部公有雲上，考慮採用公有雲的主要原因是想利用外部儲存空間，也將評估其安全性和資料整合度。
在高度雲端化的同時，車王電子也一併將所有的系統資料數位化，接下來，他們要做的是大資料應用。賴昶予表示，第二代IT平臺與第三代IT平臺主要差異，在於高度智慧化，目前做的資料分析大多還是針對已經發生過的資料，但是車王電子更想做的事情，是從既有資料，推導到後續的預測模式，如報價模擬、銷售預測、庫存預測，最終希望做到創新服務、降低成本，產生更大銷售額。因此在大資料應用方面，他們目前已經在資料蒐集的階段，從產品面和IoT機臺這兩大面向進行資料蒐集，並持續在增設感測器，下一步便要採用現成的大資料分析平臺，賴昶予表示，以他們的需求和現有IT人力，不可能花太多時間驗證技術可行性，重要的是要將平臺快速建起來，開始蒐集、分析資料，才能做後續的產品面應用。
 相關報導 
【iThome 2016年CIO大調查｜雲端企業時代來了】
【iThome 2016年CIO大調查IT投資篇｜CIO看2016】
「iThome 2016年CIO大調查：資安應用篇｜臺灣資安數據大解密」
",https://www.ithome.com.tw/news/103823,"新聞,CIO大調查,IT投資,IT預算,雲端投資,雲端,Cloud,車王電子"
103986,26,2016-02-19,Container雙周報第3期：Docker Hub下載次數突破20億次,"Docker更表示，甚至光是在今年1月的下載次數，就占了過去累積三年的15％。最多人下載的Docker映象檔可不是Ubuntu，而是號稱嵌入式Linux瑞士刀的Busybox（6,860萬次）"," 重點新聞（2月6日-2月19日）
·Docker Hub下載次數破20億次，每分鐘下載次數高達7,000次
根據Docker官方統計，提供Docker映象檔儲存服務的Docker Hub，累計下載次數已經超過20億次，光是在今年1月，每一分鐘內下載的映像檔次數就高達7,000次。
Docker更表示，甚至光是在今年1月的下載次數，就占了過去累積三年的15％。Docker則認為，這些跡象都代表Docker目前正是一個蓬勃健康的生態系。Docker更表示，未來也會在Docker平臺中加入一鍵部署及安全性掃描的功能。更多資訊

Docker更表示，甚至光是在今年1月的下載次數，就占了過去累積三年的15％。圖片來源：Docker

·Docker疑似要將官方映像檔從Ubuntu改為Alpine Linux，引起網友熱議
ID署名shykes的網友，在國外知名技術論壇Hacker News上表示自己在Docker工作，更宣稱Docker官方映像檔將從Ubuntu改為Alpine Linux。
此討論串會引起熱議並非沒有理由，由於shykes正是Docker技術長Solomon Hykes的名稱縮寫。而這名為shykes的網友更透露，目前Docker已經雇用了Alpine Linux的發明人Natanael Copa。不過目前Docker並沒有證實這些消息。更多資訊
·持續整合廠商Codeship推出支援Docker的CI平臺Jet
Codeship為持續整合（CI）及持續交付（CD）工具，並且AWS跟Heroku雲端環境整合良好，是許多工程師推薦的DevOps利器。而在近日，Codeship更宣布推出支援Docker的CI工具Jet。
Codeship技術長Florian Motlik表示，過去Codeship的基礎架構，已經內建許多工具及語言，但是這樣的缺點在於，相比使用者自己的系統，開發者對於Codeship的掌握度較差。
Florian Motlik認為，使用者對於系統的掌握度，不僅只是上面安裝的軟體，同時也要知道如何設定基礎架構。因此，Codeship讓使用者可以透過Docker及Dockerfiles，或是Docker Hub建立專屬的Container。更多資訊
·微軟搶進Container服務，推出Azure Container服務預覽版本
微軟也搶進了容器服務市場，在近日推出了Azure Container服務預覽版本。微軟表示，除了加強對開源生態系的貢獻外，也繼續將開源整合到產品中，藉以精進自家的產品項目。
Azure專案管理總監Corey Sanders表示，透過Docker及Mesosphere，使用者可以在Azure VM叢集上部署、調度及管理容器化的應用程式。另外，藉由開源元件，使用者可以更加簡單地創造、管理Azure VM叢集。
微軟在推出容器服務預覽版本的同時，也宣布使用者可以透過Azure Marketplace部署Red Hat Enterprise Linux主機。更多資訊
·Docker Hub最多人下載的映象檔是什麼？前三名為Busybox、Ubuntu及Nginx
據Docker統計，下載超過200萬次的Docker映像檔中，官方儲存庫的下載次數即占了其中20％。其中下載次數最多的前三名分別是號稱是嵌入式Linux瑞士刀的Busybox（6,860萬次）、作業系統Ubuntu（4,090萬次）及網站伺服器Nginx（2,550萬次）的官方映象檔。
上了前十名俱樂部的還有Docker Swarm、Docker Registry、Redis、MySQL、MongoDB、Node.js及PostgresSQL。目前Docker總共有93個官方儲存庫。更多資訊

目前Docker官方儲存庫下載的前三名分別是Busybox、Ubuntu及Nginx。

·Google客製化VM推出正式版，平均節省19％的運算成本
近日Google客製化VM終於正式推出，讓使用者可以根據自己需求，搭配VM的vCPU及記憶體。除了Google Compute Engine外，Google Container Engine及Deployment Manager也可以支援客製化VM。
目前客製化VM每個vCPU最高可以支援至6.5GiB，而每個VM最多支援至32個vCPU。而使用者可以選擇的作業系統則包含CentOS、CoreOS、Debian、OpenSUSE、Ubuntu、Red Hat及Windows作業系統。
Google表示，在去年11月推出Beta版本後，如Wix或是資料平臺商Lytics，分別省下了18%及20％的運算成本。更多資訊
·rkt推出 1.0版本，CoreOS表示此版是為安全所設計的Container引擎
CoreOS推出了rkt 1.0版本，並表示此版本是為了安全性、效能及可組合性所設計的Container引擎。
CoreOS執行長Alex Polvi表示，rkt 1.0加強了安全性，例如以KVM為基礎的容器隔離、整合可信賴平臺模組（TPM），以及支援SELinux。
此外他也表示，雖然rkt有屬於自己的標準，但是同時也相容於Docker映像檔格式，這意味著使用者可以使用Docker進行建置（build），同時使用rkt運作。更多資訊
產品動態
·用Docker資料中心管理映像檔及 Container  更多資訊
·AWS Elastic Beanstalk支援Docker 1.9  更多資訊
·Twistlock推出免費Container安全套件  更多資訊
·用於正式環境的容器調度工具Marathon  更多資訊
·支援多語言的容器化環境Ironworker  更多資訊
·Codeship推出支援Docker的CI平臺Jet  更多資訊
·CoreOS推出rkt 1.0版本  更多資訊
·以Alpine Linux為基礎的Node.js Docker映像檔  更多資訊
·微軟推出Azure Container服務預覽版  更多資訊
·讓使用者自製第三方Docker授權套件的AuthZ  更多資訊
Container資源
※影片：在Docker Container上運作ASP.NET MVC 6應用程式
※影片：紐約Container高峰會議程影片全公開！
※知識：需要知道的Docker 1.10儲存功能
※How-To：用Docker及Grafana打造Stat儀表板
※How-To：重構Dockerfile減少映像檔大小
※How-To：將Jenkins服務遷徙至Docker
※How-To：把Nginx、Redis及ASP.NET核心放到Docker Container中
※How-To：在OSX上把GUI應用程式Docker化
※How-To：結合Docker、Tutum及Jenkins導入CI、CD

※How-To：在Nano Server上運作ASP.NET核心
※How-To：綜合Node.js 、 Docker 及NoSQL實作微服務架構 

※How-To：用Mesos部署ArangoDB儲存叢集架構
",https://www.ithome.com.tw/news/103986,"新聞,Container雙周報,Docker,Container,CoreOS,Twistlock,Mesos,Alpine,AWS,Azure,Jenkins,CI,CD,IT周報"
103788,26,2016-02-07,Container雙周報第2期：近1成臺灣中大型企業預計今年導入Docker,根據統計iThome 2016年CIO大調查顯示，有將近1成的臺灣中大型愈近在今年導入Docker，相比去年更暴漲了2倍之多," 重點新聞（1月23日-2月5日）
·近一成臺灣企業預計今年導入Docker，相較2015年成長了3倍
根據iThome 2016年2月針對380家臺灣中大型企業調查的結果，顯示今年整體有9.7％企業即將導入Docker，比起去年3.2％成長至3倍。在去年導入比例為0％的金融業，今年有3.7％的業者選擇使用，而醫療業則從去年的0％一舉拔升到13％。
值得注意的成長趨勢，還有一般製造業、高科技製造業以及服務業。若不將去年沒有導入Docker的金融業、醫療業列入計算，此3大類為導入Docker成長率的前三名。在去年一般製造業的導入率僅1.1％，今年則陡升至5.5％，成長了5倍；高科技產業去年有4.7％的業者導入，今年則有近2成（18.8％）業者開始採納，也有4倍的成長；服務業則從3.5％成長至7％，也有2倍漲幅。
最後，原本政府機關在去年以7.7％的Docker導入穩坐龍頭，今年只有「小」幅成長至10.3％，被高科技製造的高超導入率迎頭趕過。
·新春大改版！Docker體質大改造，1.10新版多項基礎檔案格式大更新
映像檔大變革的Docker 1.10終於正式釋出，另外也推出了可以部署更多複雜應用的新Compose格式、以及能跨映象檔共享同層設定的新manifest檔格式，這一個新版是從體質開始大改變。例如Docker 1.10版的Docker Compose目前可以調度（orchestrating）Container，並且設定網路及容量，因此使得運作分散式應用程式變得更加容易。Docker也表示，使用者可以在自己的開發設備上，設定多網路層（multiple network tiers）以及複雜儲存組態設定，並且從開發環境、Stage環境到正式環境都使用同一組設定。更多資訊
·Docker公司的前身dotCloud宣布在今年2月底結束營業
Docker在2014年時決定把平臺即服務dotCloud售出，全心投入Docker的開發。不過，近日dotCloud表示，因為母公司cloudControl破產，dotCloud的業務也預計在2月29日畫上休止符。由於dotCloud採用Heroku的buildpacks，為了避免用戶的資料遺失，dotCloud也建議用戶逐漸把資料移轉至雲端平臺業者Heroku。更多資訊
·Photon OS、Neo4j及Nuxeo正式加入Docker Library
Docker宣布，將輕量級作業系統Photon OS、圖像資料庫Neo4j及內容平臺Nuxeo的官方儲存庫加入Docker Library中。根據Docker統計，目前Docker使用者從官方儲存庫下載的次數已經達到3億次。更多資訊
·容器基礎架構商Joyent技術長批Unikernel不適正式環境，引起網友熱烈討論
Container技術架構商Joyent技術長Bryan Cantrill在Twitter發文，表示是否該寫一篇有關單序核心（Unikernel）不適用於正式環境的文章，連Docker技術長Solomon Hykes也表示感到好奇。而Bryan Cantrill在隔日也迅速撰文，表示他認為單序核心不適合正式環境的主要原因在於無法除錯。
Bryan Cantrill的文章在Hacker News論壇引起熱議，有人認為他提出狂妄的指控，卻並未任何提出任何證據加強自己的言論的說服力，比方說相關的benchmark測試數據。更多資訊
·Rancher推出Rancher Catlog，實現一鍵部署應用程式
近日Rancher推出了Rancher Catlog，將可以用於一鍵部署常用應用程式，例如Jenkins、MongoDB、Elasticsearch等。Rancher表示，透過此功能，使用者可以將這些常用應用程式部署在自家的基礎設施上，而Rancher則可以協助使用者調度Docker Container。更多資訊
·Docker表示，容器即服務將成為開發應用新平臺
Docker表示，在過去IT常常必須在控制（control）及敏捷（agility）之間進行抉擇，但是有了Docker之後，可以很輕鬆的與他人分享開發出的軟體，同時解決「在我的機器上可以跑」的老問題，讓應用程式與不同環境間不再存在衝突，也見間的讓開發者與維運者的關係變得更加密切。
然而，企業為了能夠延續開發、維運經驗，Docker認為必須開始導入使用Docker作為容器即服務（Container as a Service，CaaS）。Docker認為，容器即服務可以讓IT團隊，不管在何處都有建置、交付以及運作應用程式的能力。更多資訊
·Docker即將要過3歲生日囉！
Docker自2013年問世，今年也即將滿3歲了。今年為了慶祝Docker的生日，Docker也預計在3月21日至26日與各地社群合作，提供Docker新手的訓練課程。如果讀者所在鄰近的區域可以報名，不妨幫這隻游得越來越快的鯨魚一同慶生吧！更多資訊

為了慶祝Docker生日，Docker社群也在世界各地展開一連串的慶生活動。圖片來源：Docker

 
產品動態
·Photon OS、Neo4j及Nuxeo加入Docker Library  更多資訊
·用Rancher Catlog一鍵部署Jenkins、MongoDB等常見應用程式  更多資訊
·加速Contianer部署，Google結盟紅帽將推專用版OpenShift 更多資訊
·Joyent推出Triton命令程式列工具  更多資訊
·Marathon 0.15加強網頁介面及穩定性  更多資訊
·Calico釋出1.0版，推出支援Kubernetes的套件  更多資訊
·視覺化的Docker Container監控工具Meros  更多資訊
·以Docker為基礎的分散式爬蟲服務zerg  更多資訊
Container資源
※免費電子書：微服務應用程式及Docker Container
※影片：Rackspace架構師比較Docker、Mesos及Kubernetes
※投影片：用Metadata管理Container組態
※How-To：用Docker 1.9建置Elasticsearch叢集
※How-To：使用F#語言連接用Docker建立的Cassandra叢集
※How-To：結合Docker及Rails API建立微服務
※How-To：如何在Windows Server 2016中運作Docker Container？
※How-To：用Windows Sever 2016運作Docker化SQL伺服器
※How-To：建立小巧可靠的Docker映像檔
※How-To：將Ruby on Rails應用程式Docker化
",https://www.ithome.com.tw/news/103788,"新聞,Docker,Container,Kubernetes,Windows Server,周報,Container雙周報,IT周報"
103738,26,2016-02-07,微軟、SAP財報亮眼關鍵，雲端服務成IT廠商營收新推力,雲端服務成為IT廠商營收新動力，SAP 2015年財報顯示雲端訂閱與支援營收成長達110%，在做為SAP雲端銷售指標的雲端訂單上翻倍成長；而微軟2016年第二季財報也公布Azure成長140%，Office365成長70%," 微軟公布了該公司截至2015年12月31日為止的2016年第二季財報，顯示微軟該季創下238億美元的營收，淨利為50億美元，比前一年同期分別下滑10%與15%。
然而，微軟的雲端營收有顯著的成長，包括Azure成長了140%，Office365成長了70%，且營收高於分析師預期，還是讓微軟近期股價上揚了1.63%，收在52.06美元。
微軟於2016財年將營收來源分為三大類別，一是「生產力與業務流程」（Productivity and Business Processes），包含Office與Dynamics，其次為「智慧雲端」（Intelligent Cloud），內含雲端伺服器產品及服務，另一則是「更多個人運算」（Personal Computing），包含Windows作業系統、Surface、手機、遊戲與搜尋等。
「更多個人運算」在該季貢獻了127億美元的營收，下滑5%，「生產力與業務流程」貢獻67億美元，下滑2%，「智慧雲端」則締造63億美元的營收，成長了5%。而微軟營收的下滑有部份是受到美元上漲的影響。
其中，各種雲端服務無疑是微軟該季財報中表現最亮眼的，若不計算匯率的變動，Azure營收成長了140%，Office365營收成長接近70%，且訂閱Office365服務的消費者數量已達到2060萬。
微軟執行長Satya Nadella表示，全球企業透過微軟雲端服務作為改造企業的數位平臺，Windows10也已被部署在逾2億臺的裝置上。
在個人運算部份，Surface裝置營收成長了29%，然而微軟的手機營收卻下滑了49%。
根據市場研究機構Gartner去年第三季的調查，Windows雖然仍為第三大行動平臺，但市占率卻只有1.7%，遠遠落後Android的84.7%與iOS的13.1%。且從微軟的財報來看，去年第四季Windows市占率勢必再度下滑。
另外，全球商業軟體應用廠商SAP也在2015年財報顯示出在雲端運算業務獲得大躍進，不只在雲端訂閱與支援營收成長達110%，在做為SAP雲端銷售指標的雲端訂單上更獲得翻倍成長，遠超過現有仍占SAP營收大宗的商業軟體營收成長比例，是SAP去年增長最快的業務，甚至SAP更大膽預期2018年相關雲端收入將一舉超過商用SAP軟體的整體收入。
SAP大中華區首席營運長李漢麟表示，去年SAP在全球雲端運算服務營收獲得大幅成長，主要可歸功於來自3大雲端應用服務，分別是SAP人力資源解決方案Success Factors、採購業務平臺Ariba，以及SAP Cloud for Customer銷售解決方案。
他表示，這些雲端服務皆是屬於企業內部的非關鍵式應用，越來越多的企業開始願意將這些非核心的企業應用搬上雲端，來縮短應用導入時間和成本，也提高企業各部門業務執行的效率。文☉陳曉莉、余志浩
",https://www.ithome.com.tw/news/103738,"新聞,雲端服務,SAP,微軟,Cloud,Azure,Office365,Success Factors,Ariba,SAP Cloud for Customer"
103808,26,2016-02-07,新春大改版！Docker體質大改造，1.10新版多項基礎檔案格式大更新,新的映象檔ID編碼方式讓Docker更安全、新Compose格式可以管理更多複雜應用、新manifest檔格式能跨映象檔共享同層設定，這一個新版是從體質開始大改變," 映像檔大變革的Docker 1.10終於正式釋出，另外也推出了可以部署更多複雜應用的新Compose格式、以及能跨映象檔共享同層設定的新manifest檔格式，這一個新版是從體質開始大改變。
Docker 1.10版的Docker Compose有新的設定檔格式，可以建立更複雜應用程式的部署了，包括了調度（orchestrating）Container，設定網路及容量，因此使得建立分散式應用程式變得更加容易。甚至可以在自己的開發環境中上，設定多網路層（multiple network tiers）以及複雜儲存組態設定，現在可以從開發環境、CI、Stage階段到正式環境全程都套用同樣的設定檔。
Docker也更加強了安全性。Docker表示，Docker Engine 1.10則支援安全計算模式過濾（seccomp filtering），讓系統程序可以區分柏克萊封包過濾去（berkeley packet filter，BPF）以及系統呼叫。以及先前在RC版本，透過安全雜湊（secure hash）的機制，Docker得以透過映像檔的內容，為映像檔進行ID編號，也正式加入1.10版本中。  
在網路功能的方面，Docker則加入了許多使用者優先要求的功能。像是在網路中可以使用連結，讓使用者可以定義容器以及不同名稱主機的關係；在Container運作或是加入網路時，可以給予Container客製化的IP位址，以及現在多主機驅動程式現在也支援Linux 3.10之上的版本。
而新推出的Docker Swarm 1.1版本，只要偵測到運算節點失靈，Docker Swarm也會重新調度Container至健康的節點，確保應用程式繼續運算。不過Docker表示，目前這個功能是實現性質，目前可能還無法完美的運作。在Docker Registry 2.3版本中，Docker也支援新的manifest格式，讓不同的映像檔可以共同分享Docker Container中的Layer，因此可以增加使用者在儲存庫執行推（psuh）程序時的效能表現。
另外，Docker核心維護者Jessie Frazelle也預告，即將在未來的Docker 1.11版本中，也會加入程序ID控制群組（PID control group）的功能，將限定可以複製（fork）到cgroup中的程序數目。
",https://www.ithome.com.tw/news/103808,"新聞,Docker,Container,容器"
103628,26,2016-01-30,IT月報｜雲端IT焦點回顧 (2016/01),AWS韓國機房正式上線服務，雲端服務EC2展開新一波策略進行降價；微軟再槓上AWS，Azure運算雲服務降價最高17％；Amazon雲端郵件及行事曆服務WorkMail正式上線,"  AWS   VM 
Amazon迎新年，雲端服務EC2降價
日前，亞馬遜（Amazon）在官方部落格宣布，雲端服務EC2（Elastic Compute Cloud）從1月1日起開始降價，這是亞馬遜第51次的降價活動，這次降價的虛擬機器規格包含C4、M4和R3，三者搭載Linux作業系統的虛擬機器在需要時才開（On-Demand）、預留開啟（Reserved Instance）和獨立主機（Dedicated Host）的計價方式上皆有5％的折扣。（詳全文）
 
 Azure 
微軟再槓上AWS，Azure運算雲服務降價最高17%
雲端業者新一波降價競賽再次展開。微軟自二月起調降運算雲服務Dv2價格，依實例及用途而定，最多調降為17%，擺明挑戰Amazon EC2。
Dv2虛擬機器（Dv2 Virtual Machine）是為大量運算效能需求而設計的運算雲服務，採用Intel Xeon(Haswell)處理器，效能較Dv1虛擬機器快35%。在經過此次調降後，以美東區服務為例， Windows版效能較高的實例服務最多降價13%，而Linux版最多調降17%。（詳全文）
 
 機房   AWS 
AWS前進韓國，首爾機房正式上線服務
AWS在韓國首爾機房正式啟用，可提供EC2、EBS、虛擬私有雲、自動擴充、ELB等多項AWS服務。同時也啟用了韓國兩處Route 53、CloudFront的Edge機房。啟用韓國機房後，目前AWS全球Availability Zones服務區域（即服務機房）數量達到32處。（詳全文）
 
 Amazon   雲端郵件 
Amazon雲端郵件及行事曆服務WorkMail正式上線

Amazon WorkMail允許用戶自各種不同的客戶端程式存取雲端的郵件、通訊錄與行事曆，例如瀏覽器、Microsoft Outlook或Android/iOS平台上的郵件程式。標榜是個方便管理且具企業等級安全功能的雲端服務，同時整合了微軟的Active Directory目錄管理功能以利用戶透過既有的憑證登入。（詳全文）
 
 雲端安全 
爬網抓房仲資料提供查詢，住通遭判違反公平交易法得賠30萬元

用程式大量蒐集網路公開資料來牟利，即使不侵權，在特定案例上恐遭判違反公平交易法。
近日台灣房屋控告以會員收費制提供房仲資訊的住通搜尋系統，未經同意擅自取得臺灣房屋自行蒐集的房屋交易資料，恐讓民眾誤以為臺灣房屋與住通有合作關係，而對臺灣房屋構成「顯失公平」的情況，違反公平交易法規定，因而請求100萬元的損害賠償。（詳全文）
 
 資訊安全 
小心Android木馬偽裝33家網路銀行App伺機竊取帳密
資安業者FireEye警告，偽裝成正牌金融服務App的Android木馬家族SlemBunk危害程度與攻擊手法精細度超出原本的預估，至少已經有33個不同的金融相關App被發現遭到假冒，而且還被駭客用來作為未來持續攻擊的墊腳石，而非竊取單一帳號密碼而已。
FireEye在官方部落格公布該公司在2015年12月首度披露的Android木馬家族SlemBunk的後續研究結果，顯示此木馬家族不但只被設計用來釣魚騙取用戶金融機構的帳號密碼，其攻擊手法與攻擊鏈設計其實更為精細周全，整個惡意程式被拆成三個階段，並透過指令與控制伺服器(C&C Server)調整整個過程，讓一般的安全監控軟體不容易直接判斷其存在的安全威脅。（詳全文）
 
 影子IT   SaaS 
思科推出Cloud Consumption服務來偵測影子IT
Cloud Consumption主要的功用即在於偵測企業內部存取公共雲端的流量，再結合思科所提供的分析與標竿，將可協助企業更了解企業內部的影子IT現況，繼之有效地與各部門溝通，並降低安全風險及管理成本。（詳全文）
 
 OpenStack 
DevOps利器Ansible大改版，翻新任務執行模式還能管理OpenStack

DevOps自動化組態管理利器Ansible三年來首度大改版，推出了2.0新版。超過800人參與開發的2.0版，不只重構了程式碼，還新增了超過200個新模組。
新版最大特色之一是Task Blocks功能，提供了劇本式的多任務組合方式，和更動態的任務指派方式。新增的Task Blocks功能可以讓DevOps像安排劇本一樣地，組合多項任務來達成CI目的，甚至可以使用標籤和條件（conditional）來安排任務，訂定發生不同情況時要執行的對應任務。（詳全文）
 
 雲端市場 
研究機構：2015年全球雲端市場營收破千億美元

市場研究機構Synergy Research調查顯示，2014年第4季到2015年第3季間，全球雲端市場年營收達1.1千億美元，相較於2014年成長了28％。其中公共雲IaaS和PaaS基礎建設服務的年營收成長率高達51％。（詳全文）
 
 雲端硬碟 
Google Drive改善檔案管理，更直覺地新增或移動檔案
新的Google Drive檔案管理功能提供更直覺化的管理介面，瀏覽檔案時點選檔案就能「加入My Drive」中或是移到其他文件夾，搜尋時也可將搜尋到的檔案拖曳到文件夾中。（詳全文）
 
 協同服務 
Cisco推新雲端協同服務，訊息、會議、通話3功能大整併

思科（Cisco）在臺發表全新雲端協同合作服務思科Spark，將訊息、會議、通話這3大企業常用溝通工具整併至單一服務，把既有的通話與視訊會議服務通通搬上雲端，並開放應用程式介面（API）供開發者使用。（詳全文）
 
 
",https://www.ithome.com.tw/news/103628,"新聞,Cloud,雲端"
103597,26,2016-01-30,SAP將在臺推出工業4.0解決方案，引進HANA企業雲,2016年SAP在臺灣將推出針對工業4.0應用的解決方案，未來也計畫提供包括Ariba、SuccessFactors以及CRM等雲端解決方案，並結盟電信商引進HANA企業雲," 全球商業軟體應用巨頭SAP在最新公布的2015年財報顯示出在雲端運算業務獲得大躍進，不只在雲端訂閱與支援營收成長達110%，在做為SAP雲端銷售指標的雲端訂單上更獲得翻倍成長，遠超過現有仍占SAP營收大宗的商業軟體營收成長比例，是SAP去年增長最快的業務，甚至SAP更大膽預期2018年相關雲端收入將一舉超過商用SAP軟體的整體收入。
HR、採購和銷售雲端產品去年營收成長最快
SAP大中華區首席營運長李漢麟表示，去年SAP在全球雲端運算服務營收獲得大幅成長，主要可歸功於來自3大雲端應用服務，分別是SAP人力資源解決方案SuccessFactors、採購業務平臺Ariba，以及SAP Cloud for Customer銷售解決方案。他表示，這些雲端服務皆是屬於企業內部的非關鍵式應用，越來越多的企業開始願意將這些非核心的企業應用搬上雲端，來縮短應用導入時間和成本，也提高企業各部門業務執行的效率。他並透露，這3類雲端商業服務，也是目前在大中華地區增長最快速的雲端應用，而臺灣則以Ariba雲端採購應用成長最快。
儘管，企業對於要讓內部核心應用如ERP等上雲端，仍有諸多疑慮，但即便如此，李漢麟也認為ERP上雲端勢必也是未來企業迎向IT轉型的必然趨勢，不過對於SAP而言，他表示，未來公司並不會自建機房來提供雲端ERP服務，在策略上反而是傾向和其他合作夥伴協作來提供雲端服務，例如去年底SAP也與中華電信合作推出雲端ERP產品Business One，即是透過部署於中華電信的實體伺服器上來遠端提供ERP服務，此外，在中國方面，SAP目前也跟中國電信旗下的中數通信息合作，並也使用了中國電信的機房，來提供如SuccessFactors等雲端應用。
不過，對於SAP這幾年積極向雲端靠攏，甚至讓自己也要轉型成為一家雲端商業軟體應用公司，李漢麟也解釋，某種程度也是隨著近幾年雲端技術成熟，加上對於雲端安全保護也因而提升，使得市場對於雲端服務接受度普遍提高，因而越來越多企業開始嘗試利用雲端模式，來做為企業內部應用的方式。而這樣的改變也反映在企業IT主導權的轉移。李漢麟指出，傳統企業在做IT採購時，大多是由IT團隊來主導整個IT決策流程，但在雲端時代下，現在越來越多的企業反而是放手交由各業務部門來自行決定，比如說人力資源長、採購長會依照各部門應用需求來找尋合適的雲端應用模式，而不再全得經由傳統IT部門決定後才能執行，在業務推動上也就更有效率。
此外，新加入的雲端業務也增加了SAP在營收上更穩定的成長。李漢麟表示，有別於SAP傳統商業應用產品多是一次性的購買，企業後續再添購的機會其實不大，相形之下，近年來SAP大舉投入資源在雲端產品發展，則是提供企業新的一種雲端租用服務，只要這類雲端應用需求一直存在，企業每年都會持續租用下去。
李漢麟也表示，未來不管是SAP的ERP或CRM等商業軟體應用都將持續往雲端來靠攏，希望做到提供企業傳統就地部署之外的雲端新選擇。他也透露後續計畫將已在美國、歐洲上市的SAP HANA Enterprise Cloud服務也跟進在大中華地區推出，目前已積極尋覓具有電信級資料中心基礎設施規模和服務能力的合作夥伴，來共推企業雲應用。未來在雲端服務租用收費上，也將以用戶數、採用不同的應用模組和功能來彈性計價。
而對於2016年SAP在臺灣產品布局方面，SAP臺灣總經理謝良承則表示，除了將推出針對工業4.0應用的解決方案外，未來也將提供包括了Ariba、SuccessFactors以及CRM等的全方位雲端解決方案，並也將深耕中小型企業，提供包含SAP Business ByDesign及SAP Anywhere等雲端應用及管理服務，此外也將加強SAP在服務、製造、零售和金融等產業的HANA平臺應用，如大資料分析等，更將力推臺灣本土電子商務平臺的轉型。
不只有SAP過去一年在雲端業務繳出亮眼成績單，其他雲端服務業者也在這一波雲端風潮下獲得顯著成長。像是已在雲端打滾10年的亞馬遜AWS在去年首度揭露的第一季財報顯示AWS營收仍有近5成的成長，達到了15.66億美元，是Amazon單季成長最快的業務，即便微軟至今尚未公布Azure雲端業務的營收數字，但亦透露在2015年雲端營收上，較前年獲得135%的增長。
",https://www.ithome.com.tw/news/103597,"新聞,SAP,工業4.0,HANA,雲端服務,Cloud"
103427,26,2016-01-22,Container雙周報第1期：Docker人才需求今年爆增700倍,根據全球最大的職缺搜尋引擎Indeed搜尋資料，今年Docker相關職缺暴增了700倍," 重點新聞（1月9日-1月22日）
·Docker人才需求今年爆增700倍
從橫跨50個國家職缺搜尋引擎Indeed站上資料可以發現，Docker相關職務在今年爆增了700倍，這是Indeed蒐集數千個求職網站後的結果。
而Docker表示，這顯示企業逐漸加重在Docker方面的投資，而對於開發者、維運者，只要有開發、運作Docker化分散式應用程式的一手經驗，將會是絕佳機會。更多資訊

Docker引用工作搜尋引擎Indeed的報告，指出Docker人才今年需求將會成長700倍。圖片來源：Indeed

·Docker預測2016年Container技術5大趨勢
Docker映像檔的下載次數從2014年底至2015短短一年，就從6,700萬次陡升至12億次，而Docker企業行銷副總裁David Messina也點出Container技術在2016年的5大趨勢。
1.Container技術的應用將會急速成長。
2.應用程式將會定義一切。
3.容器即服務（Container as a Service）的興起，對於應用程式交付將會是一大助力。
4.開發（Dev）與維運（Ops）、敏捷（agility）與控制將會趨於平衡。
5.Container技術將會超越開發與測試，成為正式環境中的支柱。更多資訊
·Docker映象檔大變革，全新ID雜湊編碼，更安全也省空間
2016年才到不久，Docker就推出Docker Engine 1.10 RC版本，除替映像檔提供更好的安全基礎外，Docker也提供舊映像檔更新的搬遷步驟（migration step）。
Docker Engine 1.10版本將完全改變Docker Engine在本機儲存映像檔的方式。過去的映像檔都是隨機指派通用唯一辨識碼（Universally Unique Identifier，UUID）進行命名，而新版本透過則安全雜湊（secure hash）的機制，Docker得以透過映像檔內部的資料，為映像檔進行ID編號。更多資訊
·Docker買下Unikernel Systems，放眼通用核心應用
Docker宣布併購開發無核化技術的新創業者Unikernel Systems，替未來的通用核心應用布局。

Docker認為，集結程式運作所需作業系統功能無核化，在未來Container生態環境會是很重要的一環，而買下Xen專案及開放源碼虛擬化平台等開發先鋒所組成的Unikernel Systems，將為Docker帶來大量的知識與豐富的新一代架構技術。更多資訊

·網路虛擬化開源專案OPNFV董事表示，Container技術將成為網路虛擬化的關鍵要素
由Linux基金會及電信業者如AT&T、Docomo共同成立的開源專案OPNFV董事Heather Kirksey表示，Container技術將在網路虛擬化NFV平臺中，成為關鍵元件。她表示，Container技術目前相當的火熱，而這股熱潮也蔓延至NFV至SDN領域。許多網路業者也開始尋求更有效率的方式導入虛擬化網路功能（Virtual Network Function，VNF），而Container技術則提供了另一種透過VM，運行Guest OS的方法。更多資訊
·Google說明Kubernetes為何不用Docker網路套件Libnetwork
Kubernetes並未在Docker運行環境中使用Docker的網路模型Container Network Model（CNM）以及網路套件Libnetwork。Google工程師Tim Hockin則表示，Docker在網路驅動程式的基本設計概念上，對Kubernetes造成許多不便。
例如，Docker的本地驅動程式（如bridge），無法做到跨節點調度，或是Docker 1.8及1.9版本中，discovery功能在實作上有根本性的缺陷，導致Container中的/etc/hosts 文件損毀，而此discovery功能無法輕易的關閉。Tim Hockin表示，相較之下，CoreOS的網路套件Container Network Interface（CNI）的設計哲學比較符合Kubernetes，比起Docker的CNM來得簡單，也不需要Daemon程式。更多資訊
·DockerCon 2016找講者，徵求高手上臺！
2016年的DockerCon將在6月19日至21日於西雅圖登場，目前Docker也積極招募講者，希望高手能在DockerCon上，與會眾分享一線的實戰經驗及知識。
今年DockerCon關注的議題則包含Docker在多主機、多Container環境下的應用、企業如何在正式環境下使用Docker部署、Docker如何融入企業文化以及Docker在IoT方面的應用。更多資訊
產品動態
·AWS EC2開始支援Docker 1.9版 更多資訊
·AWS開源釋出支援Docker的EBS儲存擴充外掛Blocker更多資訊
·Marathon 0.14加強網路安全，為Container運作環境帶來更好的網路
Mesosphere釋出了工作排程系統Marathon 0.14版本，包含更簡潔的網路功能、加強網路安全以及服務發現（service discovery）。更多資訊
·Oracle推出Virtual Box 5.0.14版本
修改Linux Kernel 4.5的臭蟲，以及Mac OS X El Capitan版本中的USB Bug。更多資訊
Container資源
※免費電子書：透過Docker及Rancher導入持續整合、持續交付
※FAQ：超詳細Docker入門教學
※How-To：在Spring Boot框架中導入Docker
※How-To：英雄聯盟開發商用Jenkins控制Docker映像檔
※How-To：Docker結合Raspberry Pi打造閘道器
※How-To：用Travis CI進行Docker build測試
",https://www.ithome.com.tw/news/103427,"新聞,Docker,Container,Jenkins,持續交付,持續整合,AWS,Container雙周報,IT周報"
103305,26,2016-01-19,Docker映象檔大變革，全新ID雜湊編碼，更安全也省空間,從UUID隨機命名改由安全雜湊機制命名，其中關鍵差異在於，新版本映像檔ID全部都必須透過映像檔內部的資料來產生。因此，映像檔內容與映像檔ID，將會形成1對1的對應關係。," 2016年才到不久，Docker就推出Docker Engine 1.10 RC版本。而Docker表示，新版本Docker Engine能為映像檔提供更好的安全基礎外，Docker也提供舊映像檔更新的搬遷步驟（migration step），並且提供相關搬遷工具，將遷移時間降到最低。
Docker資深工程主管Arnaud Porterie表示，Docker Engine 1.10版本將完全改變Docker Engine在本機儲存映像檔的方式。過去的映像檔都是隨機指派通用唯一辨識碼（Universally Unique Identifier，UUID）進行命名，而新版本透過則安全雜湊（secure hash）的機制，Docker得以透過映像檔的內容，為映像檔進行ID編號。
著《Docker源碼分析》的孫宏亮解釋，Docker從UUID改由安全雜湊機制命名，其中關鍵差異在於，Docker每一層layer的映像檔ID，全部都必須透過映像檔內部的資料來產生，不再是使用過去的隨機UUID。他表示，藉由此方法，透過docker build建構映像檔時，映像檔內容與映像檔ID，將會形成1對1的對應關係。
由於每一個映像檔僅會產生一組獨特的ID，因此可以減少儲存同樣一份的映像檔，孫宏亮表示，對於減輕Docker Hub的儲存壓力也是大有好處。他也舉例，過去同一個Dockerfile，在10臺不同的機器上build，因為映像檔快取僅僅在本機端有效，因此將會產生10個內容相同，但是ID編號不同的映像檔。另外，由於是透過UUID產生隨機編號，如果這10臺機器，分別把這10份映像檔儲存到同樣的Doocker Registry，則會產生多餘的9份映像檔，因此也會對Docker Registry產生儲存上的壓力。
孫宏亮也解釋了為何新版Docker Engine使用雜湊機制的命名方式，將會比使用UUID命名映像檔來得更加安全。他表示，由於映像檔ID與映像檔內容所形成的1對1對應關係，如果有心人士只有偽造映像檔ID或映像檔其中之一，都無法成功。他解釋，對於單一映像檔，雖然可以同時偽造ID以及映像檔內容。但是映像檔間所形成的父子關係（parent），將會導致原有的子映像檔記錄的ID失效，因此仍然不可使用完整的映像檔，除非有心人士將某映像檔以及其所有子孫映像檔檔全部進行偽造，但是這樣所付出的成本非常高。
針對有升級需求的用戶，Docker也提供了前置作業的指南。Docker表示，如果要讓現有映像檔能符合新的運作方式，必須將現有映像檔的命名方式從UUID，改為由內容產生ID編號。而這也意味使用者必須計算目前檔案的安全總和檢查碼（secure checksum）。
Arnaud Porterie表示，Docker daemon首先會計算使用者目前檔案的安全總和碼，在開啟Docker daemon後，現有的映像檔、標籤以及Containers也會完成遷移，而所有的映像檔及標籤也都會配有新的安全ID。孫宏亮則認為，Docker使用者遲早必須導入這一步措施，而「長痛不如短痛。」他表示，由於新版本並不會改變映像檔內容，因此轉換過程可以透過離線作業完成，而開發人員也可以使用Docker 1.10來製新的映像檔。
不過孫宏亮也表示，新版本也會對於既有的維運團隊、開發團隊帶來衝擊。比如，舊映像檔與轉換後的新映像檔的標籤、儲存庫很有可能一致，進而產生了衝突問題，使用者也必須事先需要規畫相對應的轉換策略。同時他也認為，線上環境映像檔的更新會是一個值得關注的議題。儘管Docker Engine會為使用者帶來陣痛期，「但是不可否認，映像檔的大改，我認為是一個劃時代的功能，我個人非常喜歡。」孫宏亮表示。
",https://www.ithome.com.tw/news/103305,"新聞,Docker,Docker Engine,Container,映像檔"
103003,27,2016-01-11,Synergy：2015年全球雲端市場營收破千億美元,市場研究機構Synergy Research調查顯示，2014年第4季到2015年第3季間，全球雲端市場年營收達1.1千億美元，相較於2014年成長了28％。其中公共雲IaaS和PaaS基礎建設服務的年營收成長率高達51％。," 市場研究機構Synergy Research調查顯示，截至2015年9月為止，全球雲端市場在過去一年的營收達1.1千億美元，比2014年成長了28％。
Synergy調查了6大關鍵雲端服務，包含了公共雲IaaS／PaaS的基礎建設服務、私有雲和混合雲的基礎建設服務、SaaS雲端服務、整合通訊服務UCaaS、公共雲軟硬體基礎建設服務，以及私有雲軟硬體建設服務。
年營收成長最多的是公共雲IaaS和PaaS的基礎建設服務，達51％，微軟和Amazon主導了此市場，成長次高的是私有雲和混合雲的基礎建設服務，成長率為45％，由IBM和Amazon主導。而年營收規模成長了3成的SaaS市場則是由Salesforece和微軟把持。
儘管營收大幅成長，但根據Synergy調查顯示，在2014年第4季到2015年第3季間，雲端營運商和供應商在基礎建設上的軟硬體支出也超過了600億美元。不過，這些基礎投資也為雲端服務供應商帶來了200億美元的營收，這些服務包含了IaaS、PaaS，以及私有雲和混合雲的基礎建設服務，而SaaS更為供應商帶來了270億美元的營收。另外，Synergy在調查報告中表示，整合通訊服務（Unified Communications as a service，UCaaS）也有穩定的成長。
 
",https://www.ithome.com.tw/news/103003,"新聞,Synergy,Cloud"
102401,27,2016-01-10,2016年是IT翻轉的關鍵一年,2015年在技術、企業內部平臺、外部雲端環境到組織工作模式上的劇烈變化，再加上跨界併購案和IT大廠重組帶來的市場重劃，都將在2016年發揮綜效，甚至將大幅改變了IT的樣貌," 過去2年中，不論在哪一場全球性規模的IT巨頭年會，只要有Docker設攤，那裡都是會場中最搶手的攤位之一，與Docker相關的演講場次也場場爆滿，發問不斷。不只2014年如此，2015年也是如此。Docker爆紅不只是因為Container技術本身，更重要的關鍵是Docker的出現，引爆了IT架構的新變革。
Docker這把火，先從近幾年企業內部IT架構轉型最重要的虛擬化技術燒起。一燒，讓兩大虛擬化技術巨頭VMware和微軟都跳腳。不同於傳統虛擬化技術是要建立OS層級的隔離環境，Docker可說是一種建立應用程式層級的虛擬隔離環境。也因從AP層來隔離所建立的映象檔，可以兼顧AP相依性的完整封裝又能實現免Guest OS的輕量化，讓Docker化後的應用程式，具備了高度移動性，更容易在不同環境或雲端平臺上部署。
虛擬化技術出現，讓企業進入了虛擬化時代，透過虛擬化平臺來整併企業IT的工作負載，多VM集中到單一實體伺服器。後續進一步出現的私有雲平臺，將分散式架構帶進了企業。企業可以將從資料中心視野的角度，來調度大量伺服器上的運算資源，自動分配給不同的應用需求。
 

 
微服務架構將更盛行
但被譽為全球第一技術長的前Netflix技術長Adrian Cockcroft認為，不同於過去虛擬化技術或雲端平臺，是以分為單位的部署速度，以及按周來計量的生命周期，「Container部署速度可以達到以秒為單位，生命周期只有數分鐘或頂多數小時。也因此，他認為， Container帶來的速度，將會驅使和更多微服務（Microservices）架構的盛行。
不同於過去只靠單一應用系統（Monolithic Application）來提供各種應用功能，微服務架構是一種以大量微型服務來組合成一套應用系統的架構。就像Twitter其實是來自7百多個小服務而組成的一個Ap。這樣做最大的好處是擴充性，更容易將運算資源分配給其中幾項高負載的小服務，讓運算資源利用效率更高。而Docker的問世，降低了微服務架構的門檻，只要將一套應用系統內所需的功能程式，各自打包到不同的Docker映象檔中，就能部署為提供不同功能的微服務，也因此，可以快速部署到大量伺服器上來執行。
許多知名網路服務都採用了微服務架構的設計，例如臉書上的的「讚」按鈕，就算遇到一天有上億人按讚，臉書也只需要單獨擴充「讚」這支程式而不用調度大量資源給整套平臺。這就是微服務架構能帶來的精準式擴充力。這也讓微服務架構成了原生雲端應用服務的主流架構。
過去2年，Docker大多應用於開發測試環境中，尤其更讓DevOps風潮如虎添翼。早在2010年就興起了DevOps風潮，打破開發和維運間的圍籬，讓產品或服務可以更快上市。已有多種IT自動化工具或配置管理工具來協助企業建立持續整合（CI）甚至是持續交付（CD）的流程，如Puppet、Chef、Jenkins等。但是，Docker的出現，讓DevOps自動化所要處理的應用程式程式碼，有了一個輕量化的標準封裝容器，也讓基礎架構程式化（Infrastructureas Code），開發人員可以用撰寫程式來控制這個容器的調度。
DevOps將邁向軟體工廠化
Docker能讓軟體開發流程，像工廠生產線作業那樣，透過標準化的容器，從開發、測試、品管、封裝到部署都能透過自動化工具來控管。各種DevOps工具可以以Docker為溝通基礎，來建立相互搭配的機制，甚至更進一步能成為一個軟體開發生產線，就像是一間高度自動化的軟體工廠（Software Factory），在設計完成後，只需少數幾人就能維運來生產自家的軟體產品。
在過去一年，Docker不只開放支援自建映象檔管理服務（Private Registry），也將自家映象檔格式捐出來作為Container標準之用，也和多家大廠成立OCI聯盟合推，年底時更內建了網路和叢集功能，讓Docker從單一主機環境跨入了多主機架構，再加上雲端巨頭如AWS、Google、Azure都開始支援。
到了2016年，微軟若如期在新版Windows Server中支援Docker，屆時，Docker就成了可以通吃不同作業系統，以及不同雲端平臺的關鍵技術，這也將更帶動企業擁抱新的微服務架構，和新的DevOps組織工作模式的風潮。
併購和重組將改變IT市場版圖重塑
不只IT技術和企業架構開始翻轉，2015年IT產業也出現了多項市場板塊重組的大地震。最大一宗併購事件是10月初，硬體巨頭Dell宣布以670億美元買下儲存龍頭EMC的併購案。連帶著也影響了VMware成了Dell旗下公司之一，即使Dell創辦人兼執行長Michael Dell信誓旦旦承諾，不會干涉VMware營運，但市場仍高度關注，後續完成併購後VMware的發展。
這宗IT科技史上最高金額的併購案，讓Dell一舉擁有了伺服器、儲存、虛擬化技術和PC市場領導地位。不只成為全球儲存龍頭和第二大伺服器供應商，也將是全球軟體供應商巨頭之一，更是虛擬化技術龍頭。受人矚目的跨界併購不只一宗，OS廠商紅帽買下了DevOps熱門工具Ansible、幾大巨頭搶著買下大資料分析的新創團隊來擴充實力。
除了併購，分拆重組也是2015的重頭戲，HP正式分家為專門銷售個人電腦與印表機的HPI，以及鎖定雲端及伺服器等企業市場的HPE。Google則是自己重構，成立了自己的母公司Alphabet，將原有Google旗下事業體，分別獨立為各自不同的子公司。賽門鐵克出售了旗下資料儲存和復原部門Veritas。另外也有重量級IT廠商，退出競爭激烈的雲端IaaS紅海， HP結束了Helion公有雲服務，VMware則在公有雲事業上退居二線技術支援，而非直接經營。這些IT業界的併購和重組，勢必將牽動接下來一年IT市場版圖的重劃。
2015年另有多項新興架構或技術開始成形，大資料架構SMACK（Spark、Mesos、Akka、Cassandra和Kafka）是矽谷最夯的大資料架構，這個以解決Fast Data串流資料為目標的架構，成了矽谷新創公司人人重視的新一代IT基礎。
擴增實境AR產品在2015和2016年陸續問世，伴隨著PLM平臺開始支援AR，也讓現代化工廠更容易升級為新生產型態的智慧工廠。
開源成了IT大廠和網路新創開發產品的新戰略，2015年，微軟、蘋果等更多IT大廠紛紛將自家產品程式碼放上GitHub釋出，就算是競爭對手，也能藉此成為優化自家產品功能的助力。
從技術、企業內部平臺、外部雲端環境到組織工作模式上，過去1年來，IT界都產生了劇烈的變化，這些改變會在2016年發揮綜效，讓2016年成為IT翻轉的關鍵一年。
2016各類IT應用趨勢分析，請參考：「展望2016：關鍵趨勢翻轉IT」
",https://www.ithome.com.tw/news/102401,"新聞,回顧展望,2016趨勢,Docker,DevOps,軟體工廠,微服務架構,虛擬化"
102837,27,2016-01-07,遲到的精彩筆記：Docker 對傳統 DevOps工具鏈的衝擊,如何建立系統所需環境？純VM？純Docker？還是Docker in VM? 這篇筆記摘要了葉秉哲對這項架構技術決策上的建議," 本文經作者陳正瑋同意轉載，原文網址為http://blog.chengweichen.com/2016/01/ithome-container-summit-2015-docker.html
延續去年的盛況，今年 iThome 再次舉辦了 Container Summit。當舉辦的消息剛釋出時，本來是沒有太多興趣的，是一直等到議程公佈，發現有邀請了數位國外講師，包含 Mesos、Rancher 及 DaoCloud⋯⋯等，才改變心意，立馬向公司申請公差決定要來好好朝聖一番。
這次的議程我覺得可以分成三種類型，分別是「大師推坑」、「觀念分享」及「就是來賣產品」。因此並非每一場都需要做詳細的筆記，有些場次只有幾個重點需要記錄，剩下的時間都是在欣賞講者的推坑功力，看看能不能順利讓聽眾們買單。
這次「小城故事不多-科技部」以團體戰術在第一時間就釋出了各場重點筆記，有興趣者可以直接參閱他們的兩篇筆記文，內含每一場的重點筆記。
http://smalltowntechblog.com/2015/12/10/ithome-container-summit-day-1/
http://smalltowntechblog.com/2015/12/11/ithome-container-summit-day-2/
在這一次的 Container Summit 2015，iThome 依然邀請了葉秉哲（以下簡稱：葉大）為大家分享議程，這次葉大同樣帶來一場屬於「觀念分享」的題目「擁抱或對抗？談 Docker 對傳統 DevOps 工具鏈的衝擊」。簡報已釋出，可直接線上瀏覽

Docker 對傳統 DevOps 工具鏈的衝擊 (Docker's Impact on traditional DevOps toolchain)  from William Yeh

開場葉大先用幾則笑話調侃了一下 DevOps 的現況，基本上就是 DevOps 的定義問題、DevOps 涵括太多的領域及 DevOps 的工具種類與數量多而繁雜。
有鑒於 DevOps 目前的現況，因此若想要在一場分享中介紹這麼多 DevOps 相關的內容是不可能的，必須換個角度思考，只能針對有限的關鍵問題分享。
那麼到底在實際面上 DevOps  切身相關的問題是什麼？
於是葉大借用了 Brian Brazil 在文章中提出的三個嚴肅的問題來回答。這三個問題分別是：
How to recreate your system（如何重建你的系統 ）
How to safely change your system（如何安全地改變你的系統）
When something has gone wrong（你有辦法知道系統出狀況並解決它）
相信 Ops 一定會立刻認同這三個問題的重要性，因為不論是重新打造或修復重建系統，系統建立是 Ops 最基本的關鍵工作。
而系統建立之後，還會遇到需求變更或軟體升級⋯⋯等原因導致系統必須被改變。最後即便放了綠色乖乖也不代表系統永遠不會出問題，因此系統監測絕對是第三項不可缺少的關鍵項目。可以說對 Ops 而言若想要提供一個穩定的系統，這三項是絕對逃不了的關鍵問題。所以在談更多 DevOps 的內容之前，不如先好好的討論這三個問題。
接著葉大就一一的針對這三項問題以「傳統作法 vs Docker 作法」的方式一一介紹 Docker 所帶來的衝擊，並分別從「機器」、「組態」與「角色」三個項目切入。
但在進入正題之前，葉大立刻就說今天只會談到前兩個問題。因為在 Docker 如此火紅的時代，還沒有任何一間 Monitoring 相關廠商膽敢不支援 Docker。不論是新興廠商或老牌廠商，多多少少都已經支援 Docker  ( 或 Container) 的 Monitoring，差別只在於能做到多細緻，所以第三項問題直接 PASS，整場分享只會聚焦在前兩個問題。
首先是「How to recreate your system」，從「機器」開始談起。
傳統作法基本上就是先有一台資源超強的實體機，為了善用它的所有資源，於是實體機上再透過虛擬化技術建立出多個 VM。但 VM 的缺點就是會有資源消耗的問題，畢竟它不是直接取用實體機的資源，中間必須透過 hypervisor 這一層。於是假如應用程式是各自放在不同的 VM 之中，那麼每個 VM 皆會各自在 hypervisor 上有資源消耗。
那 Docker 作法呢？基本上 Container 的出現有一部分原因就是為了解決 VM 在 hypervisor 的資源消耗。將每個應用程式獨立放在各自的 Container 中，所有的 Container  共享一個 hypervisor，如此即能節省這部分的資源。而目前很多應用程式也都已經被 dockerized，方便使用者可以快速建立並使用。
若由此進一步思考 OS 的重要性，會赫然發現 OS 似乎只剩下用來運行 Docker ( 或 Container) 的價值。所以 Container OS 這種新玩意也就此誕生，Container OS 即是專門用來在其上運行 Container 的作業系統，如目前有名的 Core OS、Rancher OS⋯⋯等。
另外，VM 並沒有因為 Container 的出現就被徹底捨棄。如果你非常看重「硬體資源」的隔離，那麼 VM 依然是一個好選擇。在追求「資源隔離」的前提之下，又延伸出另一派的新思維「Container per VM」，例如 Hyper。
順道提一下 Hyper，之前就有注意到這個有趣的專案，就如它網頁的介紹 “Make VM run like Container. Fast as Container, Isolated by VM.”，它嘗試保有 VM 與 Container 兩者的優異之處，也許這是另一條不錯的路線，可以繼續觀察它後續的發展。
在 OS 層面最後一個影響就是「Unikernel」，個人是前一陣子才在 Docker 相關的資訊中看到這個詞，這次能聽到葉大的解說，剛好解答了一些疑惑。
它的重點即是將能拔除的東西全部拔除，連 OS 都嫌太大太多，連 OS 都想拔除。在此思維之下，將環境精簡到只有特定應用程式所需的 “minimal set” 形成所謂的 “library OS” 的概念。
那為何要這麼做呢？我覺得可以先看看葉大在 jcconf 2015 的分享「Immutable infrastructure：觀念與實作 (建議)」及 Boxfuse 的介紹 “Why Immutable Infrastructure ?”，應該能提供一些觀念上的補充。
上面講了這麼多，到底該如何選用哪一條路線？葉大的建議可以參考簡報 P. 30，根據 service consolidation 與 resource isolation 相互的重要性來評估。
接著談到「組態」。
不同的應用程式在環境設定上會有各種不同的組態，如果是傳統的 DevOps 做法，第一個想法應該就是利用 Configuration management tools 來解決它。不過在使用如 Chef、Puppet 或 Ansible 這些工具之前，先決條件是你必須先具備足夠的環境建置、部署及維運能力，同時還要學會這些工具自己的腳本語法、使用情境、操作邏輯⋯⋯，才能有效地運用它。
不過即便有了 Configuration management tools 的輔助，但「組態設定」這件事本身的「複雜度」依然並未減輕多少。
而 Docker 呢？我們可以先回想一下 Docker 官網上重要的三個字 “Build, Ship, Run” 。透過 Dockerfile 與 Docker image 的 Layer 特性，Docker 這個工具可以讓你分層管理、重複利用、快速遷移與部署。
因此你可以將複雜的系統環境或組態切分為數層 Layer 方便管理。build 的 Image 還能存放於自己的 Docker Registry 重複利用，或者也能直接上 DockerHub 尋找優質可用的 Image。只要透過妥善的設計與規劃，不論是在 dev、stg 或 production 的各種複雜環境也能透過簡單的 “Docker pull、Docker run” 再現。
這樣看起來 Configuration management tools 似乎變得不再重要？就如葉大簡報 P. 40 的重點，Configuration management tools 未來將可能只被用來安裝 Docker 及初始化設定。簡報 P. 40 中附註的文章《Containers Vs. Config Management》個人建議也值得一讀。
最後談到「角色」。
這裡葉大要講的是 “Pets or Cattle” 的觀念。因為這觀念已不是第一次聽見，所以就沒有記錄太多細節，如果用 “Pets or Cattle”、 “Pets vs Cattle” 之類的關鍵字去 Google 即可找到許多優質文章與簡報。
葉大也在這段分享中再次提到 12 Factors App，呼應 Docker 在運用上與 Cattle 的觀念及 12 Factors App 有多麼吻合。個人的想法是這一切都與「架構」有關，不管是系統架構、應用程式的軟體架構。假設你期望系統能做到彈性擴展，但你的架構卻缺乏彈性、可移動性，應用程式的資源被高度綁死在一台又一台的 Pets，那怎麼有辦法彈性？
How to safely change your system ?葉大這場分享主要都是花在觀念說明。因為只要了解這些觀念就不難理解第二個問題「How to safely change your system」在傳統作法與 Docker 作法的差異。
如何安全地改變系統，在傳統作法即是會採用一些如 Rolling upgrade、Blue / Green deployment、Canary deployment 的方法來嘗試安全的更新軟體或改變系統，同時你必須要自己事先注意好所有的細節，避免在系統改變中出錯。
那麼 Docker 作法呢？則延續前面介紹的 “Pets or Cattle” 的觀念，如果你的機器是以 Cattle 的方式管理並且應用程式的架構吻合 12 Factors App，更將應用程式封裝為 Docker image，那麼傳統作法中的某些繁雜細節你就不需擔心了。
例如 Google 的 Kubernates 要做出 Rolling upgrade 即非常容易，只要一行指令即可。很多麻煩的細節 Kubernates 會幫助你處理。至於其他如 Mesos 與 Docker 官方更不用說，也都在這方面有工具可以輔助。
所以說重點依舊是 “Pets or Cattle” 的觀念，若想要獲得 Docker 作法帶來的優點，還是先好好的檢查一下你的「架構」吧！
葉大的分享就到此，結束前會再有一次總結，即是簡報 P. 71~75，基本上看簡報就知內容重點，所以就不再復述了。
",https://www.ithome.com.tw/news/102837,"新聞,Docker,DevOps,Kubernates,Container Summit,VM"
101610,27,2015-12-28,微軟混合儲存服務StorSimple更新以整合主要儲存陣列,微軟宣布在混合儲存陣列StorSimple中新增虛擬陣列，和強化StorSimple 8000系列中硬體和雲端裝置的規格。微軟表示，此虛擬陣列可在VMware或Hyper-V Running 上運作，StorSimple 虛擬陣列提供整合主要（Primary）儲存設備、災難復原，也提升StorSimple 8000 系列的本機產量能力(local volumes capability)，可以將主要儲存放在StorSimple 8000 系列的磁碟陣列或是虛擬陣列的本機層(local tier)，適用於就地部屬的工作負載如SQL Server、Hyper-V 儲存設備或VMware的虛擬機器。," 微軟繼去年7月推出結合StorSimple與Azure的混合儲存服務後，本周再度宣布在混合儲存陣列StorSimple中新增虛擬陣列，微軟雲端暨企業部門副總裁Mike Neil表示，此虛擬陣列可在VMware或Hyper-V Running 上運作，StorSimple 虛擬陣列提供整合主要（Primary）儲存設備、災難復原、為小型IT基礎設備與管理環境設計出容易部屬的解決方案。
另外，透過StorSimple 虛擬陣列，使用者不再需要在主要的資料中心中裡面，集中資料保護和災難復原工作，而資料管理和部屬則是由StorSimple Manager統一管理，另外，也強化了StorSimple 8000系列中硬體和雲端裝置的規格。
再來是提升StorSimple 8000 系列的本機產量能力(local volumes capability)，Mike Neil表示，透過本機產量能力，可以將主要儲存放在StorSimple 8000 系列的磁碟陣列或是虛擬陣列的本機層(local tier)，此功能適用於就地部屬的工作負載，對於IO的需求比較高，如SQL Server、Hyper-V 儲存設備或VMware的虛擬機器。
StorSimple混合儲存涵蓋了混合儲存陣列StorSimple 8000系列、Azure StorSimple虛擬裝置，與用來管理就地部署及雲端儲存的Azure StorSimple Manager。目前StorSimple 8000系列有兩款產品，分別是StorSimple 8100提供15TB儲存空間，與StorSimple 8600提供40TB容量，且可以使用的雲端儲存空間為200TB與500TB。
",https://www.ithome.com.tw/news/101610,"新聞,Cloud,Virtual Array,微軟"
101963,27,2015-12-27,IT月報｜雲端IT焦點回顧,VMware退出與EMC合資公有雲計畫。惠普關閉自家公雲服務，力推微軟Azure。Google優先索引HTTPS網頁以加密通訊,"  VMware 
VMware公有雲策略大轉彎，退出與EMC的合資公有雲計畫
原本VMware與EMC在10月20日時，宣布將共同營運公有雲服務商Virtustream，並且各自持有Virtustream 50％的股份，但此協議卻在近日變卦。到了12月14日時，VMware宣布不參與Virtustream的營運，重新將VMware定位為技術提供者，繼續經營vCloud Air。（詳全文）
 
 公有雲   Azure 
惠普關閉自家Helion公雲服務，下一步將力推微軟Azure雲端服務

惠普今年10月宣布明年1月關閉Helion公有雲服務，惠普執行長Meg Whitman則在財報會議上透露，已與微軟結盟以推廣微軟的Azure雲端服務。（詳全文）
 
 Google   CDN 
Google推出CDN服務測試版，要用全球機房幫你派送網頁
Google Cloud CDN是利用Google分散全球的前端快取把經過HTTPS負載平衡的內容儲存於接近使用者的伺服器上，旨在更快將內容遞送給終端使用者，同時減輕用戶伺服器的負載。Cloud CDN為Google Cloud Platform服務的一環，初期可支援小量HTTP回應的前端快取，以執行HTTP/HTTPS流量負載平衡作業。（詳全文）
 
 Adobe 
雲端轉型策略奏效，Adobe營收創歷史新高
Adobe在2012年初推出Creative Cloud訂閱模式，並在同年宣布未來將不再以傳統套裝授權模式銷售Creative Suite產品，臺灣市場則是在2013年引進Creative Cloud訂閱制服務。Adobe調整軟體授權銷售模式的策略還包括大幅調整通路與全球分公司架構，例如在宣布調整商業模式後的同一年年底，便裁撤了臺灣分公司。（詳全文）
 
 微軟   開源 
微軟預計明年1月開源釋出Edge瀏覽器核心ChakraCore

微軟宣布，將藉由GitHub釋出ChakraCore開放源碼，內含Chakra的各種核心元件，包括支撐Microsoft Edge瀏覽器之JavaScript引擎的所有核心元件。他們進一步說明自Chakra開始，JavaScript將從一個主要用來支援瀏覽器的語言變成一項可支撐各種應用的技術。（詳全文）
 
 雲端資安   微軟 
微軟更新IE 11及Edge的SmartScreen以攔截偷渡式攻擊
微軟釋出的Windows 10更新中，透漏已在Microsoft Edge及IE 11瀏覽器的SmartScreen防毒過濾機制中，新增對偷渡式（drive-by）攻擊的保護措施。SmartScreen本來是一網釣及惡意軟體過濾機制，此次微軟則是讓IE 11與Microsoft Edge瀏覽器的SmartScreen可攔截偷渡式攻擊。（詳全文）
 
 Gmail   DLP 
Gmail增加DLP資料外洩防護功能，自動攔截敏感郵件
Google陸續強化企業服務的安全性，Gmail加入資料外洩防護（Data Leak Protection，DLP）功能。Google指出，雖然Google for Work已加入加密、共享控管、行動裝置管理、雙因素驗證能力協助管理員確保資訊安全，但有時卻因少數使用者不當行為而危害了整體安全，而DLP提供預先定義的內容偵測工具，可讓特定部門防止包含特定資訊的信件寄出。（詳全文）
 
 雲端資安   Google 
推動加密通訊，Google將優先索引HTTPS網頁
在各大網路業者的努力推動下，HTTPS加密通訊已逐漸成為主流的網路通訊協定，Google宣布將調整搜尋引擎的索引系統，以HTTPS網頁為優先索引對象。當發現兩個擁有同樣內容但分別採用HTTP與HTTPS不同協定時，就算沒有其他網站連至此一HTTPS網頁，也會優先索引基於HTTPS的網頁。（詳全文）
 
 雲端協作 
Office365的高階企業版E5正式上線，支援萬人會議強化資安防護機制

Office365除了個人、家用等版本外，針對企業用戶也推出多種版本。微軟揭露最新的高階企業版本E5於臺灣正式上線，新增多項企業級功能，包括整合企業雲端通訊服務、提供萬人會議廣播，並強化威脅保護機制、法務稽核及BI分析工具等功能。（詳全文）
 
 Azure 
等了一年多，Azure新版管理平臺正式釋出
去年的Azure新版管理平臺預覽版（Azure Preview Portal）於官網上發布正式版了，全新管理介面多了許多好用的功能，包括在上方工具列新增了搜尋功能，讓開發者或IT人員可以在所有的資源中搜尋所需物件，此外也大幅提升瀏覽與存取資源的使用體驗，開發者可以透過名稱來篩選，並可以直接訂閱。目前語言支援包含正體中文在內共18種語言。（詳全文）
",https://www.ithome.com.tw/news/101963,"新聞,雲端,Cloud"
101580,27,2015-12-20,專訪Rancher Labs創辦人梁勝：為何Container比vSphere更適合打造企業私雲,打造出最輕量Container OS的Rancher Labs共同創辦人暨執行長梁勝表示，雖然目前企業私有雲最佳解決方案是VMware的vSphere，不過，Container服務技術具備了與應用程式層親和性高，以及比VM更容易跨異質環境轉移運算工作兩大特性，是實現私有雲更好的方式," 2013年Pycon中，一場展示Docker Container 5分鐘的閃電秀，引起了全球IT業界的漣漪，IT大廠如紅帽、VMware及微軟紛紛向其靠攏。而為運作Container而生的輕量級OS也紛紛出籠，如VMware的Photon、微軟的Nano Server。
其中，又以Rancher Labs推出了只有22MB大小的Rancher OS引起高度關注。
打造出這款最輕量作業系統的Rancher Labs共同創辦人暨執行長梁勝，過去曾在昇陽電腦擔任首席開發者，帶領研發JVM的團隊。離開昇陽後創立了Cloud.com公司，開發出了曾被視為OpenStack競爭者的CloudStack，連全球最大網站代管業者Go Daddy都採用。後來Citrix買下Cloud.com後，梁勝也成了Citrix雲端平臺技術長。儘管後來OpenStack成功以開源策略站穩腳跟，而CloudStack式微，但梁勝仍沒有打消想要自己打造出企業私有雲平臺產品的企圖。
當Docker出現後，梁勝再度出來創業，快速推出了RancherOS乘上這一波Container技術浪潮，在今年6月更發表了第一款可用Container技術來打造企業私有雲的平臺產品Rancher，可以打造出一個多租戶架構的企業私有Container服務，目前尚處於開放測試階段。12月時Rancher進一步還和老牌資料中心設備商Redapt合推了一款融合式架構產品，讓Rancher可以用於打造出一套通吃Container和VM的平臺。梁勝也在12月初首度來臺，在Container Summit 2015中介紹Rancher最新進展和未來藍圖。
 

 
 Q  從CloudStack到Rancher Labs，你精確掌握IT趨勢來創業，你如何發掘新的企業需求？
 答  我是從自己的創業過程，挖掘到企業的需求。在成立CloudStack之前，我先創辦了一家網路公司Seven，那時經常碰到的問題是，很難預測應用程式所需要的伺服器資源，有時分配得太多，有時則過少，這樣的經驗，讓我了解到AWS EC2服務的重要性。
AWS在建立彈性擴充基礎設施的服務上很有一套，但並不是所有的公司都一定會使用AWS。所以從此角度出發，市場上對於能夠提供一套如CloudStack這類基礎架構平臺產品服務的廠商，存在明確的需求。而現在的趨勢開始轉向提供Container服務，我也看到了市場存在著新興需求。
過去我創立CloudStack是為了提供企業私有雲服務，希望幫助企業、新興網路公司打造出類似於AWS的基礎設施。但是，真正能建構起大規模私有雲運算的私人企業案例並不多。這是因為，以前打造私有雲的作法還是存在許多問題，使得CloudStack後續發展並不是特別成功。直到現在，我認為，透過Container技術才是可以實現企業私有雲的方法。
 Q  企業如何透過Container技術實現私有雲？
 答  許多企業選擇建構私有雲是為了滿足內部開發的需求，而目前最好的解決方案是VMware的vSphere。不過，我認為Container服務是實現私有雲更好的方式。Container技術具備了兩大特性，能讓企業實現私有雲，第一，Container與上層的應用程式關聯比較密切。第二，Container與底層提供儲存、運算資源基礎設施間的關聯並不是那麼緊密。企業可以更容易在VMware、AWS甚至是裸機這些異質的環境間進行調度Container。
甚至，企業也不應該被自己的私有雲綁死，應該要具備彈性的調度運算資源的能力。未來，企業也可以採取公有雲、私有雲的混合模式，選擇使用外部雲端廠商作為基礎架構，並且透過加密程序，在外部執行網路、儲存等功能。
 

Container技術是實現企業私有雲更好的方法。——Rancher Labs創辦人暨執行長梁勝

 
 Q  為什麼要推出輕量級作業系統RancherOS？
 答  Docker Container引發業界開始使用Container的風潮，使Container管理服務變得更加熱門，涉及的應用層面也越來越廣。這樣的風潮，也提供Container運作的底層基礎架構以及作業系統很多新機會。
Rancher OS本身只有Linux核心加上Docker Daemon，加上網路、日誌紀錄、DHCP及NTP等作業系統的核心功能。
過去的作業系統很複雜，例如所有作業系統都要具備打包功能，將應用程式打包後進行部署，如Red Hat的RPM。但是，在Docker問世後，作業系統的打包功能變得沒那麼重要，因為Docker的目的就是打包應用程式，並且進行部署。
而作業系統背後也有一套完整的支援，負責執行網路、儲存、日誌紀錄及DHCP等系統層面的功能。Rancher OS的特點就是透過Docker，提供使用者系統層面的功能，藉此提高Rancher OS的調度性。另外，Rancehr OS也讓使用者可以Docker包裝應用程式。
 Q  Rancher OS和其他Container作業系統的差異為何？
 答  在所有Container OS中，Rancher OS所占的容量最小的，其他的Container輕量級作業系統仍需要幾百MB的空間。再加上其他廠商開發的作業系統仍須背負較多舊包袱，像是Red Hat的Atomic host，必須支援Red Hat原本的RPM。而Rancher OS的體積小、結構簡單，因此運作的也更快、更安全，也更易於管理。
此外，Rancher OS是針對Docker而設計的作業系統，只要透過Docker Container就可以完成許多事情，像是透過Docker打包作業系統需要的系統層級功能。
 Q  Rancher瞄準的目標是成為企業架構私有雲的新選擇嗎？
 答  沒錯，Rancher是設計給有搭建Container私有雲服務需求的企業。目前業界的研發人員對Container的技術接受度比較高，但是，如果真正要把Container推廣到線上環境還是有許多要克服的挑戰。
例如，底層基礎設施的管理、上層的應用程式與Container的相容性、Container的調度、排程管理 ，或是調度工具Swarm、Kubernetes都必須進行整合。目前具有研發能力的企業可以自行架構私有雲，但是要投入10個人以上的團隊，專門研發內部使用的Container管理系統。而Rancher就是企業等級的Container管理系統，透過Rancher，企業可以管理Container、基礎建設及用戶系統等。而企業部署Rancher後，即可將Container導入線上環境，並且使用Docker打造私有雲。
使用Docker打造的私有雲好處在於，可以在VMware、OpenStack、裸機等不同的基礎設施間進行調度。
甚至，使用公有雲的企業用戶也可以享受Docker的這個優點，即使企業的運算、儲存資源是來自外部雲端廠商，內部的應用程式、Container管理服務、容器服務也還是維持私有的形式，這也是企業可以採取的新架構方式。
 Q  Container技術能夠取代VM嗎？
 答  雖然Container技術與伺服器虛擬化技術功能上有一定的重疊，而這必須端看使用者要拿伺服器虛擬化技術做什麼樣的用途。傳統伺服器虛擬化主要是要打造隔離的環境，讓企業可以在一臺實體伺服器上運作不同作業系統，彼此互不影響。Container技術並不能做到這樣的效果，但是Container的優點在於，可以應用程式打包並且快速地進行部署。過去也有人嘗試將應用程式轉換為OVF格式後進行部署，但是OVF始終沒有成為主流。
大部分資料中心的機器都是使用VM為基礎架構，而目前我看到的狀況是，絕大部分的企業，都還是將Container部署在VM上。
因為Container需要機器才能運作，而VM就是可以提供Container運作的基礎設施，很多人認為它跟實體伺服器沒有什麼差異。此外，美國使用Rancher的用戶，許多人也選擇將它部署在AWS上運行。
不過，如果用戶只使用VM進行環境隔離的話，它的的重要性的確會不如從前，因為無論是採用VMware或是KVM，都可以達到類似的效果。
將VM比喻為OS X、Windows等作業系統，而Container是在作業系統上運作的瀏覽器。如果瀏覽器占的使用比例很高的話，使用者選擇何種作業系統的重要性就不高了。而目前大多人採取將Container在VM上運行的策略，用戶如果只關心在上層運作的應用程式，底層採用任何基礎設施差異也不大。
此外，由於基礎架構需要滿足多用戶、多種作業系統的需求，因為Container是共用作業系統核心，它的隔離機制還不足以滿足基礎架構的需求。所以，我認為，基礎設施還是必須仰賴VM。
 Q  設計這套可用於超大規模部署的Rancher時，遇到什麼挑戰？
 答  世界企業碰上的問題，絕大多是出自於是否有需求存在，而不是技術是否可行。比方說，筆記型電腦工廠的經營者需要擔心兩種問題，第一，如果這間公司擁有超過世界一半的市占率，要如何生產這麼大量的筆記型電腦。第二，是要如何賣掉目前庫存的電腦，維持工廠的營運。然而，只要市場上對筆記型電腦有需求，如何生產大量電腦的問題，都會迎刃而解。
所以，讓系統擴充規模的技術不是問題，真正的關鍵是是否有大規模叢集或是Container的管理需求。目前全世界包含廣達、Dell等伺服器廠商，1年內所售出實體伺服器數量大概有1,000多萬臺。假設一臺實體伺服器上運作30臺VM，而一個VM上面運行30個Container，總共有數百億個Container，然而，Rancher可能只會管理到其中的幾百萬個Container，對於Facebook這些具有數十億用戶的企業，在實作上才會碰上技術的挑戰。
過去CloudStack最大規模的部署案例，達到4萬臺實體伺服器。按照目前企業對於軟體的標準，Rancher要應付這樣的規模並沒有問題。企業一定有存在需求，目前我最關心的問題是，企業對於Container相關技術的接納度，而目前接納度還未達到一定的程度。像是阿里巴巴、淘寶網都有大規模部署的需求，但是Docker、Kubernetes等技術，還沒有成熟到企業可以輕易採用。例如，使用Docker的人很多，但是都局限在企業開發端，而不是營運端。目前要解決的問題是，如何讓維運團隊開始大規模使用Docker。接下來的問題，才是如何將Docker導入大規模的基礎架構上。新技術有許多優點，但也存在使用門檻高或是不穩定等缺點。如何讓企業開始導入這些技術，是目前我想要解決的難題。
 Q  OpenStack及VMware是Rancher的競爭對手嗎？
 答  由於Container管理服務是新興的事業，Rancher的競爭對手並不明確。如果使用者決定在裸機上運行Rancher，那麼VMware、OpenStack就會是Rancher的競爭對手。但是，Rancher除了在裸機上運作，還可以在VMware或OpenStack等基礎架構上運作，從這個方面來說，Rancher則是他們的合作夥伴。
另外一方面，跟Rancher存在競爭關係的是平臺即服務（PaaS）。傳統PaaS的整合程度比Rancher高，但是靈活度則比較差。許多人認為，Container管理服務架構在VM之上，與上層的應用程式關聯性更高，從這樣的角度切入，Container管理服務比較偏向PaaS。
 Q  Container雲端服務是IaaS還是PaaS？
 答  原本PaaS跟IaaS是壁壘分明的兩種雲端服務層，但用Container技術來建立的雲端服務層，相當於是IaaS層的上端與PaaS層的下端，形成了一個介於基礎架構以及平臺間的交集。由於Container具備網路、儲存以及負載平衡的功能，所以跟IaaS層有重疊的功能。如果使用者在裸機上運作Rancher，可以完全取代掉IaaS層的功能，或是選擇將Rancher安裝在VM或是AWS上，也可以取代部份IaaS層的功能。
過去PaaS只能用於Web應用，透過前端的路由器、負載平衡器發送服務。但是，新一代PaaS將基礎功能，轉讓由Container執行。未來PaaS會走向更上層的應用，整合更多新工具，例如分散式資料庫、大資料技術或大資料分析工具，而這些原本並非PaaS所要執行的功能。
PaaS所蘊含的可能性非常多，目前使用者能透過應用程式完成的目標，以後都可以透過PaaS執行。
",https://www.ithome.com.tw/news/101580,"新聞,梁勝,Rancher Labs,Container,雲端服務,Container OS,Rancher OS"
101558,27,2015-12-17,超詳細！Container Summit 2015大會現場筆記總整理,兩天主題中，我最喜歡微博、Docker In CI、DevOps 這三場，超有感覺，透過 Container 技術可以讓 DevOps 更容易，省去不少時間與資源成本，這是採用 Docker 能帶來的實質改善," 本文作者為RojerChen，原文網址為http://rojerchen.blogspot.tw/2015/12/container-summit-2015.html 
今年的 Container Summit 2015 實在是相當的精彩，這兩天的研討會著重在 Container 技術在雲端上的應用 (Google、Azure、daocloud、Mesos、RANCHER、和信雲端)、資源運用 (微博) 、CI (貝格樂)、DevOps 、Docker 1.9.x、Docker swarm。
除了內容精彩、講師陣容豪華之外，會議場地與餐點也都準備得相當不錯！全天候咖啡與點心供應實在是太貼心了，難怪有人說辦活動只要餐點準備好，評價就至少有 80分！唯一的缺點大概就是會場的網路很爛，只好用自己的手機上網 XD
這兩天這麼多的主題中，我最喜歡微博、Docker In CI、DevOps 這三場，這幾場聽起來超有感覺的，透過 Container 技術可以讓 DevOps 更容易，省去了不少時間與資源成本，而這是採用 docker 能夠帶來的實質改善。  以下就是相關的筆記：
※Container的過去、現在與未來
docker 讓 infar as a code
讓開發與營運可以擁有共通的版本
從單一主機執行，跨入多主機架構，不再是單機開發或測試模式
※Mesos 大建大規模 Container 平台 
 
特點
resource management
把資源公平分散出去
將 IP 給某一個 Container ，你不需要知道這個 Container 再哪一台機器，但是你可以用這個 IP 找到該 Container

programming abstractions
security
monitoring , debugging , logging

 Mesos 提供 API 使用
各種不同的 framework 都可以在Mesos這個平台上使用

 
 
 
※Docker in CI：Cacoo與Backlog導入Docker的經驗分享

日本人用台語自我介紹，超強！
公司業務介紹
Backlog (http://backlogtool.com/tw)
Cacoo
Typetalk



利用 Docker 的特性來做 CI
測試遇到的瓶頸
分支問題
太多開發人員、太多分支
需要經過單元測試後才可以 review

測試環境
不同開發環境，需要不同的測試環境與工具

速度
整合測試前必須先完成單元測試後才可以進行，需要等很久


使用 Docker 的優點
容易設定 slave
啟動快速，只要啟動 docker 後就可以執行測試了

簡化環境設定
只需要 dockerfile 就可以達到需求

加速
自己有架設 docker register

資源利用
測試完畢後就可以將 container 移除，節省資源
權限問題
in some case , test should be run by non-root user
owner of host directory inside container is indefinite
writing build result to host directory by non-root user can fail
change ownership to non-root user during build time

copy build result from container
no permission issue 
complicate



Docker in CI
good place to start docker
ci becomes common practice
installing docker in ci doesn’t change many things
we could have best practice in this area


日本在production 應用案例


※新浪微博大規模基於Docker的混合雲應用實踐
 
業務背景
業務量變化非常大、瞬間的峰值很高，需要大量的設備以確保服務在尖峰期間能夠正常
業務突發狀況
突發事件、三節(元旦、春晚、耶誕節)、紅包飛
日常推撥

資源浪費
每個業務單位有各自的設備，以確保尖峰期間服務能夠正常
每個業務都有設備閒置，造成資源浪費

設備
申請週期過長
機房空間有限


目標
個業務除了有各自的保留空間外，有部分的空間如10%設備會共通用，
讓共用的空間做靈活的彈性轉移

大陸業界處理方式：12306 (類似台鐵訂票網站)
目前有兩個資料儲存中心，但是仍舊有問題
額外申請阿里雲，用來應付尖峰流量

雲端
使用阿里雲
持續部屬不會用在雲端，單純用來扛尖峰值
拉專線，兩個機房各 1G 專線，三節尖峰狀態拉 10G 專線
拉專線才可以降低延遲時間，使用公有雲方式處理速度太慢

Docker Registry
有自己的 Docker Registry 用來做版本管理
Docker 有升級過，額外用 Nginx 做處理，得知目前服務請求要用 V1 or V2 Registry

具有內部私有機房，並透過專線與阿里雲溝通
docker
swarm
mesos (離線數據分析用)
dispatch (自行開發任務系統)
後端服務為JAVA
前端服務 PHP

有一個共用的資源池，當其他系統有需要資源再做調配
大規模集群操作自動化
設備申請
內：共享池
外：阿里雲

初始化
標準化
配置管理
安裝、升級自動化、操作 API 化
RPM+Puppet MasterLess
業界可能透過 CoreOS、RancherOS、Atomic、DCOS 來做初始化，但是對微博來說，這樣成本過高，所以自己做初始化。

服務上線
容器動態調度
服務彈性擴充
各項業務有10%的設備提供做為共享使用
資源不足時進行申請，使用後歸還


具有報警平台、業務監控
部屬模式
優先調度內網共享

擴充容，單次操作時間 < 5min

※群暉科技運用Docker研發新世代產品之路
NAS 提供 Docker 服務遇到的困難
網路
NAT Port Mapping
使用 open vswitch 方式處理網路問題

儲存空間
讓 DMS 上共用同一份 docker image
stateless data：like image or library
stateful data：user data、documents、images
利用 DSM 升級，自動調整 config 檔案
用 BTRFS subvolume 的 quote 機制，限制 docker dsm 用量
支援 snapshot 、backup

安全性
cgroup
capability
apparmor
namespace
read-only sysfs
sysfs 設定為唯讀
procfs 部分路徑唯讀



內部使用案例
demo site：讓每一個使用者資料隔離，不會讀到前一個使用者看到的資料
QC
模擬多 client 情境效能測試
保存/還原測試問題環境


※兩大平臺完整結合: 談Windows Container & Azure Container service
 

 
 

 
 
windows 世界的 container 技術
docker vm extension
hyper-v containers
visual studio tooling
continuous integration with visual studio online
docker trust repository

可以用 power shell 或是用 docker command
MS自己的 container
Server Core
Nano Server
最佳化 for container 的 os

原生支援 docker command

使用 Apache Mesos Scale
Apache Mesos on Windows Server
※擁抱或對抗？談Docker對傳統DevOps工具鏈的衝擊
 
 
Slide 
DevOps
How to recreate your system  (如何在另外一個地方重新建立、從無到有)
How to safely change your system (如何改變你的系統)
When something has gone wrong (當系統發生狀況，如何快速地知道與解決)
detection
recovery
diagnosis


除了 DB 之外，其他服務很難裸機，通常都用 VM 來處理，但是使用VM一開始就會消耗硬體10%資源
Container OS
是否OS要不要這麼肥？
作業系統瘦身
CoreOS
Windows Nano Server
Snappy Ubuntu Core
VMWare Photon
Red Hat Atomic

container per vm
每一個 container 的用途是用來跑單一VM

unikernel
MirageOS、Boxfuse
boxfuse 把東西 convert 成 image 並丟到AWS上run

docker 
immutable image
versioned image
devlprod parity
以後電腦的功用是開好SSH、系統參數設定完後，剩下就交給Docker


pets and cattle
差別
有名字
是否可以拋棄

傳統 AP (寵物開發)
很難移植、必須好好照顧

牲畜開發法
由電腦幫你決定要丟到哪一台電腦上執行
可以容易複製與轉移
參考12 factors
docker swarm、Mesos....

kubernetes
rolling upgrade
canary deployment







※如何在Kubernetes上持續部署微服務型應用
simple microservice
program language : go 
backend (json)
frontend (html)

kubernetes
manage a cluster of lunux containers as a single system
opensource
5 basic things
cluster
one master and at least one node
kubernetes as a managed service

pod (感覺就像docker一樣)
co-located docker containers 
containers share volumes and localhost
pod.yaml (很像 docker compose，給 master 使用)

Service
abstraction to communicate with pods
have frontend & backend services

namespace
have own resources


Continuous Depolyment
commit often
deploy every commit
validate and rollback deploys
minimize human interaction
code -> test -> commit -> push -> build -> test


continuous deployment
Jenkins workflow plugin
docker image 要設定別名，這樣之後才可以管理


 ※深入理解Dockerfile、Docker映像檔以及Docker容器
docloud  公司業務介紹 (http://www.daocloud.io)
daoship
持續交付流水線

daohub
可追朔的交付件倉庫
突破城牆！ Docker hub 鏡像

daocloud
快雲端網的容器集群管理


Agenda
Docker introduction
容器技術：有效分配與管理物理資源，實現資源隔離
對容器來說，關注的點有沒有 linux kernel 
資源隔離 ( 除了CPU、RAM、kernel 也是一種資源，

鏡像技術
打破代碼即應用的觀念，從系統環境開始，自底至上打包應用
let infar as a code
windows 對 ap 層實現容器技術
dependency、configuration

docker 化實踐
dockerfile -> docker image (can ship anywhere) -> docker container
dockerfile 定義一切


Dockerfile
cache
先看作這一步動作的時候 Image 有沒有變，沒有變再看看


docker image
一個 image 由多個層來組合
一些資料不應該存入，如 hosts、hostname、resolv.conf

docker container
不存在傳統的 init 進程
缺少基本的服務進程
與內和進程通信能力薄弱
docker 比較適合高層次的AP，如果是跟系統硬體設備比較相關，要管理和監控比較不足
cache
docker 服務的最終交付
受到資源的隔離與控制
收到權限的控制
linux container & linux kernel 都是 root 
container 內部與 container 外度的 root 有巨大的差異

支撐用戶應用的運行
docker engine 對於 docker container 有比較好的管理



※和信雲端 Container 實戰經驗
container cluster
scale 
full tolerance
container 角度，增加 container instance 
benefits of collaboration
cloud native computing
more than just the container
hybrid cloud



※深入瞭解 Docker Container Networks

網路處理機制
bridge (很久以前一開始 RUN 的版本)
none (啥鬼都沒有)
host ( container和主機網路組態相同)
container
used-defined network

以前只有在同一台底下的container 可以互相溝通，現在不同台主機的container 可以互相溝通
docker network commands
docker network create/connect/ls/rm/disconnect/inspect

不同 bride 的 container 不能相通
inspect 可以看到每個 container 底下網路的狀況

 overlay network  (讓不同台主機的 container 可以彼此互連)
prepare a key value store
add cluster options to each docker engine 
docker engine run 起來要加參數
--cluster-store=consul://ip:8500
--cluster-advertiser=eth1:2376


create on overlay network on one of the host
host 上要 create overlay network 所有有加入這個 consul 的 device 就可以看到
可以一台主機在Azure，另外一台在digital ocean ，兩台再串起來
eth0 用來做 overlay network


weave network plugin
有好用的介面讓你看狀況


※用Docker Swarm打造多主機叢集環境

Slide
讓一個 container 讓多個 container 存取
docker machine 啟動 swarm master 再啟動 swarm node
Port Allow
特種不同的雲端平台需要開的 PORT 不同
docker engine port (TCP 2375)
VXLAN：UDP4789

注意Kernel版本
透過 key-store 讓swarm master node 知道彼此位置

※Q&A
docker 版本更新很快，該如何跟上步調？
參考雲端服務者使用的版本
雲端服務提供的版本一定不是最新版，但是該版本會和雲端服務整合的最好才會提供該版本服務
知道每個版本的功能，升級上去並做測試，不要用 x.x.0 的版本
微博經驗
大量的測試、壓測之後才上線
目前也只有用過 1.3.x , 1.6.2 這兩個版本


記憶體問題 JVM 
如果要考量scale與穩定性，自己要做好記憶體管理，了解 memory limit、heap size
JCCONF 有人講過相關的主題，可以參考 連結
eBay 經驗
主機裝 VM，每個 VM 底下再裝 Docker or Container
performance 對 eBay 不是考量
人的 development cost 比較高
結論：有錢真好


擁抱 docker 有甚麼 business model
是一個趨勢
以前的程式只能在舊的OS執行，OS升級後程式還要繼續支援，這樣能夠降低 dependency
彈性調度資源、硬體資源的管理、自動化的安裝
自我思考
思考開發、維護對現有工作可以帶來的改變
調整開發思維 (寵物與畜生牲畜)


發明一個新的 container 技術不是太困難，但是要做得像 docker 一樣好，擁有好的 ecosystem 、並且把使用者從 docker 轉移到其他的 container 技術才是困難的。

",https://www.ithome.com.tw/news/101558,"新聞,Container,Rancher,Docker,Mesos,微博,DevOps,Kubernetes"
101431,27,2015-12-15,關鍵摘要！iThome Container Summit Day2筆記大整理,第二屆Container Summit大會第二天精彩內容包括了Kubernetes、Rancher、Docker深入剖析，Docker最新網路功能和多主機叢集建置," 本文作者為蔡宗城，原始連結：http://smalltowntechblog.com/2015/12/11/ithome-container-summit-day-2/
由iThome舉辦的臺灣第二屆Container Summit大會，第二天精彩內容包括了Kubernetes、Rancher、Docker深入剖析，Docker最新網路功能和多主機叢集建置等。
Smalltown Tech Blog接連兩天整理了這次大會的參加心得。第一天重點整理請見：第一天重點回顧！iThome Container Summit Day1筆記大整理
進入到第二天的 Container Summit，今天持續將現場的第一手訊息告訴大家。
如何在 Kubernetes 上持續部署微服務型應用 ( Evan Brown / Google 雲端解決方案架構師 )
今天 Evan 以現場實際展示的方式，詳細的解說怎麼利用 Kubernetes 在自己的本地端以及 GCE 上面部署 Kubernetes，運用的範例是 Evan 自己寫的一個小程式，輸入一個 JSON 檔案，前端會輸出成一個簡單的網頁。
Evan 在今天的演講詳細的講解了 Kubernetes 的基本概念以及組成 Kubernetes Cluster 的各部分組件，包含 Pods, Replication Controller, Service 以及搭配 Jenkins 跟 Kubernetes 來做 Continuous Delivery，詳細的解說也在會後吸引了許多人對 Kubernetes 感到有興趣，許多聽眾在外面的講師詢問處都待了 30 分鐘來問 Evan 問題，反應相當熱烈。
如何搭建企業級容器服務(梁勝 / Rancher Labs 共同創辦人暨執行長)
這場由於前一場在外面問問題花了比較多時間，大概在中場的時候才進來聽，不過從中間聽起來也算還可以，主要就是在講介他們自己做了一個平台叫做 Rancher，可以在他們的平台上面跑 docker，比較特別的是它可以幫你連接各個廠商的雲端平台，在上面架好 docker 平台後，用 docker machine 去連接各平台，比較有中央控管的感覺。
另外它也支援 Kubernetes 以及 docker swarm，各平台的整合性算是滿不錯的。連接完平台之後，它有提供像是 app store 的東西，內建了像是 elasticsearch, nginx 等普遍的應用程式，讓你可以直接點完就開好服務，算是滿方便的，不過他中間顯示出來的設定黨實在是長的有點恐怖，要我自己寫感覺會很累。
深入理解Dockerfile、Docker映像檔以及Docker容器(孫宏亮 / DaoCloud 軟件工程師 )
這場演講感覺是今天最硬的一個場次，深入的探討了 Dockerfile, Docker Image, Docker Container 之間的關係，一開始還是免不了有一點工商時間，簡單地介紹了 DaoCloud 在中國的發展，也由於一些沒辦法言明的原因(講師自己說的XD)沒辦法連接到 DockerHub，也造就了 DaoHub 在中國的發展，他就是將一些在 DockerHub 比較熱門的專案鏡像複製一份到 DaoHub 以方便中國的用戶來開發 Docker。
講師提到為什麼他會開始研究 Docker 原始碼的原因，是因為大家每個人都著重在開發上層應用，可是他對於架構比較有興趣，所以就一頭栽進了 Docker 原始碼的世界。詳細內容太多了，在這邊就不仔細寫出來，大致上就是講解 Docker 從 Dockerfile 怎麼理解，怎麼產生 Docker Image 的各個層級，之後各層級在執行起來變成 Container 之後，真實作業系統又是怎麼應對 Container 裡面的各個行程。
和信雲端Container實戰經驗(孔祥嵐 / 和信雲端 首席技術顧問)
基本上就是工商時間，由於之前有聽過他們的產品發表會，這次聽起來跟產品發表會的時候內容差異不大，簡報檔也有 80% 是一樣的，跟上面的 Rancher 比較不一樣的地方是，客戶群是指向公司內部使用，對於 multi-tenant  的部分比較重視，以及各單位或用戶之間的資源限制，使用記錄，權限設定方面似乎有比較多的著墨，不過在展示的時候沒有展示到相關的設定，是比較可惜的部分。
深入瞭解Docker Container Networks(郭韋廷 / Docker全球開發競賽冠軍/Docker Taipei Meetup共同創辦人)
講解 Docker Network 各種模式以及怎麼設定，還有新的 Network Command 跟 Overlay network，簡單總結，Docker Network 分為五種，分別是 bridge, host, none, container, SDN，Docker預設是使用 bridge，Docker Network 的部分可以看作可以幫 Container 加入網路卡，可以自由指定 Container 要使用哪一些網路設定或是藉由 Network command 來增刪或是列出詳細的設定。
另外一個 Overlay Network 的部分看來是開始要取代之前使用的 Link，也可以把Docker 分佈在不同的雲端服務業者之後，利用 Overlay Network 做通訊，讓使用者可以真正的不受限制於單一業者。最後一個 Docket Network Plugin 的部分，是因為先前還沒有像 Docker Network 這種東西的出現，各廠商或是團體就先開發了網路工具，像是 weave。
用Docker Swarm打造多主機叢集環境(謝宗穎 / 創科資訊 共同創辦人兼研發經理)
這場接在這邊實在是很好的安排，剛好上一場講解了各種網路模式以及 overlay network，這邊直接開始講實際怎樣使用。
濃縮一下重點，步驟大概是先建立一個 key-value store，可以選用很多像是 consul, etcd, zookeeper 等等，接下來先開swarm master, swarm node，設定好overlay network，之後就可以建立一個跨越不同雲端服務業者的服務了。
這樣打起來很簡單，不過講師也是解釋了好一段時間，講師之後應該會把演講稿放出來，大家可以直接看文件嘗試建立一個跨雲端服務業者的服務。
最近研究 Kubernetes 比較多，就在外面跟大家一起跟 Evan 聊了好一陣子，我自己問了 Evan 幾個我遇到的問題：
Q1: 有沒有辦法自己客制化 Kubernetes 裡面的 LoadBalance 模組，因為 Kubernetes 分別支援了 AWS, GCP 等等雲端業者，可以在設定好 LoadBalance 屬性之後直接幫你設定好業者所屬的 LoadBalance，並且把它指定好的外部 ip 或是  DNS name 傳回 Kubernetes，可是公司內部是使用 Citrix NetScaler ，如果要跟 Kubernetes 整合的話勢必會需要這塊。
Evan: 目前為止我知道有一些人有做過類似的事情，有聽過F5, Juniper, NetScaler 還有一些其他的，可是我不知道到底要怎麼做，可能要看那部分的模組模組化的程度多深，才有辦法看有沒有辦法做出這個功能。可以敲留言給我的 Twitter 我會幫你再問問看。
Q2: 最近在研究 kafka，可是我們資料中心的架構只能掛磁碟到部分機器，並沒有辦法所有的節點都是同樣的容量的話，Kubernetes 有沒有辦法指定我要把某個 Pod 或是 Replication Controller 指定掛到某一種節點，像是利用 selector 來做？
Evan: 沒辦法，目前 Kubernetes scheduler 是看目前節點還有沒有資源，像是 CPU 或是記憶體來選擇的，並沒有辦法選擇可以把 Pod 放到特定的節點上面跑。
補充：文章轉載到 Docker Taipei 後，有熱心的網友提供意見，其實是可以做到的，詳細的官方文件在這邊
另外在別人問的問題裡面 Evan 也說到有一個新功能是Kubernetes API Server federation，目前已經在 Pre-Alpha 的階段，大家可以期待一下，也就是這個功能出來之後，就可以在各個雲端業者都建立好 Kubernetes 之後，建立的時候指定 Container 要擺放的國家或是業者，以達到就近服務或是降低成本的功效。
",https://www.ithome.com.tw/news/101431,"新聞,Container,Docker,Kubernetes,Swarm,Rancher"
101408,27,2015-12-15,重點回顧！iThome Container Summit Day1筆記大整理,為什麼Kubernetes每個節點的預設組態限制只能跑40個Container?一位軟體公司工程師蔡宗城趁休息時間，當面問了Google雲端解決方案架構師Evan Brown," 本文作者為蔡宗城，原始連結為http://smalltowntechblog.com/2015/12/10/ithome-container-summit-day-1/
有幸參加今年 iThome 舉辦的 Container Summit，把今天在現場所聽到的一些內容整理做成筆記
以Mesos搭建大規模Container平台 (Timothy Chen / Mesosphere Apache Committer/PMC、Mesosphere分散式系統首席工程師)
簡介 Mesos 如何管理 Cluster，運用 Scheduler 去做伺服器 resource 分配使用，zookeeper 去做一些使用狀態的紀錄…(這一段跟昨天 Big Data section 講 得一模一樣)。然後說他們其實本來就有在用 Container，但不是 Docker 的, 至於怎麼用 Mesos 管理 “Docker” 的 Container，並沒有比較多加詳述…
Docker in CI：Cacoo與Backlog導入Docker的經驗分享 (染田貴志 / NuLab Growth Hacker)
主要講述 Docker 在 CI 中的 User Case，而不是把 Docker 用在 Production 環境上。先提到在 CI 中 Jenkins 扮演很重要的角色(Typetalk, Backlog Plugin)，不過太多的 Jenkins Slave 不好管理。Project 中 Git branch 很多 ( Master, Develops, Features)，要測試完所有的 Branch 很累。
因此建立 Private Docker Registry 來當成 Docker Hub 的 Cache，根據不同 Application 的需求與特性來建立 Image，最後透過 Docker Container 來跑測試，並且把測試結果傳給 Jenkins 做 Parse，最後再把成功測完沒問題的 Build 傳到 Repository，這個部分跟我自己實做的 CI Work Folw 蠻像的
新浪微博大規模基於Docker的混合雲應用實踐 (王关胜 / 新浪微博 平臺維運架構師)
以前 Scale Out 的過程很繁瑣而且費時冗長，因為甚至需要從實體伺服器的採購開始，而且閒置設備無法善加利用，所以開始想要使用混合雲-阿里雲 (Private & Public Cloud) 解決問題，不過為了數據的安全性，只把計算和商業邏輯搬移到阿里雲。
Docker Host 在 Private Cloud 採用實體伺服器，而在 Public Cloud 採用 VM，Linux Distribution 為 CentOS，至於在管理 Docker Host 的資源方面，在新板使用 (Docker Swarm & Mesos)  V.S. 舊版(Mesos & Dispatch-微博自己開發) 作為其底層管理工具，當然也架了擁有 HA 的 Docker Private Registry
混合雲的核心思想為設計一個 Resource Pool，讓公司的所有服務可以共享這個混合雲，也講了很多管理混合雲或是如何 Scale Out 的 SOP (介紹nginx-upsync-module，應付新長出來 Container)，讓線上服務可以穩定的服務使用者。
在伺服器 Provision 的方面，所有需要被安裝的東西都包成 rpm package，並且使用 Puppet 擔任 CM (Configuration Management)的 角色，而 Log Management 部分大量採用ELK(ElasticSearch+Logstash+Kibana)，在 Metrics 的部分使用 Graphite，這兩個東西對於 Trouble Shooting有很大的幫助
群暉科技運用Docker研發新世代產品之路 (曹經世 / 群暉科技 研發經理)
Synology  廣告時間…介紹 DSM 如何管理 Docker Container 。由於在 Docker 在網路方面有點麻煩，所以採用 Open vSwitch bridge 來解決外部網路無法連接到內部 Container 的問題；而儲存問題，利用 Docker mount 功能，讓全部的 Docker DSM container 共享一樣的檔案，並且利用 BTRFS subvolume 來管理儲存空間；而在安全性方面，用 Cgroup,Apparmor… 等來達到 process 資源使用限制，權限的控管…等
兩大平臺完整結合: 談Windows Container & Azure Container service (馮立偉 / 台灣微軟 Open Source Lead)
強調微軟擁抱 Open Source 和廣告 Azure 的運用，而許多既有的Docker Image 在 Azure 也有提供。Demo 運用 Azure CLI 建立VM，然後再用 Docker Command 在 VM 上面開 Container。而微軟跟 Docker 合作開發了 Windows 版的 Docker Engine ，讓其跑在微軟自己客製化的 Nano Windows Server 上面，而所有的 Docker Command 都跟官方在 Linux 環境一對一且映成，開啟一個 Windows Container 基本上會耗掉 100 MB 的 ram。最後提到微軟的伺服器底層資源管理也將會使用 Apache Mesos
擁抱或對抗？談Docker對傳統DevOps工具鏈的衝擊 (葉秉哲 / Gogolook 架構師)
DevOps 最重要的三個問題 (Recreate, Change, Monitor)，而因為 Application 的功能都跑到 Container 內，所以 OS 功能越來越簡化，因此 RancherOS, CoreOS 之類的輕量化 OS 應運而生，甚至有 Unikernel 的誕生。
運用 Dockerfile 就可以一層一層把 Application Image 做出來，CM (Configuration Management) 的重要性越來越輕微，而且做出來的 Image 是 Immutable 並且具有版本控制，利用 Docker Image 產生的 Container 地位比較像是牲畜而不是寵物；不過要用 Docker 的話，Application 的設計方式也必須做更改，跟環境不能有太深的相依性，要讓 Application 可以輕易的在不同的 Server 上運行。最後提到運用 Kubernetes 或是 Mesos 做 Deployment 的話，可以輕易地達成 rolling upgrade
由於第二天沒有要繼續參加，所以先跑去找第二天 Google 的講者 (Evan Brown / Google 雲端解決方案架構師) 問了一些關於 Kubernetes 的問題
1. 為什麼每個 Node 的預設組態限制只能跑 40 個 Containers?
Evan: 這是 Google 測試調校完覺得比較適合的數字，跑起來的穩定度比較好；當然可以自己把數字往上加，不過建議要使用版本 1.1 之後，並且把 Iptables based Proxy enable 起來，而這個功能在版本 1.2 會變成預設
2. 設定 Master HA 的文件還有 Provision Script 都很不完善，對於初學者來說要30分鐘就上手有點難度，有計畫改善嗎？
Evan: 沒有錯，所以打算在版本 1.2 把 Master HA 的功能變成預設，而版本 1.2 會在幾個月後 Release
結論：假如沒時間一直去研究探討，就等 1.2 吧XD
 
 
接著看：關鍵摘要！iThome Container Summit Day2筆記大整理
",https://www.ithome.com.tw/news/101408,"新聞,Container,Docker,Mesos,DevOps"
100737,27,2015-12-05,英特爾物聯網副總裁揭露IoT未來戰略,英特爾物聯網事業群副總裁Rose Schooler在近期的東京英特爾亞洲IoT大會透露，今年8月鉅資投注美國OpenStack新創Mirantis的目的，除了要強化雲端基礎架構軟體實力，更要用OpenStack加速對IoT生態系的戰略布局," 【日本東京直擊】為何今年8月處理器龍頭大砸1億美元投資美國OpenStack新創Mirantis？直到11月中，英特爾物聯網事業群副總裁Rose Schooler在東京英特爾亞洲IoT大會才透露，除了強化雲端基礎架構軟體實力外，更深的目的是，要用OpenStack加速對IoT生態系的戰略布局。
用OpenStack加速對IoT生態系的戰略布局
Rose Schooler表示，在英特爾新推出的物聯網平臺參考架構（IoT Platform Reference Architecture）上，希望來建立一個通吃物聯網裝置（Thing）、網路（Nework）和雲端（Cloud）的IoT生態系，而OpenStack這個開源雲端管理平臺的加入，不只可提供英特爾打造一個軟體定義基礎架構（SDI）環境，藉由靈活調度資料中心資源和更加彈性的雲端部署，有助於強化英特爾在IoT環境實作（Implementation）的能力。Rose Schooler也用大資料（Big Data）來解釋資料中心網路和雲端架構，對於IoT部署的重要性。
她表示，相較於IoT裝置前端，IoT更大的一環，反而在後端的網路連結和雲端運算，因為，當從裝置感測器蒐集到資料後，得將這些大量取得的數據資料，透過網路傳送至雲端分析後，才能創造出新的應用價值。
因而做為IoT資料蒐集和統合的資料中心，勢必也得具有足夠的網路頻寬和雲端分析及運算能力才能夠辦到。也正因為如此，英特爾日前也打造了一個可信賴分析平臺（Trusted Analytics Platform），可結合各式開源大資料分析工具，如Hadoop、Spark等，來提供各種IoT的分析應用。
資安成為過去1年最重要的IoT進展
不過，Rose Schooler也觀察，過去1年最重要的IoT進展，並非是有更多新IoT平臺的加入，反而是在IoT資安強化成為了一大重點。她表示，越來越多的IoT廠商開始加強IoT的資安防護能力。以英特爾來說，目前在資安保護上，已可提供從裝置軟、硬體、網路端點到端點，甚至是雲端安全的防護，包括像是在經由裝置感測器來傳送資料時，可提供更安全的資料傳輸環境，並也加入主動式監控和管理機制，可隨時追蹤掌握每個裝置的使用狀況，一旦遭遇到外在威脅或遭到駭客入侵時，可短時間立即反應處理。
區塊鏈將是下一波IoT熱門技術
除了安全外，另一個Rose Schooler認為下一波熱門技術是區塊鏈（Blockchain）技術。開始有企業，如IBM等採用區塊鏈技術，來打造自家的IoT網路環境。區塊鏈最為人熟知的應用，就是比特幣交易。
因為區塊鏈採用了P2P點對點架構，來同時應付來自全球各地每日大量的比特幣交易的使用。而當將區塊鏈技術運用在IoT網路架構時，和目前以集中化IoT網路部署為主的IoT環境的最大不同，在於其採用了去中心化的分散式資料庫架構，讓IoT網路能用P2P點對點的方式，來進行大量設備與設備之間的資料傳輸，因而可以建立一個開放存取的IoT環境。
英特爾除了利用OpenStack來擴大延伸IoT應用外，Rose Schooler也透露出最近她開始對IoT與Container的結合感興趣，因為英特爾在今年6月也成為了開放容器專案（Open Container Project，OCP）的主要創立成員，來推動軟體開放容器標準，Rose Schooler也計畫評估在資料中心運用Container來提供IoT相關方案的可行性。
不僅如此，Rose Schooler也進一步認為，隨著IoT市場越來越蓬勃發展，明年將會看到越來越多的IoT應用，開始從內部概念性驗證，走向外部測試階段，特別是在零售業和汽車這2個產業上，將會優先看到更多的IoT測試及應用實例出現。
",https://www.ithome.com.tw/news/100737,"新聞,英特爾,Intel,Mirantis,Cloud,雲端,OpenStack,IoT"
100273,27,2015-11-29,IT月報｜雲端IT焦點回顧,Google推客製化VM服務，加密通訊淪為恐怖攻擊幫兇，微軟開發工具開源、大資料分析服務開放公測，紅帽RHEL 7.2支援Container,"  虛擬機   Google 
VM租多少vCPU或記憶體通通自己定，Google推客制化VM服務
Google在雲端運算平臺Google Compute Engine上，釋出新的虛擬機器客制化服務（Custom Machine Types）測試版，讓使用者可以自己決定，想租的虛擬機器vCPU和記憶體各要買多少，而不用像過去只能從預先訂定的規格中選擇。目前開發者可以在多個作業系統CentOS、CoreOS、Debian、OpenSUSE和Ubuntu中選擇來運行虛擬機器。（詳全文）
 
 雲端資安   Telegram 
巴黎恐怖攻擊讓加密通訊服務成箭靶，通訊隱私與國家安全爭議浮上檯面
伊拉克武裝組織ISIL在法國巴黎發動恐怖攻擊之後，法國與美國政府都認為恐怖份子是利用加密通訊服務來進行交流。所謂的加密通訊服務包括WhatsApp、Wickr與Telegram等，它們提供端對端的加密能力，以防通訊內容遭到攔截。（詳全文）
 
 Telegram 
通訊軟體Telegram擴大封鎖上百ISIL廣播頻道，避免淪為恐怖攻擊幫凶

隨著巴黎發生恐怖攻擊事件之後，加密即時通訊服務遭批評成為幫凶。Telegram表示，有人的確向他們檢舉ISIL透過Telegram的頻道功能進行宣傳，仔細審核後決定採取適當措施—封鎖頻道，第一波封鎖了涉及12種語言的78個與ISIL恐怖組織有關的頻道之後，再於11月20日在官方Twitter上表示已額外封鎖164個相關的頻道。（詳全文）
 
 SaaS 
勒索軟體Cryptolocker變身SaaS雲端服務，50美元開始勒索事業
一個名為Fakben的駭客團隊最近推出Cryptolocker Service勒索軟體服務，客戶只要支付50美元就能下載Cryptolocker執行檔，開始勒索事業。該軟體還能設定勒索金額，以及用來收錢的比特幣帳戶。只是Fakben將索取勒索金額的10%作為服務費。不過，Fakben團隊說，他們雖然使用與Cryptolocker一樣的名稱，但程式碼是截然不同的，這代表該軟體有別於已可被多數防毒軟體攔截的Cryptolocker。（詳全文）
 
 微軟 
微軟開發工具也開源，輕量版Visual Studio Code程式碼登上GitHub
不只.NET核心開源，微軟年初推出的輕量版Visual Studio Code開發工具也正式開源，目前VS Code已從預覽版本進入Beta版本，並已有60個擴充套件。今年初，微軟為旗下開發工具Visual Studio推出了可以支援Mac和Linux的免費輕量版Visual  Studio Code，目標是要讓.NET開發經驗和生態系能夠延伸到非Windows世界。（詳全文）
 
 Azure 
微軟Azure Data Lake確定年底開放公測
微軟宣布今年底推出大資料分析服務Azure Data Lake Store與Analytics公共測試版和新的查詢語言U-SQL，另外，微軟也在SQL Server 2016 Community Technical Preview第3版中支援SQL Server R Services，將眾多人使用的R語言正式帶入微軟的資料庫中。（詳全文）
 
 紅帽 
紅帽RHEL 7.2網路功能大躍進，在SDN及NFV環境下吞吐量倍增

紅帽釋出RHEL 7.2版本，新功能除了加強安全、網路及系統管理功能外，也更進一步增進Container技術支援，包含支援Docker Engine、Container調度工具Kubernetes、Linux伺服器管理工具Cockpit，加強企業在Linux Container應用程式開發及部署能力。（詳全文）
 
 Google  機器學習 
Google機器學習系統TensorFlow以開放源碼釋出
Google宣布以Apache 2.0授權模式開放TensorFlow函式庫、相關工具，以及說明文件、範例等資源，並邀請開發人員透過TensorFlow.org加入參與計畫。Google資深院士Jeff Dean指出，TensorFlow是Google開發的第二代機器學習系統。它內建支援深度學習，用途更廣，可用於任何運算流程圖（Computational flow graph）。（詳全文）
 
 OpenStack 
惠普Helion OpenStack 2.0出爐，推週期管理服務、更新免停機
繼去年惠普推出自家的OpenStack雲端平臺HP Helion OpenStack後，發表進階的2.0版，同時包含商業版與企業版本，但仍採用OpenStack上一版的Kilo而非最新版，包括在更新期間不需要停機，在連續性補丁管理時也不會受到其他應用程式的干擾，與改善原有的管理介面，更強化集中登入和監控功能。（詳全文）
 
 Google 
Google獎勵民眾撰寫地圖服務的資訊，等級達標可獲1TB免費雲端空間
Google為了鼓勵於Google Maps中撰寫評論並更新圖資的「在地嚮導」（Local Guide），宣布擴充該專案的福利，只要等級達到4級（Level 4），就能獲得免費1TB的Google Drive雲端硬碟空間。（詳全文）
",https://www.ithome.com.tw/news/100273,"新聞,雲端服務,Cloud,雲端"
100050,27,2015-11-18,Docker風潮微軟也瘋狂！在Minecraft的虛擬遊戲裏管理Docker容器,這可能是微軟併購Minecraft遊戲一年多來最瘋狂的想法：在Minecraft的虛擬世界裏管理Docker Container容器。," 這可能是微軟併購Minecraft遊戲一年多來最瘋狂的想法：在Minecraft的虛擬世界裏管理Docker Container容器。
Meta-#docker oculus vlc stream to container to minecraft managing itself!!! Wat!?! #dockercon pic.twitter.com/dsC7dU91ip
— Nirmal Mehta (@normalfaults) November 17, 2015
微軟在DockerCon Europe 2015大會上對外公布名為Dockercraft的技術，示範的工程師戴著虛擬實境頭盔，在Minecraft的虛擬世界裏走進一間間房子，而這每一棟房子都代表一個Docker容器。

在房子的外牆掛著顯示容器資訊的看板，包括容器的名稱、正在執行的應用程式、處理器與記憶體的使用率等系統資訊。走進房子裏，則有管理容器的功能，例如扳動牆上的開關，可以開啟或關閉Docker容器，此外，也有移動容器等功能。
雖然在玩遊戲的過程中管理Docker容器的做法，目前看來有點無厘頭，如果你面對的是管理大量Docker容器，一間間房子逛下來顯然不太有效率，不過這項技術的示範倒也透露出未來系統管理與虛擬實境整合的可能性。微軟已經在GitHub開放Dockercraft程式的原始碼。
 


 
",https://www.ithome.com.tw/news/100050,"新聞,Docker,Dockercraft,Minecraft,Microsoft,Container"
99617,28,2015-11-07,愛立信亞太區CTO：5G可望2020年推標準開始商轉,愛立信亞太區技術長Magnus Ewerbring：5G是最適合物聯網裝置使用的行動通訊網路，除了可以做到向下相容外，透過包括軟體定義網路、網路功能虛擬化和雲端等3大驅動5G的關鍵能力，可望帶動5G行動網路的成熟發展," 電信設備業者愛立信（Ericsson）集團技術部亞太區技術長Magnus Ewerbring日前來臺時表示，5G是最適合物聯網裝置使用的行動通訊網路，除了可以做到向下相容外，透過包括SDN（軟體定義網路）、NFV（網路功能虛擬化）和雲端（Cloud）等3大驅動5G的關鍵能力，可望帶動5G行動網路的成熟發展。目前，5G是下一代行動網路的趨勢，相關的標準制定仍處於草案階段，愛立信已經推出一套5G測試平臺，預計到2020年，國際電信組織將可推出完整的5G標準，屆時就可進行5G行動網路的商轉。
LTE-M及NB-LTE是未來5G行動網路的關鍵技術
根據愛立信行動化報告指出，2014年所有可以連網的裝置數量達135億個，直到2020年，連網裝置數量將近260億個（258.7億個），成長率為9成。若進一步區分連網的裝置類別，2014年機器對機器的物聯網連網設備數量只有13.5億個，但到了2020年連網裝置數量將高達73.2億個，成長將近4.5倍，是所有連網裝置中，成長比例最高的裝置；至於其他包括客戶端行動裝置、電腦筆電和平板、行動裝置等，也都有1倍以上的數量成長，只有室內電話的比例是不增反減。
Magnus Ewerbring表示，5G是現在LTE技術的再進化，可以做到向下相容並增添新的接取技術，目前的研究，以可提供廣泛行動連網且適合新型態應用的LTE-M技術為主，至於新一代的5G技術行動窄頻LTE（NB-LTE）技術，則是針對低階物聯網終端裝置設計的，是一個具有可擴充性的行動網路技術，能在超低功率下，做到最大範圍的覆蓋率。他強調，對電信業者而言，包括3G的GSM到5G的LTE-M及NB-LTE，最終都必須在同一個網路內營運，才能發揮最大的效能。
以5G應用需求來看，Magnus Ewerbring認為，因為5G流量比現在的行動網路增加1千倍，讓連網裝置的數量可以增加10倍～100倍，而影響使用者連網感受最深的終端裝置連網速度，將因此可以加速10倍～100倍，對於低功率設備的電池續航力更可以延伸10倍。
他認為，未來5G的應用主要可分成關鍵型（Critical）應用的機器連網，以及普及型（Massive）應用的機器連網應用。若以關鍵型應用來看，他表示，因為特別重視安全性、保密性和完整性，不論是可以遠端遙控的健康管理裝置，或者是交通安全控管、工業應用控管，以及可以遠端操控的訓練和手術等，都必須在低於5毫秒以下的通訊延遲、時速500公里的高速傳輸速度，以及絕對的可靠性下，才可以達成。
其他像是一般普及大量的應用型態，常見於大量的訊息傳輸，而這些訊息除了數量多以外，但訊息本身夾帶的資料量一般都比較少，常見於智慧建築、物流、追蹤、車隊管理、智慧電表、智慧農業和蜂巢細胞網路等應用，但Magnus Ewerbring指出，因為應用範圍擴大，除了要做到低成本外，更難的技術在於，要能達到10年以上的電池壽命。
SDN、NFV和雲端是驅動5G關鍵能力
Magnus Ewerbring表示，2G主要傳遞聲音，3G新增傳遞資料的功能，4G則新增影像與強化資料的傳遞，但到了5G時，更重要的是，要能提供不同應用程式之間的溝通和聯繫，對於網路和維運品質的要求也最高。因此，他認為，若要落實下一代行動網路5G的技術發展，現在SDN、NFV和雲端的關鍵技術能力，都有加分。
他進一步解釋，SDN針對網路的控管、協作與管理，提供新的簡化架構，但是，透過NFV功能，可以提供跨網路虛擬化功能有更彈性的部署方式，而雲端運算則讓5G行動網路可以達到資源共享（Pooling）和擴展（Scaling）的功能，最終都加速5G核心網路的整備能力。
目前，愛立信集團已經在瑞典和其他歐洲國家，以及韓國LG Uplus電信等公司合作5G的相關應用發展與IoT技術，預計在2016～2018年，就可以推出5G相關的技術文件以及進階的5G測試平臺，等到2019～2020年，就可以推出完整的5G標準與規格；而有了相關標準之後，就可以很快進行商轉了。
",https://www.ithome.com.tw/news/99617,"新聞,5G,行動網路,物聯網,SDN,軟體定義網路,NFV,網路功能虛擬化,雲端,Cloud,愛立信,CTO,Magnus Ewerbring"
99597,28,2015-11-01,IT月報｜雲端IT焦點回顧,AWS物聯網套件上線，資料庫商機上億推服務。各廠搶搭容器風，OpenStack釋出容器流程管理服務套件正式版，阿里雲也推Docker,"  AWS   EC2   VM 
AWS物聯網平臺亮相，EC2推出2TB超多記憶體VM
AWS第四屆re:Invent年會多項新產品，其中EC2增加2TB超大記憶體容量的虛擬機器X1，採用了Intel Xeon E7處理器來實現TB級記憶體的支援，可用來執行虛耗用大量記憶體的SAP的記憶體式運算平臺HANA，預計明年上半年正式推出。同時，Amazon IoT平臺測試版亮相。此平臺可用於蒐集億級裝置來的資訊量，支援輕量化的IoT通訊協定MQTT、並提供了一個規則引擎來簡化處理IoT裝置回傳的資訊。Amazon也釋出了IoT開發套件SDK，可支援C、JavaScript和Arduino。（詳全文）
 
 AWS   資料庫 
搶10億美元資料庫服務生意，AWS推新資料服務

AWS資深副總裁Andy Jassy揭露多項AWS營運數據。其中，資料庫服務營收在過去一年（2014年Q2到2015年Q2）成長了127％。「資料庫服務已經是一個10億美元營收的生意了」他說。也因此，AWS一口氣推出多項資料相關服務，包括首次進軍BI市場，推出了QuickSight商業智慧分析服務預覽版、資料庫轉移服務預覽版（包括Schema自動轉換工具）、並正式推出更容易即時上傳串流資料的Kinesis Firehose服務、以及RDS服務增加了與MySQL相容的姊妹資料庫MariaDB服務。（詳全文）
 
 臉書 
臉書搜尋功能更新，2兆篇貼文皆可搜尋
去年臉書更新搜尋功能讓使用者更容易找到友人分享的貼文，現在臉書進一步宣布擴大搜尋範圍，將可搜尋包括人物及粉絲專頁等公開貼文在內高達2兆篇貼文，而不限於使用者友人的張貼內容。臉書搜尋部門副總裁Tom Stocky指出，臉書索引每天搜尋高達15億次及超過2兆篇貼文，每當有事件發生時，使用者常常到臉書上觀看親友的反應。
現在臉書更新搜尋服務，未來除了親友貼文之外，搜尋結果還會顯示近日其他人的相關貼文，包括新聞報導。目前這項功能已開放給iPhone、Android及PC版的美國英語系用戶。（詳全文）
 
 OpenStack 
OpenStack新版大變革，不再全套下載改採主餐加點模式釋出
在第11版Kilo推出半年後，OpenStack如期推出了新版本Liberty，採取了全新的版本釋出方式，從過去套裝（Integrated）下載，改為大帳棚（Big Tent）模式釋出。開發者不需要一次下載全套OpenStack，而只需下載核心套件再搭配周邊套件即可。（詳全文）
 
 Docker 
Docker併購Tutum，打通Container服務部署的最後一哩
Docker公司宣布併購Tutum，這家公司專門針對Docker容器（Container）提供部署與管理的平臺，補齊了容器化應用程式開發流程的最後一哩：部署與上線。在買下Tutum之後，Docker就可以進一步提供部署上線的功能，讓容器化應用程式從程式碼組建、程式釋出以及部署上線的自動化流程一氣呵成。（詳全文）
 
 公有雲   惠普 
惠普宣布明年一月關閉Helion公有雲服務
惠普（HP）負責雲端服務的副總裁Bill Hilf宣布將變更該公司的公有雲服務模式，準備於明年1月31日關閉HP Helion Public Cloud公有雲服務，而且不再接受新的客戶，未來將協助客戶轉移至其他的公有雲，同時強化旗下的私有及代管雲端能力。Hilf說明，在惠普旗下客戶的混合雲端策略中，公有雲雖然與私有雲（Private Cloud）及代管雲端（Managed Cloud）同屬重要服務，但客戶卻發現這些不同雲端服務的界線已逐漸模糊，他們想要的是基於大型企業等級的彈性混合雲端模式，能夠整合不同的雲端環境，因此，惠普決定改變該公司的公有雲政策，採用多合作夥伴的運作模式，並將在明年1月31日關閉公有雲服務。（詳全文）
 
 戴爾   微軟 
戴爾和微軟聯手，新一代Azure混合雲機櫃現身
戴爾繼以670億美元買下EMC，擁有對VMware控制權，以補強虛擬化與雲端方面的缺口後，再宣布和微軟合作，發表新一代混合雲系統（Dell Hybrid Cloud System，DHCS），此混合雲可以在Azure上運作，戴爾表示，使用者更容易將工作負載搬到Azure上，且符合微軟雲端平臺標準（Cloud Platform System Standard）。戴爾表示新的混合雲系統，已將伺服器、儲存設備與軟體整合在一個機櫃中，而且可以整合Azure雲端服務，打破了混合雲之間的壁壘與降低安裝的複雜度與時間。微軟雲端暨企業部門執行副總裁Scott Guthrie表示，微軟和戴爾合作透過微軟雲端平臺標準來整合戴爾混合雲與Azure，整合之後，微軟會提供企業和Azure相通的混合雲服務，和協助企業打造自家的雲端策略，而戴爾新混合雲系統已正式上市。（詳全文）
 
 Docker 
搶搭容器風，阿里雲也推Docker

繼今年7月阿里雲推出眾多雲端產品及服務後，阿里雲隨即一連發布了10多種雲端新產品，囊括了各種雲端服務及應用。包括推出可支援開源的新混合雲方案，還發布第一個可支援Docker部署的阿里雲容器服務，將於11月上市，它用來縮短企業部署Docker環境的時程，也整合相關Docker編排服務。（詳全文）
 
 PaaS 
連發電廠也能上雲端，奇異推工業PaaS平臺供企業打造數位工廠應用

生產發電機起家的奇異公司，近日推出一款數位發電廠軟體（Digital Power Plant），能在雲端管理一座發電廠的各項設備和資產，甚至將各項電廠管理資訊上雲端，來優化電力業務的經營效率。這不是一個專屬軟體，而是奇異新推出的工業PaaS平臺Predix Cloud上的一個範例，企業開發者也可用此平臺來打造自己的數位工廠。奇異計畫以此PaaS平臺來進軍工業網際網路市場的野心，奇異更喊出未來要成為全球十大軟體公司的願景。（詳全文）
 
 Dropbox 
對抗Google Docs，Dropbox也推雲端文件協作Paper
Dropbox繼雲端儲存服務後，首度推出雲端文件協作服務Paper，強調簡單、協作與雲端編輯三大功能，當使用者要編輯文件時，Paper文件頁面為了簡化編輯模式，只會顯現文章標題和內文編輯頁面，也可以直接打開儲存在Dropbox和Google雲端硬碟中的文件。而線上協作功能為，使用者也可以在Paper中建立的待辦清單，再和同事分享，與利用@符號，在文件中標記同事，以提醒其他人需要完成的檔案或是需要提供意見等，且在每個人編輯過的地方，Paper會藉由標註姓名，來辨識檔案編輯過程與來源等。目前為公開預覽版，並希望有更多企業用戶參與測試。（詳全文）
 
（圖片來源／iThome）
",https://www.ithome.com.tw/news/99597,"新聞,Cloud,雲端服務,雲端月報"
99541,28,2015-10-27,第一手報導！OpenStack東京峰會Day1現場直擊（超多圖片）,於2015年下半舉行的OpenStack東京高峰會，今天（10月27日）正式展開，預計進行4天，10月30日閉幕。這次的活動，分為OpenStack會議與OpenStack設計高峰會等兩大部分。現場總共有超過四千人參加，來自全球54個國家。," 於2015年下半舉行的OpenStack東京高峰會，今天（10月27日）正式展開，預計進行4天，10月30日閉幕。這次的活動，分為OpenStack會議與OpenStack設計高峰會等兩大部分。
現場總共有超過四千人參加，來自全球54個國家。
活動一開始，首先由OpenStack基金會現任執行總監Jonathan Bryce致詞。


OpenStack管理者認證登場，OpenStack CEO呼籲，需要更多專業人才加入。

新版OpenStack最大變革之一，是改採大帳蓬發布，只需下載核心套件，再搭配自選套件，採用類似一套主餐再加點的概念。
 
想了解OpenStack每個套件的普及度多寡，現在可透過新成立的OpenStack專案成熟資訊網站來檢視，一看便知。若想評估套件成熟度，這是最佳參考。



 
Lithium雲端平臺工程團隊登上OpenStack峰會主題演講舞臺，分享他們用OpenStack打造Container執行環境的實戰經驗。



 
好大膽的現場實機展示！立即將遊戲改版從雷射攻擊變魚攻擊，能這麼做，主要是因為Container可以用來快速部署新版。



今年八月來臺分享的Yahoo日本OpenStack專家伊藤拓矢，他今天也上臺分享5萬臺VM部署經驗，相關內容早先在臺灣OpenStack大會已搶先一步發表。當然，今天有最新的建置經驗發表，你也可參考他先前在臺分享系統環境架設實務的報導。





 
年度超級使用者頒獎，表揚用OpenStack的超強企業，入圍該獎項的有下列公司：FICO、GoDaddy、NTT Group、Lithium。




 
獲得年度最佳OpenStack Superuser獎的團體是NTT的團隊。他們是規模頗大的團隊，證明OpenStack要做好也不容易，整個團隊預計明年免費到德州參加OpenStack高峰會。




每個月提供百萬次部署的Ap市集平臺Bitnami，他們也到OpenStack高峰會分享建置經驗。該公司的營運長說，這年頭，就連給企業資訊部門看的Ap部署安裝說明書，若不是透過一支手機App來呈現，那你就落伍了。


 
為何Intel大力推廣OpenStack？ Intel軟體與服務VP親口說，有500億個理由，未來全球85%應用在雲端，而OpenStack是其中關鍵基礎。




 
這年頭透過雲端，遊戲公司很容易進軍全球，這家日本遊戲公司使用實體機來部署Nova套件，連進軍臺灣都容易。




擁有45000臺VM的ebay，如何讓開發和測試自動化？Puppet、Docker和OpenStack的串接很重要，目前他們對於Docker只用於測試，線上環境還是VM。

 
跨國企業要建置多套平台式雲端服務，該部署幾套OpenStack？
在美日新三處機房內管理13萬個VM的雲端供應商GMO建議，一套平臺產品裝一套OpenStack，再用Keystone套件統一管所有帳號。


每月10億次網頁瀏覽量的日本goo網站，導入OpenStack以提升速度與反應能力，他們在6個月內部署400個Hypervisor，已經穩定運作超過1年，他們的管理經驗強調DevOps工作流程的重要，並且選擇以Puppet來管理虛擬機器，服務部署時間由過去的5天，大幅減少至30分鐘，在4個月內啟動1300臺虛擬機器，以支援70多項服務。
goo的下一步則是持續提升虛擬機器的密度，以及把負載平衡從手動作業，升級為Load balancing as a Service。
相關報導請參考「直擊OpenStack東京高峰會」
",https://www.ithome.com.tw/news/99541,"新聞,OpenStack,OpenStack Tokyo,Container"
99538,28,2015-10-27,【OpenStack東京高峰會】第一張OpenStack證照明年推出、新版全面支援容器技術,OpenStack Summit Tokyo高峰會今日（10/27）在日本東京品川舉行，宣布官方專業技術證照明年出爐，Liberty新版本全面支援容器技術。," OpenStack Summit Tokyo高峰會今日（10/27）在日本東京品川舉行，來自56個國家、超過5千人與會，這是OpenStack基金會每年舉辦的兩場高峰會的其中一場。
OpenStack基金會執行長Jonathan Bryce在今天的大會演講主要宣布三件事情：OpenStack官方專業技術證照將於2016年推出、新版OpenStack Liberty首度加入完整版的Magnum容器服務，以及官方網站推出OpenStack Project Navigator，提供各個專案的成熟度、採用度等資訊供使用者查詢。
在Docker容器（Docker Container）聲勢高漲的當下，OpenStack在新版本Liberty也呼應容器技術的發展，Liberty版本已經提供容器服務Magnum的完整版，對於現今主流的容器叢集管理工具：Kubernetes、Mesos及Docker Swarm皆可支援。
Magnum容器服務可與OpenStack的重要模組整合，包括運算模組Nova、實體機模組Ironic及網路模組Neutron。而明天的大會演講中，則會進一步討論Kuryr專案，Kuryr可將Docker的容器網路技術Libnetwork，轉換為Neutron的API。
Jonathan Bryce指出，從OpenStack的用戶紛紛整合Amazon AWS服務、Container技術、大資料等等技術來看，這除了表示OpenStack已經是一個橫跨虛擬機器、容器與實體機的平臺，讓用戶可以整合自己想使用的技術。也代表不同的企業有各自的需求，新創公司很快就採用能加速開發部署的容器技術，而應用大資料技術的企業則對資料處理模組Sahara及實體機部署模組Ironic更有興趣。
他表示，從Liberty版本開始OpenStack的開發就採取大帳棚（Big Tant）模式，這個大帳棚下有核心服務：Nova、Cinder、Keystone、Swift、Neutron及Glance，同時也可容納更多創新的專案，並且讓使用者可自選大帳棚內的專案組合。
OpenStack基金會同時也推出OpenStack Project Navigator，在官方網站開始提供各個專案的狀況，方便使用者依照自己的需求找到最佳技術組合。Jonathan Bryce在演講中出示一張分析OpenStack專案的技術成熟度與採用度的象限圖，他說每次演講只要秀出這張投影片，聽眾就會立刻拍照下來，以掌握OpenStack專案的發展狀況，在OpenStack Project Navigator推出後，使用者就不必這麼辛苦了，由官方網站即可查詢各專案的成熟度與採用度等資訊，這些訊息是匯整技術委員會及用戶委員會的相關資訊。
Jonathan Bryce也宣布OpenStack在專業技術證照的第一步，2016年第二季將會推出第一個OpenStack認證管理員（Certified OpenStack Administrator，COA）認證，並將採用虛擬測試的方式進行認證測驗。至於OpenStack專業技術認證的標準，則由來自10個國家的生態系代表參與社群工作群組，協助定義所要驗證的技術能力。
",https://www.ithome.com.tw/news/99538,"新聞,OpenStack Tokyo,OpenStack,Container"
99465,28,2015-10-24,搶搭容器風，阿里雲也推Docker,阿里雲在2015雲棲開發者大會上，發布了大資料、IoT及機器學習應用等新雲端產品，並推出第一個可支援Docker部署的阿里雲容器服務," 【杭州雲棲大會現場直擊】當進入競爭越來越激烈的雲端產業市場，前有像是亞馬遜AWS、微軟Azure等大型雲端服務商持續引領雲端風潮，擴大雲端事業版圖，後則有像是來自阿里巴巴集團旗下的阿里雲計算緊追其後，積極展開布局搶攻全球雲端市場。
繼今年7月阿里雲推出眾多雲端產品及服務後，才相隔僅僅不到3個月，阿里雲隨即在近日杭州舉行的2015雲棲開發者大會上，一連又發布了10多種雲端新產品，囊括了各種雲端服務及應用。包括推出可支援開源的新混合雲方案，還發布第一個可支援Docker部署的阿里雲容器服務，也首度推出打造完成的大資料運算平臺E-MapReduce、機器學習平臺DT PAI，以及推出可結合雲端分析運算的IoT解決方案。
這次由阿里雲發布的眾多雲端新產品中，其中一大亮點是將阿里雲API全數開源，因而推出了一套企業混合雲整體解決方案，讓開發者也能透過這些API搭建專屬的PaaS平臺，來開發更多雲端應用，此外，在這套方案中也提供了能相容OpenStack的統一介面，有助於企業做為雲端集中化管理。
而為協助企業解決將大量資料上傳雲端的難題，不同於AWS以採用實體SnowBall資料運送箱來讓資料上雲端的作法，阿里雲在這次大會上同時宣布提供了一套一站式數據上雲端的整體解決方案，除了原本就有的硬碟寄送服務外，還加入了一款高速通道產品ExpressConnect，做為提高企業跨地理、跨疆域的高速資料傳輸能力，預計這項解決方案將在11月率先於中國數個城市推出。
第一個支援Docker的阿里雲容器服務即將推出
阿里雲不只開放API，針對近年來火紅的Docker技術，也正式發布了第一個支援Docker的阿里雲容器服務，用來縮短企業部暑Docker環境的時程，也整合相關Docker編排服務。阿里雲運算資深總監李津表示，阿里雲已成為繼亞馬遜AWS、微軟Azure後，全球第3家由Docker官方支援的雲端服務供應商，除了能將Docker運用在物件儲存系統（OSS）上，他更透露，在新版Docker推出時，也將進一步支援阿里雲的雲服務器（ECS），讓企業能迅速在ECS上部署Docker，預計阿里雲推出的這項容器服務，將在11月正式上市。
隨著企業對於雲端運算及分析的需求逐年升高，阿里雲也在這次大會中首度推出第一個打造完成的大資料運算平臺E-MapReduce。這個平臺主要提供了基於阿里雲ECS的大資料分析服務，可支援包含了Hadoop、Spark及HBase等多項大資料分析工具，來協助企業分析利用。
李津也指出，阿里雲已實際將大資料分析相關技術運用在中國貴州省的交通改善計畫項目上，透過將蒐集到的海量交通資料拿來平臺分析後，至今已在高速公路事故的發生比例上，做到較往年達8成的改善幅度。這項大資料分析服務將在11月推出。
不僅如此，阿里雲連同將在年底推出第一款可視化的機器學習平臺DT PAI，能將原本阿里巴巴用在內部開發數據的運算分析技術，首度對外開放一般企業用戶使用，未來，這個機器學習平臺也將做為一站式的數據開發平臺，包括提供資料分析處理、特徵工程、演算法模型和評估等，讓原本不具備數據開發能力的企業，也能很快利用此平臺來挖掘新的加值應用。
另一方面，阿里雲也同時宣布將展開一項基於GPU與高速匯流排標準InfiniBand結合的高效能運算（HPC）測試項目，後續也將提供具有高度運算需求的企業採用或做為深度學習等分析應用。
而對於物聯網掀起的新浪潮，阿里雲也首度做出回應而推出自家第一款商用IoT解決方案。阿里雲表示，在這個IoT方案當中將提供各項物聯應用的產品組合，包括了資料存取分析、訊息發送、安全認證及韌體升級等，並也將與阿里雲後端的平臺服務整合，例如語音解析、蝦米音樂、支付寶及室內定位技術等服務，來協助企業開發更多物聯網應用。
除了推出雲端新產品及服務，阿里雲在這次發表會中，同時也強化雲端安全防護機制，包括在企業安全防護上，發布一款雲盾安全網路產品QuickShield，可提供企業安全的動態CDN，並也能用來過濾及淨化來自外部不正常的網路流量。
",https://www.ithome.com.tw/news/99465,"新聞,阿里雲,Docker,Container,雲端服務,Cloud"
99476,28,2015-10-23,首款國產Container管理平臺亮相，和信雲端搶頭香,透過Docker的Container技術，和信雲端打造臺灣第一款Container叢集管理平臺，方便建置一套部署內部的容器叢集管理平臺，來搶攻企業內部DevOps需求和物聯網應用需求," 和信雲端發表了臺灣第一款國產Container叢集管理平臺，稱為特立方容器引擎。採用了Docker技術，再搭配自行開發的管理和部署平臺，來提供視覺化介面的Container管理平臺軟體，可供企業用來建置一套部署於內部的容器叢集管理平臺。
和信雲端執行長李承勳表示，和信已有一套採用OpenStack打造的虛擬化平臺軟體產品，但曾在協助客戶導入時發現化，虛擬化只能發揮實體機器效能的70%，因此，後來採用Docker來打造容器平臺，提供連30％效能損耗都在意的企業需求市場。
因此，一年前，和信雲端開始打造Docker管理平臺軟體，投入10個研發人力。不過，和信雲端並非專供工具平臺軟體，而將採產業應用解決方案來推廣Docker管理平臺。
例如，李承勳表示，Docker也很適合用於物聯網應用，尤其像是物聯網閘道裝置的軟體更新。過去得整套更新韌體的作法，但有些物聯網閘道器會部署在網路連線品質不佳的地區，像是山區或偏遠地區，遇到網路不穩斷線，就得重新下載。透過Docker來打包閘道器上軟體時，就可以透過遞增（Incremental）方式來更新，而不用整套打包更新，更能適應網路不穩的環境。另外他也看好臺灣企業DevOps需求對Docker部署的需求。他估計，明年臺灣容器導入需求，包括物聯網應用和企業內部需求，可上看10億元。
不過，因為臺灣多數企業仍採用微軟平臺，李承勳表示，微軟Windows Server何時能內建對Docker的支援，將是帶動臺灣Container需求起飛的關鍵。
目前，和信雲端以協助企業建置、企業應用Docker化和提供Docker部署軟體為主，而沒有提供Container公有雲服務。
",https://www.ithome.com.tw/news/99476,"新聞,Docker,Container,國產容器管理平臺,和信雲端"
99477,28,2015-10-22,Docker併購Tutum，打通Container服務部署的最後一哩,在買下Tutum之後，補齊了容器化應用程式開發流程的最後一哩：部署與上線，未來Docker公司將可提供容器化應用程式完整的自動化流程。," Docker公司宣布併購Tutum，這家公司專門針對Docker容器（Container）提供部署與管理的平臺，補齊了容器化應用程式開發流程的最後一哩：部署與上線。在買下Tutum之後，未來Docker公司將可提供容器化應用程式完整的自動化流程。
Docker產品資深副總裁Scott Johnson表示，目前Docker公司提供的Docker Hub雲端服務，具有程式碼整合與CI持續整合等自動化功能，就應用程式開發的三階段流程：程式碼組建（Build）、程式釋出（Ship）、部署上線（Run）而言，Docker Hub已可涵蓋程式碼自動組建及程式釋出的功能。若使用者不想使用Docker Hub的公眾雲服務，Docker最近也推出了Docker Trusted Registry的私有雲版本。
而在併購了Tutum之後，Docker就可以進一步提供部署上線的功能，讓容器化應用程式從程式碼組建、程式釋出以及部署上線的自動化流程一氣呵成。

Tutum是專門為Docker容器所打造的部署與管理平臺，這個服務能夠讓用戶從Docker Hub或其他類似的服務，將Docker容器或是Docker Compose定義的應用程式部署到多種環境，包括AWS、Azure、Digital Ocean、Softlayer等公眾雲、Docker叢集或企業內部系統。
既然是Docker容器的部署與管理平臺，Tutum當然也提供管理功能，包括管理Docker容器及應用程式架構，如監看容器化應用程式的健康狀態、容器的更新、架構的縮放等等。Tutum也提供Web圖形管理介面、REST API與指令列程式。

Tutum是從2013年中開始開發，其創辦人暨執行長Borja Burgos指出，這項服務大約在一年前對外公開，至今已部署超過百萬個Docker容器，用戶超過2萬4千人，這個服務目前仍在Beta測試階段，可免費使用。
其實，Tutum開發團隊是因緣際會跨足Container世界，Borja Burgos表示，他們一開始是開發雲端資安服務，因為Tutum的拉丁文意思就是安全，而為了驗證服務，他們必須建立雲端測試環境，也因而開啟Docker的大門。
Docker買下Tutum，既可提供更完整的功能，提升用戶體驗，而Tutum的公眾雲模式又可帶來獲利的管道。雖然Docker強調併購Tutum之後仍會依循初衷：「用戶可自由更換電池」，使用者仍可選擇與Tutum類似的服務而不受影響，不過一旦Tutum成為Docker官方預載的服務，勢必會成為使用者的首選，說不會影響類似產品是不可能的。
",https://www.ithome.com.tw/news/99477,"新聞,Docker,Tutum,Container"
99447,28,2015-10-21,一片Raspberry Pi能跑多少個Container？答案驚人,一顆4核心時脈900MHz的ARM處理器，加上1GB記憶體，這樣的規格可以執行多少個Docker Container呢？," 一片Raspberry Pi 2單板電腦，有一顆4核心、時脈900MHz的ARM Cortex-A7處理器，以及1GB記憶體，這樣的規格可以執行多少個Docker容器（Container）呢？
在6月底舉行的DockerCon大會上，Hypriot的Dieter Reuter當場示範Raspberry Pi執行Docker容器的能耐，他以Raspberry Pi 2搭配HypriotOS執行Docker引擎，可以運行500個Docker容器，不過他認為這並不是極限，最起碼還可以再執行多一倍的容器數量。於是，Docker官方就舉辦Raspberry Pi DockerCon挑戰賽，看誰能以一片Raspberry Pi 2執行最多的Docker容器。
結果，在9月份活動期間，就有人提交了執行2334個網頁伺服器的記錄。這麼一片小小的單板電腦竟然能承載如此多的伺服器，著實令人驚訝。豈知，近日這場挑戰賽終止後，上述的記錄又被刷新了，最後奪冠的記錄是一片Raspberry Pi 2可以執行2499個Docker容器。這個打破記錄的團隊將在11月的DockerCon歐洲大會上發表細節。
#RpiDocker 2740 web servers running on a #Rpi, could have more. But using a patched docker daemon with a hack that isn't a valuable fix.
— Nicolas De loof (@ndeloof) October 13, 2015
 
",https://www.ithome.com.tw/news/99447,"新聞,Docker,Raspberry Pi,Container"
99354,28,2015-10-18,Red Hat併購DevOps新秀Ansible,Ansible是近年來知名度不斷上升的DevOps自動化軟體，雖然自2013年創立至今不到3年，但由於其採用無代理程式的架構，部署靈活，程式碼易讀，因而迅速成為受矚目的DevOps工具。," 開源軟體廠商Red Hat宣布併購DevOps自動化軟體Ansible，雖然紅帽尚未公布收購金額，不過據VentureBeat所掌握的內幕消息，交易金額可能超過1億美元。
Ansible是近年來知名度不斷上升的DevOps自動化軟體，雖然自2013年創立至今不到3年，但由於其採用無代理程式的架構，部署靈活，程式碼易讀，因而迅速成為受矚目的DevOps工具。Ansible除了有開源版本之外，還針對企業用戶推出Ansible Tower版本，已有許多知名企業採用，如Apple、Twitter等。
目前DevOps自動化軟體知名的工具有Puppet、Chef、Ansible、SaltStack及CFEngine等，而在紅帽併購Ansible之後，毫無疑問的紅帽將在近年來熱門的DevOps領域取得重要的地位。紅帽在新聞稿中指出，未來仍將持續推動Ansible專案與社群，繼續服務Ansible Tower的企業用戶。
其實，Ansible的團隊成員與紅帽頗有淵源，Ansible的發明人Michael DeHaan在紅帽任職期間即開發伺服器部署軟體Cobbler，也就是Red Hat Satellite所使用的技術；而Ansible執行長暨共同創辦人Saïd Ziouani、市場行銷副總裁也都在紅帽任職多年。不過，Michael DeHaan已在今年初離開Ansible。
針對Ansible併購案，紅帽預計在10月22日舉辦媒體及分析師說明會，目前僅以新聞稿、FAQ，以及紅帽雲端管理策略總經理Alessandro Perilli在官方部落格發表的文章來對外說明。
Alessandro Perilli表示，單就產品與紅帽整個產品線來看，Ansible併入紅帽都是完美的結合。就產品面來看，他指出Ansible易於使用、模組化設計，亦是熱門開源專案等優點。
Alessandro Perilli說：Ansible之所以易於使用，其一是Ansible用以設定自動化部署的Playbook，是以易讀易懂的YAML程式碼來撰寫，對於DevOps撰寫程式碼與維護自動化流程相對容易；再者，Ansible無須代理程式，以SSH來執行自動化程序，對於企業要採用也比較容易。
Ansible的模組目前已經超過400個，Alessnadro Perilli指出，模組化讓Ansible可以廣泛支援各式需求，其模組從支援OpenStack的映像檔服務Glance、Linux Container的管理，以至於從F5 Big-IP應用服務控制器收集資料，應用之廣泛，有助於企業面對複雜的環境。
就紅帽的產品組合來看，Alessandro Perilli表示，Ansible的發展也符合紅帽支援多層次系統架構、一致性與多廠牌異質環境的開放策略。Ansible對多層次系統架構的支援從Container（容器）、虛擬機器（Virtual Machine）以至實體機，例如它可以管理VMware vSphere虛擬化環境的虛擬機器及寄宿的客戶作業系統（Guest OS），也可以管理OpenStack IaaS雲端環境，或是OpenShift這樣的PaaS環境。
在Infrastructure as Code的風潮下，透過Ansible以軟體程式自動化部署與管理整個企業IT架構，Alessandro Perilli表示，包含網路、儲存、運算（如OpenStack）、作業系統、中介軟體及應用程式層皆可適用。
此外，Ansible也支援異質IT環境，而這能解決企業面臨的多廠牌異質架構的現實問題。Ansible不僅支援Linux環境，也支援Windows環境。基於其模組化架構，Ansible可支援廣泛的產品，如F5 Big-IP、Citrix NetScaler網路控制器、Amazon AWS或Google等雲端服務。在近日舉辦的Amazon AWS年會上，Ansible才剛發表一系列支援AWS雲端服務的功能。
去年（2014年）紅帽（Red Hat）發動了幾起具有高度戰略價值的併購案，2014年4月併購Inktank Storage，取得了Ceph儲存技術，為其企業儲存策略奠基。Ceph是開源的分散式儲存軟體，同時具備區塊儲存與物件儲存的特色，不僅在OpenStack社群獲得廣泛使用，也是近年來呼聲極高的開放儲存軟體。
緊接著在2014年6月，紅帽併購法國的eNovance，取得OpenStack整合服務的相關技術；9月紅帽再併購愛爾蘭的FeedHenry公司，取得MBaaS（Mobile Backend as a Service）技術，進軍行動開發市場。

從紅帽在2014年併購連連，以及今年併購Ansible，不難看出紅帽正在快速布局新一代IT架構的策略。在今年紅帽高峰會（Red Hat Summit）上，紅帽產品和技術總裁Paul Cormier再次以印度聖雄甘地的名言來說明開放原始碼運動所遭遇的狀況：「他們先漠視你，接著嘲笑你，攻擊你，最後你贏了。」在開放原始碼運動這幾年來，前三項「漠視、嘲笑、攻擊」都已經發生了，而最後一項：開放原始碼是否贏了？他說最後一項幾乎快要可以打勾了，因為開放原始碼軟體幾乎可以完全支援企業整個IT架構，就連一般人認為開源軟體較難企及的企業儲存系統，現在也有Ceph這樣的開放儲存軟體了，接下來就等開放網路的部分到齊，就可以把「我們贏了」這項打勾了。由此看來，或許紅帽下一個併購目標就在開源網路軟體。
【延伸閱讀】
了解更多DevOps議題，請看iThome DevOps相關文章集錦
【專題】DevOps：搶先一步的IT競爭力
【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具
【專題】臺灣第一場DevOps技術大會：iThome DevOps 2015大會專題報導
【專題】開放儲存當導，Ceph從雲走入企業
",https://www.ithome.com.tw/news/99354,"新聞,Red Hat,Ansible,DevOps,紅帽,精選"
99307,28,2015-10-17,【專家嚴選】8個DevOps好用工具大介紹,DevOps工具百百種，除了市面上主流的Puppet、Chef、Jenkins跟Ansible等，是否還有其他沒用過的好工具？讓高手推薦你更多好用工具，深化自動化程度，讓導入DevOps的過程更加順利,"  【Docker】自動記錄環境參數加速部署效率

Docker透過Dockerfile記錄建立Container映像檔的步驟，並且完整建立應用程式執行環境的過程及設定參數，讓開發、建置、執行以及部署步驟變得更有效率。此外，Docker Hub網站也提供許多映像檔讓開發者使用。


 開發公司  Docker
 網址  www.docker.com
 推薦  HTC技術副理邱炫儒：「Docker可以使建置及部署更有效率，實踐基礎架構即程式碼（Infrastructure as Code）的目標。此外，亦有廣大的開源社群貢獻映像檔。」
 
 
 
 
【Packer】通吃主流平臺映像檔的打包工具

Packer除了支援VirtualBox，亦可支援VMware、AWS及Docker等主流平臺，幫助使用者打包虛擬機器或作業系統的映像檔。Packer也可以與組態管理系統結合，方便使用者在本地端用組態管理系統進行環境設定。

 開發公司  Hashicorp
 網址  www.packer.io
 推薦  Gogolook系統架構師葉秉哲：「使用者可透過Packer建置VirtualBox、AWS或Google的映像檔，讓環境的組態設定完全一致，方便後續的測試或運行。」
 
 
 
 
【Vagrant】本機端模擬虛擬機器最佳選擇

透過Vagrant，使用者可於本機端模擬其他的作業系統、組態及網路環境，甚至也可以實驗雲端主機的運作。傳統的虛擬機不易透過程式的方式控制，而Vagrant在VirtualBox或VMware的虛擬機器外實作一層控制介面，方便使用者透過程式控制。


 
 開發公司  Hashicorp
 網址  www.vagrantup.com
 推薦  Gogolook系統架構師葉秉哲：「由於DevOps十分講求自動化，故必須要透過程式控制相關流程。而Vagrant幫助使用者透過程式操控虛擬機軟體，是本地端操控虛擬機的最佳選擇。」
 
 
 
【Datadog】方便使用者快速建立監控儀表板

Datadog可以與市面上許多知名DevOps工具整合，如Chef、Puppet及Jenkins，並且根據蒐集的資訊，產出系統資訊的即時報表。此外，Datadog也可以提供使用者基礎建設的概況，如列出目前所有伺服器的CPU使用率等資訊。

 開發公司  Datadog
 網址  www.datadoghq.com
 推薦   得寬科技DevOps工程師陳正瑋：「Datadog有提供免費與付費方案的監控服務。對於中小企業或只有中小型系統架構的公司，使用者可以透過Datadog快速建立監控儀表板。」
 
 
 
 
【Sauce Labs】模擬多種前端的線上測試平臺

Sauce Labs是線上測試服務平臺，並且可以模擬多種前端開發環境。讓使用者線上透過API，在不同瀏覽器的環境下執行UI測試。而除了跨不同瀏覽環境的服務，Sauce Labs也提供iOS及Android環境的自動化測試服務。

 開發公司  Sauce Labs
 網址  www.saucelabs.com
 推薦  創科資訊研發團隊負責人謝宗穎：「使用Sauce Labs的好處在於可以輕易在各種版本瀏覽器間切換。雖然透過Docker也可以達到一樣效果，但不是每個團隊都有熟悉Docker操作的成員。」
 
 
 
 
【Codeship】省去許多自行部署第三方套件的麻煩

Codeship為持續整合及持續交付工具，並且AWS跟Heroku雲端環境整合良好，可以省去許多前置設定作業。此外，Codeship的目標為讓使用者專注於開發，其餘的工作如管理基礎架構、釋出流程，則交由Codeship執行。

 開發公司  Codeship
 網址  www.codeship.com
 推薦  創科資訊顧問戚務漢：「Codeship的操作簡單，而且介面簡潔。此外，Codeship簡化使用Jenkins時的前置環境設定，省去許多自行部署第三方套件的過程。」
 
 
 
 
【Twilio】設定觸發條件，透過API發送通知

Twilio提供雲端通訊服務，透過網路API服務發送簡訊或語音電話。另外，使用者也可以利用Twilio製作監控系統，設定觸發發送通知的條件，例如系統在突然半夜停止運作，Twilio則會自動發送簡訊，通知相關維運人員進行處理。

 開發公司  Twilio
 網址  www.twilio.com
 推薦  趨勢科技資深工程師蔡宗城：「過去半夜需要有輪班的人手，如果發現系統異常必須通知相關人員處理。而使用了Twilio後，這方面的人事都可以進行精簡。」
 
 
 
 
 
【Runscope】檢視網站健康度，確保API運作順利

Runscope的主要功能為檢測網站的健康度，確認API是否運作正常，並且產出視覺化API效能表現圖表，提供使用者分析數據如API的反應時間及回傳成功率。此外，Runscope也支援Slack、Pagerduty、Hipchat及E-mail機制，自動回報系統斷線等訊息。

 開發公司  Runscope
 網址  www.runscope.com
 推薦  創科資訊顧問戚務漢：「Runscope提供開發者乾淨簡潔的使用介面。過去要測試網站健康度時，使用者得撰寫複雜的腳本，而透過Runscope可以簡化這方面的工作。」
 
 
 
 
相關報導請見「【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具」
",https://www.ithome.com.tw/news/99307,"新聞,Continuous Delivery,持續交付,DevOps,專案開發,Docker,Packer,Vagrant,Datadog,SauceLabs,Codeship,Twilio,Runscope"
99306,28,2015-10-17,【4大DevOps工具】自動化組態管理軟體新秀 Ansible,Ansible是以Python開發的自動化組態管理工具，架構靈活、部署模式不需依賴代理程式，目標是實現基礎建設即程式碼（Infrastructure as Code），協助開發者部署出一致的運作環境,"  Ansible 

● 開發公司：Ansible
● 網址：www.ansible.com
● 作業系統：Linux、Mac OS X及Windows
● 問市時間：2012年2月
● 採用公司：NASA、Twitter及Evernote
 
Ansible是以Python程式語言開發的自動化組態管理工具，目標是實現基礎建設即程式碼（Infrastructure as Code）的目標，協助開發者部署出一致的運作環境。此外，Ansible可以用於部署應用程式以及幫助開發者導入持續整合的作業流程。
Ansible的部署模式不需要依賴代理程式（agent），與Puppet及Chef的拉取（Pull-based）屬性為特色的工具相比，Ansible的屬性則為推播式（Push-based）。
故不如Puppet跟Chef進行部署時，需要透過架設額外的Puppet主機或是Chef伺服器，Ansible只需透過SSH協定，對遠端伺服器進行控制或部署，而這樣的設計方便使用者不必對所有管理節點預先安裝代理程式，減少部署的前置作業。
Ansible透過劇本（Playbook）以及模組（Module）對節點進行管理。Ansible比喻：「如果模組是工作室內的工具，那麼劇本就是你的設計規畫。」
劇本是Ansible的配置、部署及編排使用的語言，用於描述某個透過遠端主機執行命令的方案，或者一組程序運作的命令集合。此外，劇本被設計為人類可讀，使用YAML格式撰寫。而劇本為了專注於成為組態的模型，在設計時就盡量減少了類似程式語言或者腳本的語法。
在基礎層面的應用上，Ansible的劇本可以被用於管理部署到遠端伺服器的組態管理文件。而在更高層面上，劇本可以依序對多層式架構的伺服器執行滾動更新（Rolling Updage），或是將任務指派給其他主機，例如監控伺服器或平衡負載設備。
而在每個劇本中被Ansible實際執行的任務則稱為模組，通常也可被稱為任務套件（Task Plugin）或函式庫套件（Library Plugins）。使用者可以撰寫自己專用的模組，用於控制系統的資源或執行系統命令。
此外，模組也分類為核心模組以及額外模組。核心模組為系統預設的模組，由Ansible團隊所共同開發及維護，而額外模組則由Ansible社群開發。此外，受歡迎程度高的額外模組，未來也有機會被併入核心模組。Ansilbe也提供另外3種付費版本：Basic Tower、Enterprise Tower及Premium Tower。
相關報導請見「【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具」
",https://www.ithome.com.tw/news/99306,"新聞,Continuous Delivery,持續交付,DevOps,專案開發,Ansible,自動化組態管理"
99305,28,2015-10-17,【4大DevOps工具】持續整合軟體一哥 Jenkins,Jenkins是由Java撰寫的開源持續整合工具，可以幫助使用者達成專案建置、測試及部署等階段自動化的目標，是實現測試自動化及持續整合的利器,"  Jenkins 

● 開發公司：Cloudbees
● 網址：www.cloudbees.com
● 作業系統：跨平臺
● 問市時間：2011年
● 採用公司：Netflix、Nokia、Yahoo
 
Jenkins的前身為甲骨文的Hudson，而在一開始的Hudson版本，安裝過程中必須使用透過Java來操作。而隨著版本的演進，現在Jenkins可以使用安裝檔進行安裝，方便不熟悉指令的使用者也可以輕易上手。
在專案進行開發前，使用者首先要將運作環境建置完成，而在自動化建置的過程中，使用者可以透過Jenkins完成此步驟。在專案中套件或函式庫版本變更時，可以透過Jenkins確保更新的過程沒有錯誤。
隨著目前開發方法逐漸走向測試驅動開發（Test-driven development，TDD），開發人員在撰寫功能程式碼前，首先要撰寫測試程式。而當專案建置完成，使用者可以將單元測試、整合測試交由Jenkins定期執行，並且透過自動化程序，削減人為干涉的因素，此外，UI測試也可透過Jenkins執行。
此外，Jenkins也能自動測試程式碼涵蓋率。而除了會呈現程式碼涵蓋率外，使用者也可以設定事件並自動觸發Jenkins寄送通知使用者。例如使用者可以設定當程式碼涵蓋率低於某些百分比時，Jenkins會自動發送E-mail或透過RSS通知使用者進行改善，抑或部署的失敗、成功，也可以透過Jenkins發送通知。
Jenkins也可以根據測試結果產出報表，提供使用者視覺化的檢驗。例如，當測試失敗時呈現紅燈，測試成功呈現藍燈，若有部分成功部分失敗則呈現黃燈。使用者透過報表也可得知各燈色持續的時間，了解專案的運作狀況並且進行修改或維護。一般而言，Jenkins產出的常用報表有測試狀況曲線圖、涵蓋率曲線圖以及壓力測試圖。
Jenkins的自動化部署可視使用者的需求，如部署到雲端或實體機器，兩者因為部署環境不同則有不同的過程，例如使用者可透過SSH協定進行部署，或是利用AWS提供的命令列工具。
通常使用者會透過SSH金鑰或是AWS token進行遠端存取，在部署的過程中減少人為干涉。而透過Jenkins撰寫腳本，可以清楚記錄部署的過程。即使開發人員或維運人員都不在場的狀況下，其他人亦可以透過Jenkins自動部署。
相關報導請見「【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具」
",https://www.ithome.com.tw/news/99305,"新聞,Continuous Delivery,持續交付,DevOps,專案開發,Jenkins,持續整合"
99304,29,2015-10-17,【4大DevOps工具】自動化組態管理後進之秀 Chef,Chef 是由Ruby及Erlang程式語言所開發的開源組態管理軟體，採取程式碼導向設計，可以對所管理的對象實行系統管理及安裝所需軟體等自動化組態設定,"   Chef 

● 開發公司：Chef
● 網址：www.chef.io/chef
● 作業系統：Linux、Mac OS X及Windows
● 問市時間：2009年1月
● 採用公司：Rackspace、Standard Bank、Bloomberg
 
Chef 主要由3大元件所組成：Chef工作站、Chef伺服器和Chef節點。而一套 Chef環境則包含1個Chef Server、最少1個Chef工作站以及到1或多個 Chef節點。而付費版本的Chef Enterprise中，使用者則可以使用功能完整的控制臺、Chef分析工具以及高可用性工具等。
Chef環境的一般架設步驟為先安裝Chef伺服器，並且配置Chef工作站，而Chef伺服器與Chef工作站除可以安裝在同一臺機器上，亦可以分開配置，最後在客戶端上安裝chef-client agent並註冊為Chef節點，而節點的形式可以是實體主機、虛擬機器、Container及路由器等網路裝置。
而為了達到組態管理的功能，使用者需在Chef工作站上使用Ruby撰寫Cookbook，並且傳送至Chef伺服器。此外，安裝在節點中的chef-client agent會從Chef伺服器中取得Cookbook，確保各個節點皆符Cookbook中所設定的組態。
Cookbook是Chef的重要功能，裡面包含了 Recipe、Files及Metadata等用於部署Chef節點的元件，如Recipe用來定義對目標節點進行部署的操作細節，包含如何安裝軟體，Files則指示Cookbook如何在不同的節點、不同的平臺進行正確的部署，而Metadata則確保Cookbook正確部署在每個節點上。
透過Chef，使用者不需要了解如何手動架設環境，只要使用現有的Cookbook部署即可，而Chef具備重複部署的特點，也讓使用者不需擔心安裝軟體失敗的後果。Chef也架設了Supermarket網站，上面超過6萬名的開發者總共貢獻超過2,400份的Cookbook。此外，Cookbook也支援版本控制，根據不同版本的Cookbook，使用者可以在同一套Chef框架下部署出不一樣的環境。
相關報導請見「【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具」
",https://www.ithome.com.tw/news/99304,"新聞,Continuous Delivery,持續交付,DevOps,專案開發,Chef,組態管理"
99285,29,2015-10-17,【4大DevOps工具】老牌自動化組態管理軟體 Puppet,Puppet是一款由Ruby所撰寫的開源組態管理軟體，採取模組化導向設計，可使用Puppet自有的宣告式語言或是Ruby特定領域語言進行開發，亦可在Linux、Unix及Windows運作,"  Puppet  

● 開發公司：Puppet Labs
● 網址：www.puppetlabs.com
● 作業系統：Linux、類Unix及Windows
● 問市時間：2005年
● 採用公司：美國銀行、紐約證券交易所、GitHub
 
Puppet由Puppet Labs在2005年所開發，是一款由Ruby所撰寫的開源組態管理軟體，使用Puppet自有的宣告式語言或是Ruby特定領域語言（Domain-Specific Language，DSL）進行開發，亦可在Linux、Unix及Windows等作業系統運作。
Puppet產品管理負責人Susannah Axelrod表示，Puppet是一種簡單的塑模語言（Modeling Language）。而使用者透過使用Puppet編寫的程式，可以實現IT基礎架構的管理自動化。
她表示，當使用者在使用Puppet時，即在將IT架構轉為基礎架構即程式碼（Infrastructure as Code），開發者可以透過程式碼管理基礎架構。另外，不如其他的程序式腳本（Procedural script），Puppet的塑模語言可以跨平臺運作。
Puppet的運作方式與程序式腳本有非常大的差異。如果開發者使用程序式腳本部署伺服器，必須清楚了解部署流程中各步驟的細節，才能正確編寫腳本，使伺服器部署成為開發者所需求的狀態。而使用Puppet，開發者只要得知伺服器最終的狀態為何，不需要清楚了解其中的過程，只需將實作的細節，如指令名稱、系統參數以及檔案格式交給Puppet。使用者也不必擔心腳本的撰寫錯步驟，而導致部署錯誤等問題。另外，使用者若執行一般的腳本文件，就必須對系統進行變更。
但是Puppet可以一直不斷的重複被執行。若伺服器已經處於理想的狀態，Puppet也會確保它一直維持如此狀態不變動。
Puppet採用主從式架構，由Puppet客戶端及一個或多個Puppet主機所組成，而客戶端定期與Puppet主機連線，取得最新的組態設定。而使用者得以Ruby特定領域語言來撰寫組態樣板，稱之為宣告檔，而Puppet主機再依據宣告檔的內容，自動在客戶端部署一臺伺服器所需的軟體。
而每臺透過Puppet部署的伺服器上都會安裝一個Puppet agent程式定期檢查，確保客戶端的組態符合宣告檔的設定。而當客戶端配置完成以後，也會自動發送訊息，通知Puppet主機有關客戶端部署的資訊。
Puppet模組的優點在於可重複性，使用者可以重複使用他人撰寫的宣告檔，不須自己重新撰寫。
除了Puppet Labs釋出的模組，也可以在Puppet Forge網站上搜尋Puppet社群所撰寫超過3千個模組。此外，Puppet Labs也有提供付費版本的Puppet Enterprise。
相關報導請見「【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具」
",https://www.ithome.com.tw/news/99285,"新聞,Continuous Delivery,持續交付,DevOps,專案開發,Puppet,自動化組態管理"
99284,29,2015-10-17,【雅虎經驗談】導入持續交付，必須建立持續整合自動化流程,雅虎亞太區產品研發工程部軟體工程師李卿澄表示，雅虎對於持續交付的定義為從提交程式碼到產品到線上環境，必須排除所有的人為因素," 雅虎亞太區產品研發工程部軟體工程師李卿澄表示，雅虎自己有一套對持續交付的定義：從提交程式碼到產品進入線上環境中，都沒有任何人為的介入，一切都要仰賴自動化。「要達到如此，必須建立持續整合的流程。」他表示。
在持續交付中，李卿澄表示，他著重於更快的開發行程及更好的軟體品質。而如何在顧及品質的前提下加速開發步調，他表示，必須在開發流程之中盡可能導入自動化，讓開發人員的時間、精力都集中在開發新功能上，其他的事情如測試、部署等例行公事，可以透過電腦自動化執行。此外，因為這些流程由電腦執行，比人類可靠許多，在軟體品質上也能獲得一定的提升。
在開發階段中，他認為，必須特別注意的一些事情，如開發者須確定程式碼可以在本地端進行編譯，並且自行執行基本單元測試，避免提交品質不佳的原始碼到程式庫中。另外，Code review也相當重要，讓團隊中的成員彼此了解對方的程式碼，確保程式碼應有的品質。
而原始碼自提交就開啟了自動化流程。他表示，自動化流程要盡可能地結合版本控制系統，讓原始碼每一次的改變都會自動地產出相對應的上線候選版本，如此在釋出最終版本前，就能有許多候選版本可挑選，並且得以決定不同種的功能分別要於哪些版本中釋出。
此外，原始碼提交後，也可以透過Jenkins等DevOps工具，觸發自動化流程。例如程式碼若有所改變或者無法通過編譯，自動化的流程會立即停止。團隊必須停下手邊工作，一同思考如何解決問題。如此一來，開發者可以提早得知問題並且進行修正，避免把有問題的版本發布給使用者。
而為了讓團隊成員對於流程的動態都有所掌握，目前可以透過開源的Web Dashboard顯示目前開發的動態。不過，李卿澄認為此方法成效有限。由於團隊成員多忙於開發或其他工作，無暇理會這些自動化程式送出的通知。
所以雅虎決定使用實體燈泡，顯示團隊目前專案的狀況，如綠燈就是代表正確，而紅燈代表錯誤。他表示，視覺化的意義除了讓團隊快速的得到回饋，也讓團隊的人都意識到必須為產品品質以及自動化流程的順利與否負責。
李卿澄表示，目前雅虎導入自動化流程總共有3大步驟，第一是提交暫存（Commit stage），第二是驗收測試，第三則是非功能測試。
當程式碼通過審核並提交到程式庫中，便會進入提交暫存的階段。此階段的目的為確保App在技術層級可以運作。另外也要對程式碼進行單元測試，檢驗假想輸入是否會產出預期的輸出。當單元測試進行結束時，也會針對App進行基本分析，如App的測試覆蓋率。當覆蓋率越高，代表原始碼通過越多自動化測試，可預期未來釋出的App也會有一定的品質保證。
在驗收測試步驟中，團隊得衡量是否確實把產品價值傳遞給使用者。另外，此階段也要進行基本的UI測試，如煙霧測試，確保最重要的功能是否能運作。如果使用者一開啟App就當機，就代表程式碼本身有很大的問題。
最後，當App通過非功能性測試就可以釋出。此階段主要測試App的穩定性及效能表現。首先要通過猴子測試（Monkey test），即撰寫腳本程式隨機地滑動App，測試其穩定性。不過，他表示此測試會碰上實務面問題，比如腳本自動打開了飛航模式，導致無法得知與網路相關的測試結果。而效能表現則要測試冷開機測試、記憶體的使用量等項目。
李卿澄表示，全面自動化目前仍然屬於理想階段。產品在釋出前，仍然需經過最後一道的人工測試步驟。不過，他表示，目前人工測試所占比例已經非常的小，僅有比較特別的案例需要經過人工測試，比方說App中涉及金流的過程。但是事情並不在App釋出後就打住，如果上架後發現錯誤，下次便會檢討是否要在流程中增加額外的測試，避免錯誤再次發生。

雅虎亞太區產品研發工程部軟體工程師李卿澄表示，雅虎已經將提交暫存、驗收測試及非功能性測試的流程導入自動化，手動測試所占的比率已經非常低。（圖片來源／雅虎）

相關報導請見「【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具」
",https://www.ithome.com.tw/news/99284,"新聞,Continuous Delivery,持續交付,DevOps,專案開發,雅虎,Yahoo,李卿澄"
99282,29,2015-10-17,從找到對的DevOps工具開始，實現基礎架構程式化的第一步,想要培養出擅長DevOps技能的團隊並非易事，建立DevOps文化更難，企業如何擁抱DevOps，找對合適工具入手，是建立基礎架構程式化，讓IT邁向高度自動化是第一步," 9月初，臺灣首次DevOps大會登場，超過340位來自臺灣各行各業的參加者，不只是網路公司或新創公司，還有來自金融、資服、電信業、科技業、創投、甚至是傳統產業的IT人，讓集思臺大會議中心座無虛席。如有位電信業副總經理帶著多位管理階層人員參加，想一窺未來的IT架構變革趨勢，也有臺灣資訊業者總經理，帶頭率旗下研發和維運部門主管和成員全程參與，想找出能讓自家產品研發速度更快一步的關鍵。
跑遍臺灣尋覓IT講師，在中華電信學院資訊學系一手規畫中華電信內部IT教育訓練課程的負責人林光龍也很驚訝地說，本以為這股風潮在臺灣還不盛行，沒想到這麼多人都想了解DevOps，DevOps風潮真的吹進臺灣了。
有位在臺灣知名保險公司任職的女性資訊主管，中場休息時特別走到臺前詢問臺灣是否已有DevOps顧問服務。這家保險公司打算明年要大幅汰換現有開發工具，以符合現在App開發需求。負責編列預算的她，聽到非洲最大標準銀行擁抱DevOps後，服務遞送速度比以前快了2千倍。她非常有興趣，也想要調整開發工具採購計畫，將DevOps工具納入，所以，急著想找人協助評估。
全球知名DevOps工具Chef的全球傳教士Michael Ducy也來臺分享國外趨勢時表示，DevOps名詞問世至今也不過6年，但DevOps已經從邊緣趨勢，更進一步成為企業IT的主流，DevOps不再只是小團隊、新創公司或網站公司解決問題的工具，Michael Ducy表示，除了科技業之外，電信業、零售業、醫療業與能源產業都已經開始重視DevOps。
傳統開發到部署維運的流程中，大多以版本釋出（Release）為分界。Dev流程從功能設計、程式開發、專案布建、測試到釋出。
而Ops多從取得釋出的程式碼版本開始接手，來進行後續的部署和維運工作。Dev和Ops的高牆也豎立在版本釋出階段，隔開了兩個團隊的作業流程。
敏捷開發趨勢已經發展出優化開發速度的成熟作法和工具，例如持續整合（Continuous Integration，CI）工具可以從版本控制系統一路串接到測試、布建和發布的Dev全程自動化。
但也因此，DevOps整合多半所欠缺的是如何整合到後半段的Ops。儘管Ops段也有如ITIL等優化維運的作法，但維運所面臨的複雜性和變動管理，更隨著虛擬化技術的普及和公有雲服務的成熟，Ops團隊不只要管理實體設備還有虛擬環境，甚至也要負責異質平臺的雲端服務，這也成了新式DevOps工具所要解決的課題。
DevOps為開發和維運間反覆迭代的新協作模式
DevOps工具中，過去幾年以持續交付CD（Continuous Delivery）自動化工具為擁抱DevOps常見的上手點。CD不只涵蓋了CI工具的範圍，還進一步跨過發布，延伸到部署。
而DevOps自動化工具則多半從布建開始，串接了測試、發布、部署到維運環節。此外，DevOps監控（Monitoring）工具涵蓋的範圍也多聚焦於布建之後到維運間的流程透明化，和DevOps自動化工具兩者相輔相成，監控工具的示警通知，往往能用來觸發自動化工具採取對應的行動。
DevOps現行作法大多延續已高度自動化的Dev流程，進一步延伸到Ops，一手建立工研院雲端團隊敏捷和CI開發流程，後來獨立成為雲端新創雙子星公司執行長符儒嘉直言，DevOps就是將開發階段快速發布的壓力帶進維運團隊，開發所用的敏捷方法現在也能套用在維運上，「DevOps就是開發和維運間反覆迭代的新協作模式。」
舉例來說，Gogolook架構師葉秉哲表示，導入DevOps時，一般作法是延續現有Dev端工具，沿用現有程式語言與對應開發工具，如敏捷開發所用的單元測試、整合測試工具，常見Dev團隊會使用Jenkins來整合CI和組態。
更進一步跨入Ops段可以靠組態管理系統，讓系統執行環境的狀態能像程式碼一樣地管理。所以，要落實DevOps至少需要配備一套組態管理工具。接著再視執行環境（虛擬機器）部署地點，本地端或是雲端來搭配可支援雲端工作自動化的工具。
葉秉哲表示，雲端供應商多半也會推出專屬自動化工具，若不想受限於單一雲端平臺，可使用開源工具來統整不同雲端廠商的API，如DevOps中常見的工具Chef、Ansible、Puppet等，皆整合雲端部署管理。一般還會搭配適當監控工具來即時回饋系統最新狀態，以實現DevOps另一個快速部署的特色。「並非擁抱DevOps非這些工具不可，但使用這些工具能讓IT流程自動化程度更高。」他表示。
或像HTC得以實踐DevOps的關鍵，HTC技術副理邱炫儒表示，正是導入了一套App建置自動化工具Gradle。這類DevOps工具能夠將IT自動化，讓產品流水線（Pipeline）在頻繁嵌入程式碼的執行建置時，還能追蹤每次變動順利執行。「好用的DevOps工具不能只是協助開發流程順暢執行，還要讓開發流程順利和產品維運端的流程銜接。」他說。
讓基礎架構能像程式碼一樣管理
正如葉秉哲所言，DevOps的目標之一是讓Ops所管理的基礎架構，也能像Dev所管理的程式碼一樣控管，簡而言之，就是要實現「基礎架構程式化」（Infrastructure as Code）。
Michael Ducy表示，連基礎架構都程式化以後，「可像對待程式碼那樣來對待異質維運環境，將元件配置和資源調度分配都程式化。」甚至可以透過程式碼儲存庫，資料備份機制、運算資源的管理上，來重新架構企業的商業模式。
日本樂天集團旗下旅遊網站，2014年因為CI伺服器大當機導致多項服務上市延期，而決定翻新開發到維運的流程。負責重建的樂天旅遊業務開發維運部旅遊網站團隊經理直井和久表示，基礎架構程式化的好處不只是減少開發者和維運團隊間對開發環境溝通的誤解，也讓維運團隊部署工作更容易，只需重現和測試由開發者建立並且驗證過的測試任務和配置菜單。最重要的是，「一旦發生問題，很容易可以回復先前狀態，就像結合版本控制的程式碼一樣。」
Docker更容易實現基礎架構程式化
直井和久表示，樂天從CI架構翻新到實現基礎架構程式化的另一個關鍵技術是Docker。甚至，藉助這項Container主流技術，「能打造出不需變更的基礎架構（Immutable Infrastructure）」。
過去因為基礎架構資源調度和變動管理難度高，為了簡化複雜度，管理維運上傾向建立少量部署範本，在此基礎下進行微幅調整，但如此一來很難為了不同應用更進階的優化需求而建立更多客製配置。
但藉助Docker可以快速建立起能通吃異質環境的部署映像檔，包括不同廠商雲端平臺或本地端環境，還能將配置資訊具備程式化管理特質。
葉秉哲表示，Docker出現後，更容易實現基礎架構程式化，Docker和其生態系所發展的大量叢集管理工具，將會削弱上述DevOps工具的重要性，甚至DevOps工具的排名將重新洗牌，端看這些工具未來與Docker的整合而定。儘管Docker技術仍處於發展階段，但已成為難可撼動的新一代DevOps技術，明年Windows若也能支援，就可通吃兩大主流作業系統。
但對大型企業或傳統企業而言，就如同前述提到有意採用的臺灣保險公司，不一定非得擁抱還在發展中的Docker，才能享有DevOps的好處。現在已有許多DevOps工具和軟體，甚至有軟體業者仿效元素週期表，也整理出一個DevOps工具週期表，匯集了上百個相關工具。
但要如何從中找出合適的好用工具呢？接下來我們找來臺灣具有DevOps實戰經驗的專家，為大家嚴選出他們心中的好用DevOps工具。
相關報導請見「【IT基礎架構邁向程式化的第一步】專家嚴選DevOps自動化工具」
",https://www.ithome.com.tw/news/99282,"新聞,DevOps,基礎架構程式化,DevOps大會,Docker,Continuous Delivery,持續交付,專案開發"
99283,29,2015-10-16,【誰說大象不能實現DevOps】雅虎97％專案擁抱持續交付的關鍵,「沒有Continuous Delivery，專案不得上線，我不是在說笑。」這是Yahoo執行長Marissa Mayer的宣言。雅虎不僅採用流程自動化的工具，更擴大成立持續交付領導團隊，透過訂定統一組織內使用語彙、準則，並印製各種文宣洗腦，逐步讓持續交付成為雅虎的普遍共識," 「沒有持續交付（Continuous Delivery），專案不得上線，我不是在說笑。」雅虎（Yahoo）執行長Marissa Mayer的宣言，在雅虎內引起一陣軒然大波。

雅虎執行長Marissa Mayer強推持續交付，宣示沒有導入持續整合的專案不得上線。（圖片來源／Adam Tinwort）

2014年下半年，雅虎打算全面導入持續交付，Marissa Mayer還對全公司發出這個強硬宣示，不只雅虎美國團隊，連全球各地、日本、臺灣的亞太研發團隊的開發流程都面臨了全新的大衝擊。
甚至為了導入持續交付，光是前期準備工作，雅虎就分成兩階段來進行。第一階段是在30天內，將1,800多個使用集中版本控制軟體SVN管理的程式碼儲存庫，轉移到分散式版本控制系統Git上。
第二階段則是在30天內，將雅虎總共130座的Jenkins farm，集中規模到4座。而這些Jenkins farm目前一天總負責超過4萬項的工作及應付6.5萬次的Build，雅虎資深工程師應百怡表示，光是持續交付準備階段，雅虎都設定了這樣非常有野心而且大膽的目標。
不少雅虎員工得知後紛紛發出抱怨，甚至為執行長的宣言感到憤怒，認為為了進行中的專案，已經忙得焦頭爛額，卻還要為導入不熟悉的作業流程拖累進度。有工程師的第一個反應：「全面導入持續交付？我們團隊的專案應該不包含在內吧。」連雅虎測試工程師都質疑，怎麼可能在短時間內將3萬個手動測試全部自動化。
另外，亦有團隊開始尋求折衷方案，希望手中負責的專案可以進行例外處理。但是，面對這些內部反對的聲音，Marissa Mayer堅守著她要走的路，對雅虎全面導入持續交付的態度沒有鬆動。
雅虎還沒導入持續交付時，應百怡表示，一開始工程師完成專案開發後會交由測試工程師測試，而此過程將會重複多次，直至產品品質達到一定水準。而當專案進行至預期釋出一周前，雅虎會召開會議，決定是否要將產品釋出。與會者則包含工程師經理、測試工程師經理、服務工程師等人，討論系統中的各個元件釋出的順序。
而在釋出日當天，雅虎會將專案參與者集中在一室，或是使用IRC確保所有人都隨時掌握目前產品釋出的進度。而釋出結果總是一翻兩瞪眼，應百怡表示，不是產品成功釋出，團隊歡喜慶祝，就是失敗回到原點所有過程重新執行一次，不僅要耗費心力將專案關係人召集起來，而且這種釋出模式也對團隊成員造成相當的情緒壓力。應百怡表示，過往沒有導入持續交付時，「此種工作模式一個月只能釋出一次」，無法支撐頻繁釋出的工作流程。
領導團隊定義統一用詞以及準則，協助員工上手新工作模式
應百怡表示，而為了快速得到使用者回饋，迅速對產品做出修正，雅虎勢必要改變工作步調，加速產品釋出頻率。此外，領導團隊也統一雅虎內持續交付的詞彙，方便團隊間的溝通。
應百怡舉例，雅虎每個部署的單位稱為包裹（package），而一到多個包裹則組成映像（image）。映像則會部署於主機上，而主機群則稱為元件，而如果多個元件要釋出，就會稱為系統。
在Marissa Mayer喊出「沒有持續交付，專案不得上線」的口號後，她還特別成立了負責持續交付的領導團隊，來引導其餘全公司各部門的研發團隊如何順利導入持續交付。
由這個領導團隊來制訂規則，確保持續交付的工作流程圖符合內部規定。而雅虎的規定是每次的建置一定要符合可重複性及可重現性。應百怡表示，可重複性的規定為，某次的產出若部署到某臺機器上，不論部署幾次，產出結果都必須一致。而可重現性則是某次的產出，在不同的機器上部署，產出的結果也應該一致。此外，每次團隊的產出都要有版本序號，如果程式碼有改變就必須有新序號出現，方便追溯每個版本間的差異。
另外，所有的程式碼都必須使用版本控制系統，如原始碼、發行腳本、測試檔案及測試碼。不過，即使領導團隊訂出了規則並且給予許多協助，「每個團隊仍然要思考如何執行以及導入持續交付。」應百怡表示。
每個事業單位也必須定期與領導團隊開會，回報進度以及報告專案上碰到的問題。而領導團隊也要訂定與持續整合相關的作業準則，或是提供案例給事業單位做參考，「這些都是雅虎成功導入持續交付的重要元素。」應百怡表示。而領導團隊統一內部持續交付的詞彙以及訂定工作規則的做法，都擴大工具的範疇，讓工具不再局限於軟體。
不過，導入持續交付的過程也不是一帆風順，應百怡表示，常常非技術背景的員工對持續交付產生誤會，以為要排除人為干涉便略過中間程式碼測試階段，直接進入線上環境。此時必須與他們解釋，流程中的測試流程仍然都存在，但是變成自動化執行。
此外，測試工程師也會提出質疑，是否要在短時間內將3萬個手動測試全部自動化？而應百怡表示，並非如此。當手動測試的項目越多而單元測試越少，如此的工作流程並沒有效率。她表示，正常的測試流程，單元測試所占比例應為最多，依序為整合測試、端對端（End to end）測試，而手動測試則占最少比例，如此的測試流程才有意義，並且進行快速。
領導團隊為了加強員工對持續交付印象，也印製許多文宣、海報，無時無刻宣傳執行長所交付給雅虎員工的任務。而透過領導團隊種種教育以及洗腦，持續交付終於在雅虎內成為普遍共識。一開始，應百怡認為導入持續交付應該很輕鬆，沒想到過程卻如此艱辛。她表示，因為每個團隊都有自己產品釋出的流程，而在導入持續的過程中，除了把人工作業改為自動化外，勢必會碰到許多變化。
此外，導入持續交付的成本也會取決於專案的複雜度跟歷史長度。她表示，從頭開始的新專案要導入持續整合相較容易，但是雅虎許多的系統與產品大多都是存在已久，所以付出的導入成本相當高。
導入持續整合，兼顧釋出速度與品質並非不可能
然而，時常有人質疑，快速的釋出頻率與品質是否不能同時兼顧，必須要在兩者中做抉擇？應百怡表示，其實仍有辦法同時顧及兩者。例如，如果專案的規模龐大而複雜，可以將專案劃分為多個小型專案，批次釋出或是導入自動化流程。
應百怡表示，如果專案採取少量而多次的模式釋出，團隊可以很快地發現產品問題，並且迅速進行修改，讓整體反應時間加速，「釋出階段發現問題並不是件壞事，因為發現錯誤並且迅速修復，對於品質其實是正向幫助。」她也表示，少量的釋出也能確保程式碼如預期中運作。例如，檢查10行程式碼錯誤的難度，相較1,000行程式碼低得多。
此外，導入自動化流程也可加速釋出速度。她舉例，如果測試是以人力進行，不僅速度較慢，過程中也可能因為牽扯到人為因素而出現錯誤。
應百怡表示，導入持續交付後，除了改變既有工作模式外，團隊也都有相關正面的回饋。例如，由於測試的重要性提升，開發團隊轉而開始先著手撰寫測試，因為產品如果未經測試直接進入線上環境，可能會得到不理想的結果。
而每次少量的釋出，除測試工程師很快抓到測試目標外，因為釋出品質更加穩定，少了許多突發事件，服務工程師也可從事更有產值的工作。最後，產品負責人亦可以更快看到使用者對於產品設計的回饋。所以，「持續交付不只是工程上的策略，雖然主要由工程團隊主導，但是受益者絕對包含整個公司。」應百怡表示。
不過，速度只是持續交付的一部份，如果只有做到快速交付軟體，讓工程團隊以及專案經理感到高興還不夠，「持續交付的重點是同時快速交付軟體跟傳遞價值。」她表示。
應百怡舉例，假如開發團隊的目標使用者目前需求必須要被解決，而傳統沒有導入持續交付的團隊，也許花了數個月的工作時程，卻交付使用者不需要的服務，進而造成人力與時間的浪費。
然而，在產品釋出後必須經過多次的測試、反覆上市的過程，才會釋出好的產品。所以，雅虎導入持續交付的目的便是確保在每個工作週期中都可以交付價值，讓產品可以兼顧品質跟釋出速度。
雖然工具在導入持續交付中占有一定程度的重要性，但是工具的選擇多如毛牛，也不可能期待蒐集到所有的完美工具後，才開始導入持續交付，反之，即使你中意的工具不完美，也可導入持續整合的流程。應百怡表示，導入持續交付的過程中，人其實最重要，而人的重要性在於思維方式改變後，也會進一步的影響公司文化，如雅虎最初導入時，雖然引起員工的反彈，但是到了現在，「如果知道哪個專案沒有導入持續交付，大家會倒抽一口氣」，她表示。
應百怡表示，雅虎有一位懂持續交付的優點並且強力推行的執行長，是件幸運的事情。因為非技術背景的員工較難理解持續整合的優點，只覺被交付額外的工作而心生不滿。如果沒有Marrisa Mayer的強力捍衛，推行持續交付的過程將會碰上更多問題。起初員工可能認為被交付了額外任務，但是若將眼光放遠，「持續交付是幫團隊排除障礙的工具。」應百怡表示。
而事實也證明，Marissa Mayer的堅持是對的，根據雅虎的統計資料，從2014年第三季開始導入持續交付後，全球雅虎釋出的產品增加了4倍以上，而亞太區的表現則更亮眼，釋出產品增加了7倍之多。而持續交付的流程在雅虎內目前導入的比例高達97％，「導入持續交付後就回不去了。」應百怡表示。
",https://www.ithome.com.tw/news/99283,"新聞,Continuous Delivery,持續交付,Yahoo,雅虎,Marissa Mayer,DevOps,專案開發"
99179,29,2015-10-10,微軟推Docker Container雲端服務,微軟推出的Azure Container服務，提供用戶以Apache Mesos，及Docker為基礎的雲端環境，結合Azure的巨型規模（Hyperscale），讓用戶能運用此服務在多個主機上部署與配置Mesos叢集，對Docker化的應用程式排程達到Container協作與管理," 微軟於今年九月底舉行Azure年度技術會議AzureCon，發表多項Azure的新服務，包括結盟Mesos推出可支援Docker的雲端Container服務、正式推出物聯網套件公開預覽版等。同時，增加了新的合作夥伴Akamai，能提供用戶更多選擇。
微軟Container終於能支援Docker了
微軟推出的Azure Container服務，提供用戶以Apache Mesos，及Docker為基礎的雲端環境，結合Azure的巨型規模（Hyperscale），讓用戶能運用此服務在多個主機上部署與配置Mesos叢集，對Docker化的應用程式排程達到Container協作與管理。
此一新服務其實包含多項開源計畫，如Docker、Mesos以及Mesosphere的資料中心作業系統（Data Center Operating System，DCOS），未來也將支援Windows Server Container，並且計畫於今年年底釋出此服務的預覽版。
當今許多企業多使用Mesos部署以Container為基礎的應用程式，Azure團隊副總裁Jazon Zander於官方部落格說，因此，微軟選擇與Mesosphere協助使Mesos成為微軟第一個支援的Container協作工具。
此服務為Azure託管服務，支援Mesos以及Mesosphere工具，如初始化系統Marathon、服務探查（Service discovery）系統Mesos-DNS以及排程器Chronos，並且透過Docker Swarm對Container進行部署、調度。

微軟Azure結盟Mesos，推出Docker的Container服務，此項新服務為Azure託管服務，將支援Mesos以及Mesosphere工具，如服務探查（Service discovery）系統Mesos-DNS以及排程器Chronos，且透過Docker Swarm對Container進行部署、協調。（圖片來源／微軟）

Azure物聯網套件正式上市，加快IoT應用時程
另外，年初微軟在其企業用戶大會Convergence 2015上發布的Azure物聯網套件（Azure IoT Suite），現在正式上市供用戶購買，其套件能整合公司既定流程、裝置與系統，擴展用戶的物聯網策略。
主攻行動裝置互動平臺的紐西蘭科技公司VMob技術長David Inggs即於AzureCon分享，VMob利用Azure物聯網套件及Cortana分析（Cortana Analytics），為麥當勞打造手機App平臺及設計店內外數位看板。
該麥當勞手機App可以根據用戶所在位置、時間、天氣、瀏覽畫面時間、點選次數、購物習慣等提供個性化產品訊息、餐廳地址及推送不同的優惠券。
而數位看板側邊裝有感測器，透過它投射正在注視看板的人臉部，辨識顧客年紀、性別，再依據當天天氣資料，如濕度、溫度、氣壓等為判斷，David Inggs表示，將收集到的207.66TB終端資料儲存至雲端，再就資料分析消費者的消費模式，像在不同季節能發現顧客偏好的商品不一樣，因此能做更好的策略性行銷。
另外Azure物聯網套件的推出，除了提供各式協作、分析和管理工具外，也提供一個IoT的預配置解決方案（Preconfigured Solution），可用於常見的IoT應用上，例如目前已經有的遠端監控IoT使用，之後將加入預測性維護保養和資產管理等更多優化IoT的管理應用。

主要建置行動裝置互動平臺的科技公司VMob的技術長David Inggs於AzureCon分享VMob使用Azure物聯網套件及Cortana分析的經驗，他指出，裝置將能收集到的207.66TB終端資料儲存至雲端，再利用資料分析消費者的消費模式，做更好的策略性行銷。（圖片來源／微軟）

於印度建置資料中心，搶攻2兆美元商機
同時，微軟Azure也在印度建置資料中心提供雲端服務。根據調查機構Gartner去年4月統計，印度公有雲市場今年有5.57億美元的價值，當時微軟執行長Satya Nadella就指出印度超過9億的手機用戶、2.5億的智慧型手機用戶，就是微軟雲端服務的機會所在；今年微軟表示，印度網路使用率將達到2兆美元的商機，而他們也認為，未來的世界，所有資料都會上雲端。
微軟在AzureCon正式宣布，於今年年底在印度設立三座資訊中心，分別於印度中部浦那（Pune）、東南部清奈（Chennai）以及西部孟買（Mumbai），提供當地用戶在多個地區擁有資料落地（Data residency）與複製／備援（Replication）能力。
在Azure服務於印度正式上市後，Office 365也會於10月推出，Dynamics CRM Online服務則將於 2016 年上半年跟進。
微軟亞太研發集團營運長申元慶曾表示，每一座資料中心大小可以停放32架波音747客機，相當於可以容納超過50萬臺伺服器，用來提供各種雲端平臺服務。目前微軟在全世界有24個Azure地區，除了微軟，現在沒有其他雲端業者獲准進入印度建置資料中心。
同時，微軟也發表了Azure安全中心（Azure Security Center），讓用戶能看見使用Azure的整體情況，及進行監控與管理，今年底Azure用戶即能開始使用。
微軟繼Google推低價VM跟進，將掀價格戰
繼Google雲端平臺推出低價虛擬機器服務後，微軟也推出內建Nvidia GPU繪圖加速器的N系列虛擬機器，臺灣微軟表示，N系列虛擬機器跟其他系列相比，特色在於能夠快速處理圖片、影像，而主要客戶是針對大眾傳播及遊戲業。
同時，微軟也會針對某些服務降價，並認為Google的低價虛擬機器將會掀起一波虛擬機器低價格戰，像是7月Google上市的低廉雲端儲存服務，意在與Amazon雲端服務競爭，當時雲端儲存服務價格越來越低，這次虛擬機器也會有相同的趨勢。
臺灣微軟指出，雲端運算的價格乃屬規模經濟，機房成本固定，客戶多價格自然往下走，而微軟對雲端運算的定價主要根據Amazon，再參考Google，在雲端服務價格戰爭裡，其實三家做法大抵相同。
與Akamai合作，Azure提供CDN更多選擇
臺灣微軟表示，這次發表重要的部分除了新服務外就是與Akamai合作。Akamai主要提供內容遞送網路（Content Delivery Network，CDN）服務，為了讓網路使用者能更快的下載網頁內容所設計的一種網路架構。
微軟Auzre本身其實也有CDN服務，許多人對此感到疑問，這樣服務豈不互相打對臺？「微軟Auzre不僅僅只有CDN服務，還有提供IaaS、SaaS、PaaS等雲端服務，因此讓客戶有多點選擇，少了整合問題，能更方便進一步使用其他服務。」臺灣微軟解釋。
",https://www.ithome.com.tw/news/99179,"新聞,微軟,Azure,Docker,Container,Mesos,物聯網,IoT,Akamai,CDN,精選"
99166,29,2015-10-10,IT月報｜雲端IT焦點回顧,Container服務出現了更多選擇：Google雲端Container Engine上線，以Google所建立的Kubernetes開放源碼框架來管理Google Cloud平臺上所運作的各種Docker容器，並提供自動化的容器管理功能。微軟也推出Azure Container服務，提供用戶以Apache Mesos以及Docker為基礎的雲端環境，在雲端部署Container的服務,"  微軟   Container 
微軟Azure推出Docker的Container服務
微軟宣布推出Azure Container服務，提供用戶以Apache Mesos以及Docker為基礎的雲端環境，在雲端部署Container的服務。此項新服務包含了許多項開源計畫，如Docker、Mesos以及Mesosphere的資料中心作業系統（Data Center Operating System，DCOS）。（詳全文）
 
 Google   Container 
Google雲端容器服務Container Engine正式上線
Google Container Engine是以Google所建立的Kubernetes開放源碼框架來管理Google Cloud平臺上所運作的各種Docker容器，並提供自動化的容器管理功能。Google宣布，其雲端容器服務已進入正式營運，將適用於99.5%的Google服務等級協議（SLA）。（詳全文）
 
 微軟   資料中心 
微軟開發自己的Linux，用於資料中心網路交換器系統
微軟表示，基於相容性及開放性等理由，已開發專為資料中心網路互通而設計的Linux版作業系統Azure Cloud Switch，這也是微軟首次開發自有版本的Linux。（詳全文）
 
 Google   虛擬機 
Google低價虛擬機器雲端服務正式上線
Google推出旗下雲端平臺的低價虛擬機器服務Preemptible VM，每小時的固定費用只要0.015美元，最多可比標準的虛擬機器服務便宜7成。（詳全文）
 
  VMware   虛擬機 
VM零停機搬到公有雲不是夢
今年在舊金山舉行的VMworld大會，VMware預告vMotiton將支援新的使用模式。這源自於該公司正在研發的vSphere混合雲應用新功能，VMware將這項計畫稱為Project Skyscraper，目的是讓用戶能將現有的資料中心延伸到公有雲環境上。（詳全文）
 
  雲端資安  Firefox 
Mozilla的Bugzilla遭入侵，Firefox機密漏洞資料外洩
Mozilla坦承，該基金會所使用的臭蟲追蹤與測試工具Bugzilla遭到駭客入侵，駭客總計存取了未被公開的185個臭蟲，其中有53個臭蟲屬於重大的安全漏洞，而且駭客已透過其中的1個漏洞來攻擊Firefox用戶，蒐集Firefox用戶的個人資訊。（詳全文）
 
  雲端資安   Blue Coat 
10大危險網域，小心這些駭客最常利用的頂級網域
長年分析網路攻擊手法的Blue Coat臺灣區技術總監曾良駿觀察到，近2年有越來越多駭客是採用以頂級網域（Top-Level Domain，TLD）來做為攻擊跳板，透過在一些管理鬆散TLD的網站來埋入惡意程式，進而長驅直入滲透企業或政府內部。（詳全文）
 
 SDN 
Brocade推新版SDN控制器，加強雲端協作與網路流量優化管理
Brocade近日正式推出以OpenDaylight新版Lithium為基礎開發的開源商用SDN控制器，除了加強API的互通性，也終於支援OpenStack的網路套件Neutron API，來強化資料中心基礎設施的雲端協作及管理，企業現在更容易通過OpenStack做到與底層儲存、運算、網路資源池的整合和協作管理。（詳全文）
 
 雲端資安   DDoS 
46萬支中國手機發動DDoS洪水攻擊
在香港真普選行動中挺身力抗中國DDoS攻擊的CloudFlare，最近證實了以手機發動超大規模DDoS洪水攻擊的可能性。CloudFlare的Marek Majkowski日前在官方部落格揭露一起主要由行動裝置發動、攻擊流量高達45億次的DDoS攻擊。這次攻擊事件針對CloudFlare所代管的客戶網站，在大約8個小時的攻擊行動中，總計有65萬個裝置對網頁提出45億次連線的請求量。（詳全文）
",https://www.ithome.com.tw/news/99166,"新聞,雲端,Cloud"
99197,29,2015-10-10,【reInvent大會直擊】AWS物聯網平臺亮相，EC2推出2TB超多記憶體VM,AWS今年reInvent年會第二天有4大亮點，包括了2TB超大記憶體的新虛擬機器X1、增加更多Container管理服務、能用Python語言開發Lambda應用，以及重頭戲Amazon自家IoT平臺終於亮相。," 【美國拉斯維加斯Amazon re:Invent大會現場報導】
AWS第四屆re:Invent年會第二天由Amazon技術長Werner Vogels揭開序幕，接連發表了多項與開發者息息相關新產品，四大亮點是2TB超大記憶體的EC2新VM規格X1、Container支援新增更多管理機制、Lambda事件驅動型運算服務新增Python支援，以及Amazon自家的IoT平臺終於亮相。其他新發表如可串流資料時序分析的Kinesis Analytics服務（明年上市），以及AWS Mobile Hub來簡化App開發和測試工作。
EC2則增加了2TB超大記憶體容量的虛擬機器X1，採用了Intel Xeon E7處理器來實現TB級記憶體的支援，可用來執行虛耗用大量記憶體的SAP的記憶體式運算平臺HANA，預計明年上半年正式推出。另外也推出更迷你型的虛擬機器T2.Nano來執行簡單的網頁應用，只提供1的vCPU和512MB記憶體。
AWS去年開始積極展開Container技術布局，推出了Container服務，今年更從技術支援進一步跨入Container管理層，如增加了EC2 Container Registry服務等。而用於打造無伺服器應用的Lambda事件驅動運算服務，也新增Python語言支援，並增加多項企業級功能，如VPC支援，可用於開發企業內網的Lambda應用。
而第二天的重頭戲則是Werner Vogels親自發表了Amazon IoT平臺測試版。此平臺可用於蒐集億級裝置來的資訊量，支援輕量化的IoT通訊協定MQTT、並提供了一個規則引擎來簡化處理IoT裝置回傳的資訊。Amazon也釋出了IoT開發套件SDK，可支援C、JavaScript和Arduino。另外，Amazon也和多家硬體廠商合作推出IoT入門硬體模組。如臺灣聯發科也在Amazon IoT平臺發布同時，全球同步推出了物聯網入門套件盒，內有聯發科自家LinkIT控制版和多項偵測裝置，如3軸加速感測器、聲音感測器、光線感測器、溫度感測器、濕度感測器等，單套售價109美元。
趕在AWS年會前一周，微軟也搶先宣布Azure的IoT套件正式上市，以Azure來打造IoT PaaS平臺及大量資料的處理平臺，並推出Azure IoT認證來擴大生態系。而Google則早年年中I/O年會上，發表了以Android打造的物聯網作業系統Brillo。雲端三強今年紛紛大動作搶進IoT市場，展開了各自的布局，待明年各家IoT平臺或產品正式釋出後，IoT平臺大戰將更加白熱化。
AWS發表新的超大記憶體EC2虛擬機器規格X1，採用了Intel Xeon E7處理器，可提供最大2TB的記憶體，可以用來執行像SAP HANA應用。


EC2的Container增加更多管理服務，如可全程管理Contaienr映象檔的Contaienr Registry服務和其他兩項新容器服務。



AWS去年發表的事件驅動運算服務Lambda，原本只支援Java，現在也能使用Python語言來開發。


第二天重頭是Amazon發表了自家IoT平臺，號稱可任意擴充，有能力支援上億裝置，也能和現有AWS服務或分析平臺整合。不過，目前只有Beta測試版



為了簡化IoT資料的處理，AWS推出了一個規則引擎，使用SQL語法就能新增資料過濾規則，還能將過濾判斷結果，發送的其他AWS服務來驅動進一步的處理



Amazon在這次活動會場中的乾式洗手器，就使用了AWS的IoT平臺


乾式洗手器內有IoT裝置，會將乾式清潔器的存量資訊，定期發回報給AWS的IoT平臺


透過監控後臺，可以監控會場中何處的乾式洗手器內清潔液需要補充，不用人工一一檢查才能得知。

 
 
",https://www.ithome.com.tw/news/99197,"新聞,AWS,Amazon,IoT,Container,X1"
99171,29,2015-10-07,AWS加速DevOps市場布局，推出合作伙伴DevOps能力認證,APN合作伙伴DevOps能力驗證，涵蓋持續整合、持續交付和配置管理三大類工具和能力的驗證，這也透露出AWS未來對DevOps產品布局將以此三大目標為主軸。," 【美國拉斯維加斯Amazon re:Invent大會現場報導】
趕在今年re:Invent 2015大會主題演講前夕，AWS推出了新的APN（AWS Partner Network）合作伙伴驗證DevOps能力認證，來強化合作生態系對DevOps導入服務的支援能力。未來幾個月還將推出APN整合能力認證和IoT能力認證。
過去兩年來，AWS產品布局逐漸從新創和網路公司，進一步跨入傳統企業市場。去年re:Invent大會中，AWS資深副總裁開場就鼓吹雲端平臺成為新的典範。並推出與MySQL相容的新關連式資料庫引擎Aurora（極光）服務，以及多項開發生命周期管理工具如CodeDeploy部署服務，以及3項企業資安與法規遵循新服務，如配置檔管理服務AWS Config。
其中去年發布，今年正式上線的兩項開發生命周期管理的工具，一個是持續整合（Continuous Integration）工具AWS CodePipeline，可用視覺化的方式來建立自動化的CI程序，以及另一個則是雲端程式碼儲存服務AWS CodeCommit，可儲存的容量無上限，檔案大小也不限，可用於結合不同的開發環境（測試、Staging、Production等）。這都透露出了AWS跨出雲端服務市場，積極走進開發工具和維運工具整合的DevOps市場布局。
最新推出的APN合作伙伴DevOps能力驗證，涵蓋持續整合（Continuous Integration）、持續交付（Continuous Delivery）和配置管理（Configuration Management)三大類工具和能力的驗證，這也透露出AWS未來對DevOps產品布局將以此三大目標為主軸。
目前已獲得APN合作伙伴DevOps能力驗證的工具廠商包括了Ansible, Apica, Atlassian, Blazemeter, Chef, Cloudbees, Codeship, GitHub, HashiCorp, Puppet, Salt Stack, Solano Labs, Travis CI, and Xebia Labs等。另有其他資服業者和雲端供應商則取得DevOps顧問能力認證。
 
",https://www.ithome.com.tw/news/99171,"新聞,AWS,DevOps,CI,CD"
98996,29,2015-10-04,【專訪】企業導入DevOps的3大考驗,IBM全球中介軟體系統部開發戰略總監：企業導入DevOps有3重考驗：安全、文化以及工具，業務是軟體開發的專案主，應以商業關鍵指標衡量DevOps最終成效," 國外DevOps爆紅，非科技產業也開始在產品開發流程導入DevOps，而這股熱潮也逐漸吹進臺灣。不過，在IBM負責ALM、DevOps以及持續測試相關產品的IBM全球中介軟體系統部開發戰略總監Bartosz Charabski說，企業要導入DevOps沒這麼容易，主要有3重考驗，安全、文化以及工具。
安全是多數企業在意的課題，就以IT基礎架構來說，責任可能橫跨數個部門，當導入DevOps需要改變產品開發流程，安全性就難被集中掌控。
Bartosz Charabski提到，許多企業採用開源工具設計DevOps流程，特別需要注意流程控制是否嚴謹。DevOps應該與企業原本遵循的ISO或是ITIL等標準相關聯，例如軟體釋出（Release）等過程的管理作法是相同的。而企業推行DevOps第二重考驗是文化，他認為，應該是較安全考量還大的障礙，尤其大企業中那些工作數十年的工程師，多數想用相同的方法繼續工作數十年，比起小公司或是新創公司，大企業行之有年的文化更難以改變，因此也更難以創新。
另外，工具也是企業的考驗之一，企業流程與使用的工具息息相關，企業必須挑選適合自己使用的工具，甚至倚靠工具提供的機制，以防範非法的行為發生。Bartosz Charabski強調，DevOps不應該只是工具或是一種方法論，企業應該把DevOps當作軟體開發流程的願景般看待。
Bartosz Charabski還說，DevOps不只是導入持續交付等工具，DevOps還應該由商業驅動，目的是要加速遞送產品到客戶手上的速度，這中間的過程包含使用者、業務、開發以及營運等單位，後兩者很多時候並不想擔任專案的主事者，更甚互相推諉責任，而業務單位剛好可扮演橋樑的角色，在開發與營運中間協調。
DevOps並非只有系統開發與營運單位的責任
雖然DevOps是開發與營運2個字的合併，不少企業也從這兩部門著手，但Bartosz Charabski認為，DevOps不只是如此，從與使用者接觸的第一線，持續商業規畫、協同合作開發、持續整合、持續部署到系統營運後的最佳化與狀態監控，整個過程從最初的需求探訪到系統正式上線，都在DevOps的範疇中，而Bartosz Charabski更篤定的說，沒有業務單位的加入，DevOps不可能成功。
DevOps的難處在於沒有準則可遵循，不像是敏捷開發已有明確做法可參照，然而Bartosz Charabski表示，DevOps的核心想法就是持續改善，循著戴明循環的4個動作，依序為計畫、做、檢查成效以及調整策略，他認為，很多時候企業是做中學找出最適合自家的DevOps方法，而且更多時候要從錯誤中學習。
Bartosz Charabski則表示，企業必須藉由導入DevOps加快反應市場需求的速度，在數位創新潮流中確保企業的競爭優勢，尤其是銀行業，不少人認為實體銀行將會在10到20年間消失。目前沒有DevOps成功與否的衡量標準，他認為，DevOps就如同企業的IT建置般，非常難以計算出總價值，但是其成效最終還是會反應在商業關鍵指標KPI的改變。
",https://www.ithome.com.tw/news/98996,"新聞,DevOps"
98790,29,2015-10-04,eBay用容器造新一代CIaaS平臺,"為了提高程式品質以及部署的速度，eBay也導入持續交付（CD），並推出CIaaS（CI as a Services）Live服務，每天可執行12,000次布建，最多可同時執行4萬項工作"," 軟體開發界吹起了DevOps風，為了提高程式品質以及部署的速度，紛紛導入持續交付 （Continuous Delivery，CD），eBay也不例外。日前eBay在一場研討會中，揭露了從導入持續整合（Continuous Integration，CI），到去年還推出了CIaaS（CI as a Services）供內部開發之用的歷程。eBay透露，這套CIaaS Live服務，每天可執行12,000次布建（Build），最多可同時執行4萬項工作。
在今年7月eBay和Paypel分家前，Paypal軟體工程師首席Soma Shekar Oruganti是這套CIaaS服務專案的主要推動者之一，他表示，這是eBay內部最大規模的持續整合專案。
但這不是eBay第一次導入CI，早在2011年，eBay資訊團隊就已向內部提供持續整合的服務，不過到了2014年，由於使用需求節節升高，為提高服務的穩定度以及不過，硬體資源效率，eBay資訊團隊被迫改變原本持續整合的基礎架構，建立了這個命名為CIaaS Live的高可用性雲端持續整合服務。
2014年4月時，eBay仍使用虛擬機器來執行持續整合服務，每一個VM只用來執行一個持續整合工具Jenkins服務主機。由於內部持續整合需求大增，負責PaaS團隊被迫改變持續整合架構，來提高資源的利用率，在去年6月開始，改以雲端服務搭配容器（Container）的形式提供持續整合功能。到了11月，Soma Shekar Oruganti說，在CIaaS Live上同時執行的工作已達800項，約可節省10倍的運算資源，在之前整個持續整合的系統需要24,000個CPU核心、54TB的記憶體以及180TB硬碟，但現在只要2,400個CPU核心、7.2TB的記憶體以及18TB硬碟。
 

工作排程系統Marathon從資料中心運算資源抽象化工具Apache Mesos取得現有的運算資源後，發送命令給Mesos Master，指派Mesos Slave建置持續整合工具Jenkins Master。（圖片來源／eBay）

 

持續整合工具Jenkins Master建置完成後，根據資料中心運算資源抽象化工具Apache Mesos取得現有的運算資源，發送命令給Mesos Master，指派Mesos Slave建置持續整合工具Jenkins Slave。（圖片來源／eBay）

 
資料中心抽象化靠Mesos，運算資源省10倍
能支撐如此大量持續整合運算量的系統，必須歸功於運算資源抽象化工具Apache Mesos，它被稱為分散式系統的核心（A Distributed System Kernel），可以統一管理資料中心裡多臺伺服器的運算資源，像是CPU、記憶體、硬碟空間甚至是連接埠，再以API的方式提供這些資源給需要的應用程式像是Hadoop、Spark以及Elastic Search等。
在eBay的CIaaS Live架構中，Mesos部署在內部本來就存在的OpenStack之上，而為了讓Jenkins方便集中管理，Jenkins只部署在Mesos上，並由工作排程系統Marathon負責控制工作的進行。整個CIaaS Live的Mesos叢集設定從Mesos的Slave開始，每個Slave會向Master廣播（Advertise）各自擁有的運算資源，例如Slave 1擁有4 CPU、64GB記憶體以及500GB硬碟，Slave 2有4 CPU、128GB記憶體以及600GB硬碟，而Slave 3有8 GPU、12GB記憶體和250GB硬碟，Mesos Master會將這些可用的運算資源呈交給Marathon。
當有1個需要建立Jenkins Master的需求在工作佇列中，Marathon根據演算法挑選一個從Mesos Master呈交的運算資源，假設這個建立Jenkins Master的任務被指派給Slave 1，此時Mesos Master便會負責在Mesos Slave1啟動Jenkins Master，並由Jenkins Master控制接下來Jenkins持續整合的運算資源調度。
Jenkins Master建置完成後，當有使用者提出持續整合服務的請求，Jenkins Master會根據Mesos Master所呈交現有的運算資源，挑選一個Mesos Slave建立Jenkins Slave執行持續整合的請求，例如是一項需要4GPU、512MB記憶體和3GB硬碟的工作，而Jenkins Master挑選了Slave 3執行任務，而Slave 3切分現有運算資源承接該任務後，將還剩4GPU、11.5GB記憶體和247GB硬碟的運算資源，這些資訊會被回傳給Mesos Master，以供其他任務繼續使用，因此1個Mesos Slave可以接受多項任務指派，直到運算資源耗盡。
只有Master節點需維持高可用
eBay整個持續整合的叢集，使用Apache Zookeeper作為Master的管理工具，Zookeeper是一套集中式的服務，專門管理規模龐大的開源分散式系統，用來維護設定資訊、命名以及分散式系統的同步等工作，以建立高可靠度的服務，因此在持續整合需要高可用性的服務，也用Zookeeper來管理支撐CIaaS Live中重要的Mesos。
為了達到高可用性以及高容錯性，持續整合服務1次啟動，至少會有3臺Mesos Master，這3臺伺服器開啟完成後，便會一一向Zookeeper註冊，並選出一臺Master中的指揮，所有對於Mesos的工作請求，都會先導向Mesos Master的指揮，而這樣的運作方式可以容許同時存在多臺的Mesos Master，以達高可用性的設定。
不只Mesos要達高可用性，連Marathon跟Zookeeper也是，Marathon採用類似Mesos Master的部署方式，而Zookeeper則有內建高可用性的設定。不過，Soma Shekar Oruganti表示，需要高可用性要求的只有Master，就以Mesos為例，只有Mesos Master需要為高可用性做準備，而Slave對於工作來說都是一種資源，可依據需求而增減。不過，Soma Shekar Oruganti表示，由eBay內部隨著持續整合的需求量上升，Marathon後期已無法應付龐大的工作量，因此在2015年2月的時候，他們將Marathon更換成能夠管理更大型叢集的工作排程系統Apache Aurora。
eBay改變持續整合服務的架構後，CIaaS Live除了比之前的方式更節省運算資源外，Soma Shekar Oruganti說，因為他們不再使用虛擬機器安裝Jenkins，而是將Jenkins裝於Docker Container，並且受惠於Mesos管理運算資源的優點，當1個持續整合的副本當掉，重新建置副本的速度快上不少。
 

Mesos如何廣播資源以及分派工作



1.資料中心運算資源抽象化工具Apache Mesos的各Slave節點向主要Mesos Master廣播各自擁有的運算資源
2.Mesos Master向工作排程系統Marathon呈交可用運算資源
3.Marathon透過Mesos Master指派工作給Mesos Slave1
4.Mesos Master命令Mesos Slave1執行Marathon交付之工作
5.Mesos Master呈交可使用的運算資源給持續整合工具Jenkins的Master節點
6.Jenkins透過Mesos Master指派工作給Mesos Slave3
7.Mesos Master命令Mesos Slave3執行Jenkins交付之工作
資料來源：eBay，iThome整理，2015年09月

",https://www.ithome.com.tw/news/98790,"新聞,eBay,持續交付,Continuous Delivery,CIaaS,CI as a Services,容器,Container"
99010,29,2015-09-29,Container是開發者可以改變一切的工具,紅帽產品和技術總裁Paul Cormier說：「容器（Container）技術提供給應用程式開發者一個可以改變一切的工具，我認為那就是未來，接下來將會非常有意思。」," iThome問：容器（Container）是當今熱門的IT議題，這項技術是否已發展到足以讓企業採用的時候了？
紅帽（Red Hat）產品和技術總裁Paul Cormier回答：我不認為IT技術會有一切就緒的一天。容器（Container）技術與應用程式息息相關，容器之美，在於讓應用程式保持一致性。所以，企業必須從應用程式的角度來思考，並非所有的應用程式都適合或者需要採用容器技術，容器技術與應用程式的特性之間有很大的關係。
紅帽在3年前著手開發Red Hat Enterprise Linux 7的時候，開發人員就決定採納容器技術，這可說是很有遠見。1年前我們就已經發布支援容器技術的RHEL 7，經過了一年，現在紅帽對容器技術的支援，已經從單一主機，更進一步橫跨實體機、虛擬機、私有雲與公眾雲。
我相信未來的企業IT架構一定是混合型式，囊括實體機、虛擬機、私有雲與公眾雲等4種平臺，而今紅帽旗下的這4種平臺，都立基於RHEL，也都支援容器技術，因此容器型態的應用程式就可以遊走於這四種平臺，不需要修改就能從實體機移動到虛擬機、私有雲或公眾雲。這個結果非常有意思，因為這代表著應用程式可以保有一致性，而不需就不同的平臺而修改。
不論你的應用程式目前是什麼架構，不管是處於雲端或虛擬化環境，接下來要採用容器技術的話，我認為一開始都不可能一步到位。你可沒辦法只按個開關，一切事物就會轉換好，勢必要經過一段漸進式發展的過程。也因此，IT人員要應付的絕對是混合式架構，而這也是唯一可行的方式。
容器技術的發展非常快速，百家爭鳴，然而也因此缺乏統一的標準，呈現各自為政的破碎局面，這不免是容器技術發展的隱憂？
Paul Cormier：我認為容器技術的好處之一，是IT現在所面對的許多頭痛問題都能迎刃而解。容器技術有諸多優點，但帶給企業最大的功勞，我認為是讓應用程式能夠一貫性移動。一旦IT架構的每一個地方都支援容器，那麼就可以擁有應用程式一致性的環境。
不過，現在容器技術有多種不同的規格，確實也倍感困擾，有RHEL Container、Ubuntu Container、Windows Container，這些雖然都說是Container，但仔細看都不太相同，這個問題若不解決，將會對企業造成很大的困擾。
所幸，我們在今年的DockerCon與Docker、Microsoft宣布一起合作，展開Open Container Project容器標準規格專案，同時我們也把容器技術相關的廠商，如Google、Intel等，也一起帶入這個專案。在這個專案中，Docker貢獻Container的格式，所以Docker Container這個格式目前是開源了，這樣大家就可以共同來推動格式的標準化。此舉意謂即便RHEL Container、Ubuntu Container、Windows Container仍代表不同的技術，但它們都採用相同的標準格式，所以開發人員可用標準的格式來開發應用程式。現在產業一起坐下來，大家一起合作，各自為政的問題已經獲得了初步的解決。
企業仍對容器技術採取觀望態度，其中一個關鍵問題是安全，企業有必要這麼看待容器的安全問題嗎？
Paul Cormier：容器的安全當然很重要，由於容器是作業系統的一部分。從技術的角度來看，我們為了強化容器的安全，把SELinux與cgroups帶進Red Hat Enterprise Linux，所以RHEL Container就可以帶有管理性與安全性。
看待容器的安全性問題，就跟部署作業系統的安全一樣，其中一個重要的觀念是安全生命周期的管理，而這是許多人會忽略的。如同前不久我們面對的SSL安全的問題，才剛解決了一個Open SSL的軟體安全臭蟲（bug）問題，沒多久另一個Shellshock又來了，所以我們趕緊在24小時內解決問題，讓RHEL作業系統可以立即部署修正檔，把安全漏洞補起來。相同的狀況也會發生在容器，你不知道何時會有安全問題發生，所以必須有一套反應機制，視安全為生命周期來管理，持續強化容器的安全性。
由於容器具有高移動性，只要是在Linux的範疇內，容器就可以在任何地方運行，人們甚至不太在意作業系統元件的差異了，也因而容易忽略容器的安全其實與作業系統息息相關。容器的安全須要格外注意，畢竟容器是作業系統的一部分。而唯有強化作業系統與容器的安全，企業才可能將其用於正式的環境。
紅帽去年推出Atomic Project，今年又推出Atomic Enterprise Platform，這之間有什麼差異？
Paul Cormier：Atomic Project，是以RHEL為基礎的容器主機，也就是專為運作容器所設計的主機，可稱為Atomic Host。而Atomic Enterprise Platform則是一個平臺，讓你部署與管理多臺Atomic Host，數量是你想要多少皆可。
Atomic Project本身雖然是個有意思的技術，但還不夠有趣，畢竟容器技術真正派上用場絕不是單一主機。如果你現在要部署數千臺伺服器，要支援容器，那麼Atomic Enterprise Platform就是管理與部署數千臺Atomic Host的最佳選擇。
在去年的紅帽高峰會上，我宣布Atomic Project時，談的是打造容器的第一步，而今年我們藉由RHEL Atomic Enterprise Platform，則把容器技術更進一步推向企業應用的等級。就像紅帽當初把Linux帶進企業一樣，現在我們也要把容器技術帶進企業。
現在有多家容器技術廠商競相推出容器作業系統，你怎麼因應？
Paul Cormier：Atomic Host只有在容器的格式上規定遵循Docker Container，這是Atomic Project要求的唯一標準。至於你要選擇什麼樣的指揮調度（Orchestration）工具，基本上任何市面上的工具都可以。
在指揮調度工具上，紅帽預設使用Google的Kubernetes做為Atomic Enterprise Platform的指揮調度引擎，當然你也可以採用Apache Mesos，我相信Docker公司也已經支援Mesos。所以今天我們都可以採用這些不同的技術，只要我們認同Docker Container的標準格式，那麼軟體工程師就可以擁有共通的應用程式格式。
至於這些工具，其核心仍是Linux，我一直說不論是Linux相關工具或是Linux作業系統的分支發行版本，我們紅帽在Linux上已經領先12年了。
你對於容器技術未來的發展有何看法？
Paul Cormier：科技進步相當快，我認為容器化（Containerization）最令人興奮的是指揮調度（Orchestration），容器技術提供一個打造新型態應用程式的基礎，也就是我們常說的微服務架構（Microservices）。我認為會有越來越多企業將其應用程式放到容器內，所以透過像是Kubernetes這樣的指揮調度工具，應用程式服務彼此能溝通，也因為微服務架構，你將擁有許許多多大小不同的應用程式，有些是放在公眾雲，有些則是在裸機等等。容器技術正提供給應用程式開發者一個可以改變一切的工具，我認為那就是未來，接下來將會非常有意思。
新興的網路服務公司熱衷於微服務架構，然而這適合一般的企業嗎？
Paul Cormier：我們認為企業的IT架構將會橫跨實體機、虛擬機、私有雲與公眾雲，他們也開始在企業裏實現這些架構，我相信你將會看到，微服務架構在企業會越來越有用。
現在一般來說是以應用程式的型態去區分放在企業內部或外部雲端服務，對於一些安全性要求較高的應用程式就放在防火牆後面，另外一些應用程式則可能放在像Amazon這樣的公眾雲，然而我認為不久的將來你會看到，企業把應用程式其中一部分的服務放在防火牆之後，例如是資料庫，另外一部分的服務則可能放在像Amazon這樣的公眾雲，例如運算需求很高的服務，這樣你就可以方便擴張，而整套系統仍然可以運作。你將會看到應用程式架構在轉變，能夠適應上述四種不同的IT環境，這是我們看到未來的下一步。
既然微服務架構是個重要的趨勢，那麼DevOps對企業而言也是大趨勢？
Paul Cormier：絕對的，微服務是整個IT業界正在熱烈討論的大趨勢。一旦你打造微服務架構，就可以更快建造、更快升級、持續整合，因為在微服務架構下，你所要面對的程式碼相較之下變得很小。在微服務架構下，即便應用程式仍有臭蟲需要修正，但更新的過程會變得比較容易，比去過去要更新一大塊程式碼會來得容易許多。
我認為這將會改變整個軟體開發的方法，你會更有架構觀，在著手寫程式碼之前，就會先思考架構與程序。在這個大趨勢下，DevOps將會變得很重要，非常重要。
",https://www.ithome.com.tw/news/99010,"新聞,Container,容器,Red Hat,Atomic Enterprise,DevOps,精選"
98519,30,2015-09-03,Chef全球傳教士推薦的4個DevOps好用工具,因應雲端架構而生的伺服器管理工具Chef，讓工程師管理伺服器就像看食譜做菜一般有條不紊，而Chef全球傳教士Micheal Ducy還另外推薦了4種工具，在使用Chef部署伺服器時可幫忙除錯," 過去IT人員因為管理伺服器數量有限，因此多數情況手動管理是可以被接受的方法，不過當企業IT架構進到了網路規模（Web-Scale）時代，雲端架構下的伺服器數量動輒數以千計，如仍再用人手動管理缺乏經濟效益，因此自動化的工具應需求而生。
Chef是達到自動化管理伺服器的工具，而DevOps工具Chef全球傳教士Micheal Ducy說：「Chef是一種語言」，能將IT架構轉為基礎架構即程式碼（Infrastructure as Code），且既然是程式語言就要獲得像專案程式碼一樣的處理，同樣要做版本管理、能被測試，並能被重複執行。
Chef以廚師做菜的情境對應系統營運人員管理伺服器，在Chef中最重要的就是食譜（Cookbook），一個Cookbook便是一臺欲部署伺服器的設定檔，Cookbook中包含配方（Recipe）、資源（Resource）、檔案、樣板等多個套件，而其中的Recipe是用來設定伺服器部署的細節，像是如何安裝、安裝哪些套件或是該如何配置等，而Resource則是設定運作的規則。
而除了Chef本身就是一個方便的工具外，Micheal Ducy另外介紹了4種Chef生態系的工具，幫助系統工程師使用Chef：

1.名稱：Chefspec
功能：Chefspec是一個單元測試（Unit test）與程式碼覆蓋（Code coverage）的框架 RSpec的擴充套件，對於Cookbook的迴歸測試（Regression testing）很有幫助，避免Cookbook的更新影響既存的設定，而在部署後發生錯誤。

2.名稱：Foodcritic
功能：可以標記出Cookbook中可能會發生錯誤的部分，還能客製化規則。

3.名稱：Rubocop
功能：由於Chef就是用Ruby語言開發的，因此Micheal Ducy特別介紹了這個Ruby語法自動更正工具，Rubocop除了能找出潛在錯誤的風險外，也能提供像IDE的功能，修正輸入錯誤，並幫助開發者產出較高品質的程式碼。

4.名稱：Test Kitchen
功能：在一次性的運算節點上，實際測試Chef的程式碼。
",https://www.ithome.com.tw/news/98519,"新聞,DevOps2015,DevOps,Chef"
98505,30,2015-09-02,HTC行動開發實現DevOps的關鍵工具大公開,為了實踐DevOps，HTC開始導入Gradle來部建App應用程式，HTC技術副理邱炫儒表示，Gradle這套自動化部建工具如風水學，讓開發專案可以有一套依循的參考作法，又能讓開發者自己彈性調整。," Google早從2013年就開始使用Gradle來作為Android SDK的建置工具（Build）。臺灣使用安卓系統的手機廠商HTC也因此跟著在App開發流程中導入Gradle，HTC技術副理邱炫儒在DevOps2015研討會指出，正是Gradle才讓HTC得以實踐DevOps。
他說，DevOps是文化，同時也是一個幫助我們專案快速產出高品質結果的實作方式。而DevOps工具則要能夠將IT自動化，讓產品流水線（Pipeline）在頻繁嵌入程式碼的執行建置時，還能追蹤每次變動順利執行。
以前Java開發者常用兩種開發自動化工具Ant與Maven來管理App開發流程，不過這兩種工具的特性截然不同，Ant擁有高度彈性，可按照開發者的想法設計；而Maven則是提供了一套嚴格標準化的規範來律定開發流程。現在，Java開發者可以有另一個選擇，採用兼顧Ant和Maven特性的折衷方案Gradle，邱炫儒解釋，Gradle提供了一個自動化開發建置的範本，就像風水學可供居家布置的參考，但也不一定要照單全收，開發者可依Gradle提供的參考範本來執行，但有可依據開發者的需求來彈性調整。

Java開發者使用的開發工具Ant非常彈性，可按照開發者的想法設計；而Maven對專案有極標準化的規範。而工具Gradle則是Ant和Maven的折衷，有標準能參考依循同時也能彈性客製化。

邱炫儒進一步說明，Android App開發上的問題及對應的處理方式，如產品流水線上的溝通嫌隙，他利用Gradle建立Build配置檔案後，就可以可以讓命令行環境（Command line）與IDE套用同樣的設定組態，如此一來持續整合伺服器與開發端就可以沒有代溝的連結起來。
另外，軟體商品可能因為不同的客戶如裝置類型，而要分為好幾個商業化客製版本，邱炫儒表示，透過Gradle內的Product Flavor製作不同的Android安裝包（APK）分在不同的目錄，APK就是不同的軟體版本。透過Gradle腳本語言將他們自動化，同時管理多個APK。他認為，盡量將商業版本的客製提前到開發階段比較妥當。
而新專案最麻煩的地方在於整理程式碼及如何建置測試專案，邱炫儒指出解決方法在於建立可重複的流程。HTC利用Gradle搭配Git來管理配置檔資料夾及腳本語言，還能支援多專案架構，每個專案都可有自己的專屬目錄。
最有幫助的功能，邱炫儒認為是Gradle的相依性管理（Dependency Management），不只可以自動向遠端伺服器取得相關的函式庫，甚至還能提供了可遞移性相依（Transitive Dependencies）功能，他解釋，若相依的程式碼背後還有相依的函式庫，Gradle能一次幫開發者抓下來。
邱炫儒認為，好用的DevOps工具不能只是協助開發流程順暢執行，還要讓開發流程順利和產品維運端的流程銜接，才能真正實踐DevOps。
",https://www.ithome.com.tw/news/98505,"新聞,DevOps2015,DevOps,HTC,Gradle"
98483,30,2015-09-02,DevOps 2015大會透露的訊息,由iThome主辦的臺灣首屆DevOps大會，在今日（9/1）登場，iThome總編輯吳其勳表示，為期兩天的DevOps 2015大會不僅有超過3百人參加，更重要的是與會者來自各行各業，顯見DevOps在臺灣已受到企業的關注。," 由iThome主辦的臺灣首屆DevOps大會，在今日（9/1）登場，iThome總編輯吳其勳表示，為期兩天的DevOps 2015大會不僅有超過3百人參加，更重要的是與會者來自各行各業，並非只有一般認為的網路新創公司或軟體公司，還有來自金融業、電信業、科技業、創投、傳統產業等IT同仁來參加，顯見DevOps不只是全球熱門的IT議題，在臺灣也逐漸獲得企業的關注。
iThome總編輯吳其勳在DevOps 2015大會的開場指出，DevOps是IT未來重要的發展趨勢，DevOps很容易理解，就如其字義所言：是Developer與Operator共同合作的一種工作文化，但細究下去發現DevOps將會決定IT未來的競爭力。
他以南非最大的標準銀行為例，在導入DevOps之前，建置一套系統要花4個禮拜的時間，這樣的速度相信對大家來說並不陌生，普遍來說，傳統作法的部署速度絕對是以周來計算，而標準銀行在導入了DevOps之後，現在部署一個服務，則只需要17分鐘。
他說，這是2000倍的速度提升，套句大家耳熟能詳的電影名言：「天下武功，唯快不破。」那麼當服務的部署速度提升了2000倍，勢必會到達一個全新的境界；而今天如果你的對手是南非這家標準銀行，你該如何與之競爭。
在DevOps 2015大會首日──「DevOps企業實戰」，擔任主題演講的日本樂天集團（Rakuten）旅遊業務開發維運部旅遊網站團隊經理直井和久，分享樂天如何解決CI伺服器負荷過重的問題，以及邁向DevOps精神的Infrastructure as Code架構的過程。
直井久和在演講一開始就直指CI伺服器Jenkins效能瓶頸的問題，隨著CI（Continuous Integration，持續整合）導入的範疇逐日擴大，Jenkins就變得越來越慢，以至於CI伺服器本身的效能就是個大問題。樂天後來採取循序漸進的方式解決問題，一開始是先擴增CI持續整合伺服器，第二階段繼續把CI伺服器的架構調整為Master-Slave架構，由1臺Master負責統籌與監控，管理旗下4臺Slave持續整合伺服器。第三階段則整合Chef與Docker等工具，邁向Infrastructure as Code的架構。
緊接著第二場主題演講則由全球知名DevOps工具Chef的全球傳教士Michael Ducy擔綱，他一開始就點出DevOps過紅的怪現象，例如DevOps這個名詞問世至今也不過6年，但竟然有公司徵求擁有10年經驗的DevOps人才；DevOps太紅也導致許多工具都宣稱是DevOps工具，他呼籲大家要格外重視DevOps的文化與思想，他說，除了科技業之外，電信業、零售業、醫療業與能源產業都已經開始重視DevOps，而各個產業實踐DevOps的方式可能略有不同，所以重要的是理解DevOps的文化與思想，而不僅是視其為團隊運作或工作準則層面的議題。
Yahoo亞太區產品研發工程部工程師應百怡在分享Yahoo的持續交付經驗則提到，Yahoo已經全面採用持續交付（Continuous Delivery），然而要讓規模這麼大的網路公司全面邁向持續交付，必須仰賴高階主管的支持，而其中重要的關鍵是，高階主管支持的力道。她說，Yahoo執行長Marissa Mayer甚至對全公司宣誓：「不採用持續交付的服務，就永遠不推出，而且這絕對不是玩笑話。」
趨勢科技資深工程師陳彥宏也在DevOps 2015大會分享如何將一個資料量有2PB的服務順利轉移到公眾雲，而在美國軟體公司工作20多年的雙子星運算執行長符儒嘉，則分享回國帶領工研院ITRI雲端OS開發團隊的CI經驗，他說，DevOps的濫觴是敏捷開發（Agile Development），後續發展的兩個關鍵議題則是Continuous Delivery與Infrastructure as Code，其中CI領域的工具發展多年，已經頗為成熟，相形之下Infrastructure as Code領域的工具則仍屬新興，後勢大有作為。他也以工研院開發雲端OS的經驗提供建議，在開發流程區分出「Feature Branch」、「System Integration Test」 與「Candidate Release」 三個階段，每個階段都是一個持續交付的流程。
DevOps 2015大會首日最後一場議程，則由Gogolook架構師葉秉哲分享Whoscall服務的即時監控架構，他逐步剖析Whoscall如何針對不同的風險指標，整合多種開源工具，打造出最有效的即時監控服務。他在演講中大力推薦Flutend是一個好用的資料收集過濾工具，不過，沒有一個工具是完美的，而且DevOps的開源工具發展速度相當快，技術的推陳出新往往可以解決既有的問題，因而最近他們已經開始研究利基於時間序列資料庫架構、對資料統計功能有更好支援的監控服務軟體Prometheus。
",https://www.ithome.com.tw/news/98483,"新聞,DevOps,DevOps2015,Rakuten,Chef"
98477,30,2015-09-01,臺灣企業開始重視DevOps，Chef也派全球傳教士來臺剖析企業DevOps關鍵,DevOps工具Chef的全球傳教士Michael Ducy強調，實踐DevOps最重要的關鍵是文化。文化不能進行管理，它的逐步形成將賦予團員意義使之認同。而決策者的支持能加速文化的傳播。," 臺灣第一屆DevOps研討會今日與會者超過300人，iThome總編輯吳其勳表示，這次研討會特別的是，不只是科技資訊產業及IT人關心，也有許多其他產業參加者，甚至公司總經理都帶隊來學習DevOps。「這也反映出臺灣企業開始重視DevOps了」
首先，日本樂天先揭露了去年一次改造開發團隊，利用Docker與Chef翻新架構的經驗，樂天集團旅遊業務開發維運部旅遊網站團隊經理，同時也是推動整個計畫的核心人物之一直井和久說明，這項企畫是因為當時樂天旅遊的持續整合伺服器負載過重，同時太多任務等待被處理，若伺服器出現問題，所有程式部署都無法如期運行。
為了解決這個問題，直井和久和其團隊決定調整持續整合伺服器，利用持續交付工具Chef以確保所有的持續整合伺服器運作正常。他指出，只懂得採用工具還不夠，DevOps是一種文化。
持續交付工具Chef公司全球傳教士Michael Ducy來臺與會，Michael Ducy指出，在DevOps概念始於2008年兩位IT者Andrew Clay Shafer跟Patrick Debois的討論中，他們認為在敏捷式基礎建設（Agile Infrastructure）方面，必須有橋梁去連接開發團隊與維運團隊。而到了2009年Patrick Debois在比利時根特（Ghent）舉辦了兩天活動DevOpsDays。
Michael Ducy表示，DevOps現在在國外走紅，已有很多人說要賣DevOps工具、使用DevOps、僱用會使用DevOps的人，甚至有人聲稱自己有超過10年的經驗，不過，他笑說，DevOps在10年前還沒出生吧，千萬不要相信這樣的說法。他也以電信業、零售業為例，說除了科技業外，傳統的醫療、能源產業都開始重視DevOps。其實如何實踐DevOps取決於各產業的需求，DevOps是種文化和思想；不是團隊、原則，也不是一件工作。
Michael Ducy指出，實踐DevOps可以有三種途徑：實踐精實開發（Lean practice）、建立社群（Building strong communities）、重建文化（Rebuilding this culture）。他解釋，精實策略的目標在於減少生產過程中的無益浪費（Muda），如不明確的需求、等待存貨的處理、過多的會議、不必要的運輸認證等；建立社群則可以多利用工具，如GitHub、Slack、HipChat，社交軟體如Yammer、Chatter，同時舉辦演討會讓內部參與。
不過，企業要能實踐DevOps，Michael Ducy表示，最重要的關鍵還是文化，文化不能進行管理，它的逐步形成將賦予團員意義使之認同。而決策者的支持能加速文化的傳播。用DevOps加速專案的流程，換句話說就是落實持續交付（Continuous Delivery）。
Yahoo執行長Marissa Mayer曾說「沒有持續交付，就不會上市。這不是玩笑」因此，他們的各流程實踐持續交付的過程在兩季內即完成。Yahoo亞太區產品研發工程部工程師應百怡同樣提到文化傳遞的重要性，任何新思維、新工具、新技術的擴散在於文化的建立。而能影響文化的關鍵在於領導者是否支持。
在實踐持續交付的路上，工具技術固然重要，但我們不可能找到完美的工具，更重要的是人的思想。應百怡表示，改變人的心態，讓持續交付成為人心裡的預設，而非例外。
超過300人參與DevOps研討會，代表著臺灣企業對DevOps愈來愈重視，明天（2日）將以實際操作DevOps工具為主，像是趨勢科技利用Chef做程式部署、Gogolook以Ansible做組態管理及建置IT自動化系統、HTC使用工具Grandle進行系統開發配置管理等。
",https://www.ithome.com.tw/news/98477,"新聞,DevOps2015,DevOps,Chef"
98473,30,2015-09-01,老舊CI伺服器撐不住，日本樂天旅遊用Docker與Chef翻新架構,一臺持續整合的伺服器，竟然可以讓日本樂天旅遊的所有產品都無法如期上線，而樂天究竟又是怎麼解決這個問題的？," 在臺灣第一屆DevOps研討會中，日本樂天揭露了去年一次改造開發團隊體質的經驗，如何解決樂天旅遊網站因持續整合伺服器出現效能瓶頸，導致所有產品無法如期上線的問題。樂天集團旅遊業務開發維運部旅遊網站團隊經理，同時也是推動整個計畫的核心人物之一直井和久表示，會有這項計畫的原因，是當初樂天旅遊的持續整合伺服器負載過重，隨時都有10項工作在佇列中等待被處理，然而他們的程式要正式上線前，都要經過持續整合的過程，當這個環節出現瓶頸，所有程式部署的工作便無法如期進行。
直井和久說，之前他們使用的持續整合伺服器歷史悠久，只有一臺伺服器在提供持續整合的工作，而且沒有維護團隊負責，平均執行中的工作多達10數個，在等待佇列的工作也隨時都有10個，伺服器負荷高到無法開啟持續整合伺服器的網頁，他說，每次要開啟腳本控制臺都是賭博。
而直井和久與其他熱血同事便主動擔起更新持續整合伺服器的任務，然而這項任務並不這麼容易，首先他們必須取得產品團隊以及公司利害關係人的同意，不能僅讓工程師覺得好用而已，必須還能衡量出改進後的商業價值，最重要的不能讓這個計劃只是曇花一現，而要能持續的維護，並且培養新人接手。
樂天旅遊要解決的第一件事就是要減輕持續整合伺服器的負載，直井和久表示，而這件事也無法一蹴可幾，必須一個階段一個階段完成。第1步先簡單的擴增成5臺持續整合伺服器，並把比較複雜的工作丟給新增的伺服器，第2步將原本的持續整合伺服器轉成主伺服器（Master）並新增一些監控機制，而四臺從伺服器（Slave）同時執行任務，第3步是將整個架構轉成基礎建設即程式碼（Infrastructure as Code），他們使用持續交付的工具Chef確保所有的持續整合伺服器運作正常，而整個持續整合伺服器是建立在Container中，而Container是建構在樂天旅遊內部Vmware的虛擬機器上。
減輕持續整合伺服器的工作解決了原本部署程式的瓶頸，使用腳本主控臺不再是賭博，而新增的監控機制，系統可以自動收集比較詳細的資訊，像是工作列表、工作執行時間以及每一個從伺服器的狀態。
樂天集團旅遊業務開發維運部旅遊網站團隊經理直井和久表示，將持續整合伺服器架構改變，達到基礎架構即程式碼（Infrastructure as Code）的階段後，最直接感受到的是持續整合伺服器負載超量的警告e-mail從8月的241封下降到9月的108封。

直井和久認為，DevOps就是開發與營運團隊的合作，而專案要成功的是關鍵是，所有成員齊心朝同一目標前進。DevOps不僅是IT的工作，同時也是一種政策以及文化，光僅是採用工具是不夠的。
",https://www.ithome.com.tw/news/98473,"新聞,DevOps2015,DevOps,樂天,Chef"
98459,30,2015-09-01,臺灣第一場DevOps大會登場，2000倍的軟體交付速度帶來新啟發,臺灣第一場DevOps 2015大會於今日（9/1）正式展開，iThome主編王宏仁首先開場點出DevOps重要性及在世界的發展情形。," 臺灣第一場DevOps 2015大會於今日（9/1）正式展開，iThome主編王宏仁首先開場點出DevOps重要性及在世界的發展情形。
王宏仁表示，DevOps將開發與維運團隊合為一體，以一個高效率的團隊運作，在DevOps工具的協助下，能有更完整、更有效率的流程。
DevOps不是新名詞，它早就走在世界的路上了。早在2013年，非洲最大的標準銀行（Standard Bank）就已經導入DevOps，他們選擇Chef作為持續整合的主要工具，並且在企業內部特別成立了DevOps團隊，並取名為Chop Chop團隊。Chop Chop源自廣東話的音譯，意指快、快、快之意，代表速度是他們的最高準則，不過Chop的發音在非洲是用來形容笨蛋的俗稱，於是，非洲標準銀行的DevOps團隊干脆設計一款T恤，在背面印上「Don’t be a chop!」來提醒自己，而有趣的是這款T恤竟然成了標準銀行員工最搶手的物品。
標準銀行其實是一家已有百年歷史的銀行，資訊系統也許多包袱，很多系統也仍是大型主機，然而在導入DevOps後，標準銀行的IT體質有了大轉變，程式部署時間從原本的一個月縮短到17分鐘，整整加速了2000倍。王宏仁指出，IT速度的提升讓標準銀行可以進一步推出創新的業務，在非洲有電力與網路預付卡的型式，傳統的作法是銷售實體點數卡，然而標準銀行則藉助其DevOps的經驗，快速推出可以預付電費與網路費的預付卡App，讓非洲民眾直接透過手機購買電力與網路預付點數，結果一推出後大受歡迎，最後搖身一變成為銀行祕書了，也成為銀行服務轉型的成功案例。
",https://www.ithome.com.tw/news/98459,"新聞,DevOps2015,DevOps"
98409,30,2015-08-29,IT月報｜雲端IT焦點回顧 (2015/08),Google大動作改組震動市場，更多彈性進行跨產業投資；OpenStack營運長來臺預測，下一個大力參與OpenStack的產業為電信產業,"  Google   Alphabet 
Google架構改組，成為新成立的Alphabet子公司
Google兩位創辦人Larry Page與Sergey Brin宣布成立Alphabet公司，這家公司將成為Google在內等事業體的母公司。同時，Google原有資深執行副總裁Sundar Pichai也將成為Google的新任CEO，Larry Page在其公開信指出，企業穩定就容易停留於舒適帶而維持現狀，只追求漸進式的改變。但在科技業產業裡，若要以革命性思維推動下一個大幅成長的領域，就必需離開這個舒適帶。(詳全文)
 
 OpenStack   英特爾 
英特爾砸1億美元投資OpenStack新創公司Mirantis
Openstack軟體新創公司Mirantis宣布與英特爾投資公司（Intel Capital）達成1億美元的技術與投資合作，以進軍330億美元的雲端基礎架構市場。根據Mirantis呈交美國證管會的文件及紐約時報的報導，英特爾1億美元投資包括7500萬美元的股權投資，以及2500萬美元合作開發Openstack相關產品。雙方合作重點在解決大規模運算效能、儲存、網路整合及支援巨量資料等挑戰，進而擴大雙方客戶對Openstack的使用與部署。(詳全文)
 
 Mac   IBM 
IBM也大搶蘋果商機，推出企業大規模部署Mac的新服務
IBM日前發表一項幫助企業大規模部署Mac的雲端服務MobileFirst Managed Mobility Services，以協助企業大規模部署蘋果一系列的產品如Mac電腦等，與整合企業的各式各樣的系統與應用程式等。IBM表示，這項新服務是JAMF軟體中Casper套裝功能，企業可以透過在內部安裝Mac@IBM專案，藉由整合雲端SaaS服務，與在客戶端資料中心的就地部署的解決方案，以大規模部署Mac。(詳全文)
 
 Twitter 
Twitter來臺進攻廣告市場
擁有3.16億活躍用戶的社交服務Twitter來臺灣了。Twitter新興市場銷售總監Peter Greenberger代表Twitter首度來臺，揭露Twitter在臺策略布局。他表示，這次來臺將著重臺灣地區廣告業務教育訓練，教導廣告商、廣告主如何運用Twitter，不過，Twitter在臺灣暫時沒有成立辦公室的計畫。現在臺灣民眾普遍使用的還是Facebook及LINE，Facebook在台灣有超過1600萬用戶，LINE則有超過1700萬用戶，Twitter並未說明如何擴展臺灣用戶數與其他社群平臺競爭。(詳全文)
 
 Amazon   Flash 
Amazon也放棄Flash廣告
Amazon日前更新廣告規格與政策，宣布自9月1日起將不再接受Flash格式的廣告。Amazon說明，有鑑於Google Chrome、Mozilla Firefox與蘋果Safari等瀏覽器的設定都限制了網頁上的Flash內容呈現，為了確保顧客在Amazon網站上的一致體驗，因此做此決定。(詳全文)
 
 雲端資安   Docker 
Docker新版安全性大提升，映像檔上傳自動簽署金鑰避免遭竄改
Docker近日釋出了1.8版本，其中最大亮點是安全機制Docker內容信任機制（Content Trust），能讓映像檔使用私密金鑰進行簽署，進而提高了Docker Container的安全性。Docker資安負責人Diogo Mónica在部落格解釋此機制的運作方式，他表示，開發者將映像檔推（push）到遠端儲存庫前，Docker引擎會使用開發者的私密金鑰，在本地端與映像檔進行簽署。而下載此映像檔時，Docker引擎將會使用公開金鑰，確保此映像檔是開發者原始上傳的版本，避免有遭竄改的疑慮。(詳全文)
 
 OpenStack 
臺灣OpenStack技術年會登場，基金會營運長暨創辦人首次登臺
由 OpenStack社群、iThome及臺灣雲端運算產業協會聯手舉辦的OpenStack技術大會（OpenStack Day Taiwan 2015），在八月於臺北登場，吸引超過1,700人報名到場參與，參加人員更從企業CEO一直到開發人員都有。同時，OpenStack基金會創辦人，也是現任首席營運長Mark Collier首度親自來臺參與這場盛會，並分享了國外最新OpenStack技術趨勢。
Mark Collier指出，影視業、金融業、零售業、電商等都開始有企業使用OpenStack，而下一個將大力參與的產業將是電信產業，他表示，全球幾乎所有大型電信業者已和他接觸，討論未來5G時代來臨時，如何運用OpenStack來建置基礎架構，「當4G轉型到5G時，也就是OpenStack擴大使用的時間點」。(詳全文)

 
 Container   Kubernetes 
Google工程師親身解說20億Container管理秘訣
日前Google雲端平臺開發者Ray Tsang來臺解說Google如何管理20億個Container，Google的搜尋服務或Gmail等皆在Container內執行，他表示，去年Google將內部部分管理工具和經驗開源，打造能用來部署大量Container的協作工具Kubernetes，甚至可以在不同的平臺上執行。目前Kubernetes程式碼代管在GitHub上，任何人都能取得，「使用Container，就能利用Kubernetes管理大量電腦叢集來實現混合雲，能讓開發者管理整座資料中心，就像是管理一臺電腦。」他說。(詳全文)
 
 雅虎   資料中心抽象化 
日本雅虎用OpenStack管理5萬臺VM
全日本網站流量第一的日本雅虎要如何在系統處於高負荷的狀態下，仍確保穩定提供服務，日本雅虎網路營運總部基礎建設技術分部部長伊藤拓矢在臺灣表示，關鍵作法必須將整座資料中心的資源抽象化。
日本雅虎在2013年時導入OpenStack打造內部IaaS平臺。他說，直接使用了龐大社群所開發的OpenStack來提供日本雅虎5萬個虛擬機器的IaaS平臺，就不用像過去得自行開發介接各種虛擬化技術的特殊API。可以使用一套統一的API來管理，甚至能管理Container。更重要的是能將資料中心的硬體抽象化，使用者不再需要為了效能調校而費心研究所用的硬體設備，而是可以專注於開發服務。(詳全文)
 
 雲端資安   Firefox 
Firefox爆PDF重大漏洞，會竊用戶檔案與個人資料
Firefox爆PDF重大漏洞，一名安全研究員Cody Crews發現，此漏洞來自於俄羅斯新聞網站中的廣告，駭客在其中植入惡意的Javascript腳本，一旦使用者點選廣告便會觸發該漏洞，漏洞被開啟後，駭客可以利用PDF的閱讀程式中的漏洞，搜尋並下載用戶的檔案，甚至一旦用戶上傳完檔案，駭客會刪除相關上傳的痕跡，導致用戶無法查詢那些檔案已經被竊取。不過，Mozilla表示已經修補此漏洞，同時說明此漏洞主要針對開發者，目標是竊取FTP檔案。(詳全文)
 
",https://www.ithome.com.tw/news/98409,"新聞,Cloud,雲端,google,OpenStack,Kubernetes,日本雅虎,Twitter,Docker"
98427,30,2015-08-28,Google雲端容器服務Container Engine正式上線,Google Container Engine預計於今年11月1日開始收費，叢集中使用5個以下（包含5個）虛擬機器節點的不收費，超過5個則是每叢集每小時收取0.15美元。," Google宣布，於去年11月展開測試的Google Container Engine雲端容器服務已進入正式營運，將適用於99.5%的Google服務等級協議（SLA）。
Google Container Engine是以Google所建立的Kubernetes開放源碼框架來管理Google Cloud平台上所運作的各種Docker容器，並提供自動化的容器管理功能。
根據Google的說明，Container Engine允許用戶快速建立可供容器部署的叢集，相關叢集具備各種普遍的能力，諸如檢查容器的健全狀態或是了解應用程式的運作情形，亦可隨著應用程式的編修而改變叢集的規模。
此外，它採用了Kubernetes框架以集中管理各種容器，包括定義容器的用途、資源與政策等，該彈性框架亦允許客戶於不同的平台上移轉任務，包含就地部署與不同供應商的公有雲端架構。
Google表示，該公司從搜尋到電子郵件的所有功能都已可在Linux容器中運作，其全球的資料中心平均每周會推出逾20億個容器實例，已準備就緒。
Google Container Engine預計於今年11月1日開始收費，叢集中使用5個以下（包含5個）虛擬機器節點的不收費，超過5個則是每叢集每小時收取0.15美元。（編譯/陳曉莉）

",https://www.ithome.com.tw/news/98427,"新聞,Google雲端平台,Container,精選"
98058,30,2015-08-17,Docker新版安全性大提升，映像檔上傳自動簽署金鑰避免遭竄改,除增進了Container的安全性外，Docker也提供新的工具包給OS X及Windows作業系統，方便使用者更快地建立起Docker開發環境," Docker近日釋出了1.8版本，其中最大亮點是安全機制Docker內容信任機制（Content Trust），能讓映像檔使用私密金鑰進行簽署，進而提高了Docker Container的安全性。
Docker資安負責人Diogo Mónica在部落格解釋此機制的運作方式，他表示，開發者將映像檔推（push）到遠端儲存庫前，Docker引擎會使用開發者的私密金鑰，在本地端與映像檔進行簽署。而下載此映像檔時，Docker引擎將會使用公開金鑰，確保此映像檔是開發者原始上傳的版本，避免有遭竄改的疑慮。
新版本安全機制源自於2015年DockerCon發表的Container驗證專案Notary，讓使用者能在離線狀況下使用金鑰進行簽署，隨即受到Docker使用者的熱切注目。而Notary的前身又為TUF（The Update Framework），此架構能提供軟體更新系統（Softwayre Update System）使用者一個安全環境，進行軟體更新。
Docker技術長Solomon Hykes在DockerCon上表示，TUF除了能避免映像檔內容遭偽造及對抗中間人攻擊（man-in-the-middle attack）外，亦能提供可存活金鑰折衷方案（survivable key comprimise），「如果系統中的金鑰遺失或者遭竊，你就碰上了大麻煩了，但是並不代表你完完全全死定了，」他表示，「仍然可以依據事情的嚴重度，採取相關措施解決問題，而非關門大吉。」
此外，Docker設定檔升級至2.1版，能將映像檔儲存至OpenStack Swift、Ceph Rados以及阿里雲OSS，另外，Docker也提供新的工具包（Toolbox）給OS X及Windows作業系統，方便使用者更快地建立起Docker開發環境。
",https://www.ithome.com.tw/news/98058,"新聞,Docker,Container,金鑰"
97822,30,2015-08-02,IT月報｜雲端IT焦點回顧 (2015/7),Google雲端動作連連，不只加入OpenStack陣營，旗下雲端平臺也有大更新，不只支援Windows Server部署，還推出鎖定PB級資料儲存需求的近線儲存服務,"  雲端儲存 
Google雲端近線儲存上線，鎖定PB級企業儲存需求大搶AWS顧客
Google宣布，雲端近線儲存（Google Cloud Storage Nearline）服務正式上線。為了從競爭者吸引企業客戶，只要是從任何其他雲端服務業者跳槽，或是原本使用本地部署儲存方案改用Google Cloud Platform的新客戶，可享有最高六個月100PB免費Cloud Storage Nearline服務。不過這項優惠有許多限制，像是僅提供第一個月的100PB免費儲存，未來數個月客戶必須承諾搬移1PB以上的資料。此外，在前三個月後客戶還必須在Nearline存放1PB以上的資料至少12個月。(詳全文)
 
 雲端資安   RC4加密 
網路RC4加密演算法已可快速破解，資安研究人員呼籲別再使用了
兩名來自魯汶大學的研究人員Mathy Vanhoef及Frank Piessens公布了針對RC4加密演算法的新型攻擊程式，宣稱在多數情況下，都能攻陷RC4的漏洞並取得原本以為被妥善加密的資訊。
過去鎖定RC4的模擬攻擊可能要花2000個小時來解密，但這兩名研究人員只用了75個小時就取得cookie的內容，大幅降低了成功攻擊所需的時間，研究人員甚至還指出，在實際的裝置攻擊測試上只花了52小時就能夠成功。研究人員指出，最好的解決辨法就是不再使用RC4，或者是當瀏覽器在使用RC4時禁止平行連線能力以降低請求數量，拖慢駭客解密的速度與提高攻擊成本。(詳全文)
 
 OpenStack   Container 
Google終於加入OpenStack陣營，派出Container專家助陣
Google正式簽約加入OpenStack基金會，成為OpenStack企業級贊助商，Google表示，會持續投入技術人員開發應用目錄服務Murano與Container流程管理服務Magnum，使得未來使用者可在OpenStack中管理虛擬機器、實體主機與Container應用。這也有助於強化Google自家容器管理平臺Kubernetes與OpenStack平臺的整合，讓原生Container應用模式成為企業開發者的必備工具，以協助OpenStack能發展出更廣泛應用的私有雲應用，以及加強私有雲與公有雲之間的互通性。(詳全文)

 
 Cloud   App 
用手機就能管Google雲端平臺，Android版雲端管理App正式釋出
Google正式推出Android版Cloud Console，可讓開發人員透過Android手機就能管理Goolge雲端平臺。管理人員能隨時監看網站狀態、並設定警告通知，例如該App整合了Cloud Monitoring功能，可監控特定系統的監控指標或網站出錯時，直接將錯誤訊息發送到手機App上的通知功能，讓管理人員直接在手機上處理平臺問題，甚至Android版Cloud Console也內建SSH連線，可直接登入VM來管理。另外，Cloud Console App還提供了個人化首頁，可客製化首頁的監控儀表板，例如將常用的平臺執行狀態，費用預估表等嵌入App首頁，一打開就能看得到。(詳全文)
 
 Windows Server   GCE 
Google雲端平臺正式支援Windows Server
Google正式將Windows Server納入Google Cloud Platform雲端運算平臺Google Compute Engine所支援的作業系統名單中，以迎合部署Linux與Windows混合環境的客戶需求。Google Compute Engine會提供Windows Server 2012 R2與Windows Server 2008 R2客戶進行快速部署，透過透明維護（transparent maintenance）作業將可增加上線時間，提供便宜且可預測的儲存區塊，以及Nearline近線備份服務，也可透過可攜式的微軟授權專案Microsoft License Mobility提供Sharepoint、SQL、Exchange Server與其他微軟應用。(詳全文)
 
 OpenDaylight   OpenStack 
OpenDaylight新版讓OpenStack部署NFV更容易
開源OpenDaylight專案計畫繼去年釋出第2版SDN開源軟體Helium後，也正式發布了新一版SDN開源框架Lithium（鋰）。這次最大的改變是終於原生支援OpenStack網路套件Neutron，也結合了多個網路功能服務，像是服務功能鏈（Service Function Chain，SFC）、虛擬租戶網路（Virtual Tenant Networks，VTN），以及群組導向協議（Group-Based Policy，GBP）等，這些功能不只有助於開發人員設計裝置、用戶和群組層的協議，還可建立起一套包含了防火牆、負載平衡和其他應用網路服務的客製化服務鏈，讓OpenStack更容易實作出NFV環境。(詳全文)
 
 Gmail 
Google測試新服務月租費2美元的Gmail信箱位址客製化服務曝光
Google正在測試每月訂閱費用只要2美元的Gmail信箱位址客製化服務，讓使用者可以選擇自己的網站名稱作為郵件信箱，還可以用自己的名字作為郵件帳號。國外科技媒體GSMArena揭露了Gmail這項測試服務更多細節，使用者可自行訂定如「you@youraddress.com」的Gmail位址，youraddress可以是任意字串，但底層都還是Gmail服務。Google也向國外媒體證實此事，但尚未決定正式推出時程。
目前企業用的Google Apps服務已可提供客製化信箱位址，但入門價格是每月5美元或每年50美元。(詳全文)
 
 Gmail   Delicious 
寫錯別怕，新Chrome外掛Dmail可隨時銷毀寄出的Gmail郵件內文
當使用者於Chrome瀏覽器上安裝Dmail擴充程式之後，在Gmail撰寫郵件時可選擇銷毀郵件的期限，包括「從不」（never），以及一小時、一天、一週等選項。另外，寄出的郵件備份裡會有一個「Revoke Mail」（撤銷郵件）的按鍵，隨時可以將寄出的郵件銷毀。在郵件過期或銷毀之後，就無法再看到郵件的文字內容。要注意的是，Dmail所加密與銷毀的都只有郵件的文字內容，附件並不會受到加密，即使銷毀郵件，附件（如圖檔或Word檔）內容一樣是可以正常存取的。(詳全文)
 
 電信 
4G頻譜喬不攏，遠傳、台灣大撕破臉對簿公堂
遠傳與台灣大哥去年達成共識，兩家業者2016年6月底之前提前向NCC繳回頻段，遠傳電信去年12月首先繳回2G使用的C1頻段，台灣大哥大、中華電信因遠傳繳回頻段之賜也獲得部份頻段供4G使用。但台灣大哥大並未跟進繳回2G服務所使用的C4頻段，引起遠傳的不滿。台哥大發表聲明指出，原約定是最晚在今年6月底前「同日共同」繳回，但確切的繳回日期考量到目前2G用戶權益，需經過再協商確定。遠傳則對此回應，如一方未獲NCC核准就不能使用另一方繳回的頻段，因此台灣大原本不該申請使用C1頻段。遠傳向法院聲請假處分，要求禁止台灣大哥大使用C1頻段，台灣大哥大則已提出反擔保金以繼續使用，並嚴詞批評遠傳違反雙方協議在先。(詳全文)

 
",https://www.ithome.com.tw/news/97822,"新聞,google,Cloud"
97472,30,2015-07-21,Google終於加入OpenStack陣營，派出Container專家助陣,Google宣布成為OpenStack基金會的贊助企業，正式加入OpenStack陣營，並計畫投入更多容器管理平臺Kubernetes的技術人員，來強化OpenStack對Container的支援," Google正式簽約加入OpenStack基金會，成為OpenStack企業級贊助商，Google表示，會持續投入技術人員開發應用目錄服務Murano與Container流程管理服務Magnum，使得未來使用者可在OpenStack中管理虛擬機器、實體主機與Container應用。這也有助於強化Google自家容器管理平臺Kubernetes與OpenStack平臺的整合。
Google雲端平臺產品經理Craig McLuckie表示，企業IT未來將有兩大趨勢，一是混合雲架構仍是企業部署的常態，因為目前大部分企業都還沒有能力將企業基礎架構整套轉移到公有雲，而OpenStack將為成為企業套裝混和雲產品的主流平臺。第二個趨勢是已經企業開始邁向Container化。Google過去利用了Container、動態排程、微服務架構來建置超大規模服務，透過Kubernetes技術，Google也開始提供自己這套部署模式給企業，來解決大規模營運的問題。
因此，在Google宣布加入OpenStack聯盟後，Google將致力於整合Kubernetes和OpenStack，讓原生Container應用模式成為企業開發者的必備工具，以協助OpenStack能發展出更廣泛應用的私有雲應用，以及加強私有雲與公有雲之間的互通性。
Google已經和OpenStack簽署協助成為企業級贊助商，每年將繳納25,000美元的會費，由於名額限制，OpenStack規定只有24家企業可以成為金牌會員，Google目前尚無法升級至金牌會員。
",https://www.ithome.com.tw/news/97472,"新聞,OpenStack,google,Container,Kubernetes"
97427,30,2015-07-18,VMware擁抱Docker再進一步 vSphere也能成為Container主機,VMware擁抱Docker再進一步，發表了一項新專案Bonneville預覽版，要在Hypervisor原生支援Docker，讓vSphere平臺變成Container主機," 近日，VMware擁抱Docker再進一步，發表了一項新專案Bonneville預覽版，要在Hypervisor原生支援Docker。VMware臺灣技術總監吳子強表示，這能讓vSphere平臺變成Container主機。
未來，MIS只要運用現有的vSphere操作介面和管理工具，如vCenter Server就能管理Container，不需要額外的學習成本。
VMware高級主管工程師Ben Corrie在官方部落格上透露，早在去年VMworld宣布擁抱Docker之前2個月，VMware就啟動了Bonneville計畫，初始目標是能在虛擬化基礎架構上直接部署Container。
他進一步解釋，因為Container技術是一種將程式相依性打包的執行方式，並使用有限資源在私人命名空間（private namespace）下建立起執行環境。
而Container主機也是一個運算資源的資源池（Pool of compute resource），並搭配必要的儲存及網路基礎建設來管理Container。
「從這個角度來看，VM也相當符合Container的特質，而Hypervisor則就像是Container主機所負責的角色。」Ben Corrie表示。
因此，Bonneville專案採取了一個新的方法能在Hypervisor上執行Container。這個專案開發了一個在Hypervisor的Docker背景程式，搭配客製的圖形驅動程式、網路驅動程式及其他執行所需驅動程式，來提供一個完全相容於vanilla版Docker客戶端的API。
 

VMware的Bonneville專案在vSphere的Hypervisor內建Docker支援，結合Instant Clone技術來快速啟動一個包著VM的Docker映象檔。

 
讓Container在Hypervisor的運作像是VM
如此一來，在Hypervisor中，Ben Corrie表示，Container就像是VM，而VM也可以像是Container，兩者間並沒有明顯區分。
此外，可以不需要使用In-guest虛擬化技術（在VM中安裝Guest OS的作法），就能讓所有Container需要的基礎架構都在VM外的Container主機上提供，而「Container就能視為是一個x86架構下的虛擬VM。」他說。
去年的VMworld大會時，VMware即大力鼓吹Container與VM互為相輔相成的角色的觀念。
VMware呼籲要用1：1，一個Container搭配一個VM的作法，用VM的安全性來強化Container。
不過，當時VMware的做法仍是在VM中安裝Guest OS後，在Guest OS上啟用Container。
後來，為了加快這種VM內裝Container的啟動速度，VMware在4月時還推出了自家的輕量級Linux版本Photon，來作為VM中的Guest OS。
在剛發布的Bonneville專案中，VMware仍然是用VM來包Container，但是採取了不一樣的新作法。透過Hypervisor啟動的Container，原生就伴隨了一個特殊的VM。
 

經VMware測試結果顯示，Bonneville Container相較於VM，其大小已經非常接近原生Docker。

 
透過分支複製技術，建立小容量VM
這個VM是透過VMware的Instant Clone技術（分支複製）所複製的子VM（child VM）。vSphere內建了Photon核心（Photon Kernel），並將一份僅占25MB的迷你版Photon的映象檔，預先載在記憶體中，稱為父映像檔（parent ROM image）。
Bonneville建立Container時，會用Instant Clone技術從記憶體中的這個父映象檔來部署Container需要的子VM。由於採用寫入時複製技術（copy-on-write）機制，子VM初始大小幾乎為零，建立子VM同時也在其中建立了Container。VMware表示，透過這個方式所建立內有Container的子VM，開啟時間小於1秒鐘。
Ben Corrie表示，VMware也從用Docker儲存庫網站上下載了老舊的作業系統MS-DOS 6.22作業系統映象檔和一款DOS遊戲百戰小旅鼠的映象檔，並且成功地部署到Bonneville所建立的Container上執行。「即使是非Linux作業系統（如MS-DOS），亦可以使用Docker打包後在Linux環境下執行。」他說。
吳子強也表示，Bonneville專案的設計，就是希望能讓所有以x86架構為基礎的作業系統都能支援Docker，包括Windows作業系統。
（圖片來源／VMware）
",https://www.ithome.com.tw/news/97427,"新聞,VMware,Docker,vSphere,Container"
97310,31,2015-07-16,百年IT公司的雲端之旅：IBM雲端策略大剖析,IT發展主要動力，不只是要有可隨需應變的IT基礎架構，以及資料處理能力，能否更快速、安全開發出行動應用將是主要關鍵，IBM提出行動優先策略與平臺，並與主要的行動平臺業者之一的蘋果，展開密切合作，企圖開創新局," 對於IBM這家公司的產品，你的第一印象是什麼？很多人可能會先想到大型主機，或是對於個人電腦普及居功厥偉的IBM PC，以及IT工程師幾乎人手一臺的ThinkPad系列筆電。
不單是硬體設備，IBM也積極發展軟體與服務。因此，也有不少人記得他們併購了Lotus而成為當時最大的軟體公司，例如，當時Notes這套郵件與協同作業系統，曾經紅遍企業半邊天，Lotus旗下也有許多頗具知名度的軟體，例如八零年代、九零年代初期，很多企業在用的電子郵件系統cc:Mail、能跟微軟Office匹敵的SmartSuite，以及2000年前後推出的視訊會議SameTime；除此之外，IBM也將Lotus系列軟體，結合了軟體開發生命週期管理軟體Rational、中介軟體WebSphere、資料庫DB2、系統管理Tivoli，形成了主推的五大軟體。
另一件事也可能會讓你有印象，IBM是開風氣之先支援Linux的大型系統廠商之一。在九零年代末，該公司就開始擁抱開放原始碼軟體，並在本身的大型主機與x86伺服器，以及軟體應用的業務上，大力支援Linux作業系統。
這段期間，IBM也致力於運算技術的突破，例如，持續發展超級電腦平臺，包括Deep Blue、Blue Gene、Roadrunner，近期較知名的產品則是華生（Watson）；對於提升大資料即時分析能力，IBM則提出了江河運算（Stream Computing）的技術。
而從2008年以來開始席捲全球的雲端運算風潮，IBM當然不缺席，這樣的應用，源自於該公司時任執行長Sam Palmisano，對美國外交關系委員會提出了智慧地球（Smarter Planet）的概念，到了2011年，IBM繼而宣布智慧運算（Smarter Computing）的框架，實現智慧地球的願景。
發展至今，智慧地球牽涉到的範圍越來越大，有將近30多種應用，例如，改善城市、政府、公共安全、建築、交通、健康照護、商業、能源、通訊、教育、環保的發展，以及針對銀行、保險、零售等產業應用。而協助實踐的智慧運算技術，以資訊科技來說，則可區分為雲（Cloud）、大資料的處理與分析（Analytics & Big Data）、行動化企業（Mobile Enterprise）、資訊安全保護（Security），一般而言，這五種應用簡稱為CAMSS。
上述當中的前4種，通常被歸類為第三平臺，有別於過去大型主機與主從式運算架構然而，扭轉刻版印象並不容易，近年來，IBM投入資源和時間最多、宣傳最久、也是一般人記憶較深刻的部分，主要是雲、大資料分析，而對於行動企業、社交商務和資訊安全，很多人了解得不多。
行動化應用是IBM過去影響力最弱的一環，近年來急起直追
在CAMSS的這些應用當中，IBM過去透過自行發展或併購其他公司的方式，取得了大部分關鍵產品與技術，但看得出來該公司近年來越來越重視其中的行動化應用，例如，他們特別提出了「行動優先」的戰略思考，為什麼行動應用的重要性更勝其他產品、技術？
 

IBM亟欲發展行動優先策略，短短幾年內已併購了許多公司
針對行動應用，IBM透過併購其他廠商或自行發展的方式，取得重要技術，到2012年時，總共取得了270項專利。當中併購的公司很多，包括Emptoris、Worklight、Tealeaf、UrbanCode、Trusteer、Xtify、Fiberlink等。而在2013年，他們正式宣布了行動優先的發展策略。

 
綜觀IBM既有的軟體產品中，有些的確可支援行動化應用，但並非主力發展策略之一，2012年併購Worklight之後，算是開啟了該公司踏入行動運算平臺的濫觴，當時他們先以WebSphere Cast Iron、Worklight、Endpoint Manager for Mobile Devices等4套產品，分別提供這類方案所需的雲端環境連結、應用程式開發、安全控管、商業流程與決策支援改善。直到2013年，該公司推出了MobileFirst企業級解決方案，正式宣示進軍這個領域。
MobileFirst平臺目前提供了多種元件，包含開發設計App的工具Studio、中介軟體伺服器（應用程式、後端系統與雲端服務的閘道）Server、能強化治理能力與安全性的用戶端應用程式執行介面Device Runtime Components、可隨需擴充後端資料規模的資料庫管理系統Platform Cloudant Data Layer Local、可協助企業建立自有App市集的Application Center，以及能集中管理這一切的圖形介面主控臺Console。而且，這個平臺還能整合或延伸使用IBM的產品和服務，例如Bluemix雲端服務、可分析使用者體驗的行動平臺Tealeaf CX、具有惡意程式與越獄偵測功能的安全防護軟體Trusteer、MDM管理系統MaaS360。
 

Bluemix雲端服務提供MobileFirst開發平臺
在Bluemix雲端服務上，提供了IBM MobileFirst Platform for iOS，能作為行動應用的後端系統之用，當中包含資料庫儲存、通知推送、應用程式安全、程式碼品質分析等功能。

 
前所未有！IBM與蘋果展開合作，開發多種產業的企業級App
市面上推動企業端行動應用的廠商非常多，IBM真正聚焦在這個領域、開始發展的時機算是較晚，雖然他們本身有軟體開發工具，也有自己投入經營的PaaS平臺雲端服務，但光是這樣的應用程式開發環境提供是不夠的，要端出成果出來，才能證明IBM有能力幫企業用戶做好這件事情。
在併購Worklight之後，IBM開始與許多企業或組織合作，而這個舉動真正開始受到所有人矚目的關鍵在於，他們找到幾家重量級的廠商一起抬轎。
首先是與電信商AT&T於2013年宣布合作，IBM協助開發支援語音辨識與行動支付的App，雙方也合作發展物聯網應用，以及網路安全防護代管服務。
之後的另一個重大突破是，IBM與蘋果在2014年宣布彼此成為全球合作夥伴，雙方將針對iPhone與iPad的行動平臺，共同開發出各式各樣的商用App，可說是史無前例。
當中有幾項計畫，其中之一，是蘋果將協助發展IBM MobileFirst for iOS Solutions，打造出更多專為企業應用所設計的App，並且能藉此因應零售、健康醫療、銀行、旅遊、交通等產業所面臨的問題，或是協助企業掌握各種商機。
關於這項合作，雙方已經發表了兩次成果。第一波是趕在2014年底，推出了多種為特定產業開發的企業級App，範圍涵蓋相當廣，除了原先規畫的應用行業之外，還跨足保險、金融服務、電信、政府、航空業。
第二波是在今年3月，適逢全球行動通信大會（Mobile World Congress，MWC）舉行期間發布MobileFirst解決方案，主要重點是特別針對銀行與金融服務業、航空業與零售業，推出了App，並且宣布有50家企業簽約使用這項方案，像是花旗銀行、墨西哥北方銀行（Banorte）、電信商Sprint公司、英國藥粧連鎖店Boots UK、加拿大航空、成衣服飾業American Eagle Outfitters。
 

政府單位用App強化突發事件警示掌握能力
透過Incident Aware這支App，警察能夠快速掌握目前發生的突發危安狀況，立即查看附近場景與GPS圖資，並且查看即時視訊轉播。若事件緊急，警察可透過Apple Watch接收緊急通報。

 

醫療機構用App為病患提供更佳的健康照護
藉由Hospital RN App的協助，能節省更多時間，讓病患得到更好的照顧。此外，也可透過iPhone和Apple Watch來傳達，護士可以隨時掌握病患的需求以及必須優先處理的工作項目清單。

 

能源基礎設施業用App改善現場作業安全
在Field Connect的App當中，提供個人化的教育訓練資訊與安全作業祕訣，降低風險因素。若搭配Apple Watch，人員能夠在不中斷工作的情況下，同時檢視重要的警報。

 

保險服務業用App留住顧客，做法更容易
有了Retention App協助，保險業務員想要留住客戶，可以更為簡單。他們可根據情況的重要性差異，像是對於未付費的高級使用者聲明資訊的更新等情況來因應。

 

金融服務用App提升理財顧問的判斷力
針對iPhone和iPad應用的Advisor Alerts App，理財顧問能夠更快服務客戶，而且大大提升決策效率。同時，這支App可根據優先順序發布警報，讓顧問們能夠快速採取變更的動作。

 

零售業用App協助採購人員精準下單
採購人員訂貨時，經常會為了品項與數量的搭配是否最佳化，而延遲下單。運用Order Commit的App，可參考財務目標、產品銷售量與供應商績效等重要數值，來做決定。

 
值得一提的是，隔沒多久，IBM和蘋果的行動應用聯盟又有動作，這兩家公司和日本郵政集團在4月宣布合作，希望能開發多款App改善老年人生活品質。這項計畫將提供iPad，搭配IBM開發的App與分析應用，協助眾多長者能享有便利的服務、醫療照護，強化社區與家庭關懷。日本郵政集團將分階段推行這項服務，預計2020年能擴大到四、五百萬的用戶規模
這些App的開發，將由IBM全球商業服務部門的人負責客製，功能包括提醒使用者服藥、運動及節食，並且直接連結社區活動與支援服務，例如採購日常生活用品與媒合工作求職。
而由日本郵政集團本身員工所提供的系統整合服務和教育訓練，也可搭配IBM MobileFirst for iOS平臺提供的雲端服務，從中獲得資料整合、安全性、分析、管理大量行動裝置等功能。
 

迎接高齡社會，日本郵政集團推出服務App
IBM、蘋果、日本郵政集團合作開發行動應用服務，目的是提升老人生活品質，讓年長者能與各種支援服務、家人、社群保持聯繫。

 
除了這些產業應用，單就整個行動平臺而言，IBM也將提供MobileFirst Platform for iOS的解決方案。
該方案的主要作用，是設法滿足相關的資料分析、工作流程、雲端儲存，以及大規模的行動裝置管理、安全防護與整合需求，同時也包含進階管理功能，像是封閉式App型錄（private app catalog）、資料與交易安全服務，以及提升工作生產力的軟體套件。
而且，這項方案的建置與使用，將提供兩種環境的選擇：企業內部專屬（on-premise），也可以從IBM經營的Bluemix雲端服務上租用。
針對企業對於蘋果行動裝置的大量採用，這個合作案當中，也提到了供應方式與客戶支援支援。
企業若要快速將行動裝置與App部署出去給員工使用，IBM會特別提供一個套裝服務MobileFirst Supply, Activate and Manage。而對於企業日常使用iOS行動裝置與技術支援需求，可選購AppleCare for Enterprise──在這項服務裡面，蘋果將為IT人員與一般使用者提供24/7的電話支援，若需駐點處理疑難雜症，則由IBM的人員來負責。
相關報導請參考：看大象如何在雲上跳舞──IBM雲端策略大剖析
",https://www.ithome.com.tw/tech/97310,"IBM,雲端服務,雲端策略,資料分析,行動應用,社交業務,Cloud"
97087,31,2015-06-30,紅帽Container大躍進，企業Microservices平臺成形,紅帽視Container為未來的主流，預期企業的應用程式將會開始採用Microservices架構，推出可管理多Container主機的Atomic Enterprise Platform，而新版PaaS平臺OpenShift Enterprise 3，也以Container為核心，營造一個Microservices應用程式架構的環境。," Container（容器）技術的發展，正如當下的夏日氣候，越來越火熱。在上周相繼舉辦的Docker與紅帽（Red Hat）的年度用戶大會，話題紛紛圍繞著Container。
Container技術的當紅廠商Docker，在DockerConf大會上宣布，將Docker Container的格式與Runtime執行環境，提供給Linux基金會，由其主持Open Container Project（開放容器專案），以推動Container技術的標準化。
Open Container Project（OCP）一成立就獲得多達20家公司加入，涵蓋了當今市場上所有重要的Container技術廠商，其中還不乏一度公開挑戰Docker不夠開放，而推出自家容器格式的CoreOS，也都加入聯盟而化敵為友，一起推動Container的標準化。此舉讓人對於Container技術未來的發展有新的期待。
身為OCP聯盟成員的紅帽，在紅帽高峰會（Red Hat Summit）上發表的新產品，亦全面支援Container的應用，其中兩款最重要的產品分別是Atomic Enterprise平臺，及其PaaS（Platform as a Service）平臺的新版本OpenShift Enterprise 3。而與Container主題相關的議程，不僅擠滿了人潮，有的甚至是爆場擠不進去；Container技術之狂熱，可見一斑。
從單一Container主機邁向多主機：Atomic Enterprise Platform
在今年4月，紅帽已針對Container的應用推出Red Hat Enterprise Linux Atomic Host，此為單一主機的Container平臺，也可以說是Container OS，而新發表的Atomic Enterprise Platform，則由單機進一步發展成為多主機的架構，成為可支援Container的IaaS（Infrastructure as a Service）平臺。
Atomic Enterprise支援Docker的Container格式，並採用Google的Kubernetes，做為Container的指揮調度（Orchestration）工具。Atomic Enterprise不僅可支援Atomic Host這種新型態的Container OS，亦可支援企業傳統上慣用的Linux OS，也就是Red Hat Enterprise Linux。
目前Atomic Enterprise尚未正式上市，僅提供給部分企業測試使用。

 
以Container為核心的企業PaaS：OpenShift Enterprise 3
紅帽的新版企業PaaS平臺－－OpenShift Enterprise 3，則與過去迥然不同，它首度以Linux Container為核心，提供一個可以快速部署Container應用程式、打造Microservices架構的應用程式平臺。此舉展現紅帽視Container為未來的主流，以及預期企業的應用程式將會開始採用Microservices架構。
OpenShift Enterprise 3架構在Atomic Enterprise這樣的IaaS平臺，結合了Linux Container、Docker、Kubernetes、Project Atomic等Container相關技術，同時再加上程式語言執行環境、資料庫、中介軟體與DevOps工具，成為一個適合開發與快速部署Container應用程式的PaaS平臺。
OpenShift Enterprise 3支援Docker的容器映像檔規格，所以開發者可以直接由Docker Hub取用容器映像檔，而在OpenShift開發的應用程式的容器映像檔，也可以分享至Docker Hub。同時，為了強調Container的安全性，紅帽除了在Atomic Host是以安全強化版的SELinux為基礎，也推出容器映像檔認證。
以Container打通企業IT，貫穿4種主要平臺
在OpenShift Enterprise 3與Atomic Enterprise推出後，紅帽產品和技術總裁Paul Cormier表示，企業部署Container主要的4種環境，紅帽都可以支援了，包括單機的Container OS（Atomic Host）、可管理多Container主機的叢集平臺（Atomic Enterprise），亦或是私有雲與公有雲（OpenShift可在企業內部建立私有雲平臺，並介接AWS、Google公有雲），因此Container應用程式就能在這4種環境中轉移，達到企業所需要的應用程式高度移動性。
Paul Cormier指出，Container與Microservices代表新一代敏捷IT架構，雖然企業沒有必要把所有應用程式都轉移到Webservices架構，但對於需要快速部署、高度敏捷的應用程式，他認為Container與Microservices就是王道。
",https://www.ithome.com.tw/news/97087,"新聞,Red Hat,Atomic Enterprise,OpenShift,Container,Microservices,精選"
97003,31,2015-06-26,進軍企業市場再跨一大步，Docker終於要開賣企業版,Docker進軍企業市場，再邁一大步，擁有全球最火紅雲端Container技術的Docker公司，終於開賣企業版本，也同步在AWS、IBM或微軟雲端平臺上開賣," Docker終於不再只提供開源服務平臺，也正式跨入商用軟體市場，Docker在今年Dockercon大會上宣布，正式開賣企業版Docker，提供包括技術支援、官方認證的Docker引擎和管理工具。採訂閱制每月要價150美元。除了Docker網站以外，也同步在AWS、IBM和微軟的雲端平臺上銷售。
企業版Docker服務的核心為Docker Trusted Registry（DTR），是源自Docker原本的Container儲存服務Docker Hub Registry。此外，此項服務也能與LDAP及Active Directory整合，所以企業可使用現有的認證系統，設定RBAC（role-based access control）存取政策及保留稽核日誌（audit log）。Docker表示，今年2月開始釋出DTR測試版後，吸引了約800家企業使用，而其中超過半數都是財星500大的企業。
除了直接向Docker租用新服務外，亦能從AWS Marketplace、微軟Azure Marketplace及IBM購買。此外，從IBM訂閱服務的用戶，亦可以直接獲得IBM的顧問服務。訂閱用戶可以獲得Docker全天24小時的技術支援、至多10個認證的Docker引擎以及Docker管理工具。而Docker也可以根據用戶獨特的需求，提供額外的服務。
自Docker Hub在去年6月推出之後，已經有超過24萬名的用戶，Docker映像檔的下載也超過5億次。
",https://www.ithome.com.tw/news/97003,"新聞,Docker,Container"
97007,31,2015-06-25,紅帽高峰會大秀物聯網與行動整合技術,在美國波士頓舉辦的紅帽年度大會Red Hat Summit（紅帽高峰會），紅帽特別設計讓與會者即時參與互動的物聯網（IoT）與行動應用，藉此展示其新發表的行動應用平臺，以及PaaS平臺、Container（容器）與IoT等技術的整合應用。," 
在今天（6/22）於美國波士頓舉辦的紅帽年度大會Red Hat Summit（紅帽高峰會），紅帽特別設計讓與會者即時參與互動的物聯網（IoT）與行動應用，藉此展示其新發表的行動應用平臺，以及PaaS平臺、Container（容器）與IoT等技術的整合應用。
紅帽以旗下多項技術的整合，來展示企業已可採用行動與物聯網的應用，其中包括新發表的行動應用平臺Red Hat Mobile Application Platform（RHMAP）、及剛推出新版本的PaaS平臺OpenShift Enterprise 3，並且搭配企業服務匯流排JBoss Fuse、訊息平臺JBoss A-MQ、即時資料分析Spark與即時動態儀表板。

紅帽設計的IoT應用，是即時分析與會者的移動狀態。紅帽在會場安裝多個由紅帽工程師以Raspberry  Pi自行設計的Beacon感應器，並且發放近2百個Beacon給DevNation Conf的與會者，DevNation是與紅帽高峰會在同一地點舉辦的開發者研討會，前身是JBoss用戶大會。因此，這兩百位開發者在現場的活動狀況，都會被該IoT系統記錄下來。

從即時動態儀表板的資訊，顯示該系統能夠即時呈現與會者移動的狀況。例如透過儀表板重播大會主題演講前30分鐘的情形，一開始大多數的與會者是分散在DevNation的各個分堂教室與上機實驗室，然而就在大會主題演講前的15分鐘，所有與會者就陸續抵達主題演講的大廳。所以，藉由資料蒐集與分析，再透過回播，即可了解與分析事件發生的整個過程。

紅帽其實在會場部署了不少Beacon感應器，例如在主題演講大廳的兩側就分別設有掃描器，因此甚至能記錄攜帶Beacon的與會者是在何時抵達演講廳的大門，又在何時移動到另一側。也因此，系統要蒐集與處理的事件資訊非常多，例如上述由左側移動到右側的例子，就有Beacon登入左側感應器、登出左側感應器，與登入右側感應器等事件資訊。

今年紅帽高峰會的重頭戲之一：Red Hat Mobile Application Platform，是紅帽在去年底購併愛爾蘭的MBaaS（Mobile Backend as a Service）廠商FeedHenry後，首次推出的成果，因此在大會上必然得好好展示一番。
紅帽的工程師先在RHMAP平臺上設計一個可由手機傳送手繪塗鴨的系統，而RHMAP是建立在Red Hat OpenShift Enterprise此一PaaS平臺。
RHMAP的伺服器端架構採用Node.js，可支援原生App、HTML 5或混合模式，對於行動裝置則可支援Android、iPhone、Windows Phone。紅帽的工程師利用RHMAP的表單設計功能，很快就把所需欄位以拖拉的方式設定好了。

另一組負責Red Hat OpenShift的工程師，則建立了Container（容器）執行環境，他們除了展示Container的特性，更要彰顯OpenShift平臺不只是程式碼代管，還有應用程式部署的功能，例如能夠快速因應大量Container部署的需求，所以他們將Container與手繪塗鴨的應用結合起來，當現場的與會者以Red Hat事先提供的App應用程式Red Hat Keynote完成塗鴨後，在圖片上傳時OpenShift平臺就會為每個人部署一個專屬的Container，負責處理該圖片。

在工程師介紹完系統架構之後，就開放與會者上傳塗鴨圖片。舞臺上的大螢幕呈現1026個蜂巢狀相連的空格，在與會者以手機App上傳圖片後，這些空格就一個個被上傳的圖片所填滿，此時OpenShift平臺正在快速處理每個Container的部署工作，而在幾分鐘內這1026個空格就被與會者填滿了。

緊接著，主題演講的主持人紅帽應用程式部門副總裁Craig Muzilla宣布，將從這些上傳圖片的聽眾中選出幾位幸運兒，贈送Samsung的智慧手錶，此時，紅帽的一位工程師就以其手上戴著的Samsung智慧手錶，連接該系統，在手錶上操控方向鍵，逐一挑選塗鴨圖片，選出得獎的聽眾。
紅帽之所以用Samsung智慧手錶，除了是展示其行動應用技術的整合，已可支援穿戴裝置，另一個目的是宣布紅帽與Samsung合作開發企業行動應用解決方案。
Craig Muzilla表示，紅帽將與Samsung一起開發RHMAP平臺的企業行動應用，諸如商業智慧、顧客服務、資產管理、訂單、定價、發票、銷售管理等企業需要的行動應用，同時也將提供相關的工具，建立開發生態圈，以及提供相關的支援。紅帽也計畫在明年將FeedHenry的技術以開放原始碼專案的方式釋出。
",https://www.ithome.com.tw/news/97007,"新聞,Red Hat,IoT,OpenShift,RHMAP,Container,Samsung"
96859,31,2015-06-25,2千倍軟體交付速度的破壞性變革,非洲最大的標準銀行擁抱DevOps後，只需17分鐘就能發布一次新版服務，比過去4周才能建妥伺服器的速度，快了2千倍。Gartner更預言，明年將有25％的全球兩千大企業都要導入DevOps," 早在2013年中，當時在非洲最大的標準銀行（Standard Bank）擔任資訊長的Dawie Olivier，做了一項大膽的決定。為了加速銀行服務交付的步調，他決定導入一個能夠實現持續整合（Continuous Integration）的新開發流程。
對於一家成立超過150年的老字號銀行來說，這可是一個大工程。因為標準銀行是大型主機的大客戶，儘管使用了許多前端技術，如Java和AngularJS等，後端系統主要開發語言還是COBOL，內部系統所用OS則包括了Red Hat、SUSE、Solaris和大型主機用的AIX。
如何整合這些異質平臺，成了標準銀行導入持續整合流程最大的絆腳石。因為這些異質環境在部署和管理的作法差異很大，想要找出一套能夠通用各平臺的作法非常困難，標準銀行IT團隊花了半年討論，仍舊沒有進展。而且標準銀行當時內部資訊基礎架構的自動化程度也不夠高，光是要建立一個虛擬機器就得花上好幾個禮拜。
直到2014年初，Dawie Olivier找來IT維運部門主管Mike Murphy共同討論，才啟動了標準銀行擁抱DevOps的轉型之路。第一步是先決定流程變革的大方向，Dawie Olivier找來Chef開發團隊擔任顧問，花了1天時間和35位銀行高層討論先決定大方向，一方面也讓高階主管了解什麼是DevOps的基礎知識，讓這群主管熟悉同一套DevOps的詞彙，另一方面則是讓高層能夠預先掌握導入持續部署後，自動化流程對銀行基礎架構及應用程式開發上的衝擊。
當天下午，高層們決定先選擇一個能快速凸顯出顧客價值，又是銀行IT團隊熟悉的服務作為試行專案，後來決定先從預付卡服務作為第一個導入DevOps的專案。這項服務可供非洲民眾直接透過手機App預付電費和網路費用，取代過去得購買實體點數卡片的作法，民眾想要用上網時，直接透過APP從個人銀行戶頭扣款後就可以啟用。
先將Dev和Ops集中到1間辦公室
訂定專案目標後，標準銀行也決定放棄由上而下制訂流程的方式，改將開發團隊（Dev）、維運團隊（Ops）和業務部門成員，集中到同一間辦公室內，讓他們一起工作，一起討論出更快交付服務和應用程式的作法，他們選擇了Chef作為持續整合的主要工具。
Dawie Olivier接著再花2天時間來培訓實際參與這個專案的所有工程師以熟悉Chef工具。
標準銀行的DevOps團隊先共同討論出一套工作準則，例如不要變成一個Chop（非洲用來形容笨蛋的俗稱），速度是最高準則凡事先做再說、絕不事後指責、要像新創公司一樣思考、快速失敗快速前進、練習信任和尊重彼此等。
他們還自稱自己是Chop Chop團隊（ChopChop源自廣東話的英譯，意指快、快、快之意），也仿效新創公司的做法設計了一款T恤，衣服背面印上「Don’t be a chop!」來提醒自己。這件衣服後來成了標準銀行員工最搶手的物品，大家都想要一件。
團隊成立後，標準銀行先解決手動建立虛擬機器部署太慢，甚至得耗時數周的問題。Dawie Olivier觀察過去作法發現，每一道手動作業會降低15～20％的效率，超過5次手動作業，就等於白白多花了一倍時間。所以，Chop Chop團隊花了幾個禮拜先建立一個高度自動化的Full-Stack部署環境，包括了虛擬機器內所需安裝的OS、資料庫或中介軟體等都能自動建立，連原有紙本公文申請程序都放棄了。最後只要17分鐘，Chop Chop團隊就可以建妥一個開發網路銀行服務所需要的執行環境。
資訊基礎設施自動化之後，Chop Chop團隊再著手改變開發流程，放棄了舊有的瀑布式開發流程，改導入敏捷開發。另外，還調整了過去的開發測試作法，將資訊基礎設施的測試也納入開發品質控管的一環。甚至還翻轉了過去資訊基礎設施測試的流程，不是等到裝妥伺服器後才測試，而是要求QA人員先討論出合適的測試案例，再進行虛擬機器建置，最後再執行測試。
除了使用Chef工具，Chop Chop團隊還使用了Bamboo工具來管理持續整合（CI）流程，透過自行撰寫的腳本程式，每小時會自動執行建立一個沙箱環境，並自動從版本控制系統上，取得最新版的程式碼，再部署到虛擬機器中，安裝完成後也自動展開應用系統測試和資訊基礎環境的測試。管理人員直接從Bamboo系統的儀表板上，就能得知最新的應用系統程式碼和環境的測試結果。新功能是否能順利運作，不論開發團隊或是高層主管，人人一看就知道。
花了一年時間，同時導入了敏捷開發和DevOps流程，標準銀行在今年2月11日，才正式推出了預付卡服務。
標準銀行Chop Chop團隊中一位主管Derek Chung說，過去標準銀行為了區分權責，習慣用ITIL觀點來管理，因此可以接受「花4周來部署一臺伺服器」，但是標準銀行擁抱DevOps之後，顛覆了過去的觀念，現在，Chop Chop團隊建立一套預付卡服務所需的上線運算節點只需要17分鐘，包括了部署2臺網站伺服器（Apache）和2臺應用程式伺服器（EPA/JBoss），並完成所有程式部署與測試工作。
從4周到17分鐘的變革
從4周到17分鐘，標準銀行推出新服務的速度，足足快上2千倍，這不是只有第一次如此，而是未來每次推出新服務或程式改版，都可以擁有17分鐘完成的發布能力。
標準銀行的故事並不是特例，已有不少企業因為擁抱DevOps而大幅改善了自家軟體上市的時程。根據DevOps主流工具廠商Puppet Labs在2013年底針對全球9千位科技從業人員的2014年DevOps大調查資料中顯示，擁抱DevOps後最明顯的成果則是IT部門部署程式的速度平均比過去快了30倍，而出錯率則減少了50％。
這項調查是目前最大規模的DevOps調查，涵蓋全球110個國家的科技從業人員，超過1成受訪者來自擁有5千臺伺服器的大企業。
調查結果還發現，高達16％約1,485位的受訪者所屬企業，已經建立了專屬的DevOps團隊，超過3成受訪者的職稱甚至直接就是DevOps工程師，而且不只是20人規模的新創公司才會設置DevOps，連3、4百人規模的大企業，也設置了專門的DevOps職務。娛樂業、科技業和網路軟體公司是DevOps工程師最多的三大產業。
Pivotal技術行銷部總監Michael Coté認為，標準銀行這個例子，正凸顯了DevOps不再是超大型網路公司、或是技術領先企業的專屬技術，而是開始會成為一般企業也想用的主流IT技術，他說：「尤其是非科技類的傳統企業更要擁抱雲端和DevOps。」
Gartner更預估，2016年時，全球兩千大企業中將有四分之一的企業將DevOps視為企業主要戰略，光是DevOps工具的市場規模將達到23億美元之多，相當於伺服器廠商戴爾在2015年第一季的總營收。Gartner研究總監Laurie Wurster在報告中解釋，因為數位經濟的本質是軟體，軟體交付的速度，決定了企業在數位大環境中的競爭力。
儘管臺灣這股DevOps風潮仍舊環繞在網路公司和新創公司為主，但也有一些企業開始擁抱DevOps，例如趨勢科技消費端產品研發團隊，早就擁抱DevOps，讓產品發布時間可以加速到每周發布一次，來因應消費端防毒市場的快速變化。
DevOps風潮即將席捲全球，臺灣企業，準備好面對在這一波將帶來數十倍、甚至是百倍或千倍上市加速度的軟體改版追逐戰了嗎？
相關報導請參考：DevOps變革三部曲（一）DevOps：搶先一步的IT競爭力
",https://www.ithome.com.tw/news/96859,"新聞,DevOps,持續整合,Continuous Integration,標準銀行,Standard Bank"
96982,31,2015-06-24,企圖挑戰AWS，Oracle雲端服務大升級,甲骨文新添雲端平臺（Oracle Cloud Platform），同時，其平臺於SaaS、PaaS和IaaS中新增超過24項服務。例如甲骨文資料庫雲（Oracle Database Cloud – Exadata）、甲骨文歸檔儲存雲 （Oracle Archive Storage Cloud）、甲骨文流程雲 （Oracle Process Cloud）等。," 甲骨文創辦人暨技術長Larry Ellison於22日發布新添甲骨文雲端整合套件服務：雲端平臺（Oracle Cloud Platform），同時，其平臺於SaaS、PaaS和IaaS中新增超過24項服務。他有信心的表示，甲骨文的成長快速，上一季藉由SaaS和PaaS賺了近億元美金，與去年同季相比上升200%。他認為新增的服務技術能讓其公司比其他競爭者更符合成本效益。
甲骨文雲端服務不只大升級，也大打價格策略，和AWS較勁意味濃厚。Larry Ellison甚至喊出，最新的甲骨文歸檔儲存雲（Archive Storage Cloud）只有AWS Glacier價格的十分之一。其他多項甲骨文雲端服務售價也有不小的調整，從儲存歸檔（Archive Storage）來看，甲骨文歸檔儲存雲及AWS Glacier皆以月費計算，甲骨文每月每GB為0.001元美金，AWS Glacier則是每GB以0.01元美金為計，相較之下，甲骨文歸檔儲存雲的價格的確是AWS Glacier的十分之一。然而，資料傳輸（Data Transfer）則另外計算，甲骨文和AWS Glacier於當月未達到1GB前皆免費，在達到10TB前，Oracle每GB為0.12元美金，AWS Glacier則只索取0.09元美金。
新增的雲端服務包括甲骨文資料庫雲（Oracle Database Cloud – Exadata）、甲骨文歸檔儲存雲 （Oracle Archive Storage Cloud）、甲骨文巨量資料雲 （Oracle Big Data Cloud）、甲骨文整合雲 （Oracle Integration Cloud）、甲骨文行動雲 （Oracle Mobile Cloud）及甲骨文流程雲 （Oracle Process Cloud）。
據甲骨文官方網站指出，其雲端服務每天支援超過7,000萬名用戶和超過330億筆交易，在世界各地的19座資料中心有54,000台設備、以及超過700PB的儲存空間中運行。
甲骨文認為這次把該公司傳統的資料庫和客戶關係管理服務轉移到雲端、增加多項應用項目等，此策略讓公司不再只是針對傳統的雲端業者，而是將目標設在整個IT部門。
過去微軟也曾想藉由Azure削弱AWS的市場，然而，這幾年AWS在雲端服務中調降了48倍的價格，因此微軟並沒有成功，反是被迫採取提供優惠套餐讓用戶買單。
",https://www.ithome.com.tw/news/96982,"新聞,Oracle,Cloud,AWS"
96864,31,2015-06-24,馬上能用的DevOps工具包,想要發揮DevOps流程的威力，得有一套好用的DevOps工具。趨勢科技消費產品的開發團隊累積了多年DevOps導入經驗後，整理出了一套實戰用的DevOps工具包," 想要發揮DevOps流程的威力，得有一套好用的DevOps工具。趨勢科技消費產品的開發團隊累積了多年DevOps導入經驗後，整理出了一套實戰用的DevOps工具包，這也是他們目前正在使用的主要DevOps軟體。
在這個DevOps工具包中的軟體又分成六大類，包括了版本控制工具、組態管理（Configuration Management）工具、持續整合（Continuous Integration）工具、測量（Measurement）工具、Log工具，以及服務上線的調度（Provisioning）工具。
趨勢科技研究開發部技術經理江盈宏表示，如果在時間資源有限，無法面面俱到的情況下，最重要的工具為組態管理工具及測量工具。
組態管理工具是DevOps核心
江盈宏認為，DevOps工具包中最重要應屬組態管理工具。透過組態管理工具幫助企業持續部署伺服器，而第二順位是測量工具，比方說Graphite、Icinga及Smokeping，使用它們監控系統的運作狀況。他表示，如果沒有過多的時間資源的話，第一要確保的是保持伺服器狀態穩定，第二則是確定伺服器都有在提供應有的服務。而為了滿足上述兩個前提，最基本的DevOps工具包得包含組態管理工具跟測量工具，如此就可以讓服務上線了。

使用Graphite，開發人員可以觀測系統長時間的平均運作狀況。

DevOps工具必須以Puppet為基礎才能建立起整體架構，Puppet是整個工具包的核心，以Puppet為基礎，導入其他DevOps工具並且跟Puppet做整合。Puppet在部署伺服器的同時，能掌握伺服器的部署狀況，而其他的工具透過Puppet，了解目前的部署狀態後，才能發揮各自的功能。
Puppet是一套用Ruby語言開發的組態管理工具，所以得使用Ruby特定領域語言（Domain-Specific Language）來撰寫組態樣版，稱之為Manifest檔，而Puppet再依據Manifest檔的內容，自動部署出一臺伺服器所需的軟體，並能進行大量自動部署。
每臺透過Puppet部署的伺服器上都會安裝一個Puppet agent程式，每隔30分鐘檢查一次，確保伺服器的組態符合Manifest檔的設定。
趨勢科技研究開發部資深工程師陳彥宏表示，在Puppet問世前另外有一個組態管理工具叫做CFEngine，由於趨勢開始導入DevOps時，CFEngine已經逐漸式微，Chef也尚未成熟，剛好Puppet有跟上DevOps的腳步而且比較穩定，所以趨勢就決定採用Puppet為組態管理工具。不過，他強調，Chef跟Puppet沒有誰優誰劣，只要工具符合開發者需求，並且能跟上時代潮流就是好的工具。
趨勢每次要部署一臺伺服器的時候，第一件事情就是在伺服器中安裝Puppet，然後連到Puppet主伺服器中。開發者必須預先設定好Manifest檔，而Puppet agent會自動比對Manifest檔，確保伺服器符合其所設定的組態，整個過程都是自動化。比方說，OS必須要確定SSH認證是正確的，或者NTP認證為正確，系統上的時間才會正確。
而最上層就是應用程式的部署，Puppet根據伺服器不同的需求，部署不同的應用程式，比方說，資料庫伺服器跟網頁伺服器需要的軟體就會有很大的差異。
由於Puppet跟Chef此類的組態管理工具都為開源軟體，所以在網路上都可以找到其他開發者釋出的Manifest範本檔，如Puppet Forge網站。趨勢表示，寫出第一個專案的樣版會是最困難的，不過當專案完成後，後續專案就可用第一個專案的樣版為基本架構，再根據新專案性質需求的差異來進行微調。
趨勢的做法是並用Puppet與Saltstack，利用Puppet建立起OS上的基礎架構，並且使用Puppet部署機器。Saltstack的運作，基本上根據開發人員寫的腳本去執行，特性較偏向一次性機制，其效果也類似於探針，可以使用於收集一次性的資料。如開發人員下指令，命令伺服器重啟HTTP服務，或是想要了解目前所有伺服器的核心版本，此時便可以透過Saltstack下指令，命令所有的伺服器回傳版本資訊給開發人員。
雖然Puppet跟Saltstack都被分類在組態管理工具，但在實務上，兩者的目的並不相同。
其他DevOps重要工具
在這個DevOps工具包中，測量工具也是另一個重要的工具，如Graphite、Icinga及Smokeping。Graphite用於收集伺服器運作的長期數據供開發人員參考，而Icinga跟Smokeping則是即時監控的工具，讓開發人員了解現在系統運作的現況為何。
比方說，使用Icinga監控特定的API，開發人員可以設定條件，如回傳時間必須要小於200ms，如果系統正常就會顯示綠燈。但江盈宏表示，無法透過即時監控得知系統長期運作的變化。如伺服器也許長時間處在回應時間小於10ms的穩定狀況，但也有可能一直處在平均回應時間190ms的尖峰狀況，此時開發者可用Icinga或Smokeping搭配Graphite，除了能了解伺服器的即時狀況外，也能從圖表看出伺服器長期的平均運作狀態。
江盈宏表示：「對DevOps來說，工具很重要，但是不一定要限定哪些工具，比方說組態管理工具，你可以考慮使用Puppet或Chef，但是其他如Ansible、Saltstack也都是很好的工具，並沒有優劣之分。」

趨勢科技開發人員透過Icinga監控系統，讓伺服器的即時狀態在圖表中一覽無遺，如果狀況正常即顯示綠燈，反之，則以紅燈警示。

相關報導請參考：DevOps變革三部曲（一）DevOps：搶先一步的IT競爭力
",https://www.ithome.com.tw/news/96864,"新聞,DevOps,DevOps工具,趨勢科技"
96863,31,2015-06-24,趨勢科技DevOps實戰經驗大公開,趨勢科技順利導入DevOps流程的關鍵是，直接在Dev研發團隊中建立Ops角色，第一步則是先找出具備Ops技能的研發工程師," 如同非洲標準銀行先從消費端服務開始導入DevOps一樣，在趨勢科技中，率先擁抱DevOps也是消費者產品的研發團隊。趨勢消費端產品研發部門下，超過半數的開發專案（包括外部產品和內部服務）採用了DevOps流程，累計有十多位DevOps隸屬在不同的研發專案中負責Ops任務。
早期，趨勢消費端防毒軟體多半是每年改版一次，對於軟體交付速度的需求不高，直到2008年前後，趨勢開始大力發展SaaS服務，例如線上掃毒服務TrendSecure，或者是供內部各部門共用的內部線上服務，例如儲存資料同步服務。
雲端服務帶來了更多的使用者，但也讓趨勢科技的開發團隊面臨了新的挑戰。傳統瀑布式的開發流程再快也得花上數個月、甚至是半年才能推出一版更新程式，趕不上隨時都能更新的雲端服務步調。所以，在2010年時，趨勢科技導入敏捷開發流程來加快產品研發的腳步。
可是，趨勢研究開發部經理張懿表示，敏捷開發只是加速了研發團隊內部的改版速度，卻無法進一步延伸到維運層面，從顧客角度來看，產品發布的步調仍舊快不起來，例如很難每個月發布一次新版。
當時，趨勢科技內部不論是哪個研發團隊完成後的程式碼，都統一交給管理資料中心維運的DCS部門（Datacenter Services）負責。為了避免因執行環境異動而影響了各項服務的穩定性，DCS部門早就導入了IT服務管理架構ITIL，來強化各項系統變動的管理。但因ITIL管理程序嚴謹，許多作業需要耗費一段時間才能完成。趨勢科技研究開發部資深工程師陳彥宏舉例，早期Dev和Ops兩團隊的分工嚴明，Dev人員無法直接存取上線環境的系統，遇到對外服務當機，光是要申請進入的許可至少得花30分鐘。
2011年初，趨勢有項雲端儲存相關的新專案需要更快的產品發布速度，趨勢決定趁機調整維運策略，不再將所有專案的維護工作全權交給DCS部門負責，而開始改變流程改交給Dev研發團隊中具有Ops能力的工程師接手這個新專案的維運工作。DCS部門只負責伺服器設備、網路等實體環境的建置，其餘從作業系統、中介軟體到應用系統的部署改由DevOps人員接手。
「導入DevOps前，跨部門溝通的成本過高，」趨勢科技研究開發部技術經理江盈宏表示，DCS團隊得先花時間先了解應用系統種種特性後才能管妥維運，但是遇到了應用程式面的問題，還是得回頭尋求研發部門協助，等於多費了好幾次工，DevOps可以節省彼此溝通的成本。
張懿表示，由Dev負責Ops工作還有另一個好處是能夠統一開發和上線環境，避免在開發環境可用的程式碼，部署到上線環境後出錯。

趨勢科技在不同產品研發團隊中設置各自負責Ops的DevOps人員，這群人再形成跨專案的DevOps社群，分享DevOps工具和維運問題的解決經驗。（圖片來源／趨勢科技）

從CAMS四面向導入DevOps
趨勢科技從4個面向來推動DevOps。陳彥宏表示，包括了文化轉換（Culture）、善用自動化工具（Automation）、重視測量（Measurement）和鼓勵分享（Sharing），可以用CAMS這四個字來簡稱趨勢的作法。
陳彥宏表示，改變既有開發和維運文化先從組織改變下手。趨勢直接在現有Dev研發團隊中設立了Ops角色，再搭配作業流程調整，許多原本要等到程式碼交付給DCS團隊後才會開始考慮的問題，如擴充性或備援等基礎架構設計、基礎架構程式化、持續交付環境設計、監控機制、備份策略、災難復原SOP、高可用性的破壞測試、安全性設計、效能測試等，都改由DevOps人員接手，提前到開發階段就開始考慮後續維護的需求。
對不少研發人員而言，維運人員好像是一位處理大量例行瑣事的黑手，但江盈宏澄清：「只管20臺機器可能只是例行瑣事，但要維運一套2千臺機器的叢集，可是一項需要創新能力的挑戰。」率領這個導入DevOps團隊的張懿也經常要求，DevOps要懂得用更聰明的方法解決維運問題。
江盈宏表示，只要善用自動化工具，即使DevOps人員遠少於DCS部門的維運人力，還是可以管理大規模的設備。
趨勢DevOps自動化作業涵蓋了程式碼組建、測試、部署、監控機制、自動恢復、系統配置、自動擴充、基礎架構調度等。
另外也搭配了三類監控機制，包括了服務狀態即時監控機制、長期性系統維運趨勢的分析矩陣、以及可快速檢視最新系統狀態的儀表版，甚至可提供給高階主管或業務部門人員瀏覽，快速取得服務運作的基礎參考數據。
不過，想要找到熟悉Ops技巧的Dev工程師並不是一件容易的事，江盈宏是第一批順利勝任Ops工作的研發人員。他解釋，因為過去，研發人員只需負責自己使用的機器，而不需要考慮大量機器管理的情況，因此多半不諳維運所需的技巧如配置管理一致性設計、自動化設計能力、大量伺服器部署技巧。
趨勢目前有十多位DevOps分散在不同專案中，平時這群DevOps又形成自己的內部社群，透過電子郵件或是不定期發起讀書會來分享自己處理DevOps問題的經驗或DevOps相關開源工具的使用經驗。目前，趨勢科技可以做到每30分鐘發布一次Alpha版本，包括部署和測試都全面自動化進行，每周再正式發布到上線環境中提供給外部顧客。
服務所有權從Ops轉移到Dev
導入DevOps之後，張懿表示，更重要的意義是，應用服務的所有權從Ops轉移到了Dev。陳彥宏以系統變更為例，過去是一種Request for Change（請求變更）的作法，研發部門得向維運部門提出系統變更的申請，但現在趨勢想要推動的是IWC策略（I want change）。研發人員自己做決定，只是通知維運部門，我們要進行變更了。
經過4年實戰嘗試，趨勢科技也累積了不少DevOps的實務作法，包括如結合了Puppet和git來實現基礎架構程式化（Infrastructure as code）、部署工作全面自動化和模組化、兼顧長期和即時預警的監控機制、效法敏捷開發的雙人協同學習策略等。
江盈宏表示，建立工具包是導入DevOps第一件必須完成的關鍵，透過第一個專案建立了適合自家環境的工具後，以及部署各項環境所需的相關自動化整合機制，後續就可以此為基礎來修改，快速將DevOps流程推廣到其他專案。接下來，我們將用另一篇文章來介紹趨勢科技幾年實戰經驗所累積出來的DevOps工具包。
相關報導請參考：DevOps變革三部曲（一）DevOps：搶先一步的IT競爭力
",https://www.ithome.com.tw/news/96863,"新聞,DevOps,趨勢科技"
96862,31,2015-06-23,【專訪】Pivotal技術行銷部總監：DevOps就是持續交付,全美三大科技分析師Michael Coté：DevOps開始成為企業IT主流技術，就像是ERP、敏捷開發、BI那樣的企業尋常技術，尤其非科技類的傳統企業更要重視DevOps," 今年初剛進Pivotal擔任Cloud Foundation技術行銷部總監的Michael Coté，早從2011年就開始觀察DevOps趨勢，他不只是全美三大科技分析師，還一手創辦了專注開發趨勢的分析機構RedMonk，甚至他還一手設立了Dell公有雲事業背後的軟體團隊。近年Michael Coté更是大力呼籲DevOps變革的重要性。
在今年美國Austin的DevOpsday活動中，他引用Gartner數據，2016年時，全球2千大企業中，將有25％的公司擁抱DevOps。
Michael Coté預言，DevOps將成為「尋常」技術，就如同ERP、敏捷開發、BI、行動應用等企業視為理所當然的必要科技一樣。不只是超大型如Google般的獨角獸網路公司，或技術領先者企業，而是「DevOps開始成為一般企業也得重視的IT主流。」他說：「尤其是非科技類的傳統企業更要擁抱雲端和DevOps。」
不過，Michael Coté認為，缺乏適當的文化轉換和流程改造，導入DevOps有90%的失敗率。
要成功擁抱雲端和DevOps的第一步，他建議，必須定義出明確的目標，最好的目標就是要求自家軟體能做到每周交付一次新版本。換句話說，企業要用DevOps來加速雲端專案最好的策略就是落實持續交付（Continuous Delivery），甚至可以說「DevOps就是持續交付。」他說。
Michael Coté解釋，未來所有企業都將是科技公司，企業現在得趁早擁抱軟體定義商業（Software-defined Business），包括了要改採用產品導向的管理思維，同時也要擁有一個夠用的雲端平臺，至少要是一個能勝任所有企業需求的基礎架構環境。這兩項都是有助於善用持續派送的基礎。
另外，導入DevOps流程時，Michael Coté建議，企業也要考慮到既有系統程式碼的維護和開發專案，而不只是將DevOps套用於新專案。企業可先評估現有IT資源和企業營運目標的優先順位，有系統地規畫既有程式碼導入DevOps流程的順序。
為了進一步了解DevOps對一般企業帶來的衝擊，我們也跨海採訪了Michael Coté的看法。
 Q  什麼是軟體定義商業？
 A  所謂的軟體定義商業是指，企業有能力自製軟體，大幅改變或強化他們自己原本做生意的方式。Uber就是一個好例子。
Uber這家公司不是提供計程車或租車服務，而是善用軟體改寫了原有的商業模式，讓乘客用自己的手機叫車和付款，而不是在街上攔車和付現。越來越多保險公司和銀行也更加依賴行動App或是各種自製應用程式，來提供日常業務和招呼顧客。如使用了Pivotal Cloud Foundry的美國Allstate保險公司、Humana醫療保險公司等。對這類企業而言，DevOps非常重要。
 Q  為何你主張DevOps就是持續交付？
 A  我認為DevOps就是那些與持續交付相關的種種流程和「文化」，目的是要充分發揮持續交付的完整效果。不過，我目前特別重視如何交互運用這些流程。就算你不需要運用DevOps來獲得持續交付的效益，這些流程也能彼此搭配運作的很好。
就像是你只愛吃果醬土司，或只愛吃花生醬三明治，但我認為，混合這兩種醬之後的三明治更好吃。
為了讓軟體或服務產品能夠更頻繁地推陳出新，持續交付總是不斷尋找可以更自動化的作法，並且會善用快速循環的回饋流程，來觀察使用者每周或每天的行為，而不只是每六個月的變化而已。而這些都是能夠讓DevOps運作得更好的關鍵。
 Q  導入DevOps最難克服的環節是什麼？
 A  有時人們很容易陷入DevOps的爭論，花大量時間來討論該如何改變或是該建立哪些「文化」，我的確也關心這議題，但我總是希望聽見真實的聲音、了解企業實際情況，來了解如何找出DevOps的效益，而不只是空談而已。大家都知道，必須善用IT讓公司營運運作的更好，但實際上很難做到。
所以，擁抱DevOps，不要光講，趕快採取行動！
 Q  導入DevOps前，企業得先導入敏捷開發嗎？
 A  理論上來說，能夠先了解敏捷開發絕對有幫助，能夠先落實一些敏捷開發的作法也有助於建立DevOps的思維。不過，企業從來沒有嘗試過敏捷開發也沒關係，這只是將敏捷開發變成了導入DevOps過程中的一環而已。
少了敏捷開發，企業想要導入DevOps，恐怕很難成功。
 Q  非科技公司的CIO，該如何說服CEO支持DevOps？
 A  產品上市時間更快是最主要的價值，也是明確可量測的價值。對我來，這意味著可以更加頻繁地提供新版軟體給顧客。DevOps可以讓企業每一周都可以推出新功能或修補更新，不用像過去得花6到12個月才能改版一次。
要說服CEO，CIO必須找出縮短上市時間後對公司生意能帶來的效果，例如要思考產品每周可以增加一項新功能時，對業績有什麼好處？從顧客角度來說，功能越多，代表了你的產品比競爭對手更好，至少在心理層面上更有競爭力。從商業角度來說，做生意的步調越快，應變能力越快，就越能發揮搶先上市的優勢。
任何CEO都不會滿足於IT只是步調更快，快還不夠，還要能經常開發出有關鍵影響的新功能。
 Q  可以舉個例子嗎？
 A  Humana醫療保險公司就是很有趣的例子。因為他們不斷地優化IT交付軟體的流程，所以才能夠只花了短短5周時間，就從無到有開發出了一款Apple Watch上的App，相較於大多數企業IT專案來說，Humana在這麼短的時間就能推出產品，是非常驚人的，所以，Humana這款App，才能趕在Apple Watch上市的第一天，就上架到App Store上亮相，搶先其他人一步。
 Q  Gartner預言2016年將是DevOps元年，你同意這個說法嗎？
 A  當然同意。不過，我認為，不只是明年，未來3年都將是DevOps年。就像你很難清楚地分辨出，過去15年來，哪一年能夠稱為敏捷開發元年一樣，這都是一個非常緩慢的變革過程。
重要的是，企業必須了解DevOps所帶來的幫助是，軟體驅動的產品可以擁有更快的上市時間，找出這項新能力可以創造的影響。
想要做好DevOps並不容易，所以，企業更需要強調最終結果所能創造的價值，否則就會在還來不及完成流程轉型前就失去興趣，讓這項變革草草了事而無助於公司營運。
相關報導請參考：DevOps變革三部曲（一）DevOps：搶先一步的IT競爭力
",https://www.ithome.com.tw/news/96862,"新聞,DevOps,Pivotal,Michael Coté,持續交付,Continuous Delivery"
96861,31,2015-06-23,為什麼會出現DevOps？,DevOps試圖解決開發（Dev）團隊與維運（Ops）團隊之間存在已久的衝突及矛盾：開發團隊責難維運團隊的機器出了問題，維運團隊則把問題歸咎於開發團隊的程式碼上," DevOps運動承襲自敏捷系統管理（Agile System Administration）運動以及企業系統管理（Enterprise System Management，ESM）運動。
ESM運動約起於2005年，當時許多人認為，儘管經過多年的努力，目前運作系統的觀念仍然顯得過於原始，而Zenoss副總裁Mark Hinkle及前Chef服務副總裁John Willis等人都參與了這一波活動。同時進行的還有敏捷開發（Agile Development），此想法過去比較侷限在開發端，逐漸成為公司內的普遍慣例（Common Practice），特別在歐洲，此觀念已經衍伸為敏捷式系統管理。
當時，比利時籍IT顧問Patrick Debois與政府部門合作，共同進行資料中心遷移的計畫，而他則負責相關測試工作。Patrick Debois必須時常在開發團隊以及維運團隊間變換角色。前一天他正習慣於敏捷開發的步調，第二天卻必須上陣救火，確保系統能正常維運。經歷此項計畫後，Patrick Debois了解到，開發團隊與維運團隊不僅中間像隔了座山，運作方面還處處衝突。
在2008年時，Puppet實驗室共同創辦人Andrew Clay Shafer跟Patrick在多倫多的Agile大會中相遇，兩人針對Andrew Clay Shafer的議程主題敏捷式基礎建設（Agile Infrastructure）深談許久，他們兩個人都認為，必須思考出一個方式，搭起開發團隊與維運團隊之間的橋樑。在當時，持續整合（Continuous Integration）的想法已經逐漸開發社群間發酵，並且應用在部署服務的方面，但是此觀念還尚未應用在維運團隊中。
2009年6月23日，在加州聖荷西O'Reilly Velocity大會上，兩個Flickr的員工，資深技術維護員John Allspaw以及領導工程師Paul Hammond，在會議中報告了一個主題：「10+ Deploys per Day：Dev and Ops Cooperation at Flickr」震驚了許多在場的開發者，因為一天內部署超過10次是何等艱難的任務。此演講很快速地受到社群的認同，因為他們證明了開發團隊與維運團隊彼此是可以順利合作。John Allspaw跟Paul Hammond認為打造新一代軟體的方法應該是讓開發團隊及維運團隊兩個都變得透明，並將兩者互相整合在一起。
此時，隔著大西洋觀看直播的Patrick Debois受到很大的激勵，他在推特上表示，如果能親臨現場該有多好，而很快地就有人回覆他的推特，並表示何不自己在比利時舉辦一個活動，這樣大家就可以參加了。雖然是推特好友的一句玩笑話，卻無心插柳柳成蔭，讓Patrick Debois決定開始籌組自己的活動。

Flickr在O'Reilly Velocity研討會首度分享了開發團隊與維運團隊的成功合作經驗，如雙方使用IRC搭配多種Log資訊即時解決系統問題。（圖片來源／John Allspaw）

DevOps從比利時萌芽紅遍全球
Patrick Debois把Dev及Ops結合成DevOps，而因為活動有兩天，他決定另外再加上Days，所以活動名稱就成了DevOpsDays，並在當年的10月30及31日在比利時根特城舉行。活動結束後，社群間的對話仍然在推特上持續進行，由於推特公開發文有140字元的限制，社群決定刪掉後面的「Days」，採改用#DevOps在推特上進行討論。
很快的，DevOpsDays走出了比利時，成為定期舉辦及吸引開發社群參與的全球會議，並在John Willis、DTO Solutions創辦人Damon Edwards及Puppet實驗室共同創辦人Andrew Clay Shafer等人的幫助下，美國也舉辦了第一個DevOpsDays。
看到DevOps在各地蓬勃的發展，許多知名分析師也開始注意到這一波熱潮，開始撰寫相關文章並鼓吹DevOps的觀念。其中Gartner研究副總裁Cameron Haight在文章中預測，在2015年，全球兩千企業中的20%會擁抱DevOps。來自451研究機構的分析師Jay Lyman呼籲，如果企業想針對客戶、軟體開發有更快速的反應，勢必要導入DevOps。此外，O'Reilly內容策略副總裁Mike Loukides亦撰文「What is DevOps？」他認為DevOps是對於開發團隊以及維運團隊兩者之間都有深入、貼近地了解。DevOps相關的書籍開始變得熱門，如Tripwire創辦人Gene Kim、Gartner研究總監George Spafford等人共撰的《The Phoenix Project》及Chef副總裁Jez Humble及軟體開發者Dave Farley共筆的《Continuous Delivery》。
除了IBM、紅帽、微軟等科技業外，梅西百貨、手工劍橋包公司 Cambridge Satchel 及迪士尼也紛紛擁抱DevOps。根據Puppet實驗室、IT Revolution及ThoughtWorks的調查，有16%約1,485位受訪者表示，目前所屬企業已經建立了DevOps團隊。在2014年，第一場以企業為導向的DevOps企業高峰會也在加州開始舉辦。

隨著DevOpsDays活動在全球各地舉行，反映出DevOps熱潮蔓延全球的趨勢。（圖片來源／Michael Coté）

相關報導請參考：DevOps變革三部曲（一）DevOps：搶先一步的IT競爭力
",https://www.ithome.com.tw/news/96861,"新聞,DevOps"
96940,31,2015-06-23,Google、微軟、IBM、英特爾等大廠合推開放容器標準,OCP專案創始會員公司包括Amazon、Apcera、Cisco、CoreOS、Docker、EMC、Fujitsu 、高盛、Google、HP、Huawei、IBM、Intel、Joyent、Linux基金會、Mesosphere、微軟、Pivotal、Rancher Labs、紅帽及VMware，並由Linux基金會代管。," 包含Google、微軟、IBM、Amazon、EMC、思科及Docker、CoreOS在內的多家軟、硬體大廠共同宣佈，將攜手投入開放容器專案（Open Container Project, OCP），打造軟體容器相關標準。
軟體容器可說是近年最熱門的虛擬化技術議題，吸引不少雲端、網路大廠，如Google、Intel、Amazon、微軟、Red Hat等投入採用，其中最知名的技術是Docker，不過其實還有其他技術，如CoreOS也獲得部份大廠的支援。但長久以來可能因為軟體容器格式的不相容，對雲端服務的部署造成阻礙。
隨著容器解決方案快速增加，受到數百萬開發人員及數萬家企業、數千名貢獻者及數家科技公司的支援，促使產業領導業者亟思合作建立一個開放、標準化的容器格式與執行環境，以便為使用者維護服務可攜及相容性。OCP組織指出。
OCP專案創始會員公司包括Amazon、Apcera、Cisco、CoreOS、Docker、EMC、Fujitsu 、高盛（Goldman Sachs）、Google、HP、Huawei、IBM、Intel、Joyent、Linux基金會、Mesosphere、微軟、Pivotal、Rancher Labs、紅帽及VMware，並由Linux基金會代管。
開放容器專案旨在於現有標準上建立共通而簡約的標準，讓使用者及廠商可以持續開發與創新容器解決方案，又能確保既有開發成果得以沿用，避免產業的分裂。OCP及會員公司將在Docker的映象檔（image）格式及容器runtime技術基礎上，依據開放、安全、可攜、組合（composability）、簡約及回溯相容等核心價值，發展容器格式及runtime。Docker也將捐出其容器格式與runtime程式碼及相關規格給OCP專案，同時容納CoreOS的主導的Application Container（appc）規格。
OCP標準的指導原則是，不受限於高階的概念，如特定用戶端或協同堆疊(orchestration stack)，不與特定廠商或商業專業所約束，而且可在多種作業系統、硬體、CPU架構、公有雲之間獲致服務可攜性。
Docker專案將在捐贈的技術基礎上持續維護Docker用戶端、所有平台工具及所有Docker協同（orchestration）功能，而其他專案及公司也得以用OCP格式和runtime開發技術。該專案預計三個月內完成建置、程式碼移轉與出版以Docker捐出的程式碼為基礎的規格草案。
OCP表示，Docker技術獲得主要Linux、Windows及雲端業者、所有虛擬化平台和大部份主要CPU架構，包括x86、 ARM及IBM z、POWER System p的支援。以Docker映象檔格式開發的容器單單去年一年下載就超過5億次，並有超過4萬個公開專案是以Docker格式發展而成。（編譯/林妍溱）
 
",https://www.ithome.com.tw/news/96940,"新聞,Container"
96531,31,2015-06-12,群暉引進Docker，顛覆NAS應用,Docker/Container輕量級虛擬化技術投入廠商不在少數，但商用成果不多，群暉在很短的時間內，就在NAS直接整合並提供Docker應用，世所罕見," 臺灣儲存廠商推出的產品當中，一向以磁碟陣列和NAS設備為大宗，最被一般人所熟知的的廠牌，仍是主推NAS、特別針對入門等級產品應用的公司，例如威聯通（QNAP）、群暉（Synology）、色卡司（Thecus）、華芸（Asustor），這些廠商近年來也紛紛擴展產品線，橫跨到中型企業以上的應用環境。
除此之外，這些NAS廠商也以本身的產品為基礎，搭配出各式各樣的解決方案，最知名的例子，莫過於網路視訊監控的整合，幾乎每一家都能提供。近年來興起的另一股風潮，則是廠商開始提供類似智慧型手機App市集概念的線上軟體套件中心，當中提供許多附加應用程式，使用者可依照自己需求去選擇適合應用軟體套件，隨即下載、安裝到NAS上，像群暉NAS提供了Package Center、威聯通NAS也有App Center，選擇相當豐富。
全球首創！群暉在NAS系統搶先導入Docker輕量級虛擬化技術
NAS廠商競爭如此激烈，今年又有新的變化發生。群暉宣布旗下NAS作業系統DSM推出5.2版，當中最重要的特色，是正式支援了Docker，它是目前眾多雲端服務環境當中，最受到矚目的輕量級虛擬化技術，想要應用這樣的功能，竟可以在一臺NAS上輕輕鬆鬆地完成，而且可透過圖形化的網頁介面操作、使用，這對目前急遽發展的Container應用來說，也是一大創舉，而且，放眼全球IT，雖然也有不少大廠積極投入Container的發展，目前卻沒有其他廠商推出類似的應用，因此，這的確是前所未有的突破，而且是由臺灣NAS廠商一馬登先搶進。
這麼快就在NAS作業系統上引進Docker，可謂相當大膽，我們曾經介紹過6大Container OS，但在既有產品上直接應用Container技術，例子並不多見。
引進Docker關鍵考量：將系統軟體虛擬化，提供更多可能性
群暉科技執行長呂青鴻表示，當Docker的技術一出現，他們一直在思考是否有可能把自己的系統虛擬化，產生價值，進而提供給用戶。
對群暉而言，他們在商用產品的定位分為兩個層級，對於大型企業應用，群暉扮演的角色是專業的、純粹的儲存設備廠商，提供很多備援、資料保護功能，而在中型企業環境，群暉並不只是將自己視為儲存廠商，而是整體解決方案的供應商，呂青鴻表示，群暉在這個層級上，某種程度可以說是伺服器廠商。
對於整體解決方案的提供，群暉很有信心能做到，其中，視訊監控的整合就是最典型的例子，而網站架設軟體、網路相簿、資料共享等應用程式的提供，也是因應許多學校不同班級拍照分享、各自架設網站的需求而生。
「More Than Storage」，可說是整體解決方案概念下的最佳註腳，呂青鴻強調，群暉過去一直在做這件事情，成果也不錯，不過，當他們看到Docker出現之後，第一個感覺是，它很符合群暉在上述定位產品的需求，於是第一個步驟開始踩進去研究，在目前這個階段，群暉的作法是把Docker放在DSM裡面，可藉此執行很多Image，他們希望，藉由Docker的力量，接下來，可以將群暉DSM系統做到某種程度的虛擬化，群暉將這個目標稱為DDSM（Docker DSM），即將在今年下半推出。
之所以在自家NAS產品用Docker，群暉另一個重要考量是，許多應用程式和系統服務的執行負擔較小，並不需要用到一般認知的伺服器虛擬化環境來進行，在實際環境下，存在著不少的輕量級虛擬化應用需求。
該公司的軟體開發部資深經理凃惇竑說，有時只需要做到應用程式或系統服務的虛擬化，或要切割、隔離出不同的工作環境或儲存空間、虛擬網路，如果用傳統虛擬化的方法來執行這些應用，非必要的負擔會比較重。相對地，當應用程式或系統在Docker這樣輕量虛擬化環境下執行，效能幾乎與在原生硬體環境一模一樣。
NAS下一波虛擬化應用風潮即將開展，群暉搶先取得入場券
群暉另一個即將推出的DDSM應用，也是基於這樣的平臺來進行，當NAS系統可同時執行多個虛擬的DSM系統後，這些DSM彼此的工作環境、儲存區，都是獨立、互不干涉，使用者也可以讓這些DSM分別執行不同應用程式，例如一臺DDSM提供Photo Station、媒體伺服器的服務，另一臺DDSM執行其他應用程式，彼此提供的服務是隔離的、互不影響。
目前DSM提供Docker套件的安裝，讓使用者能夠以最簡單的方式，安裝第三方Docker Image套件，雖然方便，但某些時候玩家還是需要一些專業才會裝，呂青鴻強調，真正重要的是下一步，能在一臺機器上裝很多DSM，因為虛擬化可帶來很多好處，不論是安全性、升級測試、執行的資源限制，而在群暉的產品裡面，就能享有這樣的好處，而且對整個系統的效能影響是不大的。
群暉對Docker應用很感興趣，也發現它很有特色，是個能帶給用戶價值的嘗試和方向，但呂青鴻認為，這不表示否認KVM這類型虛擬化應用的方便，他們想要的，是在每一個部份，都能提供用戶想要的解決方案。
一臺硬體若能執行多個NAS系統，有助於應用微型服務架構
一臺NAS同時執行多個服務，很常見，但執行多個服務，就有可能會衍生多個問題，對此，群暉的第一個考量是系統效能的妥善配置，有些應用的執行，可容許系統資源充裕時就做，不足時就變慢，呂青鴻說，但有些用戶希望特定的關鍵應用系統所得到的系統資源，能夠固定下來，若沒有資源切割的技術，將無法做到。
他們第二個考量是安全性。有些用戶反應，單一環境若只執行一個服務，一旦駭客侵入此處時，對方不會存取到全部的系統和資料，因此這能達到某種程度的保護，而有了Docker這樣的技術，群暉NAS就可以做到，因為畢竟是在同個機器執行多個受到隔離的應用服務，就能獲得這個好處。
而且在虛擬化環境下，想備份相關資料，呂青鴻表示，較能做到自我包含（Self-Contained），要遷移應用執行環境和資料也容易。這麼做的好處很多，也是群暉看到Docker，決定再進一步發展的重要原因。
 

NAS不只提供儲存容量，也能成為軟體開發好幫手


群暉DSM有Docker這樣的支援，也吸引一些軟體開發者的注意。凃惇竑表示，有些軟體開發者知道之後，隨即轉進到這套NAS系統上，來開發跨平臺的應用程式。
呂青鴻說，群暉很歡迎開發者到他們的產品上，幾個中型企業需要、較關鍵的應用系統，群暉可以自己做，但無法涵蓋所有需求。因此，如何和其他公司合作，把應用軟體移上來，也是他們的目標之一，而有了Docker之後，希望吸引更多軟體開發廠商，協力完成。
過去其他應用軟體若要整合到DSM執行，是透過PHP、MySQL方式架構的環境──DSM本身有Web Station，可以將Web-based的應用系統整合進來執行，但無法更深入結合，而有些使用者需要的不只是這樣，他們想把整個Linux作業系統移過來，而有了Docker之後，要把特定應用搬到群暉NAS會更加容易。

",https://www.ithome.com.tw/tech/96531,"Docker,Container,輕量級虛擬化技術,NAS,群暉"
96119,32,2015-06-04,卡位Container熱潮，連Intel也推自家Linux,Intel設計了全新的輕量級虛擬化技術Clear Container，利用KVM、Linux核心和處理器晶片上的硬體虛擬化技術VT-x，讓一個包裹了VM的Clear Container開啟速度不到200毫秒，幾乎和建立一般Container差不多快," Container爆紅，用來解決大量部署需求的Container OS卡位戰火越演越烈，不只軟體廠商競相投入，連處理器晶片龍頭Intel也加入戰場。繼4月旬，VMware突然發表自家Linux，來搶攻Container OS市場後。近日，Intel跟進推出自家用於部署大量Container的Linux版本，稱為Clear Linux，結合處理器晶片內虛擬化技術，可用不輸原生Container開啟的速度，來開啟一個部署在VM內的Container。
因為虛擬機器開啟時間需數分鐘到數十分鐘，遠慢於幾秒就能開啟的Container，所以，許多廠商紛紛打造超輕量級的作業系統，在單一OS上能部署大量Container。
不過，Container最為人詬病的是安全性機制尚不成熟。Intel前技術傳教士Mike Richmond在Intel官方部落格上表示，使用同一個使用者命名空間來隔離兩個Container所建立的安全性，明顯比不上在Hypervisor上利用Intel虛擬化機制VT來隔離兩個虛擬機器的安全性。
針對Container安全性的問題，則有廠商如VMware，提出將容器化（Containerized）應用程式部署在VM中來解決安全性問題的作法，VMware的Photon則是打造用於Guest OS瘦身用的特殊Linux，來加快VM的效能，同時也能兼顧利用VM安全性強化Container的目的。
相較於VMware從軟體面著手，Intel自家的Container技術Clear Container選擇從硬體層面著手。
Intel不只利用OS軟體核心和KVM虛擬化技術，還搭配了Intel處理器晶片內的V-Tx虛擬化技術來設計出新的Clear Container機制。
Mike Richmond表示，Clear Container是一個包裹了VM的Container，這個VM的Guest OS使用了Clear Linux的優化副本，如此一來，開啟這樣一個帶有VM外殼的Container的速度，不到200毫秒，幾乎和建立一般Container時差不多快。
Intel目前已經釋出了Clear Linux測試版的程式碼。
 
",https://www.ithome.com.tw/news/96119,"新聞,Intel,Container,Container OS"
96281,32,2015-06-01,中國最大旅遊業攜程網當機12小時的省思,攜程網宣稱服務當機是員工人為操作不當，但臺灣IT專家認為，攜程網可能沒有落實特權管理與設計一套完善的備援機制，才導致服務中斷超過12小時," 中國最大旅遊業者攜程網（Ctrip）官方網站及App於5月28日上午11點9分出現當機，官網及App無法提供服務，一直到當天晚上11點29分全面恢復正常。這期間，對於當機的原因多所臆測，攜程網官方微博最早在上午11點9分宣布，攜程網部分伺服器遭到不明攻擊，導致官方網站和App暫時無法正常使用；之後陸續恢復部分服務功能，直到5月29日凌晨1點半發布官方聲明，表示攜程網的當機事件是因為員工錯誤操作導致，因為相關業務與服務範圍較為繁多，所以花了比較長的時間，驗證服務能否順利進行。
攜程網會員就多達2.5億人，員工人數超過3萬人，而根據攜程網2015年第一季財報，其淨營收為3.73億美元（約為新臺幣115.6億元）來估算，平均小時營收新臺幣535萬元，而當機12小時，相當於損失了新臺幣6420萬元。受當機事件影響，攜程網在美國的股價也從原本81.52美元，小跌到每股78.81美元，但中間一度跌幅超過10％。
攜程網服務當機12小時後，官方宣稱問題出在員工操作錯誤
由於攜程網提供各種機票、酒店和旅遊行程的預定，包括官方網站以及App服務出現當機時，引發中國使用者的恐慌。第一時間，網路上便有人傳出攜程網的資料庫遭到物理性刪除，引發使用者一陣恐慌；爾後，攜程網則在官方微博表示，當機源自於遭到駭客不明攻擊，才導致服務中斷。攜程網服務從上午11點9分出現當機，一直到當天晚上11點29分全面恢復正常服務，中斷服務時間超過12小時。直到5月29凌晨一點半，攜程網才對外宣稱，因為攜程網提供許多旅遊相關的網路服務，攜程網官方聲明指出，該公司技術人員要復原上線服務時，必須確認每個Web Services和系統之間的驗證與串接無誤後，才能服務恢復上線。也因此，此次的服務從當機到重新上線，技術人員花了超過12小時才復原。
果核數位營運長許武先表示，連這種規模的企業都會發生人為操作錯誤，更提醒了，高度依賴網路的服務業者，應該要重視特權管理和備援機制；臺灣線上古典音樂網站Muzik Online總工程師曾義峰則認為，為了降低人為操作出錯的風險，不論多麼複雜的網站服務，對於DevOps（開發銜接維運）中的Operation（維運）都應該預先規畫服務當機時的應對方案，有SOP（標準作業程序）照表操課，可以降低不必要的損失。
落實權限管理與災難備援機制，減少人為錯誤
對於攜程網將服務中斷原因歸咎於員工的操作錯誤，負責線上遊戲業者遊戲橘子所有IT服務與安全的許武先表示，從官方表示資料沒有遺失，訂單資料也保留完整，但服務卻中斷12小時，問題就可能發生在應用程式或者是儲存系統出問題。一般而言，應用程式出錯極有可能某些應用程式的程式碼被不當刪除或修正，改善的方式便與權限控管息息相關；若是儲存系統出問題造成的服務中斷，則會和系統資料的備份、備援機制完整度相關。
他以遊戲橘子為例，正常來說，員工在上線（Production）環境中的權限都是受到高度控管與限制的，像是刪除資料庫（Drop DB）或是欄位（Table）時，或者是修改資料庫或欄位時，都有明顯的警告機制，都必須經過授權後，才能夠執行相關的指令。為了避免類似服務中斷的可能性，遊戲橘子還引進特權管理機制，並要求所有的指令的執行，都必須先在測試環境中確認無誤後，才能在上線環境執行；而所有的服務上線，也都必須依照排程逐步進行。
早一天，中國支付寶才發生因為光纖被挖斷導致服務中斷，但支付寶在2小時內，就恢復正常服務。許武先認為，相較於支付寶的快速復原，可以推測攜程網平時的災難備援機制的演練或許不夠完善，以致於，一旦發生服務中斷的意外時，攜程網缺乏一套完善的災難應變流程。
從DevOps角度重新關注網路服務上線與部署流程
曾義峰則認為，這麼大型的網站服務公司要重新恢復線上服務時，開發與維運團隊勢必要攜手合作，這正是近期為了降低應用程式部署風險的IT顯學DevOps所要解決的難題。
他進一步指出，像攜程網這類當機事件，姑且不論是外部惡意攻擊或者是內部疏失造成的，DevOps 中的 Ops（Operations，維運） 都應該事先設想到，服務一旦當機時的備援機制，而這個方式也應該同時包含Online（線上）及Offline（離線）兩種方式。
Online的備援表示平時要有多臺伺服器做熱備援，資料庫就必須有2臺以上，1臺出錯，還有1臺可以即時接手備援。不過，Online線上熱備援的問題在於，很難處理大量刪除資料的問題。也就是說，這批同時上線運轉的機器為了隨時提供服務，也會即時同步彼此的資料和數據，一旦外部駭客入侵或內部員工下指令要刪除整個資料庫時，這些同時線上提供服務的資料庫，就會同時被刪除。
所以，曾義峰說，Online線上的備援有風險，所以也必須同時落實Offline離線的備援機制，就是備份，包括資料與系統在內。但他則提醒，Offline離線備援機制仍有層級之分，企業可以忍受多久的服務中斷時間？資料還原後，驗證服務的階段時，判斷有哪些資料遺失，有哪些資料毀損，又需要多久的時間，都必須事先做好規畫才行。此外，採用離線備援機制時，企業可以忍受多少的資料損失，有賴設定備份的頻率，上述都與企業投資在備援方案的成本多寡，息息相關。
從攜程網服務當機超過12小時，曾義峰更特別意識到，DevOps中的災難備援機制都應該同時包含Online線上與Offline離線方案， 若企業無法忍受任何資料遺失或毀損時，如何做到快速同步又能避免同時面臨資料毀滅，是很大的挑戰；但無論如何，好的Offline離線備援機制，是所有線上備援機制失效後，最後的保命符。
 
",https://www.ithome.com.tw/news/96281,"新聞,攜程網,携程网,Ctrip,權限控管,特權管理,DevOps"
96243,32,2015-05-30,IT月報｜雲端IT焦點回顧 (2015/05),新版OpenStack本月最夯，不只支援裸機還要擁抱Container。Google雲端平臺大降價，叫陣對手想拼價格戰," OpenStack大力擁抱Container
開源雲端作業系統OpenStack基金會在溫哥華舉辦半年一次的高峰會，OpenStack基金會營運長Mark Collier表示，OpenStack也要擁抱當紅的Container技術，未來，OpenStack將成為跨技術的整合引擎，可以在OpenStack上執行裸機部署、VM環境和Container。
Mark Collier表示，目前Container技術尚未有標準，OpenStack會支援Docker、Kubernetes、Mesos、Rocket等主流技術，目前相關專案為Magnum和Kolla。在年初即釋出於Nova運算平臺中整合Contaienr技術的Magnum專案，半年來進展速度飛快，42名開發者完成了10萬多行程式，完成近680次程式更新。（見全文）
 
OpenStack欲打造全球雲，宣布OpenStack Powered認證專案
OpenStack基金會在溫哥華高峰會中宣布「OpenStack Powered」認證專案，也公布了各種互通測試的新標準，涵蓋公有雲、代管私有雲、發行版本與設備等。已有14家業者基於相關標準測試自己的產品，通過測試的產品都會享有「OpenStack Powered」標章，並陳列在OpenStack Marketplace上，這些產品將有一致的OpenStack核心，並允許開發人員所撰寫的OpenStack應用程式可在全球各式各樣的OpenStack公有雲或私有雲上運作。（見全文）
 
OpenStack新版終於支援裸機部署

離上一個Juno版本半年後，雲端作業系統OpenStack如期推出第11個新版本Kilo，終於釋出了上一版來不及完成的裸機（Bare Metal）套件Ironic。另外，Kilo版本也強化了多項套件的功能，如身分識別套件Keystone則增加了階層式管理機制，網路套件Neutron也略有更新。
這次改版最引人注目的是OpenStack新增Ironic裸機部署功能。Kilo版終於可以在實體伺服器自動化部署OpenStack，等於能用管理虛擬機器的方式，來管理實體伺服器，有助於一次部署大量OpenStack主機來滿足大型IaaS環境的需要。Rackspace的OnMetal裸機部署服務，正是採用了Ironic套件。（見全文）
 
Ubuntu創辦人Mark Shuttleworth來臺宣傳OpenStack
Ubuntu近來搶進OpenStack市場的動作頻頻，日前除了搶先在Ubuntu 15.04新版中釋出Kilo新版本外，其創辦人Mark Shuttleworth也積極走訪各地宣傳OpenStack。Mark Shuttleworth認為，OpenStack應該專注於4個元素：運算、網路、儲存及身分認證。把這4件事處理好了，任何人都可以在OpenStack上順利執行任何訊息系統、任何資料庫、Hadoop或者機器學習系統。
他以Ubuntu為例，目前其運算功能可支援LXD、KVM及Hyper-V，未來也將支援ESX；儲存領域則與Ceph、Swift及PMC合作；而身分認證上則能整合Active Directory及LDAP。最後在網路方面，則與Open vSwitch、Juniper、Nuage及Cisco合作，這是Ubuntu認為能讓OpenStack變得強大的方法。（見全文）（其他文章：創辦人Mark Shuttleworth專訪報導）
 
鎖定大資料市場，微軟再推3項雲端資料庫服務

微軟在Build大會上發表3項與公共雲端資料庫有關的服務，分別是用來儲存關聯性資料的Azure SQL Data Warehouse、用來儲存大量非結構化資料的Azure Data Lake，以及可靈活管理大量資料庫的Azure SQL Database elastic database。
Azure SQL Database elastic database允許使用者打造SaaS應用來管理有不同資源需求的各種資料庫；Azure SQL Data Warehouse則可支援PB級資料量的儲存，並得以根據使用次數計價的企業級資料倉儲服務；而Azure Data Lake是鎖定各種結構化、非結構化與半結構化的混合資料儲存，允許用戶在同一個地方以資料原本的格式儲存，而且沒有檔案大小或容量大小的固定限制，亦可執行大資料分析任務。（見全文）
 
微軟輕量級OS終於現身，Nano Server版本預覽版釋出
微軟在Windows Server 2016剛釋出了新的預覽版本，也內建了最新的Nano Server部署機制。Nano Server是Windows Server的一個部署選項，用來針對雲端大量部署及DevOps需求所推出的輕量化伺服器版本，僅推出64位元版本。由於Nano Server只內建了必要元件，來縮減伺服器映像檔的大小，以減少部署時間和降低頻寬損耗，同時也縮短了系統啟動時間，也因可減少需更新的元件而能提高系統的安全性。微軟認為，Nano Server的特性讓它成為Windows Server與Hyper-V容器（Containers）的最佳拍檔，並適用於其他針對雲端最佳化的應用。（見全文）
 
Google再掀雲端價格戰，率先降價說要比對手便宜4成

Google宣布調降Google Cloud雲端運算平臺的虛擬機器費用，降調幅度介於5%~30%之間。Google技術基礎設備資深副總裁Urs Hölzle也大批對手價格過高，他說，與其他的公有雲供應商相較，Google雲端平臺的費用在許多任務上都便宜了40%，若結合Google所推出的自動折扣與以分鐘計價策略，再加上沒有轉換機器型態的罰則與不須固定價格的長期合約，堪稱是公有雲市場上性價比最高的業者。去年Google率先降價引發微軟和Amazon跟進。Google此舉挑釁，今年恐再度引爆新一波雲端價格戰。（見全文）
 
雲端團隊轉型OpenStack新創又一家
迎廣科技旗下的軟體部門雲端應用研發中心，獨立出來創立了一家OpenStack新創公司迎棧科技。資本額3億元，目前員工人數約50人。迎廣雲端應用研發中心技術長鍾惠光成為了迎棧科技的總經理，繼續率領技術團隊。迎廣兩年前看上OpenStack未來普及而設立軟體部門，如今，為了更多資源，招募更多人才從迎廣獨立。
迎棧科技並非臺灣第一間OpenStack新創公司，工研院去年12月也將旗下雲端中心團隊獨立出來成立雙子星雲端新創公司，發表雲機櫃產品，搭載以OpenStack開發的雲端作業系統，主攻企業私有雲應用。不過，迎棧科技表示，不同於雙子星雲端聚焦在OpenStack的應用層，迎棧科技則會朝基礎層發展。（見全文）
 
照片提供／OpenStack基金會、微軟、OpenStack
",https://www.ithome.com.tw/news/96243,"新聞,Container,Kilo,Ironic,裸機部署,Ubuntu"
95752,32,2015-05-15,Docker掀起微服務革命，廠商搶進Container OS競賽,隨著Container與Container OS的興起，過去實作難度很高的微服務架構不再遠不可及，有朝一日企業也能擁有與Google類似的雲端架構," 「這底下的空間還大得很」，美國知名物理學家費因曼在1959年12月29日美國物理學會年會演講中的這句話，是他預言將來有一天可以從分子甚至是原子層級來組裝或製造產品的可能性。當可以控制更細微尺寸（如單顆分子，甚至是原子的奈米層級大小）的物體時，將會顛覆了人們對於物體性質的理解和運用。這場演講促成了後來改變全世界的奈米革命。人們可控制細膩度的改變，帶來了全新的變革。同樣的故事，也正在軟體世界發生。
從2011年開始，微服務（Microservices）這個新名詞開始流傳。這個名詞相對應的是傳統慣用的單套式應用程式模式（Monolithic Application），將一支應用程式視為一個個體，所有功能都放入這隻程式中執行。企業應用系統架構通常可分成3個部分：用戶端介面程式、資料庫和伺服器端的後端程式，通常這個後端程式就是一支單套式的應用程式。而微服務的設計哲學則是反其道而行，藉由許多小型的服務，組合成一套應用程式。
單套式應用將所有功能放入一個Process中執行，當要提升系統運算效能時，得把同一隻程式整個複製到多個伺服器上執行。而微服務式的應用程式，因為是採取分散式的程式架構，每一個功能所對應的微服務，都可以在個別的Process中執行，要擴充效能時，也只需要複製所需的功能服務，而不用複製一整套的應用程式。
其實，早在微服務架構流行之前，許多大型網路服務業者，如Google、Amazon早已用來打造全球性規模的分散式雲端服務。
由大量微型服務組合而成的一套應用系統，特徵是每一個微服務都是獨立執行，也能各自大量擴充，甚至可以用不同的程式語言來開發同一套應用所需的各個微服務。然而，微服務架構雖有彈性更大、擴充性更高的優點，但最大的考驗則是管理大量Process的複雜性，其挑戰遠大於在單一Process內執行單套式應用程式。尤其發展到了全球性規模的雲端服務，要打造出分散式微服務架構的應用，往往只有像Google這類大型軟體業者才有能力做到。
Docker問世，降低微服務門檻
不過，隨著Container容器技術的成熟，過去實作難度很高的微服務架構，卻也開始出現一絲曙光。Docker透過Container技術可以將任何小程式打包成可獨立執行的映像檔，發布到任何可執行Docker的平臺上執行。開發者只要將一支應用程式所需的功能程式打包成Docker映像檔，部署到伺服器就能成為提供不同功能的微服務。開發者就可以透過同一套工具、同一套技術來管理大量的微服務，而且不用自己維護這套「微服務架構技術」。也因此連Google都稱讚Docker找到了更好用、更方便的Container實作方式，因此轉而大力支援。
IT 架構轉型三階段
過去，企業要將一支程式或一套應用部署到多臺伺服器上提供大規模服務，除了自己設計高擴充性的專屬分散式架構之外，最簡單的方法是利用虛擬化技術，將應用系統放入虛擬機器（VM）中，就容易複製、擴充。
但是，Docker的問世，讓一般企業也有能力使用比虛擬機器更輕量化的Container來封裝應用，再彈性部署或快速擴充到各種環境上。
Container技術藉由OS核心來達到資源隔離，因而不需要依賴虛擬軟體層，也沒有虛擬機器必須安裝客座作業系統的問題，所以其映像檔的容量遠比虛擬機器的映像檔小，更容易透過網路傳輸到雲端環境部署，大幅節省運算資源。Container也因為輕量化的架構，生成的速度非常快，可在數秒內啟動Container，而不像啟動VM起碼是以分鐘計算，甚至可能數十分鐘。
Container除了在技術架構上有其天生的優勢，也因為Docker提供了一套可結合版本控管、可程式化的部署配置檔機制，讓開發人員和維運人員有了一個共同描述系統環境的工具，甚至搭配持續整合、持續部署工具，開發人員自己就能透過Container來調度資料中心的資源，因而使得Container大受歡迎。
Container帶來的新能力，讓企業得以更容易地控制更精細的微服務，以組成一個應用系統，而不只以虛擬機器為最小單位來管理應用程式。而天生就透過各種網路服務串接而組成的雲端應用程式，更適合運用微服務架構。這正是Google等級的大型網路服務供應商，打造全球性服務的關鍵架構。當你打開Gmail時，其實已經啟動了多個在Container內執行的微服務，來提供郵件服務。根據Google自己的估計，每一周啟用的Container就多達20億個，數量相當驚人。雖然一般企業不會出現上億個Container的管理需求，但要在整座資料中心內的多臺伺服器上部署數百到數千個Container，仍然不是一件容易的事。
而Container OS容器作業系統正是瞄準了大量部署Container而生的專用型作業系統。以最早推出Container OS的CoreOS為例，他們盡可能移除了不必要的Linux系統程式和元件，只保留OS核心和Docker所需執行環境，以及管理Docker叢集的工具，將Linux輕量化。這麼做的好處，一方面縮減作業系統的檔案大小，另一方面，內建元件和程式越少，發生安全漏洞或後續需要更新的機會也越少。CoreOS還設計了串流式系統更新機制，減少大規模部署的維護工作。
大幅瘦身之後，CoreOS映像檔只有161MB，遠小於動輒上GB的通用型Linux映像檔，但是，還是有人覺得這太大了。另一個由Citrix前CloudStack團隊成員所創立的RancherOS，誓言開發只為Docker設計的容器作業系統，結果映像檔大小僅22.4MB，拿下了最輕薄Container OS的封號。
面對Container OS的需求，幾家知名的Linux作業系統廠商自然也不會放過這個機會，紛紛推出自己的Container OS版本。Red Hat發起了Atomic專案、Ubuntu則推出了Snappy Ubuntu Core，而微軟開始擁抱Docker之後，也推出Windows Server的Nano Server部署版本，不過，微軟採用的是自行開發的Windows Container技術，以及這個技術增加了多租戶設計機制後重新命名的Hyper-V Container技術。
然而，更令人料想不到的是，VMware在4月底也加入Container OS的戰局，發表了自家輕量級Linux作業系統Photon。VMware不只想要卡位Container OS市場，更想結合自己在虛擬化平臺上的優勢，鼓吹在VM中部署Container的策略，用Container部署雲端原生應用，而用VM部署傳統應用系統的混合雲架構模式。
哪一套Container OS最能獲得企業青睞？這類產品才剛起步，市場尚未有定論。但這場由Docker掀起的微服務革命，讓企業建置和管理應用系統的精細度，有了全新的視野，就像多年前費因曼提出的新思維，揭開了人們探索奈米世界帶來的產業革命一樣。微服務架構的出現和成熟，有機會吹響IT架構奈米革命的號角，而眾廠商搶進的Container OS競賽，正是這場革命的第一個搶灘戰。
 

 
相關報導請參考：「Container三部曲（三）IT架構的新奈米革命：Container OS」、「Container技術三部曲（二）不只快，還要更快──臺灣Docker應用案例的啟發」、「Container技術三部曲（一）迎接下一個雲端火紅技術Docker」
",https://www.ithome.com.tw/news/95752,"新聞,Container,Container OS,微服務,Microservices,Docker,Linux"
95828,32,2015-05-13,搶攻公雲市場，富士通發表OpenStack雲端服務K5，自家5千套系統全面先用,富士通最新發表的公有雲服務K5涵蓋IaaS及PaaS服務，底層採用OpenStack，雖然尚未透露更多細節，不過，富士通已先將內部5千套系統全面轉移到K5上," 【日本東京現場報導】富士通在年度大會2015富士通論壇即將展開之前，率先揭露多項新雲端服務和私有雲產品，例如以OpenStack打造的K5公有雲服務，預計最快今年10月先在日上市，明年最快第2季在日本以外市場推出。富士通也先將內部5千套系統全面轉移到K5上執行。
日本富士通雲端服務過去以日本市場為主，已有如支援微軟Azure的A5服務、NIFTY cloud等IaaS服務及十多種PaaS服務及近百種SaaS服務，日本境外市場則以協助企業建置私有雲為主。
富士通伺服器事業部本部長遠藤明表示，為了要追上數位商業的新世代，富士通將旗下大資料應用、IoT、行動應用及雲端服務等相關產品和顧問服務，集中到一個整合式的單一服務品牌下，稱為數位商業平臺（Digital Business Platforms），並發表了多項新雲端服務。
最新發表的雲端服務包括採用OpenStack建置的公有雲K5，不只日本上市，明年也將在全球提供服務。另外也推出了採用K5相同架構的私有雲產品PrimeFlex for Cloud及搭配的雲端管理軟體，將和K5同樣最快今年第3季在日本當地推出，明年4～9月全球上市。
另外，也推出了多雲端環境的綜合管理解決方案（Multi Cloud Service Management），預計最快今年7月在日上市。而在整個雲端產品架構的底層，除了富士通既有的資料中心及資安解決方案之外，富士通已在3月時推出了一相基礎架構管理服務，讓企業可串連公司內部的雲端服務與網路環境。
K5雲端服務是一個橫跨IaaS及PaaS的公有雲服務，底層採用OpenStack雲端作業系統，可整合了企業的應用、一般服務及負載管理等服務，並提供企業多個服務原型及樣板（template）作為基礎架構建置時的選擇，簡化部署流程，雖然K5的更多細節尚未透露，不過富士通早在去年就已經將內部系統率先採用。
遠藤明表示，日本富士通內部正全面擁抱開放技術，為了更容易整合並相容其他雲端平臺，基礎資訊架構全面改用OpenStack，不只要將內部部署在1萬3千多臺伺服器上，多達5千套大大小小的系統、全部轉移到OpenStack平臺上，未來，富士通推出的企業解決方案也將會支援OpenStack平臺，另外也使用CloudFoundry來打造PaaS服務，並大量使用開放技術的中介軟體、開發工具及語言等。

富士通伺服器事業部本部長遠藤明表示，為了要追上數位商業的新世代，富士通將旗下大資料應用、IoT、行動應用及雲端服務等相關產品和顧問服務，集中到一個整合式的單一服務品牌下，稱為數位商業平臺（Digital Business Platforms）



富士通最新發表的雲端服務包括在富士通內部已經率先採用的公有雲服務K5，私有雲的部分發表了PRIMEFLEX for Cloud以及搭配的雲端管理軟體，而針對企業混合雲環境，富士通也發表了多雲端環境的綜合管理解決方案（Multi Cloud Service Management），另外，在整個雲端產品架構的底層除了富士通既有的資料中心及資安解決方案之外，也新增了一個基礎架構管理服務，讓企業可串連公司內部的雲端服務與網路環境。

",https://www.ithome.com.tw/news/95828,"新聞,OpenStack,富士通,Fujitsu,Cloud,K5"
95592,32,2015-04-30,微軟因應大資料趨勢發表3項新的雲端資料庫服務,微軟在Build大會上發表3項與公共雲端資料庫有關的服務，分別是用來儲存關聯性資料的Azure SQL Data Warehouse、用來儲存大量非結構化資料的Azure Data Lake，以及可靈活管理大量資料庫的Azure SQL Database elastic database。," 微軟在Build大會上發表3項與公共雲端資料庫有關的服務，分別是用來儲存關聯性資料的Azure SQL Data Warehouse、用來儲存大量非結構化資料的Azure Data Lake，以及可靈活管理大量資料庫的Azure SQL Database elastic database。
其中於本周開放預覽的elastic database（彈性資料庫）允許使用者打造SaaS（軟體即服務）應用來管理有不同資源需求的各種資料庫，例如將主要資源置放在數據大量成長或是重要的企業資料庫。獨立的雲端服務供應商或開發人員可在預算內透過單一的資料庫資源中心來分享與控管數百個或數千個資料庫的資源。 微軟也正在打造各種支援elastic database的工具，以方便使用者查詢及蒐集不同資料庫的資訊，或是部署政策與執行交易。
至於Azure SQL Data Warehouse則可支援PB級資料量的儲存，並得以根據使用次數計價的企業級資料倉儲服務。微軟表示，與市場上其他雲端資料倉儲服務相較，Azure SQL Data Warehouse約可節省75%的成本。
Azure SQL Data Warehouse採用平行運算架構，而且相容於微軟既有的Power BI、Azure Machine Learning、Azure Data Factory與Azure HDInsight等資料分析工具，公開預覽版可望於6月出爐。
Azure Data Lake則是鎖定各種結構化、非結構化與半結構化的混合資料儲存，允許用戶在同一個地方以資料原本的格式儲存，而且沒有檔案大小或容量大小的固定限制，亦可執行大資料分析任務。
Azure Data Lake是個相容於HDFS的Hadoop檔案系統，已與Azure HDInsight整合，未來也可整合微軟的Revolution-R Enterprise，或是第三方的Hortonworks與Cloudera等資料分析服務。目前已於封閉預覽階段的Azure Data Lake預計會在今年邁入公開預覽。（編譯/陳曉莉）
",https://www.ithome.com.tw/news/95592,"新聞,Azure,Cloud"
95546,32,2015-04-29,中國網路大砲又爆新招，綁架Facebook登入服務流量作為DDoS攻擊子彈,4月26日時，不少中國網友連上使用了Facebook登入機制的網站時，發現瀏覽器還打開了wpkg.org與ptraveler.com這2個小網站，他們不知道，自己可能成為了中國防火長城DDoS大砲的子彈，成了中國對外發動DDoS攻擊的幫兇," 中國境內的網友如果最近瀏覽外國網頁時，被迫轉址到wpkg.org與ptraveler.com網站的首頁，可能已成為DDoS攻擊的幫兇。
中國防火長城巨大加農砲（the Great Cannon）又被發現新的攻擊手法，在4月26日，當中國網友瀏覽國外有內嵌Facebook登入服務（Facebook Connect）的網頁，就會自動開啟2個受害網站，因為中國網友瀏覽器連線到臉書服務的流量都會被轉為DDoS攻擊的火力。第1個受害者是開源專案網站wpkg.org，第2個則是個人旅遊部落格ptraveler.com，這2個網站都因瞬間流量過大造成服務終止，目前ptraveler.com仍未恢復。程式碼被置換的情況並不會每次發生，而有些使用者被轉址之前，會有短暫的延遲。Facebook則表示，他們正在對此事件進行了解。
芬安全首席資安研究長Mikko Hypponen解釋，這次攻擊的影響對象主要是中國境內的網路使用者，當使用者瀏覽包含Facebook登入按鈕的頁面時，其連線經過防火長城，Facebook的Javascript程式碼便會被攔截，並置換成載入wpkg.org與ptraveler.com網站的Javascript程式碼。
類似的事件並非第一次發生，2015年初時，在GitHub上特定專案的網頁，也遭到中國以同樣綁架第三方流量的模式攻擊，這次外界無從確認中國政府綁架Facebook的真正目的，而且對2個沒沒無聞的小型網站進行DDoS攻擊，也是令人匪夷所思。
延伸閱讀：
透視百Gb級DDoS攻擊趨勢 專家剖析GitHub塞爆關鍵
Google變網路CSI，還原GitHub遭大規模DDoS攻擊過程，就連AWS的CDN主機也遭殃

 
",https://www.ithome.com.tw/news/95546,"新聞,DDoS,防火長城,JavaScript,GitHub,Cloud"
95433,32,2015-04-26,IT月報｜雲端IT焦點回顧 (2015/04),AWS率先推出雲端NAS，還跟進發表機器學習服務、Google則搶推雲端DNS和VPN，而微軟Azure儲存終於可選SSD," AWS、雲端NAS
AWS雲端NAS來了！新EFS儲存服務用SSD打造多VM共享的網路硬碟
Amazon在舊金山舉辦的AWS Summit上，發表了最新AWS雲端儲存服務Elastic File System (EFS)，相較於過去的AWS服務，EFS提供的檔案系統儲存服務，就像是在雲端上使用NAS服務一樣，能夠輕易完成檔案共享，並讓多個虛擬機器同時存取同一個檔案資料庫。EFS服務能支援現在主流的網路檔案共享協定NFS v4（Network File System version 4）。目前正式版釋出時間未定，預覽版則預計在今年夏天釋出，開發者現在可以先在官網上註冊來使用預覽版。
 
AWS、機器學習
亞馬遜也推出機器學習雲端服務
不只推出雲端NAS，Amazon像微軟一樣，在自家AWS雲端服務上推出了機器學習平臺Amazon Machine Learning。Amazon表示，這項新服務提供了視覺化工具與精靈引導使用者完成建立及微調ML模式的過程，可以讓所有技能等級的開發人員都可以使用機器學習技術，開發人員不必是統計背景、無需學習複雜的機器學習演算法和技術，連一般開發人員也可以運用大量資料來進行批次或即時性的預測。
 
雲端DNS、Google VPN
Google壯大雲端服務陣容，全面推出Cloud DNS
Google加強雲端服務的可靠性並擴充Google雲端服務，除了宣布全面推出Cloud DNS服務，並擴充負載平衡服務至全球其他12個城市，也同時發表了Compute Engine VPN測試版，允許客戶透過IPsec自既有網路連結到Compute Engine，或是用來連結兩個不同的Compute Engine VPN閘道。
Google並新增了11家互連（Carrier Interconnect）服務供應商合作夥伴可提供加密的傳輸通道。
 
Azure儲存、SSD
微軟雲端儲存終於支援SSD
微軟Azure終於也跟進AWS，開始提供SSD雲端儲存服務，微軟在4月中正式推出進階版雲端儲存Azure Premium Storage，改用SSD來提供儲存空間，能大幅提高Azure虛擬機器儲存空間的效能。
微軟表示，根據使用者預覽版測試結果，在SQL Server資料庫中還原2TB資料所需時間，用Premium Storage比Standard Storage快30倍。不過，這項進階版儲存服務還需搭配特定規格的Azure虛擬機器使用。
 
雲端威脅、IIS漏洞
微軟IIS驚爆HTTP.sys死亡漏洞，SANS警告駭客正大肆搜尋肉票伺服器
微軟IIS網頁伺服器的HTTP.sys核心出現重大漏洞，資安專家評估，嚴重程度恐超越Shellshock漏洞。駭客只要發送一個簡單的HTTP請求，就能透過此漏洞癱瘓微軟IIS上的網站，甚至取得遠端控制權，恐成為駭客發動DoS攻擊的入侵手段，全球現有7千萬臺微軟網頁伺服器恐受影響。SANS更發現，已偵測到駭客大型搜尋行動，掃描全網際網路，尋找有此漏洞的微軟IIS網頁伺服器。微軟已於4月14日釋出更新。（圖片來源／SANS）

 
醫療雲、Watson技術
IBM力拱Watson技術，打造醫療健康雲
IBM今年頻頻有大動作展開，除了成立新的物聯網部門，4月中更進一步宣布成立新Watson健康事業部門，來打造一套Watson雲端健康平臺。IBM表示，這個平臺將整合醫療設備，提供醫院和醫療保健社區使用，來搜集和分析所有來自病人提供的醫療資料，除了提供各種臨床試驗研究外，也可用來做為長期慢性疾病，如糖尿病，或重大手術後的資料蒐集與復原狀況追蹤等。
IBM也表示，該團隊也將與科技大廠蘋果，以及另一家大型醫療器材製造商Johnson & Johnson and Medtronic攜手合作。未來不只是可以結合iPhone App使用來搜集和分析病人的醫療資料，也能運用於蘋果最新推出的Apple Watch上。
 
網路中立、電信法規
美國公告網路中立新法2個月後生效，美國ISP和電信產業帶頭反對
4月中美國聯邦通信委員會FCC（Federal Communications Commission）在美國聯邦公報（Federal Register）上公告一項關於網路中立的開放網路命令（Open Internet Order）。因新開放網路命令將在2個月後生效，網路服務將被納入電信法的Title II類別，業者必須基於網路中立原則，提供相同頻寬與連線速度，不應該因為私人或企業支付較高的費用，而享有差別待遇。新法規一出爐，隨即引發激烈爭議，不少團體提出反對意見，反對者認為這意味著政府將可能會介入並監控網路服務。受到直接影響的網路服務供應商（ISP）立刻提出反對訴訟，美國電信聯盟（USTelecom）也宣布對FCC提出訴訟，質疑其程序問題。
 
財政雲、e政府
財政部資訊中心揭露財政雲架構藍圖
財政部財政資訊中心主任蘇俊榮揭露，臺灣正在打造的新一代財政雲架構藍圖。整體架構分為應用系統以及基礎建設，應用系統是指各機關通用系統，而基礎建設則是標準開發環境以及機房，這些都包含在財政雲建置範疇中。財政雲已整合5個國稅局以及22個地方稅務局機房，並逐步整併關務署、國產署、國庫署和賦稅署等機關機房。
應用系統包括了財政內網雲和外網雲，內網雲以內部行政業務服務為主，分為大資料分析、行政辦公室以及各機關業務需求之資訊系統。財政外網雲則主要提供服務給財政部以外的對象，包含我的e財政和財政資訊統計，支援各機關業務的菸酒品智慧預警、賣酒預警機制以及雲端國稅服務等。

 
雲端儲存、雲端Office
網頁版Dropbox也能線上編輯Office文件
繼去年底微軟與Dropbox在平板及行動平臺上合作，現在雙方進一步宣布Dropbox與Office的整合擴大到Web上。現在Dropbox用戶在瀏覽器環境下預覽Word、PowerPoint或Excel文件時，只要按下「開啟」鍵，就能使用Office Online服務進行編輯。使用者也可使用Dropbox帳號在Office Online服務上，來讀取、開啟和編輯自己在Dropbox中的Office檔案。
",https://www.ithome.com.tw/news/95433,"新聞,Cloud,雲端,雲端NAS,雲端DNS,雲端VPN,雲端儲存,AWS,google"
95409,32,2015-04-23,管Container能像管VM，新版Ubuntu內建LXD平臺，要讓Container也可動態跨主機飄移,新版Ubuntu 15.04最大特色是內建了自家Container技術LXC的管理平臺LXD、首度推出Container跨主機線上轉移功能，讓IT人員像管理VM那樣來管理Container," Canonical釋出代號為Vivid Vervet（意指活潑黑面猴）的Ubuntu 15.04，主要新增了三大功能，包含內建了LXD (Linux Container Daemon) Hypervisor和OpenStack的下一個版本Kilo、也首度支援為物聯網裝置而設計的作業系統核心Snappy Ubuntu Core，4月23日正式開放下載。
早在2013年Ubuntu就發表了自家的輕量級虛擬化技術，來和Docker抗衡，並正式在Ubuntu 14.04 LTS版中內建。今年Ubuntu剛要釋出的15.04版中，更進一步推出了LXC輕量級虛擬化技術的管理平臺LXD (Linux Container Daemon)平臺。Ubuntu官網解釋，LXD就像是一套Container的Hypervisor層平臺。
Canonical的Ubuntu產品經理Mark Baker表示，為了協助開發者使用Container環境時，安全控管不易和執行動態遷移（Live Migration）的問題，Canonical而開發出LXD。不過，Mark Baker表示，LXD並非要取代現有的Container技術如Docker等，Docker也能在LXD上執行。如15.04可支援Docker 1.5版本
支援物聯網作業系統核心Snappy Ubuntu Core
Ubuntu 15.04也支援了最新的Snappy Ubuntu Core，Canonical指出，Ubuntu Core為雲端到裝置提供單一的統一平臺，由於Ubuntu Core從雲端到裝置提供相同的API與安全更新，因此，提供開發者在雲端環境下模擬裝置，然後可以再發布到上千臺相同的裝置上。另外，Ubuntu Core中內建的Snappy功能，可以供開發者將應用程式與操作系統等回復到先前的狀態。
內建OpenStack第11版Kilo
另外，15.04還內建了OpenStack的下一個版本Kilo，這也是第一套上市的Kilo版OpenStack產品。此版本除了強化Docker整合、也增加了共享式檔案系統服務（Shared Filesystem Service）Manila、DNS管理服務Designate、雲端訊息佇列服務（Cloud Messaging Queue Service）Zaqar、金鑰管理服務（Key Management Service）等。
",https://www.ithome.com.tw/news/95409,"新聞,Ubuntu,Open Stack,Docker,Container,精選"
94998,32,2015-04-10,微軟千人開發團隊怎麼用Scrum,數千人參與的VS團隊，導入Scrum敏捷開發和DevOps思維，將3年一次改版步調，加速到每3周釋出一次小改版," Visual Studio是微軟最重要的核心開發工具，到去年10月止，全球.NET開發人員近6百萬人，光是VS 2013年版，下載次數就達到7百萬次。參與VS開發的人數超過4,700人，分布在美國、瑞士、中國、印度等地的微軟研發中心。這群人要負責190萬個開發工作項目，完成了近3,600萬個程式碼檔案，累計資料量達到15.3TB。開發團隊平均每個月會組建（Build）22萬多次。
早從2010年時，微軟開發團隊就開始運用開源軟體，但是為了避免軟體產品的程式碼有侵權風險，直到3年前，微軟仍然嚴格禁止開發工程師接觸開源程式碼，連看一下都不行。目前近2千人規模的Visual Studio（簡稱VS）開發團隊，不論是誰，都得經過3道申請程序，上簽到微軟開發平臺負責主管，也就是得到微軟開發平臺事業部全球資深副總裁潘正磊點頭同意才行。
但在微軟宣布擁抱開源，釋出.NET核心程式碼之後，現在，微軟反而鼓勵工程師參與開源社群，任何工程師接觸開源程式碼不需要獲得任何形式的核准，除非要在自家產品內放入開源程式碼，甚至微軟還開始積極招募擅長開源開發的人才。
從看一眼都不行，到現在要能和全球開源社群合作開發，微軟並非一夕之間就有能力跨入開源。過去微軟設計產品只需和內部溝通，現在得和社群合作。開源社群貢獻的程式碼如何和套裝產品整合，也需要新的流程。潘正磊表示，擁抱開源最需要的調整不是組織，而是要改變工作方法。
擁抱敏捷開發是微軟邁向開源的關鍵一步
「過去，微軟開發工作的安排可以是計畫性，但是開源之後，無法預估多少人會有興趣貢獻程式碼。」潘正磊表示：「微軟沒有轉型到敏捷開發，現在就不可能開源。因為無法提供合適的測試、適當的自動化、適當的持續整合機制來確保程式碼的正確性。」擁抱敏捷開發正是微軟能夠邁向開源的關鍵。
早期微軟採用瀑布式開發流程，不論哪一套產品的開發團隊都有各自的瀑布式流程作法，每次要推出一個新版本，往往需要2～3年的時間才能完成。
為了加快產品開發步調，2005年左右，微軟開始在內部推廣敏捷開發模式，2006年擴大訓練Scrum能力，VS開發團隊是率先推廣Scrum的微軟產品團隊，VS也開始支援Scrum。不過，即使微軟開始在內部推廣Scrum，2005年後的3次Visual Studio改版，從VS 2008、VS 2010到VS 2012，仍舊是每隔2～3年才會推出一次大改版。
VS 2012推出後，產品發布策略大轉變
直到2012年版釋出後，VS產品發布策略出現了大轉變。潘正磊表示，微軟做了一個重大決策，要讓開發流程更加敏捷化，來加快產品交付周期。
VS 2012發布後，微軟開始每隔2～4個月就發布一個更新版本，不只修補問題，還會增加新功能。光是從VS 2012年釋出後一年內，就推出了4次更新版本，並且在2013年時還推出了VS 2013的全新改版，從此，微軟發布VS產品的步調有如搭上了順風車，既有版本每隔2～4個月可以發布一次更新，而還未上市的下一版VS也能持續發布預覽版。
過去，微軟盒裝軟體每3年才改版一次的作法就像是發行百科全書一樣，每次推出就是一整套，為了確保內容詳細程度和正確性，需要訂定長期計畫、撰寫大量內容和進行大量校對來確保每一頁內容的正確性。
在微軟舊式的瀑布式開發流程時期，微軟會花3個月時間來訂定長期計畫，部門主管還訂定5年產品計畫，而產品經理則是要想像2年後的市場需求，來擬定2年後產品上市時的功能藍圖。
完成產品計畫後，開發團隊會將2年產品開發時間，預先訂出多個要達成的階段里程碑（Milestone），每一個里程碑會發布一個對應的測試版本。工程師們再依每一個里程碑估算自己的工作進度，並修正產品進度，來計算出2年後的哪一天能發布產品。
每一個里程碑階段內還得設定程式碼開發完成的時間點（Code Complete），因為得預留時間作為測試工作和功能穩定調校，微軟過去至少會預留兩倍的程式碼開發所用的時間。多數情況是，微軟工程師很快就完成程式碼的開發，反而是花了很多時間讓功能穩定，例如整合不同功能間的衝突或整合。
微軟在1995年時曾發生過盒裝產品上市後因為致命問題而全球召回的窘況。為了避免再次發生這種微軟稱為召回等級的臭蟲（Recall Class Bug），因為微軟軟體往往會發布到全球各國，支援多種語言甚至多種OS的版本，因此衍生了大量的測試工作。
在舊式開發階段，微軟得配備了大量測試人力，幾乎和開發團隊的人數規模相當。
到了研發VS 2013版本時，潘正磊決定要改變VS團隊開發產品的方式，導入DevOps思維，要讓微軟開發更加敏捷化。
潘正磊解釋，為了因應網際網路時代非常快速的產品功能交付需求，這是許多新創公司和大型雲端服務業者如Google、臉書等都採用了DevOps思維，將開發和維運一體化的作法，讓「開發團隊要直接為維運環境中的軟體負責。」
而且更重要的是，潘正磊說，在DevOps中的Ops概念，不只是確保網站運作，讓網站不會當機而已，而應該要「擴大Ops（維運）的概念，如何讓使用者順利安裝軟體，也可以是維運的一環。」就算是盒裝軟體，只是產品提供的方式和網站服務不同，但一樣可以套用維運的概念。
開發與測試的結合是落實DevOps的關鍵之一
如何實踐DevOps流程的關鍵是開發工程師與測試工程師角色的結合，不再像過去開發團隊工作完成了才交給測試團隊接手，而是開發與測試工作合而為一，轉變成持續測試、持續整合的開發模式。
因此，微軟在開發組織分工上，也不再像過去分為產品管理、開發和測試等三大類職務，以及各自所形成的3種組織團隊，而改將工程師區分成產品經理和工程師兩種職務角色，同一項功能的架構設計、程式碼開發和測試工作都由同一個人或小組負責。
微軟也改採功能團隊（Feature Team）的團隊工作方式，一個團隊約12～18人，內有1～2個產品經理，搭配一群來自過去開發團隊和測試團隊的工程師，組成一個兼具開發與測試能力的小組，來負責產品中的一項重要功能，例如C#編譯器就由兩個功能團隊負責。
2年半前，微軟甚至還改裝總部的18號大樓，過去微軟辦公大樓是一條走廊貫穿，兩側許多小型辦公室，人人都可以關起門來工作。但是，這棟大樓改裝後，打破了舊有辦公隔間，改成了團隊辦公室（Team Room）的較大空間隔間設計。同一團隊的人都能在同一個開放辦公室內工作，彼此都可以看到對方，聽見其他人的談話，隨時站起來就可以面對面溝通，旁邊再搭配幾間小型空間，作為臨時討論或開會的場所，房間內還設有每天站立會議用的大型螢幕來呈現任務看板。這棟大樓大約進駐了1千名研發人員。因成效不錯，後續3棟大樓的裝修也都採取同樣的設計。
不同於瀑布式開發流程，微軟新開發流程聚焦於改變
敏捷開發流程結合了DevOps思維後，和傳統瀑布式開發最大的不同點，潘正磊說，是聚焦於改變（Focus on Delta），瀑布式開發就像一次推出全套新百科全書似的大改版作法，而DevOps思維更像是快速進行大量的小改版，一次只更新一個章節、甚至只是其中的某一頁。
這也是和微軟過去截然不同的產品生產流程，新作法是聚焦於不斷縮短產品生產周期，來加快交付速度。「因為這是未來的網際網路公司所必備的能力。」潘正磊說。
因此，在產品開發周期上，潘正磊也要求，所有VS開發團隊，不論是盒裝軟體版本或是VS Online雲端服務的研發團隊，都統一改採每3周完成一個Sprint（衝刺階段）作法，不再像過去那樣採取開發里程碑分階段的作法。
微軟也不再制訂產品的5年計畫了，而是縮短為只訂定每6個月的計畫，也就是兩季長的計畫，並每6個月進行市場或競爭對手評估，讓產品能因應市場最新變化。另外還會訂定一個18個月後要實現的產品願景，來規畫如軟體架構調整或本質性需求調整等需要較長時間作業的目標。
Sprint是Scrum敏捷開發中一個計算開發周期的方式，每個Sprint就是一個包括開發、測試到發布軟體的完整過程，微軟等於每3周就會發布1個新的小版本，並在內部試用一周後就對外釋出供外界試用，而不像過去得等到一個里程碑達成後才會發布一個新版本軟體。在每一個Sprint開始第一周的第一天，每一個功能團隊都要完成Sprint計畫，並於第三周結束時發布產品成果。
不過，依據開發產品不同，釋出給外部試用者的時程也略有不同。例如開發Visual Studio Online的新功能就是每一個Sprint完成後就發布到雲端讓使用者試用，而開發VS IDE版本的團隊則是每2個Sprint發布一次技術預覽版。
Scrum模式的開發團隊規模不大，原有上千人的大型團隊重組成很多個小型功能團隊後，潘正磊表示，跨團隊持續保持聯繫相當重要。
所以，每個團隊的PM在每一個Sprint開始時，要發出一封Sprint啟動郵件，將這一次的Sprint計畫描述，如任務目標，這次要完成的用戶情境（User Story）寄給其他團隊或直屬主管。Sprint結束時也同樣要發信將開發完成的項目告訴其他人，還要錄製一段操作新功能的示範影片，來展示已經完成的成果確實可用。
管理整個部門的潘正磊則是依重要性來選擇要密切關注的功能團隊，每3個星期審視一次，例如她最近最常關注的則是負責.NET開源計畫的團隊。其他功能團隊則是每隔3個Sprint親自和團隊成員聊聊。
 

微軟開發平臺事業部全球資深副總裁潘正磊決定從VS 2012版，要讓開發流程更加敏捷化，來加快產品交付周期，因此決定全面改變微軟研發軟體的流程。

 
從臭蟲數量變化檢驗是否落實Sprint
微軟VS團隊全面導入敏捷開發流程後，潘正磊經常被質疑的問題是，你們做的是真的Sprint嗎？因為有不少軟體公司在高層要求下，儘管開發團隊導入了敏捷開發，產品發布周期從一年一次縮短到每季發布一次，但其實只是將原來的1年期瀑布式開發流程，縮短為3個月的瀑布式開發流程，而不是真正的敏捷化。
潘正磊檢驗Sprint是否落實的方法是從程式臭蟲（Bug）數量的變化來觀察。倘若程式臭蟲的數量會在程式碼開發結束展開測試之後迅速暴增，再隨著功能穩定修正後再大幅減少。臭蟲數量大起大落的數據變化，代表了這只是壓縮版瀑布式開發。若真有落實Sprint，因為要確保所開發出來的產品是處於隨時可用的狀態，若出現了任何臭蟲，開發團隊會即時修復和更新，臭蟲數量就不會出現大起大落的變化曲線。
用使用者真實數據來引導開發計畫
另一個與瀑布式開發截然不同的新思維是正視真實數據的重要性，潘正磊說：「數據是落實DevOps思維的另一個核心關鍵，線上環境中產生的數據才是真正有說服力的數據，要用這樣的數據來引導所有的開發計畫和流程，而不是測試環境中假想的用戶環境。」
現在微軟每個功能團隊釋出試用版本後，會關注有多少用戶開始使用新功能，若使用人數低於預期，就要找出原因，並解決下一版本要如何改善來提高使用量等問題。
例如VS團隊有次開發了一套結合HTML 5和JavaScript來開發行動應用的套件，釋出預覽版後，產品經理追蹤實際使用數據後才發現，過半數有意下載者所用的作業系統是Windows 7環境，而這個預覽版只支援Windows 8.1。因此，很多使用者連安裝都出問題而無法使用。負責開發的團隊看到這個數據後便決定改變下一個預覽版本的開發計畫，先增加對Windows 7環境的支援。
或是幾個月前，IE瀏覽器內負責執行JavaScript的Runtime是由VS團隊負責開發。兩組功能團隊為了某一個Runtime優化作法該不該做而爭執不休，過去，微軟是由資深主管出面調解擺平，但這樣往往影響了團隊間的合作默契，現在則是靠數據來判斷。這兩個團隊後來開發了一支爬蟲程式，蒐集全球500大網站常用的JavaScript函式庫，發現有40％的網站能夠得益於這種優化方式，就不再爭論該不該這麼做而是直接就這麼做了。
善用使用者真實數據還有另一個好處。有時並非新功能不受使用者青睞，而是因為其他非軟體因素，導致使用者無法進入新功能的使用情境，連試用的機會都沒有。
「團隊要真正注重於用戶的需求和實際體驗。」潘正磊說。所以，每個月，她都會找一天，用一個下午的時間，親自從使用者情境的角度來試用新版功能。甚至，她也要求旗下VS開發人員，要用這一周編譯組建完成的Visual Studio IDE來開發下一周的新功能，等到6周後發布IDE時，至少微軟內部人員已經先試用了好幾個禮拜，這是微軟的Dogfooding作法（吃自家狗食）。
相較於過去瀑布式開發，就算取得使用者的真實使用數據，也得等到3年後的改版才能解決問題，潘正磊認為，開發團隊現在要能夠拿到數據，馬上回應，再馬上發布，這就是一個DevOps開發的迴圈，「現在是速度決勝！」。
儘管微軟VS團隊已經能夠做到3周發布一次VS Online新版本，6周發布一次VS IDE軟體新版本，但是，潘正磊仍不滿足，她說，我們只是從一本大百科全書，進展到快速發布，每次發布一本小書，距離能夠一次發布一個章節，甚至是只有更新1頁的顆粒度（Granularity），還有很長一段路。這也是微軟VS團隊下一步敏捷開發要實現的目標。
 

為了和其他敏捷團隊保持聯繫，團隊PM在每次Sprint啟動的第一天要寄出Sprint計畫郵件給其他團隊或直屬主管，結束時也要發信通知大家，並錄製一段成果示範影片來證明程式碼真的可用。圖片來源／微軟

 
 

微軟新舊開發模式大比較
（瀑布式開發vs.敏捷開發）


微軟現在所有Visual Studio開發團隊，不論是盒裝軟體版本或是VS Online雲端服務的研發團隊，都統一導入Scrum敏捷開發，採每3周完成一個Sprint（衝刺階段）作法，不再像過去的瀑布式開發流程時期，採取開發里程碑分階段的作法。



微軟舊有瀑布式開發流程
微軟過去採用瀑布式開發流程，VS產品開發時程約2年，先用3個月想像2年後的可能需求，再設定多個里程碑（如圖M1、M2）區分開發階段，每階段內先開發程式碼，再進行測試與功能穩定，達成里程碑後釋出一個顧客可用的版本。




微軟現有敏捷開發流程
現在微軟以每3周為1個Scrum敏捷開發的Sprint（衝刺）周期，每次Sprint結束後要釋出一個VS版本，試用1周後就發布給使用者。程式架構設計、開發與測試都由同一個人或同一組人負責。




瀑布式開發的Bug曲線大起大落
圖中虛線代表程式臭蟲（Bug）數量的變化，在微軟舊有的瀑布式開發時期，臭蟲數量在測試開始後大量出現，得等到臭蟲修復後功能穩定後，臭蟲數量變化大幅減少後，才能釋出一個版本給使用者。




敏捷開發的Bug曲線起伏不大
藍色虛線代表了微軟VS團隊改採3周一個Sprint後的程式臭蟲數量變化。若發現了新的程式缺陷，開發團隊可以很快修復，臭蟲曲線變化不大，代表程式碼品質更穩定。白色虛線是瀑布式開發的臭蟲曲線。


 
相關報導請參考：「她，讓.NET走向開源」
",https://www.ithome.com.tw/news/94998,"新聞,微軟,開源,.NET,潘正磊,Scrum,敏捷開發,DevOps"
94997,32,2015-04-09,【專訪】.NET開源關鍵決策者首度曝光,微軟全球開發平臺事業部資深副總裁潘正磊：微軟不會將所有程式都開源，而是會選擇性地開源。首選是Runtime，而工具則不一定需要開源,"  微軟全球開發平臺事業部資深副總裁潘正磊是微軟核心開發工具Visual Studio和.NET平臺開發團隊的領導人，1992年加入微軟，從一位工程師做起，歷練過多項微軟全球性技術和管理職務，3年前也兼任微軟亞太研發集團伺服器與開發平臺事業部總經理，同時管理美國與中國兩地的微軟研發團隊，就連C#之父Anders Hejlsberg都是她的部屬。
潘正磊一手主導微軟Visual Studio開發團隊導入敏捷開發，擁抱DevOps思維，甚至她還是決定.NET開源的關鍵人物。
Q：你何時得知.NET要開源?
 A  這是我的決定，而不是被告知。
Q：為何微軟需要這麼大的變革？
 A  原本大多是新創公司擁抱開源，但現在有越來越多大企業將開源視為戰略的一環。開源商業模式也越來越完善，可以透過提供服務的方式來建立獲利模式。軟體的程式碼只是軟體其中一小部分的價值，更大的價值要靠服務（意指雲端服務）來實現。
我們的市場競爭者Java也因開源而受到歡迎。比只靠內部.NET開發團隊的腳步，大量開源社群參與的創新速度可以更快，我們也有類似Java社群規模的.NET開發人員在微軟之外，只是我們沒有善加運用。
Q：你如何說服老闆，例如微軟新任執行長Satya Nadella?
 A  有次和我的老闆也就是微軟雲端和企業部門執行副總裁Scott Guthrie一對一面談時，我提出.NET開源的計畫，他也看到了上述類似的趨勢相當認同我的決定，甚至要求我提前3個月完成.NET開源釋出的工作。至於Satya Nadella，我根本不需要說服他，他完全支持。
Q：決定開源之後，先做哪些事？
 A  沒辦法在決定的第一天就開源，因為不是將所有的程式碼開源，傳統桌面程式碼還沒有開源，這是很大的剝離工程。另外，改用開源GitHub來管理程式碼之後，如何確保全世界任何開發人員都可以使用，不論是編譯、組建、測試等工作流程都要重新考慮，等於是整套微軟軟體開發工程的重建。所以，我們花了很多時間研究Java的作法，才發現JDK也不是完全開源，例如得和Oracle簽署使用授權後才能取得程式碼。
微軟第一個開源的程式是TypeScript，從中開始學習開源經驗，了解如何和社群共事，但還沒真正學到釋出後的商業模式。後續才將C#編譯器（Roslyn）開源釋出，然後再擴大到將.NET核心釋出。採取漸進式一步步開源的策略。
Q：在微軟推動開源，最大的挑戰為何？
 A  一開始最困難的是跟所有人解釋為何要這麼做。例如得說服法務部門，如何避免微軟的智慧財產，得向市場部門解釋，開源的必要性，什麼樣的成功情境，才是開源的成果等。
另外，微軟有一套嚴格的智慧財產權規範，這個規範結構不適合採取開源，因此也有很大的調整，讓產品部門未來很容易可以開源。第一次想要釋出TypeScript時的挑戰最大，等到了.NET開源時已經非常順利了。
另外在軟體架構上也需要調整，能將要開源的程式碼單獨抽離，若釋出的程式碼還需要其他未開源的相依元件才能組建，就等於無法開源。
Q：會擔心智慧財產權的問題嗎？
 A  早在2010年時，微軟就開始嘗試將開源軟體放入自家產品中，但會盡可能採取最安全的方式，斥資進行智慧財產權來避免發生問題，甚至還會考慮，萬一有問題，多快能把開源軟體從產品中移除。
但是，現在，沒有人會再擔心這類的問題。倘若是在對外的服務中使用開源軟體，部署在後臺環境中就不會有任何智慧財產權的風險。但若要放入盒裝軟體還是會有風險，因此，我們不會考慮任何Copyleft的授權，如GPL。
Q：開源後，對微軟工程師有什麼影響呢？
 A  3年前，微軟工程師若要看一眼開源程式碼，都得經過3道申請程序，得獲得我的同意，他們才能看。因為微軟經歷過很多侵權官司，為了避免工程師犯錯，因而設置了很多壁壘。
現在微軟工程師要「看」開源程式碼，不用獲得任何人的同意。只有要將開源程式碼放入產品時才需要批准。
當我們第一次將程式碼放上GitHub時，工程師們都非常緊張，還將程式碼中所有的註解都看過一遍，深怕寫過什麼罵人的話或隱私要趕快刪除，後來就習以為常了。
Q：開源對微軟開發流程上又有什麼影響？
 A  過去微軟設計產品只需和內部溝通，現在得和社群合作，這是一個全新的工作模式。開源社群貢獻的程式碼如何和套裝產品整合，也需要新的流程。擁抱開源最需要的不是調整組織，而是要改變工作方法。
Q：為什麼需要改變工作方法？
 A  因為這是一個全新的模式。倘若微軟仍然採取傳統的瀑布式開發流程，就不可能開源。瀑布式開發流程是一個全權控制的模式，可以自行決定程式碼開發完成的時間點，再來安排後續測試團隊的工作排程。
過去，微軟開發工作是計畫性的，但在開源之後，無法預估有多少人有興趣貢獻程式碼。開發社群貢獻的程式碼越多，就得投入愈多人力來審視提交出來的程式碼品質。
程式碼開源之後，不論是誰貢獻的哪一段程式碼，儘管是完成度很高的程式碼，幾次開源經驗來看，都需要進一步檢查如程式碼一致性或相依性等。
Q：在這種非計畫性的開源工作模式下，要如何確保產品的品質？
 A  開源釋出的程式碼任憑社群使用，但是，要成為微軟的產品，會有另一個我們認證過的發行版本，就像RedHat Linux也會發行不同的版本一樣。
或者像Google的Chromium和Chrome的作法一樣，作為產品發布者，我們有權決定哪些社群貢獻的程式碼能放入最終產品。
Q：程式碼開源後，對微軟帶來哪些好處？
 A  跨平臺是未來的大趨勢，能讓Runtime跨平臺，對所有開發人員都是福音，因為只要寫一套程式碼就能在多個平臺上使用。
若.NET沒有釋出，只有微軟自己能進行跨平臺支援，但微軟不可能支援所有的Linux平臺，開源釋出後，可以讓其他人針對不同平臺修改。
這也是一種變相的群眾外包，讓開發需求靠社群快速得到解決，而不用依賴廠商解決。
Q：微軟長期開源策略是什麼？會將所有產品都開源嗎？
 A  我覺得，微軟不需要將所有程式都開源，而應該是選擇性地開源。首選是Runtime開源，其他則是要看需求程度來釋出。例如.NET開源之後，在GitHub上受歡迎程度比C#編譯器高很多。
長遠策略是來自當下所知，目前，我認為，開源最重要的是Runtime開源，從開發過程來看，工程師能夠知道底層Runtime的程式碼怎麼撰寫，有助於調校程式碼，改善軟體效能。但是，對於工具軟體的程式碼，軟體工程師不一定有興趣。工程師傾向於使用一個好用的工具，而不一定會要求工具也要完全開源。
就像小孩成長過程，要先會爬之後才會走，能走之後才會跑。在開源之路，微軟才剛剛學會走路，但距離會跑能跳還有很長一段路。
 
相關報導請參考：「她，讓.NET走向開源」
",https://www.ithome.com.tw/news/94997,"新聞,微軟,開源,.NET,潘正磊,Scrum,敏捷開發,DevOps"
94996,32,2015-04-08,微軟開源戰略轉型關鍵大揭露,在跨入開源的旅途上，微軟目前才剛進入學步期，為了成為名符其實的網際網路未來企業，能夠永不間斷地提供服務，微軟要讓自己成為挑戰者," 去年11月12日，微軟雲端和企業部門執行副總裁Scott Guthrie在Connect()會議上正式宣布.NET核心將開源釋出，包括.NET Framework 4.6、.NET Core 5、還有Runtime跟編譯平臺等。這不是微軟第一次宣布產品開源計畫，但卻是最讓全球開發圈震撼的一次宣布。
早在1998年，一份後來被稱為「萬聖節文件」的微軟內部反Linux和反開源軟體秘密備忘錄曝光後，十多年來，微軟一直被視為是Linux和開源社群的頭號敵人。儘管，後來隨著Linux壯大，開源經濟模式逐漸成形後，微軟也開始向開源社群示好，例如2008年時，當時擔任.NET Framework部門總經理的Scott Guthrie宣布開放.NET架構程式庫，讓開發者可以瀏覽。但仍然不被開源社群認可，甚至被批評微軟只是一種「假」開源，因為程式碼只能看而不能修改，只是為了擴大影響力，假開放之名，而行拉攏用戶之實。
微軟前任執行長Steve Ballmer將Linux比喻為癌症更成了開源社群指責微軟的證據之一。
甚至在2012年，微軟就開源釋出了用來強化JavaScript開發大型應用程式的工具語言TypeScript，後來更被Google用於打造自家維護的下一代JavaScript應用程式框架AngularJS。去年4月更開源釋出了微軟新一代Visual Studio的C＃和VB核心編譯器（代號Roslyn）、ASP.NET框架、Web API等。
這些開源動作，儘管引起高度關注，但還是難以說服開源社群，微軟是否真的願意認真擁抱開源。
直到去年11月這次.NET開源宣布，以及微軟開始將.NET程式碼放上全球最大開源程式碼代管網站GitHub時，開源社群才意識到，這次微軟是玩真的。
Linux基金會執行總監Jim Zemlin更公開讚揚，微軟此舉將能讓.NET應用程式，延伸到Linux和Mac OS平臺上。他認為，微軟正在改變自己，重新定義自己來擁抱開源趨勢，這是開源軟體從根本改變軟體產業的證據之一。
微軟成立了.NET基金會推動.NET開源工作，維護在GitHub上釋出的.NET程式碼。截至2015年3月底，微軟在GitHub上最火紅的專案是CoreFX，這是.NET核心的基礎函式庫。
不到幾個月就吸引了超過7千多名開發者按星號關注，更衍生了1,419個分支版本。從2014年11月2日成立專案後，每天都有超過20次程式碼交付，最多甚至一天超過60次，其中也包括了微軟自己上傳的程式碼。
領導微軟總部VS研發團隊的微軟全球開發平臺事業部資深副總裁潘正磊，正是微軟.NET開源幕後的關鍵推手和主要執行者，她率先決定要讓.NET走向開源，並獲得Scott Guthrie的支持。
這位微軟公司最高華人女性主管，一手掌握了6百萬.NET開發者和7百萬Visual Studio使用者所使用的開發工具，任何新功能或未來發展的決策大權，她更是直接和微軟新任執行長Satya Nadella近身共事的微軟高層。
潘正磊觀察，Satya Nadella和擅長銷售、注重業績數字的Steve Ballmer最大不同之處，在於Nadella聚焦於企業文化的轉型。
例如，Satya Nadella上任第一天就發了一封信給微軟員工，信上寫著「我們這一行是不承認傳統，只承認創新。」話中所謂的傳統，潘正磊解釋，代表微軟傳統的企業文化。Satya Nadella想要告訴微軟員工，可以放下舊有的企業文化。因為「微軟現在願意不保守、不頑固、不需要每一項嘗試都考慮對既有商業模式的影響，來嘗試創新作法。」潘正磊說。
在Satya Nadella上任後，微軟願景從過去的「每一個人桌上都有一臺電腦」轉變成「要幫助每一個人或機構實現更多可能」。
潘正磊表示，因為未來每一個公司都將是軟體公司，有開發能力才可以實踐業務，而且每一個企業都將變成互聯網企業，微軟想要實現新願景，不論是軟體產品或是雲端服務，都要能支持未來互聯網企業需要的能力，也就是要有能力永不間斷地提供服務。
不過，矽谷有句老生常談說「沒有好的企業文化，再好的戰略目標也無法實現。」Satya Nadella帶來了微軟企業文化最明顯的改變之一，是微軟放下老大哥心態，轉而採取挑戰者心態。潘正磊表示，過去微軟有種業界大老的心態，很少和大型企業合作，也敵友分明，主要產品戰略是壁壘策略，會設置種種措施來圈住用戶，防止用戶流失。
從老大哥心態轉變成挑戰者思維
但是，微軟現在更像是市占率較小的市場挑戰者，不是優先鞏固顧客，而是要積極爭取各種合作機會，贏得更多新的使用者。例如推出iOS版Office或是與Salesforce、Google等競爭對手有戰略級的合作宣布，或是Azure對Linux作業系統如Ubuntu的支援等都反映了微軟想要以對等的姿態和合作夥伴對話。而「開源，正是希望得到更多開發人員的認可。」
另一個企業文化的改變是持續學習的心態，尤其微軟近年更積極向新創學習。Satya Nadella早在擔任雲端和伺服器部門主管時，就曾積極拜訪矽谷新創公司，學習新創公司的商業模式，了解新創遇到的問題，他常問這些新創公司碰到什麼挑戰？採用什麼技術？為何要用？甚至有時會在每周微軟全球高階主管例行會議中，找來新創公司分享經驗，要讓微軟所有VP級高層也開始學習新創公司的文化。
效法新創也要藉助開源加速創新
開源正是許多新創公司在資源有限的情況下，借力使力，藉助開源力量擴大影響力的常見戰略，微軟在開發市場上的競爭者Java也因開源策略而大受歡迎，這也正是微軟現在想要效法開源的原因之一。
再加上越來越多大企業將開源視為戰略的一環。開源商業模式也越來越完善，可以透過提供服務的方式來建立獲利模式。「軟體的程式碼只是軟體其中一小部分的價值，更大的價值要靠服務來實現。」潘正磊說。
潘正磊表示：「比起只靠內部.NET開發團隊的腳步，大量開源社群參與的創新速度可以更快，微軟也有類似Java社群規模的.NET開發人員在微軟之外，只是微軟沒有善加運用。」
.NET核心的開源只是微軟開源的其中一步，儘管長期開源策略還不明朗，潘正磊表示，微軟還沒有將所有產品全面開源的打算，但Runtime類程式碼是微軟優先開源的對象，未來會依需求再釋出更多。「就像小孩成長過程，會爬之後才會走，能走之後才會跑。在開源之路，微軟才剛剛學會走路，但距離會跑能跳還有很長一段路。」
 
 

微軟新任執行長Satya Nadella去年10月公開宣布微軟愛Linux，反映出微軟積極拉攏Linux陣營的企圖。圖片來源／微軟

 

微軟在開源程式碼代管平臺GitHub上最火紅的專案是CoreFX，這是.NET核心的基礎函式庫，不到幾個月就吸引了超過7千多名開發者按星號關注，更衍生了1,419個分支版本。

 
相關報導請參考：「她，讓.NET走向開源」
",https://www.ithome.com.tw/news/94996,"新聞,微軟,開源,.NET,潘正磊,Scrum,敏捷開發,DevOps"
94965,33,2015-04-03,財政部資訊中心揭露財政雲架構藍圖,財政部財政資訊中心主任蘇俊榮表示，財政雲已整合5個國稅局以及22個地方稅務局機房，並逐步整併關務署、國產署、國庫署和賦稅署等機關機房。," 財政部財政資訊中心主任蘇俊榮揭露，臺灣正在打造的新一代財政雲架構藍圖。整體架構分為應用系統以及基礎建設，應用系統是指各機關通用系統，而基礎建設則是標準開發環境以及機房，這些都包含在財政雲建置範疇中。
而應用系統切分成財政內網雲和外網雲，內網雲以內部行政業務服務為主，分為大資料分析、行政辦公室以及各機關業務需求之資訊系統，大資料分析用於選案查核以及網路輿情分析，而行動辦公室則用於外查業務、到府申辦服務以及滿足高階主管諮詢需求，另外，財政雲支援各機關的事務還有國有財產管理、菸酒品智慧預警、國產決策支援與稅收評估分析。內網雲共用的系統除了大資料分析及行動辦公室外，還有影像管理、知識管理、資料匯流和OA（含公文）。
財政外網雲則主要提供服務給財政部以外的對象，財政業務的服務包含我的e財政和財政資訊統計，而支援各機關業務有菸酒品智慧預警、賣酒預警機制以及雲端國稅服務。共用系統包含收費系統、入口網、網路交易與於情蒐集系統與資料開放系統。
蘇俊榮表示，財政雲整合了許多財政部機關的機房，因此資訊安全的控管也變得複雜，現在除了整合5個國稅局以及22個地方稅務局機房外，現在也逐步將關務署、國產署、國庫署和賦稅署等機關機房整合。
財政雲與機關間的資料傳輸，分為一般網際網路或是專用的VPN，財政機關存取外網雲可經過一般網際網路，但如果要存取內網雲，則需要經過專用VPN，而存取權限透過資源管理與監控、帳號與程式管理、資料轉換與介接以及資通安全防護四大管理機制控管。財政雲的內外網為實體隔離，而無論內網或是外網，應用程式與資源區間皆有防火牆，尤其是內網的資源管理區，存放的多為機敏資料，諸如稅務資料以及OLTP等。
蘇俊榮認為，資訊安全要從制度面、技術面以及系統面3大構面著手。制度面他分享國稅局整合的經驗，5大國稅局與財政資訊中心間的合作必須注意小細節，蘇俊榮說，每個機關重視資安的程度不一，行事風格也不同，但是合作上要取最大公約數，在異中求同，但又要同中求異，作法因地制宜，而持續優化則是他們共同努力的方向。
財政資訊中心的資安技術面策略則是講求縱深防禦，由上往下法從系統面的資安治理與服務管理，到實際資安防護系統建置的各面向強化，實際作為便是制定法令法規和SOP、監控與稽核、防毒軟體和防火牆等建置，做到資安4大行動，監控、檢測、演練與諮詢面面俱到。
蘇俊榮說，財政系統每天產生1,700萬筆的Log，容量約40G，這樣的資訊量無法用人工查核，因此必須倚靠條件式勾稽達到自動示警，像是內部人員查詢自己3等親內的資料，系統就會發出警告。他還說，財政資訊中心的辦公室內的座位間都使用透明玻璃隔板，不只可以容易看到每個行政人員電腦的行為，而且「室內燈光明亮比較不會做壞事啦」。
目前財政部財政資訊中心也將設置財政巨量資料研究中心，不只與5個財政相關實驗室合作，更納入300位資料科學家，打造國家級研究中心。
",https://www.ithome.com.tw/news/94965,"新聞,財政雲,財政資訊中心,蘇俊榮,大資料,Cloud"
94708,33,2015-03-25,當代企業IT新顯學：混合雲應用,隨著OpenStack等許多平臺技術的標準化與開放，企業想要橫跨公／私有雲兩者之間的鴻溝，不再遙不可及," 簡而言之，將公有雲和私有雲湊在一起，就是混合雲，但實務上，企業如何界定混合雲的用法呢？
根據IDC在2014年舉辦的混合雲調查顯示，有38％的人認為，公有雲服務與專屬IT資產的混合應用；有23％的人表示，將兩種以上的雲基礎架構組合在一起，就算數；認為混合雲就是資料中心能支援多種Hypervisor，或是訂閱多種雲服務，都各有11％的人支持。
不過，關於混合雲的應用，其實還可以更進階，很可惜的是，只有8%的人認知到企業可將應用系統的工作負載，順利移植到私有雲或公有雲環境，並且自動執行負載平衡與擴展規模。5％的人認為有了混合雲之後，用同一個服務等級協定來管理所有的IT服務。
所謂的混合，其實沒有特定的定義，甚至有些部分看似有別，其實是彼此共存的。在雲相關的產品和服務實作概念上，甚至還有人提出了InterCloud和MultiCloud這兩個詞彙，但根據維基百科的說法，它們和混合雲還是有區隔。
InterCloud是將不同的公有雲服務相互連接起來，形成所謂的雲中之雲，算是延伸了網際網路所用的網中之網概念，重點在於網路，目的是使不同的公有雲服務環境之間，能夠相互跨越、存取。而MultiCloud則是將多種雲服務整合為單一架構，目的是不希望太依賴、甚至被綑綁在單一雲服務供應商，以獲得更大的選擇彈性。
不論是混合、組合或整合，企業要採用之前，應該先設法了解各種雲服務的特性，以及優劣勢，才能制定最佳決策，充分運用其架構。
競爭激烈的公有雲服務環境
在企業端經常會被應用的公有雲服務，以基礎架構即服務（IaaS）的模式居多，知名度較高的供應商有Amazon Web Services（AWS）、微軟Azure，他們在很早期就投入，而且所提供的服務項目非常豐富。此外，SoftLayer也發展得很快，2013年被IBM買下，之後持續設立資料中心，到2014年底已成立40座，並積極發展專用外部雲（Managed Private Cloud）、共享外部雲（Hosted Private Cloud）。
AWS占有率大
AWS是企業公有雲服務知名度最高、提供的服務項目最多，而且許多IT軟硬體供應商都爭相將自家產品上架的平臺（虛擬設備形式），一般人或企業可隨時隨地租用他們所提供的雲服務，包括運算、儲存、CDN、資料庫、網路、管理、分析、應用程式等性質的應用，同時，還可以在他們開設的雲市集裡面，租用上架的第三方應用軟體服務，可選擇的品項有兩千個之多。
AWS的案例相當多，單是臺灣，就有D-Link、HTC、臺灣大學快速密碼學實驗室、痞客邦（Pixnet）、趨勢科技、聯合報udn新聞台、合勤科技等公司或單位採用。
微軟Azure應用日益多元
另一家雲服務業者微軟Azure，也在企業端應用有所斬獲，他們提供的雲服務，包括IaaS和PaaS，一樣有運算、儲存、CDN、資料庫、網路、管理、程式開發等應用，而且直接提供混合式整合服務，用戶可承租BizTalk Services、Service Bus、Backup、Site Recovery這四種混合雲服務。
微軟Azure旗下的雲服務，也明列出企業使用案例，像是Websites and Apps（微軟Office Blogs、SGS）、SQL Database（3M、摩達網MagV）、HDInsight（卡內基美隆大學、巴塞隆納市）、Media Services（NBC 2014冬季奧運線上轉播、XBOX、艾迴唱片），以及Site Recovery（聯合航空）。
至於臺灣使用Azure服務的企業或組織用戶，目前有三立電視、金石堂網路書店、元大寶來證券、法務部（全國法規資料庫競賽活動）、屏東縣政府、華人健康網等。
此外，在今年2月，微軟也宣布了兩家臺灣企業將關鍵應用搬上Azure的例子。當中提到，緯創資通將SAP ERP系統移轉至Azure平臺，同時，緯創資通也運用這樣的經驗，協助另一家公司吉嘉電子去完成同樣的作業。
SoftLayer後勢看漲
SoftLayer提供的服務偏重在IaaS，包括伺服器（運算）、儲存、網路、管理等應用，其中伺服器不只是提供虛擬化環境來承載，還有一項服務是其他雲端服務所沒有的選擇）──裸機（Bare Metal）租用。
若租用這項服務，我們即可在不與其他租戶共用工作負載的獨立伺服器環境下，執行一些特別需要高速計算與I/O存取的應用，單臺最大可配備40顆處理器核心、512GB記憶體、96TB本機硬碟與20TB的對外網路流量。
目前，若想要租用SoftLayer提供的裸機伺服器服務，裡面所用的運算架構是x86處理器，由於IBM本身是OpenPower的推動者，SoftLayer也預計在這項伺服器租用服務下，提供OpenPower選項。
除此之外，SoftLayer還特別提供了資訊安全防護的雲服務，與伺服器、儲存等主要租用項目並列，用戶可訂閱相關的軟體、防火牆、SSL憑證、法規遵循等服務，相當特殊。
而且，由於SoftLayer可提供裸機租用，他們在2014年也結合這樣的特性，提供相當獨特的Intel TXT（Trusted Execution Technology）安全服務，可運用處理器硬體晶片內建的TPM模組，驗證應用程式身分與安全性，相較之下，坊間各家公有雲服務環境，因為普遍架構在伺服器虛擬化平臺上，所以，無法提供這樣的硬體驗證功能。
就使用案例而言，目前有Dropbox、WhatsApp，以及線上評價網站Yelp採用，SAP也將HANA Enterprise Cloud放到SoftLayer。臺灣也有一些業者運用SoftLayer，推出雲服務，例如寶盛數位、盟立資訊、赫迅互動科技、台灣旅圖、愛樂活社會企業。
今年，臺灣也會有企業開始使用──汽車零件製造商信昌機械將近期新導入的ERP系統，放到SoftLayer上使用，若未來要前進東南亞或世界各地市場，去拓點擴張，可以藉由公有雲的全球架構，快速布建環境。
在SoftLayer的環境下，IBM也基於Cloud Foundry的開放標準，建立了新的平臺即服務（PaaS），企業可以利用這個環境來開發行動應用和網站應用程式，開發人員能運用的語言，包括Ruby、PHP和Java等。
臺灣公有雲服務業者具有本地優勢
臺灣本地能夠提供較大型公有雲服務的公司，主要是電信業者，像是中華電信hiCloud、臺灣大哥大、遠傳，其中以中華電信提供的服務類型較為廣泛，可提供IaaS、PaaS和市集；而臺灣大哥大目前有IaaS，以及SaaS（影音串流服務）；遠傳則有IaaS和SaaS，但他們提供的SaaS項目較多，包括影音、視訊會議、車隊管理、資安保全等，特別之處在於，還可在此租用由其他雲端業者提供的SaaS服務──Google Apps for Work。
除了電信公司，其實臺灣也有一些業者，同時代理或經銷國外的雲端服務。特別的是，這些代理或經銷商提供的雲服務，不一定只有一家，用戶可從多個廠牌當中選擇。以匯智資訊為例，他們目前使用了SoftLayer、微軟Azure、AWS、Google等廠商的雲服務。
該公司數據管理處副總經理王耀章表示，雲端服務的興起顛覆了許多傳統概念，像是上下游或大房東、二房東的概念；他認為這是一個互聯、物聯、商聯的網路時代，不同的服務供應商依據各自的優勢，建立合作網絡，像蜘蛛網一樣相互串聯，而匯智資訊就像是節點的角色，在不同平臺、服務供應商及用戶間，擔任了系統管理專家與顧問的角色，溝通彼此的需求。
匯智資訊主要扮演的角色，是雲平臺與企業之間的介面、橋樑。王耀章說，雲端世代是各司其職的年代，網站代管廠商的最大責任是善盡平臺供應商的角色，然而平臺至實際應用之間，仍存在極大差距；當國際廠進駐臺灣，平臺選擇日益增多，並加速了互動發展與改度，而各平臺的優勢亦不相同，如何協助用戶選擇最合適的應用，是目前的定位所在。
過去，匯智跟SoftLayer等廠商之間，是處於同等性質業務競爭關係，近來則轉為合作關係，這相當耐人尋味。王耀章表示，匯智先前的作法，傾向於投資及建立自己的網路設備、伺服器等，但近年來已大幅減少這方面投資，轉而透過這些大廠所提供的雲端平臺，提供合適的服務給用戶。
藉由這些國際知名大廠的雲端平臺，對匯智來說，反而更能突顯優勢，王耀章打了一個比喻：假如自己是司機，能開法拉利戴客，為何要回頭去開發財車呢？
以伺服器虛擬化平臺為主的私有雲環境
相較於熱鬧滾滾的公有雲服務，企業在發展私有雲環境的方向上，似乎至今還未明朗。一方面是因為企業對伺服器虛擬化技術應用，雖然算是駕輕就熟，普及度也不低，然而在實際運用時，並未將雲的特性發揮到淋漓盡致的地步。
以絕大部分企業採用的VMware虛擬化技術為例，用戶若希望擁有一個自助式服務的操作介面，讓內部使用者在線上申請、取得IT基礎架構服務，除了vSphere虛擬化平臺之外，可能還需要添購vRealize Orchestrator（之前稱為vCenter Orchestrator），或包含此項產品的vRealizeSuite套餐；如果你要的是入口網站介面，可能要買vRealize Automation（之前稱為vCloud Automation Center），或包含此項產品的vCloud Suite套餐。
同樣要提供自助式服務的介面，如果你用的是微軟Hyper-V虛擬化技術，可能需搭配System Center系列的Virtual Machine Manager，以及App Controller等產品，或是更進階的Windows Azure Pack套件。
而且，這些商用版伺服器虛擬化平臺的授權費用，幾乎都是根據所用到硬體處理器顆數來計價，因此企業在應用虛擬機器數量上，除了注意伺服器主機的硬體性能可否負荷之外，還要考量虛擬化軟體授權成本的變化（將隨著硬體伺服器數量增加而擴大），因此若要在這樣的環境，實現硬體的橫向擴展（Scale out）時，當使用規模大到一定程度後，費用會相當可觀。
也因為這樣的態勢，近年來以開源技術為主體的OpenStack套件迅速發展，席捲了整個資料中心應用，許多IT廠商紛紛積極提供相關支援，而對於希望架設雲環境的雲服務供應商和企業，也能利用這個開放架構，去建置更低成本的雲環境。
以這些虛擬化平臺來看，目前幾家主要廠商，已各自發展了混合雲的應用。例如，微軟的Hyper-V搭配System Center，或透過整合而成的Windows Azure Pack，可以組合該公司的Azure雲服務，形成混合雲應用（SQL Server 2012和2014也可以和Azure搭配）。
另一家廠商VMware的vSphere虛擬化平臺、vCloud Suite雲建置套件，則可以搭配該公司這幾年推出的IaaS服務vCloud Air，成為混合雲應用。
OpenStack與衍生的混合雲應用
OpenStack氣勢如虹，而且適用的軟硬體環境很廣泛。例如，構成整個平臺基礎之一的Nova運算套件，可安裝在實體伺服器、虛擬化環境使用，而支援的Hypervisor種類繁多，包括開源的Xen、XenServer、KVM、QEMU，以及商用環境常見的VMware ESXi、微軟Hyper-V與IBM主推的PowerKVM，並且支援新興的Container，像是LXC、Docker。
而且，OpenStack除了自身推出的版本之外，也有許多軟硬體系統廠商以此為基礎，發行分支版本，像是Ubuntu、Debian、Red Hat、SUSE、HP、IBM、VMware等等。
在臺灣，近年來，這幾家公司也是較積極推廣OpenStack使用的廠商，而本土廠商則有迎廣科技和數位無限軟體。
特別的是，這些廠商當中，除了鼓吹大家使用OpenStack、繼續鞏固自身平臺的適用性與影響力，很多公司同時想做另一門生意──提供針對公有雲、私有雲及混合雲環境的建置與諮詢服務，甚至是客製方案。
以Red Hat來說，他們最近基於OpenStack去年10月推出的Juno版，而發表了新的OpenStack版本──Red Hat Enterprise Linux OpenStack Platform 6。該公司旗下還有另外一套CloudForms，可針對混合雲應用，以去年9月推出的3.1版而言，支援多種雲環境，包括公有雲AWS、私有雲環境最夯的OpenStack，以及伺服器虛擬化環境的VMware vSphere、微軟Hyper-V的管理平臺System Center Virtual Machine Manager，以及Red Hat Enterprise Virtualization。
另一個值得注意的OpenStack分支版本，是IBM公司的Cloud Manager with OpenStack（ICM），在去年底他們推了同樣基於Juno的ICM 4.2版，其中，針對Power運算架構下的PowerKVM虛擬化平臺，以及PowerVC虛擬化管理軟體，強化相關支援。
而針對混合雲環境的運用與管理需求，IBM有另一套方案Cloud Orchestrator（ICO）對應，最大的特色是支援Power和System Z架構的伺服器虛擬化環境。
公有雲的部份，ICO可支援AWS、SoftLayer，以及用OpenStack建構的環境；而私有雲方面，ICO支援x86、Power、System Z這三種運算架構，其中，x86的環境包含VMware vCenter和KVM的虛擬化軟體，Power的部份是支援KVM、PowerVM和PoweVC，而System Z的支援主要是zVM。
而在臺灣推廣OpenStack應用的幾家本土廠商當中，也已經有公司開發了延伸應用的套裝軟體，並且能夠橫跨到混合雲環境的應用，例如數位無限軟體這家公司很特別，他們即將於今年上半推出的CloudFusion 2.0，就是這樣的產品，當中將針對異質的雲環境，提供單一化的管理、部署、應用機制。
CloudFusion可支援的私有雲環境，將包括VMware、微軟、Citrix、Red Hat、Xen、KVM虛擬化平臺，以及OpenStack；而公有雲的部份，這套系統支援AWS、SoftLayer、微軟Azure、RackSpace、Google Compute Engine、阿里雲。整體而言，相當引人注目。
 

企業環境最受歡迎的公有雲服務排行榜
不論大型企業或中小企業，AWS都是目前最多公司採用的公有雲服務。其次是微軟Azure，都在前五名內；再接下來是Rackspace。資料來源：RighScale，2015年、圖片來源／RighScale

 

企業環境最受歡迎的私有雲平臺排行榜
儘管授權費用不低，VMware vSphere仍然是私有雲環境當中最多公司使用的平臺。OpenStack表現相當突出，在中小企業環境的採用率僅輸給VMware vSphere，大型企業環境若要接受OpenStack，還需多努力一些。資料來源：RighScale，2015年、圖片來源／RighScale

 

OpenStack的演進歷程
從2010年發起專案，至今短短幾年，OpenStack發展迅速，已成為建構公有雲與私有雲環境不可或缺的重要平臺。圖片來源／Cloudscaling

 

從工作負載的需求考量導入雲的必要性
進入伺服器虛擬化應用日益普及的時候之後，企業對於應用系統的整體或個別工作負載（Workload）如何做到最佳配置，越來越重視，而這方面的需求能否滿足，也影響了他們對於雲服務採用的決策。圖片來源／IBM

 

2015年IBM的雲平臺架構配置
在雲服務平臺基礎架構的提供上，IBM分為建置、管理、安全性等三個層次。就底層硬體資源的配置上，可涵蓋Power與System Z的運算架構，以及SoftLayer；資源的管理方式上，提供Cloud Manager with OpenStack和Cloud Orchrestator，分別達到軟體定義式IT環境和模式化的快速部署。

 

國產軟體CloudFusion混合雲應用架構
CloudFusion是由數位無限軟體所研發出的套裝軟體，可支援多種公有雲服務與私有雲環境，並且提供單一操作管理介面與一致的API。圖片來源／數位無限軟體

 
相關報導請參考：「混合雲進軍企業IT應用」
",https://www.ithome.com.tw/tech/94708,"雲端應用,雲端服務,Cloud,混合雲,OpenStack"
94707,33,2015-03-24,活用混合雲策略，重新定義IT服務,IT投資有限，需求卻無止盡，混合運用私有雲與公有雲架構，兼顧效能、安全性與成本，將是當前IT發展重點," 天上的雲，一般人看得見，卻摸不著，型態也是瞬息萬變，因此，這幾年來，許多人都用「雲」來稱呼從那些網際網路迅速竄紅的新服務，例如，Gmail電子郵件及Salesforce.com的CRM應用，都是非常典型的軟體即服務（SaaS）的形式，對社會大眾而言，它們幾乎就是雲端運算和雲端服務的代名詞。
除了SaaS，雲端服務還有其他部署形式。例如平臺即服務（PaaS），有Google App Engine、force.com、AWS Elastic Beanstalk、微軟Azure Websites，以及後起之秀IBM Bluemix，則是代表；至於提供基礎架構服務（IaaS）的廠商就更多，如過江之鯽，例如AWS、Rackspace、微軟Azure、Google Compute Engine、IBM SoftLayer，也有全球各地的電信商，像是美國AT&T和Verizon，臺灣三大電信商──中華電信、台哥大、遠傳，也都提供IaaS。
這段期間，企業端環境為了提升IT軟硬體資源的使用效率，取得更多靈活調度IT服務的能力，也開始熱中採用伺服器虛擬化技術，許多公司紛紛導入了VMware的ESX與後繼的vSphere、Xen與XenServer、微軟Hyper-V等產品，將原本需要安裝在個別伺服器上的不同應用系統，透過虛擬化技術的運用，整併到少量伺服器上執行，至於有些需要大量儲存或網路I/O效能的關鍵應用系統，則繼續維持在實體伺服器執行。有些企業甚至還會額外搭配系統管理軟體，將多臺實體伺服器及虛擬化環境統合，一起集中控管。
如今，憑藉伺服器虛擬化平臺，已經能夠承擔許多大型系統的執行需求，先前無法虛擬化的關鍵應用，也能整併，因此，就算要做到資料中心100％虛擬化，其實也非難事，同時，廠商也以虛擬化技術為基礎，進一步發展出可分給更多用戶租賃的雲端服務，提供給大型電信服務商與主機代管業者使用。
私有雲與公有雲的抉擇
經歷了這樣的發展，藉由伺服器虛擬化的技術，有些企業逐漸取得了類似Google、AWS、微軟Azure雲端業者規模與能力的IT服務，再加上這些公司當中，有許多普遍希望自行建置並掌控IT環境，擔心資料外洩或效能受到影響，而不願與他人共用，僅服務內部員工或合作廠商，也因此，這類型雲端服務在部署模式上，會被歸類在所謂的私有雲（Private Cloud）。
相對地，直接面向一般使用者或各種組織、企業的服務商，像是Google、Salesforce.com、AWS、微軟Azure、SoftLayer，他們所提供的服務，就稱為公有雲（Public Cloud）。
私有雲和公有雲的差異，主要是基於擁有權的不同，但兩者的環境建置上，可採用相同或不同的技術。例如許多業者皆運用伺服器虛擬化技術，將伺服器、儲存設備與網路設備，建構成共用資源池（Resource Pool），不過由於部署規模較大，為了節省軟體授權支出，有許多公司會選擇開放原始碼、成本較低的Xen、KVM的Hypervisor，並且基於這樣的架構，來搭建整個服務的IT基礎架構。
不過，要支撐雲端服務的運作，不能單靠虛擬化技術，像是Google、AWS和微軟都建構了專屬平臺；VMware從2012年起，則開始提供了vCloud系列的商用套裝軟體，讓有意建置雲服務的企業，以熟悉的vSphere平臺為基礎來搭建平臺；至於開放原始碼軟體領域，也在2010年有了大動作──由Cloud.com發起了CloudStack專案，Rackspace和NASA則發起了OpenStack專案，2012年之後，這兩個平臺都受到舉世關注，其中，又以OpenStack後勢最被看好。
為什麼這麼說呢？OpenStack新版本推出頻率很高，平均每年發行兩次，至今已經出了11個版本。而且，有許多廠商力拱OpenStack，其中，單是跟著一起發行OpenStack分支版本的，就有Ubuntu、Debian、Red Hat、SUSE等Linux作業系統廠商，以及HP、IBM這兩家大型軟硬體系統商，今年連伺服器虛擬化廠商VMware，也宣布正式推出OpenStack版本，其他加入與積極支持OpenStack專案的業者，還有像是處理器廠商Intel、AMD，儲存廠商EMC、NetApp，網路設備廠商Cisco、Juniper、Arista，系統廠商Dell、Oracle、NEC，網站業者Yahoo!，以及電信業與主機代管服務業者AT&T、Go Daddy。
因此，目前企業若要提供或應用雲的服務，而需要IT基礎架構環境來支撐時，總共有三種選擇：導入伺服器虛擬化平臺（VMware、微軟、Xen、KVM）、自行建置OpenStack或CloudStack、向公有雲廠商承租IaaS服務。其中，前兩者是私有雲的模式，後者則是公有雲模式。
在雲端服務剛興起的幾年內，若要建置這樣的環境，多數人的考量點，往往集中在該選私有雲或公有雲，很難有周延的選擇。
對一般個人、消費大眾而言，私有雲自然是使用者無力去建置的，所選的服務型態通常都是基於公有雲。而對企業來說，私有雲是接受度較高的，因為所面對的IT環境是較為安全可信，並且能夠自己控管的，但如果要在內部大規模導入，常常囿於軟硬體的建置成本太高，而只能停留在伺服器虛擬化應用的層次，無法進一步實現到雲服務平臺。
不過，公有雲環境當中有一些特性，對企業仍有很大的吸引力，並非一無可取。例如，雖然企業無法徹底信任公有雲的安全性與可靠度，但租用公有雲服務時，企業不需負擔很高的初期建置成本，系統操作的方式也強調簡單、好上手，並且具有更大的彈性和靈活度，足以因應短期但大規模處理的需求。
因此，有些企業或新設立的小公司還是會用公有雲。為了要更快、更頻繁地推出創新IT服務，同時也不希望在使用規模還無法確定的情況下，盲目投資而導致非必要成本增加，於是，他們在公有雲環境上，開發、測試新的網站或行動App應用，並且將系統後臺部署上去，而不是等到私有雲環境建置完成之後，再開始著手發展新服務。
兩全其美的雲架構：混合雲
私有雲和公有雲各有其優缺點，看起來，兩者是相互對立，但實際上，雲與雲之間可以交互運用，也就是所謂的混合雲（Hybrid Cloud）模式。
根據美國國家標準與技術研究院（NIST）的定義，在混合雲環境當中，我們可以結合兩種以上的雲架構，然後將它們融合，以便運用；而且需讓相關的資料與應用程式，能夠順利移植到其他雲環境執行，但要達到這樣要求的條件，並不限定是透過標準或專屬技術。
在市場調查研究機構IDC，也有類似的定義，他們認為，混合雲是指多種雲服務的整併與管理，範圍包括：在自家環境擁有的私有雲、專屬的遠端代管私有雲，以及一般的公有雲。混合雲也是真實存在的，許多用戶將本身擁有的雲環境、向主機代管業者租用的雲環境，以及公有雲環境混合使用，而且有很高的比例，會希望擁有將已經放在雲環境移回自家環境的能力，這也挑戰了公有雲服務供應商業者，以及一開始就在公有雲環境當中提供服務的廠商。
混合雲統一了IT環境，同時擁抱公有／遠端的雲，以及私有／內部的雲，虛擬機器、應用程式與工作負載可以橫跨性質迥異的IT環境運作──不論是企業資料中心所在的私有雲、位於服務供應商機房的私有雲，或是公有雲環境。但混合雲不只是將公有雲和私有雲結合在一起，需要整合運算、儲存、安全、網路、應用程式與管理機制，集中到一個通用、具有強大調配能力的IT維運平臺上，並可橫跨近端與遠端環境執行，讓企業IT人員與應用開發人員能在企業資料中心環境的既有工具、系統與控管政策下，同時，充分利用公有雲的部署速度與靈活調度資源的特性。
如果能做到這樣，對傳統的應用系統也會相當有利。因為企業既有的系統都是在主從式的IT架構所發展起來的，若是透過伺服器虛擬化的方式，不只是能在企業資料中心的虛擬機器裡面執行，同樣地，也可以在提供相同虛擬化平臺的公有雲上執行，換言之，混合雲能讓原本在外部的IT資源，引入內部使用，相對地，也讓內部的系統能超越既有的執行範圍，橫跨到外部環境繼續運作。
這幾年以來，混合雲面貌越來越真實，供應公有雲服務的廠商日漸增多，服務也越來越成熟，因此，企業會去更評估自身建置相關環境的需要，所考量的不外乎：資料安全性、資源可靠性。
雲服務的應用，走向混合的模式，其實是相當合情合理的，紅帽軟體台灣分公司資深解決方案架構師游政杰，他提出一個比喻，相當貼切。
就像一般人在家裡面有廚房，也會煮東西來吃，但還是會基於一些原因而外食、上上館子。在IT結構上，同樣如此，我們通常會認為由自己來建立IT環境，可控性、安全性會比較好，而且成本一定可以壓到最低，因為資源可以重複使用；但我們也會面對一些臨時才突然出現的IT系統需求，或是需要跨到其他國家去布建新據點──並非從當地臺灣之間的網路速度都能夠很快，此時，就可以用公有雲服務來幫助企業，並且在成本可控的條件下，快速部署，以便拓展當地業務。
游政杰認為，如果企業的規模很小，可能會選擇純粹在雲端運算裡面，或是蓋一個很小的資料中心，找一兩個MIS維護就好，但是，如果等到企業夠大、IT結構需求更多時，混合雲一定會變成必然趨勢。他說，自己本身的資源有限，而公有雲比較廣大，因為有很多服務供應商，所以他們的資源池一定比我的大，要跟外界接軌，才能接觸到更廣大的資源來做業務。
話雖如此，混合雲有其必要性，但面對雲端運算的應用，許多企業仍很困惑，不知道是否該進一步建置私有雲，因為基於現行的商用伺服器虛擬化環境去實現，若需要應用規模太大，很有可能只是把原本是硬體的支出，變成軟體的支出，不一定能享受到低成本的好處；但企業又普遍對於現行的公有雲環境，無法信任，因為它畢竟屬於新興應用，經過多數企業親自驗證的程度仍相當有限，大家都不想當白老鼠，所以卻步不前。
這些都是技術上與心理上需要突破的障礙，但如果把視角提升到從更高的資源管理層次，也許就會有不同答案。去年發生的江蕙突然宣布即將退出歌壇，而導致之後演唱會訂票系統無法負荷的事件，就是一個例子。
當我們突然接到類似這樣來得又急又大的工作負載需求時，可能臨時需要加開成千成百的虛擬機器來分攤時，可能就不會想要透過建置私有雲的方式來達成，因為會不敷時間和成本。有些人會考量用一些方法，將一部分工作負載轉移到公有雲環境執行，
會從自助式服務（Self Service）的形式開始發動這樣的環境，然後，執行快速部署，同時用了多少資源會被計價，也有相關記錄可供留存和稽核。
到了那時候，該用私有雲或公有雲、評估哪一家供應商的方案比較合適，都是以管理的角度來衡量，並根據雲的特性和成本來做決定，就不是單純由IT技術人員或企業本身的偏好來判斷。目前正在發展異質雲管理平臺的數位無限軟體公司，也經常面對企業提出這樣的問題，該公司總經理陳文裕表示，這個時候，混合雲部署的概念就比較容易被接受，因為，是從需求下手，而不是從技術的硬著陸下手。
之所以會產生偏好私有雲，而不信任公有雲的現象，陳文裕認為，這跟地理位置有關。他說，亞太地區企業對於雲服務的理解與實作，主要是從伺服器虛擬化、私有雲起步，先從自家環境開始做起，但實際上，導入虛擬化之後，不一定等於得到私有雲。
相對地，歐美地區的雲服務應用發展過程，卻不太一樣。使用者一開始就面對了公有雲環境，業者針對政府或個人端提供了公共服務，而且雙方也看重並信任彼此所訂定的合約或同意書，在這樣的架構下，用戶會接受公有雲，並視為可存取的服務，不會把公有雲當成不是我的，所以兩地有了很大差異。
工作負載調度大挑戰：既有系統要持續維運，創新應用也需頻繁推出
不論企業是否打算使用任何一種型態雲端服務，目前我們所面對IT的環境，往往就是混合不同應用的工作負載。
以既有的應用系統而言，例如ERP、CRM、資料庫系統，可能執行在實體伺服器，或VMware vSphere、微軟Hyper-V、XenServer、KVM等伺服器虛擬化平臺上，我們能將這些IT基礎架構加以標準化、自動化，集中管控，並搭配資源調度管理（Orchestrator）的管理工具，即能以私有雲的模式來運作。
這部分的發展與演化，就技術路線而言，與目前許多IT廠商所提倡的軟體定義式資料中心（SDDC）、軟體定義式IT架構（SDI），或是軟體定義式環境（SDE），幾乎不謀而合。雖然形式有別於從網際網路環境所發展出來的雲應用系統，但這樣的應用還是存在的。
如果企業要針對是服務前端使用者的業務應用模式，所面對的環境是以網際網路為中心的新興蓬勃市場，例如線上購物、第三方支付等電子商務服務，提供給使用者操作的介面，是每臺電腦都內建的網頁瀏覽器，或是如今人手一機的手機∕平板電腦（App）。
如果相關業務經營起來，在特定促銷活動期間，可能會有上億筆的交易量湧入你的系統，而且你必須在很短時間內，把整個架構準備好，以應付暴量交易需求的處理，讓每個上門消費的顧客都能被系統及時服務；等到活動結束，交易量可能驟減到幾千筆，此時，你又必須將系統規模迅速縮減，或釋出手上的資源，重新配置給其他專案作為開發、測試或執行之用。
這兩種應用系統的執行，因為面向不同，因此，需要不一樣的IT架構和環境來支撐。面對這樣的現象，游政杰提出了看法。他認為，既有的企業應用系統，像是ERP，所服務的對象是公司內部員工，使用規模較為穩定，不會突然大幅增加或急遽縮減，而且是日常都需要執行的，我們所期待的是「服務常在」；企業也可能需要執行雲端化應用程式，所針對的主要目標是分散在整個網際網路上的使用者，這些程式平常執行時，不需要很大量的資源，然而，有突發的線上活動時，又必須能夠動態地擴大規模，以承擔暴量湧出的使用者交易行為。
於是，前者的需求較為密集、穩定，會以資源集中的方式來增添更大動能，如果資源不夠，必須增大CPU、記憶體、儲存設備的資源，亦即縱向擴展（Scale Up）；後者則是分散、動態的，日常的運作，不一定需要很強大的系統資源來支撐，但有時，單一應用程式可能只扛一百個使用者的處理，若使用規模激增到一千個，再設法擴增到同時執行十支應用程式或系統，將整體負載分攤出去，資源調配就像堆積木的方式，會傾向以橫向擴展（Scale Out）的方式處理。
在大部分企業裡面，兩種型態的工作負載，都會存在、甚至會相互混合運作，而在目前這個競爭十分激烈的時代，這樣不同性質的執行需求起伏，將會越演越烈，IT將用什麼樣的方式去滿足、同時又必須兼顧成本經濟，勢必成為企業工作重點，因為這是未來發展各種業務所必須面對的挑戰。
 

混合雲介於公有雲、私有雲之間的關係
公有雲、私有雲的應用架構陸續崛起，各自有擅長之處。私有雲是單獨在公司或組織內部運作的雲服務，特色是可自行掌控、較重視安全與機密與穩定效能，但延展性會受限於企業本身的IT投資。而公有雲是由外部的服務供應商所經營的環境，可快速部署應用程式，執行規模可快速擴展或縮減。而混合雲希望融合兩者優勢，企業可獲得主要的控制權，讓內外部的雲資源都能為己所用，不過要如何能讓應用系統做跨雲的相互運作，會是挑戰。圖片來源／VMTurbo

 


混合雲強調可兼容公有雲與私有雲的特色
私有雲著重在安全、可靠性的要求，公有雲講求容易使用、按量計費，並具有彈性的規模擴展能力，以往都是各行其是，如今整合在一起應用的態勢已經日益明朗，實際採用案例也變多，因此吸引許多企業與IT廠商爭相投入相關應用。圖片來源／IBM、微軟

 

混合雲已經是當前多數大型企業採行的雲策略
根據RightScale這家提供混合雲應用服務公司在2015年1月舉辦的調查，擁有1000名以上員工規模的大型企業，面對雲端應用的策略，是同時採用多個雲服務，比例高達82％，比去年高出8％，其中，單是運用混合雲的企業比例，不僅大幅超越同時用多個私有雲，以及多個公有雲，而且比去年的調查結果成長了7％。
這樣的結果或許你覺得太過樂觀，不妨讓我們對照一下IDC在2014年6月公布的混合雲調查。他們發現，64％的人表示目前或計畫用混合雲的策略，並有70％的人認為，到了2020年，混合雲將是協助企業達成業務目標的重要因素。圖片來源／RightScale

 

在不同應用與工作負載下的混合雲配置
若同時考量應用系統的新舊，以及位處應用程式開發週期的不同階段，企業在私有雲與公有雲的配置選擇上也有差異，會呈現出金字塔形的應用態勢。資料來源：2012年，VMware vCloud Blog、圖片來源／Bluelock

 
相關報導請參考：「混合雲進軍企業IT應用」
",https://www.ithome.com.tw/tech/94707,"雲端應用,雲端服務,Cloud,混合雲"
94361,33,2015-03-17,檔案公有雲服務走入企業應用,企業如果想要以最快速、便利的方式取得檔案同步和共享服務，SaaS型態的公有雲服務是首選," 隨著雲端檔案存取與共享服務的普及，現在，這類型系統也成為近年相當受注目的企業應用，在檔案同步分享應用之外，還要能提供更多安全管控的特性。而市調機構Gartner也特別將這類雲端檔案存取與共享服務，定名為企業檔案同步和共享（Enterprise File Synchronization and Sharing，EFSS）。
從服務提供方式來看，目前市面上這類產品可分成公有雲、私有雲的建置形式。如果企業想要以最快速、便利的方式取得應用，其中SaaS型態的公有雲服務便是首選，企業用戶不需特別準備專用的設備，直接租用申請，就可以馬上開始使用。
在這次採購特輯當中，我們測試5家廠商提供的檔案公有雲服務，包括兩家本土廠商──中華電信HiCloud Box與網擎SecuShare分享雲，以及全球知名大廠Box Business、Google Drive for Work與微軟OneDrive for Business方案。
提供企業使用者帳號管理、檔案分享權限管理能力
一般來說，企業檔案同步和共享服務，比起個人版更具有集中管理的便利性，以及更強的管控力，像是管理者將能建立企業使用者成員，讓企業內部成員的分享更加方便。
不過，各產品對於檔案分享管控作法有不同的設計，細節上也有諸多差異。舉例來說，使用者檔案分享，基本上要能針對企業內部或外部分別管控，當分享給外部使用者時，多數產品會提供設定密碼保護功能，讓知道連結的人還要經過密碼驗證才能存取，或是設定有效期限，讓分享的連結能夠在一段時間後自動失效，甚至設定一次分享，讓對方使用連結後就會失效。
在企業內部的檔案與資料夾共享的管控上，基本也都會提供讓使用者制定共用對象的存取，像是讓共享成員僅有檢視權限，或是可以編輯、註解，甚至是上傳、預覽、擁有權共享等。這些使用細節的提供，也增添分享管控力度。
若是企業需要更強制性的管控，將可以讓管理者來限制個別使用者的分享權限，像是設定只有管理員、資料夾擁有者及共同擁有者可以邀請合作對象，設定使用者在資料夾中的檔案存取權限。此外，也能管控使用者的應用程式使用方式，像是禁止使用者帳號執行同步功能、或是該帳號的App登入使用。在這次5款測試產品中，像是Box Business、Google Drive for Work與網擎SecuShare分享雲，就提供較多的管理者控制，可制定企業成員的分享政策或使用方式，再由企業員工決定分享檔案的存取權。而微軟One Drive for Business與中華電信HiCloud Box，則是較偏向從使用者角度出發，完全由企業員工來掌握檔案分享的管控設定。
對於企業來說，這些服務都能幫助企業做到一定的檔案分享管控，並提升企業檔案分享方便性，只是在管控與方便性上要如何拿捏，以及功能面是否可以符合企業需求，對應企業本身的使用情境，就是企業需要自己想清楚。
不僅於此，對於企業應用上，通常也會考量更多，像是可否於企業內部的AD進行整合，能否整合單一登入（Single sign On）機制。加上過去企業對於公有雲儲存服務有安全性的疑慮，因此服務本身的連線加密、安全防護，以及管理者對於使用者連線的管控，也都是值得注意的地方。常見的使用者帳號安全防護，像是二階段認證機制，定期強制使用者更換密碼，另外，系統也應能自動攔阻多次嘗試失敗的連線，並通知管理者。
同步功能與行動App為必備功能
從這些企業檔案公有雲的功能發展來看，不僅都是以SaaS型態供企業租用，許多服務在線上申請、購買這部分也做得很徹底，可以直接開立刷卡、開立發票，讓企業用戶取得服務更簡便。
在功能面上，像是行動端App應用與PC端同步功能，已經是所有檔案同步和共享服務的必備功能，因為這對於使用者來說相當吸引人且便利。像是使用者在手機、平板上能透過App，直接檢索雲端服務上的檔案，並能直接上傳與下載檔案，畢竟在行動裝置應用普及的今日，滿足行動應用存取檔案的需求很重要。與電腦端檔案同步的機制也很實用，使本機上檔案經變動後，能夠自動將檔案更新上傳，並可版本管控。
以這次測試的5款服務來說，在PC端同步功能上，大多能同時支援Windows與Mac OS系統，只要安裝代理程式便能同步個人檔案，甚至也能提供自訂同步資料夾的彈性。也有少數還不支援Mac OS系統，像是網擎分享雲，另外微軟OneDrive for Business目前也只提供預覽版。
在行動端使用上，5款服務均提供Android、iOS平臺的App，有些甚至是支援Windows Phone、Blackberry，增加應用性。基本上，這些檔案同步和共享App的使用都很簡單易用，想要從手機、平板上下載、上傳、分享檔案都沒問題，分享時也能使用網頁服務相同的權限、防護設定。
特別的是，像是Box與微軟OneDrive for Business還能設定應用程式密碼，讓每次開啟App都要輸入密碼才能使用，強化行動端的防護。
檔案管理、協作功能，已經成為這類服務的重要擴展
更進一步來看，這些企業檔案同步和共享服務對於檔案管理也有許多著墨。特別是針對「分享」這件事，更讓平臺積極積極朝向協作應用發展。
基本上，使用者在操作分享時，檔案分享方式不再是將檔案直接以電子郵件夾帶為附件，寄送到對方信箱，而是產生檔案甚至資料夾的專屬連結，透過連結的方式夾帶在電子郵件中內，供接收方下載。
分享邀請通知也變得更容易。像是檔案分享時的邀請對象設定時，幾乎都能顯示出建議的關鍵字列表。當使用者在共用檔案或資料夾時，除了能夠顯示連結讓使用者以自己的方式傳送。為了讓協作應用更順利，大多數雲端服務本身可以提供郵件寄送共用邀請的能力，相當方便。
當然，服務本身的郵件通知機制，還能提供更多幫助，像是Box服務在共用檔案上新增註解時，或工作指派檢閱時，系統能夠自動發送郵件通知相關成員，或是像網擎SecuShare會在使用者上傳病毒檔案時，郵件通知管理者。
在檔案管理方面，從目前這些企業雲端服務的發展來看，在檔案同步與共享之外，不僅結合企業管控功能，也加入許多文件管理系統該具備的特點。舉例來說，不論是在服務本身的網頁介面、手機App介面，大多數的服務都能提供檔案縮圖預覽、線上檢視、搜尋能力，並提供檔案尋找的快捷選項（如我的最愛、最近使用的檔案、共用項目尋找），讓使用者可以更簡便的去操作。
甚至在檔案搜尋功能上也能有所強化，基本的檔案名稱尋找之外，還能找到文件內容也相符的結果，像是Box、Google與微軟的檔案公有雲服務。
其他方面，像是版本管控機制、為檔案加上註解與說明，也都已經是普遍企業同步和共享服務都具備的功能，而Box、微軟提供的檔案雲服務更是可以提供工作指派、檔案鎖定的應用，讓使用者更易於協作。
更重要的是，基於檔案分享產生的協作相關應用，也逐漸成為這類產品的下一個重要核心功能。像是Google與微軟都有提供自家的線上文件服務，讓使用者直接在網頁介面上就能編輯文件，而不用另外以本機應用程式來執行。讓檔案共享應用變得更直覺，甚至讓多人可以共同編輯一份文件也沒問題。
當然，還有一種變通的作法就是讓雲端文件以本機應用程式開啟，編輯後再自動上傳回存。這些特性，讓服務本身不僅僅是同步和共享，檔案本身也能直接從平臺產生，文件編修也能直覺從介面上來執行簡化操作。
從這些面向來看，這些企業檔案同步和共享服務的發展方向，將更具檔案管理、編輯、與協作性。不過，我們從各家計費方式還是可看出一些發展差異差異，像是Box Business、微軟OneDrive for Business、Google Drive for Work都是以使用者數為計費單位，而儲存容量都是沒有上限，對於檔案管理要求也因此會較高。
比較特別的是，中華電信HiCloud Box是以每100GB儲存空間、5組使用者帳號為單位計算，網擎更是以100 GB儲存空間、使用者人數不限的方式來計費。由於儲存容量的限制，使得這樣的服務較傾向於檔案分享專屬應用。
其他檔案公有雲服務
最後，我們在這次測試的雲服務種類中，也有幾個遺珠之憾，像是臺灣本土大廠華碩也推出WebStorage for Team雲端服務，只是今年2月適逢大改版，同時改名為WebStorage for Business，並未趕上這次採購特輯的測試。還有像是大廠Citrix也推出的企業適用的ShareFile雲端服務，只可惜該目前的服務介面以英文語系為主，還不支援正體中文，對於臺灣使用者不夠友善。另外，像是在免費個人雲端儲存市場赫赫有名的Dropbox，近年也進軍企業市場，推出Dropbox for Team（已改名為Dropbox for business），提供線上直接申請、使用，只是目前產品線上客服只能以英文溝通，如果能夠提供符合臺灣環境的服務，會更理想。未來我們也將會持續對這些服務做相關介紹。
相關報導請參考「企業檔案公有雲採購大特輯」
 

檔案雲服務均能將PC端檔案與雲端的儲存區相互同步
使用檔案雲的同步服務，能讓使用者電腦上資料夾的檔案與雲端服務同步，任何一方的檔案異動，都會自動更新到另一方，相當便利。

 

可設定檔案分享的密碼與期限，增加管控力道
將檔案或資料夾連結分享給對方使用時，為了避免遭他人任意使用，因此多數服務都會提供像是密碼、使用期限的防護機制，讓得到連結的人，沒有密碼也無法下載，或是連結過期而無法再使用。

 

針對內部人員，管理者也能設定檔案分享的存取權限
在檔案同步和共享服務中，最普遍的存取管控方式，就是對資料夾或檔案共用的成員，設置不同存取權限，讓檔案分享能有較細緻的管控能力。

 
5款企業檔案公有雲比較表
                           
 
 

可將檔案分享至所有行動裝置
利用平板電腦與智慧型手機來工作，現在已經很普遍，在檔案公有雲下，使用者能夠方便地依據自己的方式，存取需要的檔案，也能依需求設定存取對象與權限。

 

結合線上編輯的檔案共用方式很方便
現在的雲端檔案同步和共享服務，也很看重線上文件建立、編輯的能力，使文件的共享應用更直覺且方便，而不單單只是將檔案傳給對方，最好還能提供像是共同線上編輯的應用方式。

 
相關報導請參考「企業檔案公有雲採購大特輯」 
",https://www.ithome.com.tw/tech/94361,"SaaS,公有雲,雲端服務,Cloud,檔案同步,檔案共享"
94340,33,2015-03-06,新創買新創，看上Docker原生SDN套件，Docker併購剛滿3個月的新創團隊SocketPlane,為了強化產品布局，也是新創公司的Docker繼續併購新創，這次看上了成立剛滿3個月，以開發Docker原生SDN產品的新創公司SocketPlane，希望來增強Docker開源網路API的開發動能。," 去年獲得4千萬美元資金後，Docker開始透過併購拓展產品藍圖，繼去年7月併購Orchard，近日，Dcoker更宣布買下了一家，成立剛滿3個月的新創SDN公司SocketPlane，希望增強Docker開源網路API的開發動能。SocketPlane主要是開發Docker原生內建SDN解決方案，使用Open vSwitch開放原始碼，在Socket層提供網路虛擬化服務。
Docker技術長Solomon Hykes說：「為了跟上開源、模組化的快速步調，我們認為有必要支持這些新創團隊。」他表示：「有鑒SocketPlane團隊在SDN開放原始碼的成果，符合我們『內建電池，可替換及標準模組化』（batteries included, but swappable）的思維，可以幫助Docker打入正蓬勃發展的網路生態系。」
SocketPlane專注於開發網路驅動程式（Network Drivers Proposal）及建立多主機網路架構（Multi-Host Networking Proposal）。目前成員有Madhu Venugopal, John M. Willis, Brent Salisbury及Dave Tucker等人。根據SocketPlane去年官網發布的新聞稿，這些成員過去來自Cisco, Dell, Red Hat, HP，並且在SDN應用、雲端計算都有豐富的經驗。
不過，Docker的快速擴張也引起開源社群的反彈。早在去年12月，Core OS創辦人Alex Polvi批評Docker逐漸失去對於Container標準化的堅持，朝向Container管理平臺的方向前進。因此，原是Docker的盟友Core OS，決定開發自家的Container技術Rocket。
",https://www.ithome.com.tw/news/94340,"新聞,SocketPlane,Docker,Container"
93333,33,2015-01-07,2015：未來十年IT架構變革元年,輕量級虛擬化技術弭平Windows和Linux壁壘、開源雲端OS助白牌設備瓦解壟斷市場……，這些2014年出現甚至成熟的新一代技術和產品，不只將影響2015年的IT發展，也啟動了企業未來10年IT架構的新變革," 回顧過去，總是展望未來的第一步。在2014這一年，過去的4大科技驅力，雲端、行動、社交、大資料開始匯流、相互交織再往外擴大影響。雲端向下延伸大幅進入企業，與商用軟體和企業私有雲更深度整合。
大資料分析變成了雲端服務，成為了解使用者透過行動裝置社交互動的最佳工具。物聯網蒐集到的大量資料，結合雲端運算架構和大資料處理能力，發展出了可以讓機器或軟體更聰明的新一代機器學習服務。
不論是軟硬體公司或雲端業者，如微軟、思科、英特爾都看準此一商機，結合大資料、雲端平臺、物聯網來打造新平臺或新服務。不論是將有50億裝置串連上網的物聯網，或是行動裝置延伸的穿戴式裝置，最終都能將資料匯流到同一個大資料雲端後臺，再轉而對使用者貼身的裝置如穿戴式裝置、手機、平版、電腦等提供服務和資訊。2014年四大驅力交織在物聯網技術和行動設備上，形成了2015年的新藍海。
科技帶動的市場新趨勢，是IT助企業創造更多商業價值的好機會。但在2014年更根本性的影響，是出現了種種翻轉IT架構的技術新趨勢。
軟體技術的世界開始出現大一統，歷經多年討論的HTML 5標準終於定案，單一網頁技術可以通吃各式大小螢幕裝置，硬體差異造成的軟體多版本圍籬開始瓦解，至少有了一個共通的基礎。新一代的開發技術也紛紛出現，向來重視設計的蘋果，推出了新的App開發語言Swift，要來取代沿用多年的Objective-C，而以技術力領先群雄的Google則發表了新的UI設計規範Material Design。新一代開發技術，將帶動未來2015年App新風貌。
軟體威力連整座資料中心都能開始虛擬化了，VMware力推的軟體定義資料中心（SDDC）願景，在2014年隨著最後一塊軟體定義儲存產品上市而成真。一座機房內，舉凡運算、儲存、網路都能用一套解決方案解決。SDDC軟體更隨著新一代伺服器規格的強化，DDR4記憶體支援擴大了伺服器內向來稀少珍貴的記憶體資源，SSD普及更鬆綁了資料I/O存取的瓶頸，這幾項變革，讓主流伺服器具備更強大的運算能力。
一臺伺服器或一櫃伺服器就足以透過軟體層就能變身成滿足不同應用需求的硬體產品，融合式架構應運而生，也催生了許多通用型的整櫃式設備，許多OEM或ODM代工廠也有能力推出白牌伺服器來搭配SDDC軟體，軟體大廠VMware也帶頭推動，連微軟都和戴爾合推Cloud in a box設備。不只是硬體架構出現融合趨勢，軟體平臺間的壁壘在這一年也開始鬆動。爆紅的輕量級虛擬化技術Docker終於在2014年推出正式版，競爭對手老牌虛擬化廠商VMware積極靠攏，主流作業系統紛紛支援，連下一版的Windows Server都將內建，Amazon和Google相繼推出支援Docker的Container叢集服務，IBM、微軟也跟進要賣Docker映象檔管理平臺軟體。Docker正一步步實現了讓一套應用程式能夠跨作業系統、跨不同雲端服務平臺到處部署的願景。這些2014年出現甚至成熟的新一代技術和產品，不只將影響2015年的IT發展，也啟動了企業未來10年IT架構的新變革。
 

 
相關報導請參考「展望2015」
",https://www.ithome.com.tw/news/93333,"新聞,Docker,大資料,開源,DevOps,IoT,物聯網,SDN,混合雲,SDDC"
93336,33,2015-01-05,[展望2015]新一代開發技術將在今年開花結果,「忙」可能是2014年開發者的最佳寫照，舊技術有重大改版，甚至還出現新技術，去年有哪些開發人員不可不知的重大事件呢？," 程式人很忙！可能是2014年開發者的最佳寫照，除了舊技術有了重大改版，甚至還出現了新技術，網頁介面標準HTML5也進入推薦階段，採用這些開發技術的產品將在2015年陸續面市。
而歷史悠久的Java則進行了史上最大改版，甲骨文在第一季釋出了Java 8，除了新增不少API外，還加入Lambda表示式語法，讓Java的整體程式碼寫作風格朝向函數式程式設計（Functional Programming）。
另外，蘋果在6月的開發者大會中，發表了全新的程式設計語言Swift，雖然目前在市面上以Swift開發的軟體並不多，但是，Objective-C勢必逐漸被淘汰，而同時間發布的新版整合開發環境（IDE）Xcode，互動式開發環境亦支援了Swift。
而Google開始跟進蘋果注重App設計統一性，在Google I/O大會上發表了設計語言Material Design，藉此統一Android平臺上App的介面設計風格。
而2014年開發界的震撼彈，就是微軟開始積極擁抱開源，首度在4月宣布成立.NET基金會負責所有開源事宜，並開源編譯平臺Roslyn，接著在11月時宣布將.NET伺服器端核心開源。微軟從過去視開源為癌症，到積極擁抱開源的態度轉變的過程中，一再顯示出開源正影響著全球的軟體市場，無論是營收模式或是廠商的策略。
網頁平臺在2014年也有很多動作，像是HTML5的標準制定進入推薦階段，雖然不少人在這之前就已開始使用HTML5技術開發網頁應用程式，不過標準比預期提早進入推薦階段，也顯示網頁平臺的重要以及發展成熟，網頁介面將轉為重要的應用程式平臺。
由Mozilla瀏覽器Firefox所研發的Javascript精簡版asm.js架構，用以滿足網頁應用程式的高效能需求，也得到IE瀏覽器的支援，以及主流遊戲引擎Unity以及Unreal的支援。
此外，DevOps的概念也逐漸在臺灣普及，從許多新創公司的部署流程中可以見到，例如Gogolook與KKTIX能每周部署一次產品，愛料理甚至每天能部署數十次，CI工具以及概念的成熟功不可沒，在未來大型企業為提升行動裝置App的更新速度，也會開始重視DevOps。
 

 

相關報導請參考「展望2015」

",https://www.ithome.com.tw/news/93336,"新聞,開發,HTML5,Java 8,Swift,Material Design,Roslyn,DevOps,甲骨文,蘋果,微軟主動保護計畫"
93102,33,2014-12-22,VMware鎖定DevOps市場 推混合雲管理平臺,VMware混合雲管理平臺vRealzie Suite 6正式版（GA），包含可管理SDDC及IaaS公共雲服務的套件，以及用於vSphere環境效能管理和Log即時分析的平臺," 虛擬化廠商VMware宣布，推出混合雲管理平臺vRealzie Suite 6正式版（GA），vRealize Suite包括了可以用來管理SDDC及IaaS公共雲服務的vRealize管理套件，另外還有用於vSphere環境效能管理和Log即時分析的平臺vRealize Operations Insight。
在混合雲管理平臺正式版中，用戶目前可以取得vRealize Operations 6.0、vRealize Business 6.0標準版、vRealize Business 8.2進階企業版、vRealize Automation 6.2，以及vRealize Log Insight 2.5。
vRealzie Suite 6提供用戶單一平臺，來統一跨實體伺服器、多虛擬機器管理、私有雲和公共雲等環境的管理。VMware雲端管理事業部產品行銷副總裁Sajai Krishnan在VMware官方部落格上表示，企業IT需要支援現代和傳統的應用程式，還需協調企業內部就地部署的環境和雲端環境，以及在維運IT的同時提供服務。
另外，VMware瞄準企業敏捷開發需求，推出DevOps管理軟體vRealize Code Stream 1.0。VMware官方部落格表示，開發和維運團隊使用Code Stream可以更頻繁、更有效率地釋出軟體，且在開發過程中降低維運風險，同時，團隊也可以充分利用既存的開發和維運工具。
開發團隊在軟體應用釋出之前，可利用Code Stream來模組化每種軟體應用釋出流程中的每個步驟，也就是開發者建立一套軟體應用釋出的工作流程，在此流程中的每個階段之間都有建立一套規則和治理政策，藉此來自動化建立、部署和測試軟體應用。
此外，Code Stream也提供開發團隊每個軟體應用工作流程狀態的概要圖，而此狀態的顯示可協助開發團隊確認問題，進而更快地解決問題。此概要圖統一了跨環境的軟體應用釋出狀態，以確保開發團隊之間的協作可以更快且更有品質。
",https://www.ithome.com.tw/news/93102,"新聞,VMware,DevOps,雲端服務,SDDC,vSphere,Log分析,雲端管理"
92634,33,2014-11-28,思科進軍中小企業 聯合Box儲存服務力推企業協作App,思科於2014年協同合作大會上宣布進軍中小型企業與新創公司，並以「雲端基礎、行動優先」策略來發展企業協作服務," 【美國洛杉磯現場報導】
思科於2014年協同合作大會中（Cisco Collaboration Summit 2014）一改過往主要針對大型企業的高階產品策略，轉而進軍25至100人規模的中小型企業與新創公司，發表了2項產品，分別是企業協作App Project Squared與協作平臺BE 6000S，另外，也針對大型企業推出了網真（Telepresence）IX 5000系列，售價299,000美元。
思科總裁兼CEO John Chambers表示，若產品在使用上過於複雜且需要耗費比較長的部署時間，會降低用戶的使用意願，因此，思科將致力於簡化產品操作流程以方便用戶使用，且改變企業傳統用電子郵件傳遞訊息等工作方式，與讓產品可以適用於各行各業，從銀行到新創公司都可以使用。
John Chambers也說，未來企業協作產品將聚焦於影音溝通，且結合了各式各樣的行動裝置，並且整合雲端服務、加強資安防護等，且計畫未來都會朝向此趨勢。
而思科全球協同合作技術事業群資深副總裁暨總經理Rowan Trollope也表示，未來企業協作方面將會以「雲端基礎、行動優先」（Cloud Based, Mobile First）為策略，來發展企業協作服務，而其中又以使用者經驗與資訊安全為最關鍵的發展目標。
另外，以思科提供的Intercloud服務來說，企業可以選擇最近的資料中心，來加速資料存取速度。
思科大中華區副總裁暨協作事業部總經理倪殿令也表示，用協同合作技術來打造企業內部流程，最終會改變了企業文化與產業鏈中上游到下游之間的關係等。
他也說，思科的目標在於，讓企業協同合作的操作流程等越來越簡單，也就是以雲端為基礎，協助企業在每一個會議室、桌面、行動裝置與應用程式中，都建有協同合作工具，並且整合所有的裝置與透過一鍵式就可以開始進行會議，以簡化操作流程。
 

思科總裁兼CEO John Chambers表示，思科未來將聚焦於影音溝通，且結合各式各樣的行動裝置，並結合雲端服務，與加強資安防護等。

 
推出企業協同合作App Project Squared
思科也和雲端儲存服務公司Box合作推出了企業協作App Project Squared，此App以思科協同合作雲端平臺（Cisco Collaboration Cloud）為基礎，結合思科今年初發表的Intercloud，協助企業進行跨裝置、跨時區與跨團隊溝通。
思科協同合作技術事業群資深副總裁暨總經理Rowan Trollope表示，目前思科在企業協作方面最重要的任務就是讓產品能適用於更多類型的企業，不論是大型企業或是新創公司，因此產品策略將走向更容易使用、更低價與適用於更多行動裝置上，如智慧型手機與平板電腦等。
另外，Rowan Trollope表示，思科開發Project Squared最重要的理念就是將產品設計得更容易操作，與因應現今企業內部更常面臨遠距離會議、敏捷式專案、截止時間更短、擁有各種的行動裝置四大趨勢，加上目前員工已習慣於使用App等來溝通，因而開發出Project Squared。
未來，Rowan Trollope說，思科也會持續了解使用者需求，並持續更新Project Squared的功能與整合其他的企業協作工具，而且計畫另外推出需要付費的進階功能。
思科協同合作副總裁兼技術長Jonathan Rosenberg則表示，目前思科在企業協作方面，主要發展策略為整合各式各樣的行動裝置與溝通工具等，且結合雲端服務，如思科協同合作雲端平臺（Cisco Collaboration Cloud），再加上提供加值服務，而如何結合以上3項策略就是目前思科主要面臨的挑戰。
思科表示，由於現今企業皆著重於開發彈性與快速的工作流程，甚至於大型企業也想要像新創公司那樣，在各部門與員工之間擁有順暢的溝通管道，如需要快速地向同事傳遞訊息與分享經驗等、工作流程更加彈性與敏捷，才能快速因應各式各樣的挑戰，因而推出企業協作App Project Squared，甚至於小型企業與新創公司也可以免費下載Project Squared，而不需要購買思科的產品。
Project Squared加入了日曆、微軟Active Directory、雲端儲存服務Box的企業雲端儲存、檔案分享服務等功能，同時也整合了WebEx、IP phone。思科表示，企業用戶在使用Project Squared時，可同時使用Box的儲存空間，但是，思科對於儲存空間是否超過容量限制就要收費，則尚未進一步揭露。
如企業中的團隊成員可以在Google Play、App Store免費下載Project Squared，註冊之後，可以開闢一個以上的Room（房間），來邀請團隊內或者部門以外的成員，透過輸入姓名或電子郵件加入此對話空間，其中使用者可以傳送即時訊息、語音、視訊，也可以在對話過程中，來分享儲存在Box中的文件等，而不需要先下載才能分享。思科表示，未來會納入Microsoft Exchange功能，且會進一步整合WebEx。
不過，Jonathan Rosenberg表示，Project Squared不會進一步發展成企業版的「臉書」，而是要聚焦於企業組織內的合作，以小組合作方式，強調協作功能，加速企業工作流程。
Box共同創辦人暨執行長Aaron Levie表示，把內容與人們最常用的工具進行連結，將會增加企業生產力及促進協同合作。透過Project Squared，Box會和思科合作來更進一步整合企業協作工具、雲端平臺及商業資訊。
另外，Box正在建構專案管理（Project Management）服務，如同GitHub所提供的程式碼多人協同管理服務，使用者可以透過雲端儲存空間進行共同作業。例如，使用者可以藉由專案管理服務，業務人員與顧客可以共同設計與建造銷售網站，以協助業務人員更能了解與掌握顧客的需求。
此外，由於使用者仍對雲端服務仍存有資安疑慮，思科表示，透過思科協同合作雲端平臺（Cisco Collaboration Cloud），使用者可以加密內容，而企業IT團隊也可以透過要求員工使用單一簽入（SSO）和IT驗證密碼，來管理Project Squared。也就是說，各個團隊在Project Squared中傳遞的內容，只有各組織之間才可以看見。
而以臺灣市場來說，倪殿令表示，臺灣使用者可以免費下載Project Squared，但思科目前仍在摸索臺灣企業的使用模式，未來才會推出相關的商業模式。另外，倪殿令也表示，因為在中國經營第三方通訊業務，需要申請多方通訊的執照，因此目前思科僅和第三方如TCR合作，提供思科Intercloud服務，仍未確定Project Squared在中國推出的時程。
目前使用者已經可以於App Store、Google Play免費下載Project Squared。瀏覽器版本則可支援Chrome、Firefox 與Safari，並可以在Firefox環境上提供無插件語音及影像，不過，還未支援微軟的Internet Explorer瀏覽器和手機平臺。
未來，思科表示，計畫推出Project Squared要付費的進階功能，且計畫於2015年第2季發表Project Squared的最終版本。
聚焦小型企業，發表協作平臺BE 6000S
為了進軍小型企業，思科也發表了協作平臺BE 6000S，主要針對中小企業，支援20至150位使用者，可以用300個裝置與10個地點，用戶可以透過思科2921整合式服務路由器（Integrated Services Router，ISR）中的協作功能，使用語音、視訊、即時訊息與出席會議等功能。
協作平臺BE 6000S底層採用了UCS刀鋒伺服器，內建路由器、語音交換器、閘道器（Gateway）、IP Phone 8800、DX80等以無縫接軌所有的企業協作平臺，且預先內建了5核心的UC apps-CUCM、CUC、IM&P與PCP等。
由於思科現在產品導向小型企業，因此也調整其銷售策略，思科表示，已經將產品銷售交由數個經銷商負責，且以BE 6000S來說，由於已經預先進行初始設定，因此約可以降低經銷商30%的產品部署時間，預計於2015年初上市。
針對大型企業，推出網真（Telepresence）IX 5000
思科也發表了網真（Telepresence）IX 5000系列，其採用一體化設計，一般由3個螢幕組成，最多可以達到6個螢幕，螢幕尺寸為70英吋，且採用4K鏡頭，當會議中有人站立時，透過平板電腦操控，按下Stand Up按鍵後，鏡頭就可以自動將人納入全景。
IX5000延續了大型會議室專用的網真設備MX700與MX800所使用的視訊壓縮標準，皆採用H.265，且3個螢幕共用1個頻寬，思科表示，IX 5000的頻寬成本和上一個版本相比降低了一半。
另外，IX 5000也可以透過降低頻寬，來支援1080p高畫質的視訊設備，若頻寬不足時，視訊畫質會自動調降為720p，而所需功耗則低於10安培。
而IX 5000總共設有18個定製揚聲器，且在麥克風中具備17,502個聲音捕捉孔，主要針對6至18人的會議規模，預計於今年12月上市，目前已經開放訂購，售價為299,000美元。
 
 思科企業協作App Project Squared新特色 
思科和Box合作推出了企業協作App Project Squared，以思科協同合作雲端平臺（Cisco Collaboration Cloud）為基礎，結合思科今年初發表的Intercloud，協助企業進行跨裝置、跨時區與跨團隊溝通，並加入了日曆、微軟Active Directory、雲端儲存服務Box的企業雲端儲存、檔案分享服務，同時也整合了WebEx、IP phone。
 

使用者可以透過下載Project Squared，來開闢個人的Room（房間），而Project Squared加入了日曆、微軟的Active Directory、雲端儲存服務Box的企業雲端儲存、檔案分享服務等功能，同時也整合了WebEx、IP phone。

 

開設一個Room（房間）後，可以啟動影音通話，來舉行會議等。

 

使用者能在行動裝置中，透過Project Squared，使用Box的企業雲端儲存、檔案分享服務，如從Box中取得檔案，來分享簡報檔與文件等，而非需要先下載才能分享。不過，思科對於儲存空間是否超過容量限制就要收費，則尚未進一步揭露。

 

使用者在進行影音通話時，也可以同時開啟簡報檔。

 
 
 思科網真（Telepresence）IX5000新特色 
思科發表網真（Telepresence）IX5000系列，一般由3螢幕組成，最多可以達到6個螢幕，螢幕尺寸為70英吋，且採用4K鏡頭，當會議中有人站立時，透過平板電腦操控，按下Stand Up按鍵後，鏡頭就可以自動將人納入全景，另外，總共設置18個定製揚聲器，且在麥克風中具備17,502個聲音捕捉孔，主要針對6至18人的會議規模，售價為299,000美元。
 

思科推出網真（Telepresence）IX5000系列，由3至6個螢幕組成，具備70英吋螢幕與4K鏡頭，可以由平板電腦操控。

 

當會議中有人站立時，透過平板電腦操控，按下Stand Up按鍵後，鏡頭可以自動將人納入全景。

 

可以透過拖拉方式，調整螢幕播放的位置。如可以將第二格螢幕，拖移至第一格播放。

 

IX5000共計設有18個定製揚聲器，且在麥克風中與具備17,502個聲音捕捉孔，主要針對6至18人的會議規模。

",https://www.ithome.com.tw/news/92634,"新聞,思科,Cloud,雲端服務,App,協作服務"
92287,33,2014-11-17,紅帽雲端基礎架構第5版出爐 首度支援紅帽衛星6.0,Satellite 6主要新增6項功能，分別可以配置在實體機、私有雲和公眾雲，協助企業進行集中式管理," 紅帽於OpenStack巴黎年會中（OpenStack Summit），宣布推出了雲端基礎架構第5版（Red Hat Cloud Infrastructure 5，簡稱RHCI 5），首度支援了Satellite 6，以協助企業從傳統的資料中心與虛擬化系統，轉移至OpenStack。紅帽雲端管理副總裁暨總經理Joe Fitzgerald表示，紅帽雲端基礎架構首度整合了Satellite 6，提供橫跨實體、虛擬和雲端系統的軟體生命周期管理與設定功能。
紅帽表示，現今許多企業正在從傳統虛擬化架構轉移到雲端架構，除了將應用程式工作負載轉移到不同架構之外，還需要維護不同平臺的管理與政策。而雲端基礎架構第5版，就是可以協助企業根據傳統工作負載所用的資料中心虛擬化技術與管理技術，來建置與管理私有雲的基礎架構即服務（IaaS）。
紅帽雲端基礎架構第5版則整合了4項雲端產品，包括了企業版Linux OpenStack 平臺5.0版（Red Hat Enterprise Linux OpenStack Platform，簡稱RHEL-OSP）、CloudForms 3.0、企業虛擬化（Enterprise Virtualization）與今年9月推出的Satellite 6，紅帽表示，企業可以透過雲端基礎架構第5版之單一平臺上，來同步管理虛擬化與OpenStack作業環境。
紅帽資深解決方案架構師游政杰表示，紅帽於今年2月推出的雲端基礎架構第4版之中，僅包含了3項產品，而在第5版中納入Satellite 6的原因在於，因為用戶在雲端架構之中，所有的底層都是Linux，而且在雲端環境當中，其中所包含的虛擬機器有可能也是Linux，而在這些環境中，就需要集中式的管理工具，來統一部署與設定等，才能加快作業流程。
Satellite 6新增6大功能
游政杰表示，Satellite 6為針對紅帽企業Linux部署管理的工具，也就是在雲端環境當中，可以藉由Satellite 6在Linux環境中進行集中式管理。Satellite 6主要新增了6項功能，分別是可以配置在實體機、私有雲和公眾雲上，而提供雲端服務的供應商包含了紅帽企業虛擬化、OpenStack、VMware和亞馬遜EC2，也具有系統探查（System Discovery）功能，提供使用者可以查詢無配置的主機，以實現快速部署。
而以Drift Remediation功能來看，則提供了使用者可以透過完整的歷史記錄、報告和審計方式，來檢視系統的狀態和自動校正系統，另外，Federated Cycle Management則提供使用者可以透過紅帽Satellite Capsule Servers來配置、設定與傳送內容等。
再來，紅帽也提供了生命周期管理（Life Cycle Management）功能、具備Puppet Forge與Git整合功能，此為透過在紅帽衛星第6版中，由Puppet Forge 與Git Repositorie中的Puppet模組，來協助企業在跨平臺中，加速管理與設定流程。
另外，以CloudForms 3.0來說，游政杰表示，CloudForms為雲端管理平臺，可以讓用戶同時管理VMware的vSphere、紅帽的OpenStack等，甚至可以將部署的範圍延伸至亞馬遜的公眾雲EC2。
而企業版Linux OpenStack 平臺5.0版則是於今年5月發布，游政杰表示，主要的功能包括，更新運算API，加強使用虛擬機器叢集（Instance-groups）、OpenStack Block儲存備份API，提供了用戶匯出和匯入中介資料（Metadata）的備份服務，與OpenStack網路虛擬化Neutron的Modular Layer 2（ML2）附加元件，支援SR-IOV（Single Root I/O Virtualization）PCI。
此外，游政杰表示，紅帽大約於OpenStack推出最新版本的2至3個月之後，就會推出相對應的企業版，因此在今年10月OpenStack發表第10版Juno後，紅帽約在今年12月至明年1月，推出紅帽OpenStack企業版。
",https://www.ithome.com.tw/news/92287,"新聞,紅帽,雲端,Cloud"
92282,33,2014-11-14,Docker掀IaaS新戰局，不只Google，Amazon也推Container叢集服務,IaaS業者在Docker戰場的競爭白熱化，從虛擬機器單機支援，進一步延伸到Container叢集的支援。Google率先發表GKE後。接著Amazon也推出了號稱可管理任何規模叢集的EC2 Container Service服務。," 【美國拉斯維加斯現場報導】
繼Google在上周雲端平臺活動中，宣布推出Container服務Google Container Engine（簡稱GKE)之後，Amazon也在拉斯維加斯的re:Invent大會中發表EC2 Container Service（簡稱ECS），並找來Docker執行長Ben Golub站臺宣示雙方合作力度。Amazon技術長Werner Vogels表示，ECS利用EC2虛擬機器叢集來提供Container，可以管理任何任規模數量的Container。
被視為新一代雲端火紅技術的Docker，釋出不到2年，多家IaaS、PaaS雲端服務公司紛紛要搶攻Docker商機，連同為虛擬化市場競爭對手的VMware和微軟都化敵為友加入Docker陣營。
Google、Amazon以及微軟也將Docker視為雲端的戰略級武器，紛紛在IaaS服務上支援Docker。例如Amazon在今年4月宣布Beanstalk服務開始支援Docker，而微軟則是6月宣布Azure虛擬機器可安裝Linux來部署Docker，10月時更決定在下一版Windows Server上內建Docker引擎。
這兩周，IaaS業者在Docker支援上的競爭更加白熱化，從虛擬機器單機支援，更進一步延伸到Container叢集支援的競賽。Google率先發表了可部署和管理大量Container叢集的GKE。而Amazon也推出了號稱可管理任何規模數量Container叢集的ECS服務。
不論Google或Amazon的Container服務，都打著免費加值服務的模式，使用者只需負擔建立Container叢集所需的虛擬機器資源，例如在GKE服務採用了叢集式架構的Kubernetes來部建，使用者不只要負擔Container所用虛擬機器的費用，還得負擔Master節點的虛擬機器費用。
Werner Vogels表示，AWS的ECS服務原生支援Docker，能透過更簡單的API來管理Docker應用，也能和Docker Hub整合。即日起釋出預覽版本，屬於EC2的免費加值服務之一。
除了ECS之外，Amazon也推出了一項由事件驅動的運算服務AWS Lambda。Werner Vogels表示，開發人員不需要管理基礎架構，只要寫簡單的JavaScript程式，甚至是訂定了判斷規則，只要Lambda接收到符合規則的事件，就會自動驅動所對應的雲端服務。Lambda可以由來自AWS服務的事件驅動，例如S3事件通知、DynamoDB串流、Kinesis事件，開發者也可以自己客制事件。
舉例來說，當使用者手機上的App拍了一張照片上傳到S3後，Lambda就會收到S3的檔案上傳通知，並自動抽取照片的相關後設資料（metadata），再自動將這些資料儲存的DynamoDB資料庫中，Lambda會再次收到DybamoDB更新資料的通知，並呼叫CloudFunction的通知服務，發送簡訊到使用者的手機上，讓使用者得知照片已經完成上傳。
Werner Vogels表示，整套應用串接不同服務的過程，只需要簡單的腳本程式，不需要管理虛擬機器或其他IaaS資源，就連物聯網的感測器收到的訊號，也能成為驅動Lambda的事件。

↓re:Invent大會第二天由Amazon技術長Werner Vogels帶頭主講。

↓Amazon表示，ECS利用EC2虛擬機器叢集來提供Container，可以管理任何任規模數量的Container。

↓關於EC2 Container Service（簡稱ECS）來建立多個Container的方式，Amazon也現場播放執行範例影片。

↓Docker執行長Ben Golub也來站臺宣布合作，他說，Docker技術這麼多人投入，不管誰贏了.都會解放開發人員，都能釋放開發人員的創造力。

↓Amazon也推出了一項由事件驅動的運算服務AWS Lambda。

↓Lambda可以由來自AWS服務的事件驅動，例如S3事件通知、DynamoDB串流、Kinesis事件，開發者也可以自己客製事件。

↓Lambda可以用來偵測伺服器後端程式、資料驅動事件、物聯網感測器通知、串流處理、索引或資料同步等情境的事件，進而自動驅動下一步動作。

↓Amazon舉了一個Lambda應用例子，當使用者手機上的App拍了一張照片上傳到S3後，Lambda就會收到S3的檔案上傳通知，並自動抽取照片的相關後設資料（metadata），再自動將這些資料儲存的DynamoDB資料庫中，Lambda會再次收到DybamoDB更新資料的通知，並呼叫CloudFunction的通知服務，發送簡訊到使用者的手機上，讓使用者得知照片已經完成上傳。

↓Lambda定價如下，例如每100萬次呼叫要價0.2美元。

↓re:Invent大會第二天也推出運算能力更強的虛擬機器實例C4，Amazon宣稱是目前CPU效能最強的虛擬機器。

↓這次大會上，Amazon另外也發表了新的EBS儲存空間，容量更大，存取速度更快。

",https://www.ithome.com.tw/news/92282,"新聞,Docker,Container,Amazon"
92146,33,2014-11-13,Docker如何用之開發篇｜用一行指令自動建構完整開發環境,時間軸新到任的開發人員，只要在電腦上安裝Docker，下達一行指令，就可以自動建妥開發環境，讓老鳥不用再一步步教菜鳥安裝所有套件和軟體," 「一用了Docker，就再也離不開了。」時間軸科技數位行銷策略處主任工程師謝宗穎興奮地不斷地說著。自從3個月前時間軸導入Docker之後，新到任的開發人員，只要在電腦上安裝了Docker，下達一行指令，就可以自動建妥整套時間軸科技團隊慣用的開發環境，「不用像過去得花1～3天，一步步教菜鳥安裝所有套件和軟體後，他才能開始有生產力。」他說，就算是老手也得耗掉半天來重裝環境，現在只要一行指令。
要讓業務人員想對客戶示範最新網站，也只要一行指令就可快速建立起示範網站。
時間軸利用Dockerfile可以用從前一個Docker Image開始增加新程式以建立新Image的方式，將慣用的執行環境從Ubuntu系統的Base Image，逐步將Nginx、Ruby/Rails、MySQL、Redis、Node.js、Sails等網頁所需執行環境，一層層分別打包成不同的Docker Image，只要部署最後一層的Dockerfile就能自動建立全套環境。時間軸科技研發中心主任工程師戚務漢實際展示了用Docker開發的新系統，除了在從網路下載基礎印象檔資料花了不少時間外，光是建立Image並啟動為Container不到一分鐘。
更大的優點是，負責系統維運的時間軸科技研發中心主任工程師陳俊廷指出，Docker實現了Infrastructure as code的精神（基礎架構程式化）。因為在Dockerfile中可以完整記錄下建置應用程式所需執行環境的指令和參數，因而解決了過去開發人員難以和維運部門溝通的困難，讓彼此有一套可以追蹤記錄的機制，甚至Dockerfile還可以結合版本控管功能，可以隨時回到前一版本。
 

在Dockerfile中，可以詳細記錄要建立一個Docker Image的完整步驟。

 

Docker能用從前一個Docker Image開始增加新程式以建立新Image的方式，一層層建立全套環境。圖為從smlsunxie/rudy-node這個舊Image開始建立新的Image。

 

要在Mac電腦使用Docker，可用boot2Docker工具，利用VirtualBox建立虛擬機器，再安裝Docker環境來執行Docker的Container。

 

時間軸利用Fig工具，用一個腳本程式來啟動一個應用程式所需的多個Dockerfile。只要執行這個fig.yml就能快速建立這個應用程式所需環境。

 
相關報導請參考「Container技術三部曲（一）迎接下一個雲端火紅技術Docker」
相關報導請參考「Container技術三部曲（二）不只快，還要更快──臺灣Docker應用案例的啟發」
相關報導請參考「Container技術三部曲（三）Container三部曲（三）IT架構的新奈米革命：Container OS」
",https://www.ithome.com.tw/news/92146,"新聞,Docker,輕量級虛擬化,時間軸,Container,軟體開發,軟體部署"
92242,34,2014-11-12,捷報！臺灣社群在Docker全球開發競賽奪冠,Docker Taipei社群參加Docker全球開發日競賽，打敗33個來自各國的開發專案，奪下冠軍，獲得明年到歐洲參加DockerCon的免費機票和門票," Docker這個出生不到2年就紅遍歐美IT界的技術，開發社群成員來自全球82國超過1,500位開發人員，而且不乏頂尖程式高手。Docker Taipei社群日前（11月1日）於在臺北舉辦開發日活動，同步和全球各國的Docker社群，一起參與第二屆Docker全球開發日活動（Docker Global Hack Day #2）。
臺灣當天共有6組開發團隊完成作品，並上傳到Docker美國和全球34個參賽隊伍競爭，奪冠者將可免費獲得明年在荷蘭阿姆斯特丹舉辦的 DockerCon14 EU活動門票和機票。Docker各地社群超過60個，在臺灣則是Docker Taipei社群。
經過各國開發者一周來的票選，結果揭曉，Docker Taiper其中一組參賽團隊郭韋廷（Willy Kuo）和彭筱肜所開發的「Enable Fig to deploy to multiple docker servers」專案，奪下Docker全球開發日冠軍。
郭韋廷是Docker Taipei共同發起人之一，他將一個原本在單機上用來簡化Docker部署的Fig協同工具（Orchestration tool），修改成可以部署到多臺伺服器。
Fig可以在單一個設定檔中，同時部署多個Docker的Container，像時間軸科技就利用Fig來同時設定和執行一個應用服務所需的各項底層服務的Dockerfile，如Node.js、Ruby、Redis等。也正因為Fig可以簡化多個Container搭配時的部署，今年7月下旬，開發出Fig的公司Orchard也成了Docker第一家併購的公司。
郭韋廷表示，Fig作者回覆說目前正在評估郭韋廷所寫的修正機制，考慮未來要納入成為Fig的正式功能之一。他也將在12月12日臺灣首場Container Summit技術高峰會上，分享如何上手Docker的經驗。
Docker Taipei社群共有6組參加Docker全球開發日競賽，Docker Taipei共同發起人郭韋廷開發的多伺服器Fig部署專案，打敗全球各地提交的33個專案，奪下全球Docker開發競賽冠軍。

郭韋廷在Docker全球開發日奪冠作品的介紹影片
 


 
 
【程式碼下載】Enable services to use different Docker Hosts程式碼下載點：https://github.com/docker/fig/pull/607
【延伸閱讀】Docker臺北社群召集人郭韋廷告訴你如何上手Docker的第一步
》12月12日臺灣首場Container Summit技術高峰會，Docker全球開發競賽冠軍郭韋廷將分享如何上手Docker的經驗
報名網址：http://containersummit.ithome.com.tw/
",https://www.ithome.com.tw/news/92242,"新聞,Docker,Container"
92075,34,2014-11-05,Google Cloud降價，再添新服務,Google發表多項新的雲端服務，同時宣布調降多項雲端服務的價格，降幅最高的是Persistent Disk Snapshots，價格調降了79%。," Google於周二（11/4）舉行的Google Cloud Platform Live線上廣播會議上發表多項新的雲端服務，同時宣布調降多項雲端服務的價格，降幅最高的是Persistent Disk Snapshots，價格調降了79%。
此次Google雲端平台的更新從提供簡單及更具彈性的運算選項、強化互動性，到新增Firebase、Google Cloud Debugger及Google Compute Engine Autoscaler等服務。
在簡單及彈性的運算選項上，Google推出了Google Container Engine及Managed VMs in App Engine。其中，Google Container Engine採用Google Kubernetes容器管理開放源碼專案，允許用戶在運算叢集中執行Docker容器，方便開發人員打造基於容器的應用程式，亦可輕易將程式遷移到各處。
Managed VMs in App Engine是一個由可控制的虛擬機器代管的環境，可於該環境中執行App Engine程式，帶來更彈性與更多的CPU與記憶體選項。Managed VMs目前仍為測試版，已支援自動縮放與Docker容器的運作環境，並且整合了Cloud SDK。
在強化與Google全球架構的互動性上，Google新增了3種選項，分別是Direct peering、Carrier Interconnect以及預計於下個月推出的VPN-based connectivity。其中Direct peering讓用戶得以快速存取Google在全球33個國家所供應的逾70個存取點，Carrier Interconnect則是藉由Equinix、IX Reach、Level 3、TATA Communications、Telx、Verizon與Zayo等與Google結盟的電信業者網路來存取Google服務。
Firebase則是Google甫於今年10月買下的雲端即時資料庫服務，其資料庫API允許開發人員自不同的客戶端同步與儲存資料。Google說明，現在的開發工具要管理不同裝置的關係或是即時的資料庫與儲存層並不容易，Firebase簡化了這些任務，讓開發人員更方便打造行動程式或網路即時程式。
仍屬測試版的Google Cloud Debugger則可自動化追蹤應用程式或服務的臭蟲。Google Compute Engine Autoscaler可根據負載狀態、CPU利用率，或客製化指標等資料來動態調整虛擬機器的資源。
除了各種新服務的誕生，Google亦調降多項服務的價格，包括網路出口費率調降47%，BigQuery儲存調降23%，Persistent Disk Snapshots調降79%，Persistent Disk SSD調降48%，Cloud SQL調降25%。Google曾於今年3月調降雲端平台的服務售價，10月再調降10%的Google Compute Engine售價。
為了鼓勵外界試用Google雲端平台，Google祭出了300美元的免費基金，該金額約可使用兩台n1-standard-2規格的虛擬機器60天，儲存超過11TB的資料，或是使用60TB的BigQuery服務。（編譯/陳曉莉）
 
",https://www.ithome.com.tw/news/92075,"新聞,Google Cloud,精選,Container,Docker"
92012,34,2014-11-03,微軟也推出超融合式整櫃伺服器,微軟與戴爾合作推出整機式解決方案，在微軟雲端平臺系統（CPS）上提供Cloud-in-a-box，協助企業在自己的資料中心部署私有雲," 微軟於10月21日，在舊金山的新聞發布會上，宣布了與伺服器廠商戴爾合作推出整機式解決方案，在微軟雲端平臺系統（Microsoft Cloud Platform System，簡稱CPS）上提供Cloud-in-a-box，協助企業在自己的資料中心中，來部署私有雲。
為了因應如今軟體定義式資料中心與軟體定義式基礎架構的趨勢，今年開始許多廠商紛紛推出了整機式解決方案，繼VMware的EVO: RAIL整合式解決方案、Nutanix全快閃記憶體超融合式平臺（All-Flash Hyper-Converged Platform）之後，微軟也宣布推出了Microsoft Cloud Platform System。
CPS是在戴爾PowerEdge機架式系列伺服器上，預載了Windows Server 2012 R2、System Center 2012 R2與Windows Azure Pack等軟體，包含了儲存、網路與管理，並且已經預先組裝與部署，構成了一個百分之一百由軟體驅動，以提供企業快速部署的產品。 
戴爾企業解決方案資深副總梁匯華表示，CPS是運算、儲存、網路與管理都嵌在Hypervisor內的超融合式架構，底層全部採用x86伺服器，讓整個基礎架構所使用的網路、儲存與運算等資源，能夠透過單一儲存池來支配，以便於橫向擴充，以強化延展性。
以CPS和VMware推出的EVO: RAIL相比，梁匯華表示，相同之處在於兩者皆為超融合式基礎架構（Hyper-Converged Infrustructure），而不同之處為，微軟目標是要將Cloud-in-a-box解決方案放到資料中心上面，也就是Azure是提供整體雲端解決方案，而EVO: RAIL則是小規模虛擬化的基礎架構，而沒有搭載針對大型資料中心虛擬架構所部署的雲端建置套件vCloud Suite等。
不過，Nutanix產品經理陳明廷表示，和CPS所搭配的機架式伺服器，不論節點數量與儲存容量都有限制，因此只能和x86伺服器，如HP cs700與IBM PureFlex系列相比較，而無法稱之為可以無限橫向擴充（Scale-Out）的超融合式架構。
而CPS底層的硬體則為戴爾PowerEdge機架式系列伺服器，梁匯華表示，目前未限定某一款的機架式伺服器，微軟會因應各企業的資訊配置情況，再來決定伺服器型號。
臺灣微軟Windows Server產品行銷經理簡志偉表示，戴爾提供的伺服器方面，目前一個機櫃提供虛擬機器的密度達到2,000臺，以大型企業為主要使用者。另外，在儲存空間方面，已結合Azure混和雲方案，若儲存空間不足時，可以利用混和雲擴充儲存空間。
CPS鎖定1至4個機架的相關應用，在每一個機架中，具有32臺伺服器，其中24臺，可用做工作負載，其餘6臺，可用於叢集管理、針對虛擬機器來運作System Center等。
另共有512個核心，支援英特爾Xeon E5-2650 v2系列伺服器級處理器，而可以使用的儲存容量為282TB、連接各機架的速率為1秒鐘達1,360GB、機架內部的連接速度為1秒鐘達560GB，而連接外部的連線速度則為一秒鐘達60GB。
不過，簡志偉也說，目前在CPS的硬體方面，第一波和戴爾合作，但是接下來會開放其他伺服器廠商加入。
微軟表示，CPS已搭載整合式防毒軟體、虛擬機器的Fabric based備份機制、災難復原、Orchestrated Patching、監控功能與REST-based API等。
此外，梁匯華表示，微軟負責行銷與銷售，而戴爾則負責提供硬體與基礎架構，預計於11月4日正式上市。
除了微軟之外，各家廠商也紛紛推出整機式解決方案，如VMware在今年8月舉行的VMworld2014大會上推出了EVO:RAIL，底層為2U/4節點的伺服器，預先搭載了vSphere、Virtual SAN、vCenter Server等軟體，由VMware軟體提供所有服務。另外，Nutanix也於今年10月推出了全快閃記憶體超融合式平臺（All-Flash Hyper-Converged Platform），新增了Metro Availability功能，主要提升在虛擬機器叢集中，資料儲存區（Datastore）的遠距離擴展能力，如可以應用至兩個距離400公里以上的資料中心。
",https://www.ithome.com.tw/news/92012,"新聞,微軟,戴爾,Dell,Cloud,私有雲"
91848,34,2014-10-29,Docker社群達人教你快速踏出Docker的第一步,上手Docker的第一步，得先了解Docker建立Container標準化的關鍵，Docker臺北社群召集人郭韋廷建議，先了解Docker映象檔，再開始動手試試看," 上手Docker的第一步，得先了解Docker建立Container標準化的關鍵，Docker臺北社群召集人郭韋廷建議，也就是要先了解Docker映象檔的運作原理，再開始動手試試看。
Docker是一個Client-Server架構的應用程式，在一個Docker執行環境中，包括了Docker用戶端程式、和在背景執行（Daemon）的Docker伺服器（也稱為Docker Engine），另外還有將Container封裝後的Docker映象檔，用來儲存映象檔的Registry服務。官方提供的映象檔Registry服務就稱為Docker Hub，這是類似Github程式碼Repository儲存服務的映象檔Repository儲存服務。
安裝Docker之後，會提供了一個命令列的用戶端程式來和在背景執行的Docker伺服器溝通。開發者可以直接從Docker Hub下載Docker映象檔（Docker pull指令），再執行（Docker run指令）就可以用這個映象檔來建立一個Container。
郭韋廷解釋，Docker映象檔是一種分層堆疊的運作方式，採用了aufs的檔案架構。要建立一個可提供應用程式完整執行環境的Container映象檔，要先從一個基礎映象檔（Base Image）開始疊起，一層層將不同Stack的Docker映象檔疊加上去，最後組合成一個應用程式所需Container執行環境的映象檔，而每一個Stack也都是可以會匯出成（Docker commit指令）一個映象檔。
舉例來說，假設一個網頁執行環境需要有OS、Apache網站伺服器、MySQL資料庫、Ruby執行環境等不同的Stack。
像郭韋廷最常用的基礎映象檔就是ubuntu映象檔，這是用來建立Container的根目錄架構，若採用了不同的OS映象檔，就會變成是那個OS的目錄架構。
第一個動作就是先下載一個ubuntu的基礎映象檔。只要在命令列輸入sudo docker pull ubuntu，Docker安裝完成後預設pull指令都是存取Docker Hub服務。這個指令會從Docker Hub上下載名稱為ubuntu的映象檔到本機端。
接著，要將新的一層Stack加入ubuntu基礎映象檔中，例如Apache，得先用Docker執行（Docker run指令）這個基礎映象檔，來建立這個映象檔的Container，然後在Container中安裝Apache，安裝完成後，再將Container打包成另一個新的映象檔。
第二層繼續反覆這樣的程序，這時候就是直接從ubuntu-Apache所建立的映象檔開始安裝下一層的MySQL程式，同樣也是先執行ubuntu映象檔，再執行MySQL安裝程序。
說來複雜，實際執行過程，執行映象檔和安裝Apache是一行指令，命令Docker從ubuntu映象檔來建立新的Container同時在這個Container內執行Apache安裝指令。
郭韋廷表示，其實當Apache安裝完成後，Container的壽命也跟著結束了，除非是Daemon式的背景程式，那麼這個Container才會一直存活。就算只是在Container裡面執行一個ls（列出目錄架構）的指令，如sudo docker run ubuntu ls -1。Container也是在ls–l指令結束後也同時關閉了。一行指令就建立了一次Container，也關閉了這個Container。
這段指令是用sudo docker來執行（run）ubuntu這個映象檔，以建立一個ubuntu的Container環境，然後在這個Container中下達ls–l列出系統目錄的指令。當ls- l回傳了Container內ubuntu的檔案目錄，並呈現在螢幕畫面後，ls–l指令結束，這個ubuntu系統的Container壽命也就結束了。
當一個Container結束後，Docker會將這個Container打包成一個暫時性的映象檔，並用一個唯一的Hash值來命名，這個映象檔則儲存在本機端的Docker暫存目錄中。例如剛剛啟用ubuntu映象檔建立Container來安裝了MySQL，裝妥後，這個Container也結束了，而裝妥MySQL後的Container內容則自動打包成一個暫時性的映象檔。我們就可以將這個映象檔匯出成一個長期使用的映象檔，並給予一個名字。
一個Stack就是一層Container映象檔
Docker提供了一個Commit指令，使用Commit指令就可以將Hash值所對應的映象檔，匯出成新的映象檔。郭韋廷表示，Docker之所以用Commit指令，是類似在Github服務用Commit來更新程式碼的意思，是採取差異更新的方式，以原來的ubuntu映象檔為基礎，來建立這個ubuntu-MySQL映象檔。反覆執行Docker來建立新的Stack映象檔時，就如同在原有ubuntu映象檔上疊上一層層新的Stack，最後的映象檔就會變成如ubuntu- Apache-MySQL-Ruby的映象檔。不過這個映象檔的名稱可以自訂，不用像這裡為了說明而以這樣複雜的方式來稱呼。
因為建立Container後是在記憶體中運作，寫在Container內的資料，在Container結束後就消失了，所以，Docker也提供了一個Data Volume參數（docker -v參數），可用來將外部目錄對應到Container內部目錄。
當Container內的程式將資料寫到這個內部目錄時，就等同於將資料寫到所對應的外部目錄。
例如可以設定要執行一個MySQL映象檔時，同時將一個本機端（或雲端）的目錄路徑，設定成Container內部的/mysql目錄，作為MySQL資料庫檔案的所在位置。這樣應用程式每次新增資料到MySQL資料庫時，寫入了Container內的/mysql目錄，也等同於寫入了外部所指定的本地端目錄。當MySQLContainer結束後，外部資料的不會隨著Container終止而消失，下次再度啟動MySQL Container，只要內部/mysql也對應到同樣的本地端目錄，就能取得先前所儲存的資料。
一行指令就能完成執行環境所有部署
因為安裝每一個Stack的程式時，通常也需要這個Stack程式所需的環境配置如指定對應目錄、設定對外溝通的通訊埠等，所以，Docker提供了Dockerfile這個設定檔案，可以將這些建立映象檔的指令全部寫在Dockerfile中，Docker能自動依據這個Dockerfile來建立映象檔（Docker build指令）。這個Dockerfile就等於保存了建立應用程式執行環境所需的所有指令和參數設定，這正是Docker解決開發和維運溝通的最大利器。雙方只要檢視Dockerfile就能清楚知道應用程式目前的執行環境配置。
因為Docker Hub服務不只儲存映象檔，也能連結到Github服務上的Dockerfile，來自動建立映象檔。Dockerfile檔案直接儲存在Github上，就具備了版本控管能力。
開發者不只可以在Docker Hub上搜尋到符合需要的映象檔，例如像ubuntu-Apache-MySQL這樣的組合，Docker Hub也會提供這個映象檔對映到在Github上的Dockerfile。開發者直接Docker命令列指令，一個命令就能從Docker Hub上下載Dockerfile，或載入Github上的Dockerfile，Docker會自動依據Dockerfile內的指令，一一將建立起完整的Docker映象檔，連自己手動下載基礎映象檔都不用。運用Dockerfile記錄所有配置後，只要一行Docker指令就能完成應用程式執行環境的所有部署，你也快來試試看吧。
 

Docker Hub結合GitHub後，只要下載Dockerfile設定檔，就能依據Dockerfile內的腳本指令，自動一步步建立應用程式所需的執行環境映象檔。圖片提供／Docker

 
郭韋廷Docker操作範例
影片網址：http://goo.gl/rO2NlX

 

相關報導請參考：
「Container三部曲（三）IT架構的新奈米革命：Container OS」、
「Container技術三部曲（二）不只快，還要更快──臺灣Docker應用案例的啟發」、
「Container技術三部曲（一）迎接下一個雲端火紅技術Docker」

",https://www.ithome.com.tw/news/91848,"新聞,Docker,Container,LXC,Linux,DevOps,輕量級虛擬化"
91839,34,2014-10-29,Docker風潮席捲IT世界,Docker一問世，IaaS、PaaS等雲端公司就紛紛搶攻Docker商機，而受到Docker興起所威脅的VMware與微軟，也化敵為友加入Docker陣營。Docker不僅是國際知名網路公司搶著用，接下來也將席捲企業IT的世界," 當Linux之父Linus Torvalds在2013年2月18日張貼了Linux核心3.8版正式發布的訊息時，只是簡單地提到為了等待一些小更新釋出，而延後到華盛頓生日這天才釋出，讓3.8版變成了一個總統版釋出。但他在公告上刻意沒提到的是，在這個版本對Control Group和Namespaces機制的強化，促成了開源社群努力多年的Linux Container技術（LXC）得以實現。
這個LXC技術不只顛覆了開發者打造應用程式的思維，推翻了MIS舊有系統維運模式，新興的搶手職務DevOps因此得重新定義角色，雲端IaaS和PaaS市場版圖更瀰漫一股沒跟上就淘汰的洗牌壓力，更撼動了VMware和微軟聯手把持的虛擬化帝國，微軟還承諾要讓Windows也能和Linux支援同一套Container標準。Container掀起了傳統IT架構下個十年的變革之路。
Google每周啟用20億個Container
許多網路服務業者或雲端平臺紛紛支援Container，如Amazon、微軟Azure、IBM Softlayer、Rackspace、紅帽OpenShift、百度、Google、Heroku、OpenStack等。甚至有不少網路業者大量使用Container來執行自家服務，Google基礎架構部門副總裁Eric Brewer在6月初的Dockercon14會議上透露，Google一周就要啟用20億個Container。許多眾所皆知的Google服務都是在Container內執行。
不過，變革的源頭並不只是因為Container技術本身，更關鍵的是一家去年3月才創立的美國軟體公司Docker一手打造的Container標準化平臺。
Docker創辦人暨技術長Solomon Hykes在今年6月首屆Dockercon技術大會上，引述了物件導向語言之父Alan Kay對網際網路的期待，有一天應該發展成一個全由虛擬機器組成的虛擬網際網路（A virtual internet of virtual machines）。Solomon Hykes發願要用Docker平臺實現這個藍圖，「現在正是讓網際網路升級的時候到了。」他說。
Container是以應用程式為中心的虛擬化
Solomon Hykes憑什麼這麼說？這要從Container技術談起。不同於常見的傳統虛擬化技術如vSphere或Hyper-V是以作業系統為中心，Container（或可稱為軟體貨櫃）技術則是一種以應用程式為中心的虛擬化技術。兩者都是為了要更方便地將一套應用程式所需的執行環境打包起來，來能簡化複雜的IT架構方便管理、移動或部署各種應用程式，而不需要讓開發人員自行管理執行這個應用程式所需的繁多目錄和大量檔案。
傳統虛擬化技術從作業系統層下手，目標是建立一個可以用來執行整套作業系統的沙箱獨立執行環境，習慣以虛擬機器（Virtual Machine）來稱呼。虛擬機器用軟體模擬出vCPU、vRAM等實體伺服器的功能，讓作業系統看起來是身處於實體機器中，所以，可以在這個虛擬機器中安裝各種作業系統，接著安裝應用程式所需的執行環境，如網站伺服器、資料庫程式、中介軟體等。傳統的虛擬化技術能將軟體和硬體的相依關係切開，讓軟體盡可能地不用綁定於特定廠牌或規格的硬體。
傳統虛擬機器的優點是安全性高，對作業系統而言，看起來就像是在一臺正常的實體機器中，就算多個虛擬機器在同一臺實體伺服器中執行，虛擬機器間也不會知道彼此的存在。這也就出現了Host OS和Guest OS的架構，負責執行虛擬化平臺的是Host OS，而在虛擬化平臺內建立的虛擬機器內則是執行Guest OS。
但是將作業系統打包進虛擬機器中的後果是，任何虛擬機器都得先裝妥一套作業系統後才能開始執行應用程式，不僅導致虛擬機器的建立速度，受限於作業系統的開機速度，得等上數十秒到數分鐘才能新增一個虛擬機器。虛擬機器的映象檔所需容量也不小，即使要執行的程式碼只有10KB，也得安裝一整套上百MB的作業系統軟體才行。執行作業系統本身也得消耗不少的運算資源，倘若一臺實體伺服器內要執行100個虛擬機器，就等同於要執行一百套Guest OS，即使虛擬化技術有許多改良來解決運算資源的利用率，但Guest OS仍瓜分了不少應用程式能用的實際運算資源。
在OS層內建立虛擬環境
電腦科學家們早在現代虛擬化技術成熟前，十幾年前就開始嘗試發展另一種虛擬化技術Container，不是在OS外來建立虛擬環境，而是在OS內的核心系統層來打造虛擬機器，透過共用Host OS的作法，取代多個Guest OS的功用。Container也因此被稱為OS層虛擬化技術。
例如1982年出現的Unix系統內建chroot機制、1998年的FreeBSD jails、2005年出現的Solaris Zones和OpenVZ，或像是Windows系統2004年就有的Sandboxie機制都屬於在作業系統內建立孤立虛擬執行環境的作法，都可稱為是Container的技術。
Container直接將一個應用程式所需的相關程式碼、函式庫、環境配置檔都打包起來，並建立了嚴格的資源控管機制來分配Host OS上的系統資源，避免因這個Container占用資源或當機時，而影響了Host OS或其他Container的執行。
因為Container是利用系統核心控管機制來分配Host OS資源，也就不需要另外安裝Guest OS個別管理。也就是說，當一臺實體伺服器內建立了100個Container時，這100個Container共用同一個Host OS的核心，再利用OS內建機制來分配每一個Container可用的資源。因為Container不需要執行OS，因此，一臺實體伺服器可以執行的Container數量，遠遠高於傳統虛擬化技術的虛擬機器，甚至可以有數倍的差異。一臺有能力執行100個測試環境VM的實體伺服器，往往能執行2、3百個用Container提供的測試環境。這批Container的映象檔案所需儲存空間，也因不用安裝整套OS而比用VM映象檔來得少。不論處理器資源或儲存空間的利用上，Container技術都遠優於伺服器虛擬化技術。
開頭提到在總統版Linux在核心內建的Control Group和Namespaces機制，正是用來分配Host OS運算資源的機制。
Namespaces是系統資源的使用名單，記錄了系統資源要分成多少份，每一份的名字是什麼，方便呼叫和取用特定一份的資源。就像辦公室的座位表一樣，不只是員工姓名清單，也記錄了每一個姓名所在的位置，甚至聯絡這個員工的分機。一個Container會擁有自己唯一的Namespaces名稱，來區分身份，而透過Namespace清單，這個Container不用知道其他Container的存在也能分配資源，就像是高一新生入學後，同班學生都還不認識時，老師可以透過點名簿知道每一個人的姓名和入學考試成績一樣。Host OS可以透過Namespaces來分辨每一個Container，而Container間也可以不知道對方的存在。
有了名單機制後，就可以利用Control Group來管理每一個名字可用資源的權限。Control Group可以管制記憶體、檔案快取、CPU使用、磁碟I/O等，也可追蹤這些資源被使用的情況，安排不同資源存取的優先順序，甚至是凍結程式的執行。LXC技術就是利用Control Group來管理一個Container使用各種資源的權限。結合了Namespaces和Control Group，就可以很容易地在Linux內建立一個虛擬的應用程式執行環境，讓應用程式看起來是在一個孤立環境中執行。
不過，早在Linux核心完善Namespaces和Control Group機制之前，已有不少PaaS服務業者看到了在OS層內建置虛擬機器的好處，也紛紛發展自家Container技術，例如Heroku、Parallels、Pantheon，連Red Hat的OpenShift也有類似技術。Docker公司的前身dotCloud正是其中一家PaaS業者。
而Google更是早從2006年就開始發展自己的Container技術，也開發了用來控管Linux資源的程式，稱為Process Containers，這個技術隔年更名為Control Group，變成了Linux核心的功能之一，這就是Control Group的第一版。Google可說是Linux Container的技術源頭之一。後來Google將自家Container技術命名為lmctfy（Let Me Contain That For You），但至今仍是測試版階段。
儘管許多人參與了Control Group機制的開發，但在總統版Linux核心3.8版釋出之前，Control Group還無法控管到核心記憶體資源，因此所建立的Container還不穩定，或是需要自行開發許多搭配的資源監測和管控機制才能有效建立沙箱環境。
Linux核心支援促成Container標準化
直到去年2月，Control Group增加了核心記憶體管理能力，不需要開發額外機制，只要利用Linux核心指令，就能實現Container環境，也讓LXC真正有機會普及每一個Linux環境。所有的Linux從此開始有了一套共同的LXC技術。Container技術的發展，也往標準化的路上邁進了一大步。不過，因為各家Container技術實作仍有不同，所以還是缺乏一套所有人都支援的標準作法。
出乎意料地，3.8版釋出才一個月，dotCloud公司就在2013年3月公開了一個從2010年開始進行的內部專案Docker，並以開源釋出程式碼。這是docCould開發自家PaaS服務時，為了利用Linux Container技術管理PaaS上的應用程式所開發的平臺。
Docker執行長Ben Golub表示，在2000年以前，應用程式有三大特性，包括了應用程式預期會長期存活、且以整套應用建置在單一環境中運作的方式設計，也只部署在一臺伺服器上。
但是到了2014年，「傳統應用程式的本質已經徹底改變了。」Ben Golub說，今日的應用程式總是持續且反覆地開發新版本，也大多由一堆鬆散耦合的元件組成，而且會部署在多臺伺服器上。
他說，要把不同開發階段或多重用途的程式，部署到不同的硬體或雲端環境中，是一個很大的挑戰，Docker正是dotCloud利用Container技術來客服這個挑戰的平臺。
目標是打造Container生態系
Ben Golub說：「Docker不只是一項Container技術，而是要打造一個Container生態系，讓應用程式可以在任何地方執行。」Docker要用Container技術讓應用程式具有相同的封裝方式、啟動方式、存取方式，不用修改就能在任何支援Docker的平臺上執行。因此，「Docker是一個可以來建置、移動和執行分散式應用程式的開放平臺」他說。
就像是因為出現了標準化的貨櫃，擁有統一的尺寸規範、一致的固定孔洞位置、封裝方式，讓貨櫃可以成為任何貨物透過各種方式、不論是汽車、火車、輪船、飛機都能載送的共通容器。
Docker專案一發表，立刻獲得廣大迴響，Linux作業系統業者紛紛支援，包括了Redhat、ubuntu、Debian、Fedora、CentOS、CoreOS，幾乎涵括了所有主流Linux版本，連雲端作業系統OpenStack都支援。許多大型雲端服務業者也相繼採用，如Amazon、微軟Azure、IBM Softlayer、Rackspace、紅帽OpenShift、百度、Google、Heroku等。dotCloud公司乾脆以Docker為名，另外成立新公司力推。
2014年6月，Docker公司發表了Docker 1.0正式版，也舉辦首次技術大會。到場分享Google自家Container發展經驗的Eric Brewer都表示，即使Google使用Container多年，也真想實現Docker這樣的運用，讓Container非常容易使用，而Docker的確做到了。也因此，Google決定大力支持Docker，發起了一個打造Docker Container管理工具的開源計畫Kubernetes，要將Docker技術延伸到伺服器叢集上使用。
就連傳統虛擬化技術的兩大龍頭VMware和微軟，今年都相繼宣布擁抱Docker，VMware在8月的VMworld上宣布擁抱Docker，將在vSphere內支援Docker，讓虛擬機器內更容易執行Docker，例如用虛擬機器來強化Container的安全性。相關VMware虛擬化管理平臺也能和Docker的API溝通，要將Docke延伸到VMware虛擬化技術生態系中。
而微軟執行長Satya Nadella也剛在10月中宣布，未來要在Windows Server中內建Docker，讓Docker不只能調度Linux上的Container，也能管理和建立在Windows內的Container。
為何連Container技術源頭之一的Google，都稱讚Docker實現了Google一直想做卻還沒做到的事？
Docker映象檔是實現Container標準化的關鍵。Docker將Container打包成一個映象檔檔案，這個檔案裡包括了所有建立Container時需要的程式和設定資訊。只要在其他支援Docker的環境中啟用這個映象檔，就能建立一個一模一樣的Container環境。曾為矽谷鐵道系統公司開發出CI（持續整合）平臺的悠邁科技解決方案架構師蘇旭昱表示，Docker打包的Container映象檔因此變成可以通行無阻的應用程式標準容器。
Docker提供了一個類似Github版本控管服務的Docker映象檔Repository服務，稱為Docker Hub（也稱為Registry服務），可以讓開發人員發布映象檔和這個映象檔的Dockerfile。其他人就可以再利用這些映象檔，或參考Dockerfile中的環境部署指令設計自己的映像檔。
Docker是一個Client-Server架構的應用程式，安裝Docker之後，會提供了一個命令列的用戶端程式來和在背景執行的Docker伺服器溝通，Docker也完整支援RESTful API，可讓開發人員透過API執行所有Docker指令。甚至Docker還提供了一個腳本語法描述的Dockerfile設定檔，可以用來紀錄和描述建立Docker映象檔的每一個指令。不用複製Docker映象檔，只憑Dockerfile也可以自動建立一個和原來一模一樣的Container的映象檔。甚至可以從Registry服務下載一個映象檔，再依此來建立下一個映象檔，例如從ubuntu的映象檔中，加入MySQL程式，來建立一個內有ubuntu和MySQL的映象檔，用來啟用Container。
Ben Golub透露，未來Registries服務將推出可在企業內部部署的套裝版，不只可以用來儲存私有Docker印象檔，也能建立私有的Docker工作流程，讓企業自建內部的Docker映象檔管理平臺。
Docker最大的特性是快，建立Container的速度不到1分鐘，甚至只要數秒鐘。遠比動輒要數分鐘或是數十分鐘才能啟動的虛擬機器來得更快。幾個月前開始導入Docker的時間軸科技研發中心主任工程師戚務漢實際展示了他們已導入Docker的新網站系統，除了在從網路下載基礎印象檔資料花了不少時間外，光是啟動一個內含Ubuntu系統、MySQL、Ruby等網頁所需執行環境的Container，不到一分鐘。
實現基礎架構程式化
曾擔任過一年Devops職務，現在負責系統維運的時間軸科技研發中心主任工程師陳俊廷表示，更大的優點是Docker實現了Infrastructure as code的精神（基礎架構程式化）。因為Dockerfile記錄了建置應用程式所需執行環境的指令和參數，解決了過去開發人員難以和維運部門溝通的困難，彼此有一套可以追蹤記錄的機制，甚至Dockerfile還可以結合版本控管功能，可以隨時回到前一版本。
不只可以改善開發團隊和維運人員的協同工作，臺北榮總醫院資訊工程師鄭淳伊指出，Docker更大的影響是讓IaaS平臺只要支援Docker，就能夠執行封裝在Container中的任何應用程式，IaaS很容易就能具備了PaaS服務的能力。鄭淳伊曾在宏碁eDC機房擔任維運人員，也在玉山銀行參與系統開發超過5年，他大膽預測，甚至，Docker可能會讓PaaS服務消失，這也是為何IaaS業者或PaaS業者莫不積極擁抱Docker的緣故，沒有跟上的人會被淘汰。
根據Docker官方統計，到今年8月為止，參與Docker開源專案開發者超過6百人，已有超過2萬個開源計畫使用Docker，眾多開發者在Docker Hub網站上也發布了超過3萬個Docker映象檔。
不過，因為Docker目前仍只能在單一主機上執行，需要搭配第三方工具，如Google的Kubernetes工具，才能將Container快速轉移到其他伺服器中，或是在伺服器叢集內移動。
下一步，Ben Golub表示，將聚焦在叢集式多引擎架構和雲端Orchestration協同機制，也希望強化內容區塊建置能力、網路和儲存管理機制、映象檔和使用者安全，並擴大和第三方技術或工具的整合。推出不到2年的Docker，距離實現虛擬網際網路藍圖的大夢，仍有很長一段路。
 

Docker發布後，Linux作業系統業者紛紛支援，幾乎涵括了所有主流Linux版本，連雲端作業系統OpenStack都支援。許多大型雲端服務業者也相繼採用，如Amazon、微軟Azure、IBM Softlayer、Rackspace、紅帽OpenShift、百度、Google、Heroku等。

 

時間軸科技研發中心主任工程師陳俊廷表示，Docker實現了Infrastructure as code的精神（基礎架構程式化），用Container來記錄各式各樣的環境配置，解決了過去開發人員難以和維運部門溝通的困難。

 
相關報導請參考：
「Container三部曲（三）IT架構的新奈米革命：Container OS」、
「Container技術三部曲（二）不只快，還要更快──臺灣Docker應用案例的啟發」、
「Container技術三部曲（一）迎接下一個雲端火紅技術Docker」
",https://www.ithome.com.tw/news/91839,"新聞,Docker,Container,LXC,Linux,輕量級虛擬化"
91847,34,2014-10-28,10個Q&A快速認識Docker,Docker和虛擬化技術有何不同？Container和虛擬機器有什麼不同？10個問答讓你快速認識什麼是Docker," 不論是Google、Amazon、微軟、VMware都紛紛擁戴，加入Docker和Container所掀起的新世代雲端虛擬化行列，這2項技術成為了IT界的新顯學。Docker和Container到底是什麼？以下10個Q&A告訴你。
Q1：Container技術和伺服器虛擬化是一樣的技術嗎？
A：不是。兩者雖然都屬於虛擬化的技術，目標都是為了將一套應用程式所需的執行環境打包起來，建立一個孤立環境，方便在不同的硬體中移動，但兩者的運作思維截然不同。簡單來說，常見的傳統虛擬化技術如vSphere或Hyper-V是以作業系統為中心，而Container技術則是一種以應用程式為中心的虛擬化技術。
傳統虛擬化技術從作業系統層下手，目標是建立一個可以用來執行整套作業系統的沙箱獨立執行環境，習慣以虛擬機器（Virtual Machine）來稱呼。而Container技術則是直接將一個應用程式所需的相關程式碼、函式庫、環境配置檔都打包起來建立沙箱執行環境，為了和傳統虛擬化技術產生的虛擬機器區分，Container技術產生的環境就稱為Container。
Q2：一般常見的虛擬機器和Container有何不同？
A：最明顯的差別是，虛擬機器需要安裝作業系統（安裝Guest OS）才能執行應用程式，而Container內不需要安裝作業系統就能執行應用程式。Container技術不是在OS外來建立虛擬環境，而是在OS內的核心系統層來打造虛擬執行環境，透過共用Host OS的作法，取代一個一個Guest OS的功用。Container也因此被稱為是OS層的虛擬化技術。
Q3：為何Container是輕量級虛擬化技術？
A：因為Container技術採取共用Host OS的作法，而不需在每一個Container內執行Guest OS，因此建立Container不需要等待作業系統開機時間，不用1分鐘或幾秒鐘就可以啟用，遠比需要數分鐘甚至數十分鐘才能開啟的傳統虛擬機器來的快。
Q4：Container技術是全新的技術嗎?
A：不是，早在1982年，Unix系統內建的chroot機制也是一種Container技術。其他如1998年的FreeBSD jails、2005年出現的Solaris Zones和OpenVZ，或像是Windows系統2004年就有的Sandboxie機制都屬於在作業系統內建立孤立虛擬執行環境的作法，都可稱為是Container的技術。
直到2013年，dotCloud這家PaaS服務公司開源釋出了一套將Container標準化的平臺Docker，大受歡迎，所以，dotCloud決定以Docker為名成立新公司力推。
Q5：Docker如何實現Container標準化？
A：Docker採用了aufs檔案系統來設計一個可以層層堆疊的Container映象檔，將Container內的所有程式（包括應用程式、相關函式庫、設定檔），都打包進Docker映象檔，並且提供了一個Dockerfile設定檔來記錄建立Container過程的每一個步驟包括參數。只要在任何支援Docker平臺的環境中，就可以從這個映象檔來建立出一個一模一樣的Container來執行同一個應用程式。如此一來，應用程式等於是可以透過Docker映象檔，或甚至只需要Dockerfile，就能將程式執行環境帶著走，移動到任何支援Docker的環境中。Docker公司也釋出API，可以用來控制所有的Container相關指令，任何人只要使用同一套Docker，就等於有了同一套管理和建立Container的方法，也就等同於將Container運用標準化了。
Q6：一個Container映象檔內可以安裝多少應用程式？
A：一個Container的映象檔內可以安裝多支程式，例如同時安裝Ubuntu、Apache、MySQL、Node.js、Ruby等。不過，Docker官方建議，一隻程式安裝在一個Container內，再把這些Container疊起來提供一個完整的服務。
Docker稱這是一種Microservices（微服務）的新軟體架構，將組成一個應用系統的每一個Stack，拆解成許多小型服務，例如Apache服務、MySQL服務、Node.js服務、Ruby服務，每一個服務都是包在Container裡的一隻程式，例如MySQL服務就是部署在Container內的MySQL。
這麼做的好處是可以建立一個鬆散耦合的彈性應用程式架構，也能輕易地抽換其中一個Container，例如要升級MySQL，只需要重新載入新版MySQL的Container映象檔，就可以完成資料庫升級，不用將整套應用系統停機。
Q7：Container內不是不需要OS，為何需要OS的基礎映象檔？
A：OS基礎映象檔的用途是讓Container擁有這OS的檔案系統，例如使用ubuntu基礎映象檔就可以讓Container建立ubuntu的根目錄架構，而不是用來執行一個OS執行實例。
Q8：Docker對Devops有何幫助？
A：因為Docker透過Dockerfile來記錄建立Container映象檔的每一個步驟，可以將建立應用程式執行環境的過程和配置參數，完整地記錄下來。開發人員和維運人員之間可以利用Dockerfile來溝通對執行環境的討論。甚至結合版本控制服務如GitHub，可以讓Dockerfile具備版本控制功能，能將基礎架構程式化（Infrastructure as code）來管理。
Q9：可以在Windows Server環境中執行Docker嗎？
A：還不行。目前Docker只能在Linux平臺上執行，但是微軟10月中剛宣布要在下一波Windows Server改版時內建Docker引擎，未來同一份Docker映象檔能否跨Linux和Windows OS，還需待微軟揭露更多細節才能得知。
Q10：在臺灣，如何找到懂Docker技術的人？
A：目前Docker公司還未在臺設點，但有一個Docker Taipei社群，成員截至10月有383人。
Docker Taipei也預計配合Docker總公司舉辦的全球HackDay活動，在11月1日舉辦臺北場HackDay。參加作品將直接發布到美國和全球Docker開發者一起評比，獎品是明年到美國參加Docker技術大會的資格。
 

Docker臺北社群約有383人，是臺灣目前唯一的Docker技術社群。預定11月1日舉辦Docker HackDay臺北場活動。圖片提供／Docker

 

輕量級虛擬化Container技術則是一種以應用程式為中心的虛擬化技術，不需要安裝Guest OS。圖片提供／Docker

 

相關報導請參考：
「Container三部曲（三）IT架構的新奈米革命：Container OS」、
「Container技術三部曲（二）不只快，還要更快──臺灣Docker應用案例的啟發」、
「Container技術三部曲（一）迎接下一個雲端火紅技術Docker」

",https://www.ithome.com.tw/news/91847,"新聞,Docker,Container,LXC,Linux,DevOps,輕量級虛擬化"
91831,34,2014-10-28,HP推SDN雲端網路套件 鎖定雲端服務供應商及IDC企業,HP新推的SDN雲端網路解決方案DCN，採分散式雲端架構，數分鐘可自動建立雲端SDN網路架構," 繼惠普（HP）於今年9月推出第一家SDN線上應用商店後，近日在2014年SDN暨OpenFlow世界大會（SDN & OpenFlow World Congress 2014）上，HP緊接新發布SDN雲端網路解決方案（Distributed Cloud Networking，DCN），透過採行分散式雲端基礎架構，使得服務供應商和大型資料中心業者，更加容易實現部署SDN雲端網路環境。
根據HP表示，此DCN雲端網路解決方案，主要包括了用來簡化網路管理配置的虛擬化服務目錄（Virtualized Service Directory）、運算和網路資源（Compute and Network Resources）、分散式服務控制器（Distributed Services Controller），以及加入基於開源技術的分散式虛擬路由和交換器（Distributed Virtual Routing and Switching），可偵測並計算環境改變，確保網路連結層可適應不斷變化的網路服務需求。
而透過該DCN解決方案，HP也表示，可大幅縮短企業部署雲端網路應用的時間，不同於過去企業得花上數個月的建置工作天，現在只需花上數分鐘就能部署完成雲端的SDN網路架構。
此外，對於企業採用的公有雲、私有雲或混合雲的資料中心，網路管理員也能通過中央位置來控制分散式的雲端網路環境，並也有助於服務供應商方便採用NFV應用。而目前此DCN解決方案也已正式釋出。
HP也宣布加入新成員共同致力於OpenNFV專案開發。OpenNFV專案是由HP於今年2月推出的NFV開源專案，主要用來制定一個標準NFV參考架構，並讓電信商可使用HP產品作為自有架構基礎來使用。
而參與OpenNFV專案的企業也可獲得NFV軟件開發工具包、API和各項資源，提供建立和測試部署應用環境。
目前包括了Brocade、Intel、Genband、Mellanox Technologies、SK Telecom、Wind River、6Wind、Spirent、Israel Mobile 以及Media Association等IT廠商及電信商都是該專案的成員。
HP表示，透過HP和其合作夥伴持續開發測試中的NFV概念性驗證，目前已經有超過20個以上的應用案例。
除了HP之外，Dell也在同一時間，發布了自家第一款NFV開放平臺。Dell表示，該NFV平臺主要建立於Dell伺服器、服務、網路和軟體上，可與企業合作夥伴的軟體相結合，並也開放軟體給予所有將它使用於Dell系統的服務供應商來加以使用。
",https://www.ithome.com.tw/news/91831,"新聞,HP,惠普,SDN,Cloud"
91034,34,2014-09-23,臺灣首次OpenStack Day技術大會登場，官方專家來臺揭露最新進展,OpenStack社群經理Tom FiField表示，臺灣技術日是全球少數大型技術日活動之一，這是一個展現OpenStack威力的日子，人們因社群精神而聚集。這正是OpenStack如此成功的原因," 首次由OpenStack基金會、iThome與迎廣科技在臺共同主辦的OpenStack技術大會今天（9/23）登場，參加人數超過900人，OpenStack基金會派出負責協調全球開發者的OpenStack社群經理Tom FiField來臺介紹OpenStack的最新趨勢。
Tom FiField是官方OpenStack維運指南《OpenStack Operations Guide》一書的作者之一，也是澳洲國家級研究計畫的雲端架構顧問與雲端團隊領導人，他設計了澳洲國家數位科學研究計畫打的雲端平臺架構，可供研究人員調度澳洲多個資料中心的運算資源。
現世4年的OpenStack，不論軟硬體IT龍頭廠商都紛紛加入OpenStack社群或提供贊助，包括了Intel、AMD、IBM、Cisco、Dell、HP、VMware、Redhat、Ubuntu、SUSE、VMware、EMC、Oracle、SAP、Seagate、WD、NetApp、NEC、Hitachi。電信或網路業者美國AT&A、法國Orange電信、RackSpace、DreamHost甚至是電子商務業者Yahoo、網路支付服務Paypal等。臺灣工研院、廣達、宏碁也有參與。
全球使用者社群超過75個，臺灣也早在2011年12月2日，就由工研院發起成立了臺灣OpenStack使用者社群。全球超過850家企業或組織加入了OpenStack基金會來參與OpenStack的開發，個人會員也高達9,500人。
也因此，OpenStack改版速度飛快，每隔半年就會舉辦一次高峰會議同時釋出一個新版本，以下是Tom FiField在會前分享的OpenStack最新趨勢，今天來不及到場參加者也可以快速掌握今年11月下一版本OpenStack的最新特色。
 
問：OpenStack和常見虛擬化平臺有何不同？
答：虛擬化平臺是只是商用雲端平臺上的其中一個模組。在OpenStack的部署上，也可使用常見的虛擬化Hypervisor，如KVM或ESX，不過，也有人試圖用新興的Container技術Docker，來取代hypervisor的功能。不管採用什麼技術，IT必須心中清楚了解虛擬化架構的目的，是為了協助IT部門改善伺服器的利用率，提高效能和降低成本。但是，如果企業所用的雲端架構不夠敏捷，終端使用者要部署虛擬機器仍舊得花上數周，甚至數個月。
藉由API來存取資料中心的運算、儲存和網通資源，並搭配自助式儀表版或命令列的操作方式，OpenStack可以協助IT部門快速提供IaaS服務。
 
問：你認為OpenStack將會如何改變雲端生態和市場？
答：OpenStack已經改變了雲端產業市場。只要觀察哪些使用OpenStack打造的公有雲服務，都是因為這個專案才得以出現。在這個生態系統中，現在已出現了數百家廠商，提供服務給數千家企業或機構，OpenStack也推出了OpenStack市集（http://openstack.org/marketplace），協助使用者客觀地比較這些廠商提供的服務。
更重要的是，多家大型企業對OpenStack的投資超過10億美元，甚至策略性地併購其他公司來強化OpenStack的能力。我自己也很興奮地看到越來越多臺灣企業加入，例如廣達旗下雲達公司(Quanta Cloud Technology)最近成為了OpenStack基金會的會員，這就一個本地產業展現創新威力的好例子。
然而，我們還在尋找對IT基層有更多不一樣的改變。傳統只是被動地消費軟體的維運模式正在轉變。越來越多負責維運OpenStack雲端平臺的系統管理員（現在也稱為Dev/Ops專業人士），將各自的使用經驗貢獻回他們所參與的專案。我們稱這種類型的使用者為超級使用者（Superuser），他們是過去一年來，OpenStack大幅強化維運能力最重要的關鍵。
基於上述原因和其他更多的理由，OpenStack已經大大地影響了企業思考雲端戰略的方式。

問：你看過最令人興奮的OpenStack應用為何？
答：OpenStack的美妙之處是，這是一個廣泛且根本性的技術。因此，可以出現任何形式的使用案例或應用模式，真的沒有限制。像歐洲粒子加速研究中心CERN團隊用來改善對宇宙運作原理的了解，Sony PS遊戲主機則用OpenStack來打造線上玩家社群平臺，或像PayPal則用來強化他們的線上交易和行動支付系統。我們也看到有許多綠色節能資料中心上的應用，例德國有家新創公司可以從執行OpenStack的伺服器上回收更多熱量。或有一家全球十大汽車製造業用OpenStack來強化大資料分析。
有一種令人興奮的應用類型，未來幾年會大量出現，那就是網路功能虛擬化NFV（Network Functions Virtualization），各國電信市場的龍頭，例如臺灣中華電信（http://ithome.com.tw/news/90495），開始落實NFV概念，不再部署大量、昂貴、專屬用途的硬體，改用有彈性、更低成本且標準化的伺服器和軟體。未來幾年後，OpenStack甚至能用來運作行動網路，強化每一通電話、簡訊、任何即時訊息都透過這個OpenStack平臺打造的行動網路來派送。
問：下一個OpenStack版本，最讓你興奮的功能是什麼？
答：我們很高興社群快速成長而且如此多元化。尤其是雲端服務商和資料中心維運商的社群成員，下一版本將會反映他們提出來的需求。他們希望能提供更一致性、可預測地且更可靠的雲端資源，不論是對內應用或是對外服務上。例如新版會提供DBaaS（資料庫即服務），備援和HA擴充套件。另外，在物件儲存套件Swift上，我們也新提供了儲存政策管理(Storage policies)，而網通套件Neutron則增加了分散式虛擬化路由器的能力。這是幾個新功能的例子。
問：你覺得臺灣舉辦OpenStack技術日的意義？
答：很令人驚訝我們可以在臺灣舉辦第一次OpenStack Day。東京幾年前也舉辦了技術日，之後就成為了OpenStack全球最活躍的城市。臺灣超過1千多人註冊，我沒有明確統計，但臺灣這次活動就算不是全球最大規模，也是少數幾個大規模OpenStack技術日之一。這是一個展現OpenStack威力的日子，人們因社群精神而聚集。這正是OpenStack如此成功的原因。
",https://www.ithome.com.tw/news/91034,"新聞,OpenStack,Cloud,Taiwan"
89516,34,2014-07-22,HDS高階儲存支援公雲雙向備份,HDS的HCP儲存系統功能再升級，可做到雙向從雲端備份資料，並支援Google和微軟雲端平臺," 儲存業者HDS（日立數據系統）日前宣布，原本提供企業內容儲存的HCP（日立內容平臺）儲存系統，從原本只能從Amazon S3公有雲單向備份資料到HCP，提升到可以做到雙向從雲端備份資料且從HCP上傳資料到公有雲雲端平臺，並新增對Google和微軟雲端平臺的支援；在資料異地備援存取上，也從原本只支援Active-Standby網路存取模式，升級到支援Active-Active的存取模式。
新增支援微軟、Google雲端平臺
臺灣HDS資深技術顧問梁萬宇表示，企業為了降低單位儲存成本，也開始評估在自建私有雲之外，透過混搭公有雲的方式，降低企業內儲存成本，又可以增加資料上傳公有雲的安全性。
為了達到讓企業更安心使用混合雲服務，HDS擴充原本HCP儲存系統的功能。梁萬宇指出，該公司將原本只支援從Amazon的S3雲端儲存平臺，透過AP將資料單向寫入HCP儲存系統中，但透過HCP升級，不僅可以從支援的雲端平臺，例如Google的Google Drive、微軟的Azure和Amazon的S3雲端平臺，將資料備份到HCP中；也可以透過API，將原本存放在企業內HCP的機敏資料，透過自動加密機制後，再藉由政策的設定，以傳輸加密方式，把機敏資料從HCP自動上傳到上述雲端儲存平臺。
除了增加支援的雲端平臺外，梁萬宇表示，HCP遠端資料跨區存取和異地備援的網路存取模式，原本只支援Active-Standby的方式，但透過此次HCP升級，則擴充升級到支援Active-Active的網路存取環境。「企業若需做到同時在多個機房或辦公室進行重要資料存取時，Active-Active的網路存取方式，可以維持一定的存取效率。」他說。
除了HCP本身支援RAID 6，可以在背景程式自動偵測檔案是否損毀，一旦有損毀，則會自動將另外一份完整的資料產生複製本並存放在HCP中，達到資料免備份（Backup Free）的目的外，梁萬宇認為，HDS提供的是一整套儲存解決方案，當有了HCP這套資料集中的儲存系統後，可以在分公司搭配具有資料目錄索引功能的閘道端產品HDI（日立數據擷取器），讓公司員工查詢所有的檔案清單，在依清單上的HCP路徑來取得實際的檔案。另外，企業也可以搭配類似企業Dropbox功能的HCP Anywhere，提供遠端辦公室或分公司的員工，可以利用行動裝置存取企業內部分享的檔案。
臺灣HDS總經理宋政勛表示，目前各家儲存業者都在談論軟體定義儲存（SDS），HDS雖然沒推出所謂軟體定義儲存產品，但實際上，HCP產品的功能便類似軟體定義儲存的功能。其中的雲端分層儲存功能，則在此次HCP功能擴充中，支援企業對主流雲端業者的資料備份和上傳。
儲存業者臺灣EMC業務拓展協理李百飛表示，該公司推出的軟體定義儲存ViPR 2.0儲存軟體，是提供一個儲存環境自動作業與管理的環境，企業可以透過ViPR 2.0虛擬化EMC自家儲存設備和其他廠商的儲存設備外，並整合VMware、微軟與OpenStack等雲端環境的雲端分層儲存，更特別的是，可以支援大資料分析平臺Hadoop的資料儲存和分析。
",https://www.ithome.com.tw/news/89516,"新聞,Cloud"
88451,34,2014-06-09,【WWDC 14快報】Objective-C再見！Apple發表全新App開發語言Swift,專為Cocoa及Cocoa Touch所設計的程式語言Swift，強調簡潔、明瞭、有趣、安全與快速，該語法類似直譯式腳本語言容易上手，互動式除錯環境能提升開發效率," 蘋果於6月2日的WWDC大會上發表了專為Cocoa及Cocoa Touch所設計的程式語言Swift，強調簡潔、明瞭、有趣、安全與快速。Cocoa為OS X平臺的應用程式介面（API），而Cocoa Touch則是iOS的API。
Mac OS X平台有Carbon 和Cocoa兩種API，Carbon是OS 9末期，Apple為幫助舊程式轉到OS X，所提出的API架構。而Cocoa應用程式介面與Apple公司創辦人賈伯斯淵源頗深，當時賈伯斯被自己創辦的Apple公司掃地出門，因此他另外創辦了NeXT.Inc，並開發了以Mach和BSD為基礎，擁有先進GUI的NeXTSTEP，後來Apple買下NeXT.Inc，同時也引入以Objective－C為原生語言的NeXTSTEP，而NeXTSTEP就是Cocoa的前身。
利用Swift與Cocoa開發，結合了編譯語言的效能與效率，以及腳本語言的簡單及互動等特性，透過消除各種普遍錯誤的類別來協助開發人員打造更安全及更可靠的程式，並能與Objective－C並存，方便開發人員將Swift植入既有的程式中。蘋果軟體工程副總裁Craig Federighi表示，蘋果希望以Swift來取代Objective－C與Python等程式語言。
行動通訊軟體Cubie Messenger的開發公司Gamelet，其行動裝置App開發工程師黃千碩表示，Objective－C是歷史悠久的程式語言，因此對於開發人員來說並不友善，無法使用較新的程式語言所提供的程式設計方法。
根據蘋果的說明，Swift是該公司結合蘋果打造各式平臺經驗以及對程式語言的研究所得到的成果，具備簡潔與清楚的語法，使其很容易了解及維護；各種的推論類型讓程式碼更乾淨也更不容易出錯，還有各種模組與可自動管理的記憶體。
在Xcode整合開發環境（IDE）中的遊樂場（Playgrounds）互動式開發情境亦支援Swift，開發人員只要輸入一行的程式碼，結果就會立即呈現，或是透過時間軸功能以圖表檢視程式的進行，或是以SpriteKit進行動態播放，在Playgrounds中完成的程式碼可以直接移到程式專案中使用。Xcode的除錯機制針對Swift語言也提供REPL（Read-Eval-Print Loop）環境，可利用Swift語法來評估或與程式互動，或是撰寫新程式碼並觀察它的運作。
蘋果強調了Swift的安全性，因為它消除了不安全程式碼的所有類別，例如變數在使用者皆會經過初始化，陣列及整數都會經過溢出檢查，而記憶體則具自動管理特性，讓語法更為簡單及精確，例如以3個字元的關鍵字就能定義變數或常數。
此外，Swift使用了高效能的LLVM編譯器，讓Swift程式能夠轉換成優化的原生程式，以充分利用Mac、iPhone與iPad的硬體能力，同時汲取了C與Objective－C中的許多優良設計。
黃千碩說，Swift看起來很像是直譯式語言，很好上手，程式碼相對於Objective－C來說簡潔很多，也因為Swift核心的研發工程師來自前C＃團隊，所以Swift有不少語法借鏡C＃。
在全球70個城市都能通行的行程規畫App TransitTimes＋開發者Quentin Zervaas表示，Apple用心的使他們的開發流程以及開發工具更簡單，讓使用者不需要耗費太多心神在克服程式開發技術上，而能專注於開發更好的App，而且Xcode提供的除錯環境有助於簡化程式碼。另外，他也認為，Swift是Apple用來榨乾硬體效能的手段之一。
阿碼科技創辦人黃耀文則在臉書上表示，Swift不僅是一個程式開發語言而已，加上Xcode的互動的除錯環境Playgrounds，發揮了直譯式語言才有的特性。這整個流程縮短了App部署時程，如此，友善的開發環境將吸引更多開發者進入Apple開發圈，有了豐富的App支援才能稱為是好手機。黃耀文也提到，隨著Swift的發表，也點出了軟硬體整合的議題，值得探討未來是硬體主導抑或是軟體主導。
開發人員可下載最新的Xcode 6測試版以試用Swift，並可於今年秋天隨著iOS 8與OS X Yosemite正式版的出爐提交Swift程式。蘋果已透過iBooks Store出版多達500頁的Swift開發準則供外界免費下載。文⊙陳曉莉、李建興
 iOS 8 SDK史上最大改版，蘋果釋出4千個新API 
iOS 8號稱是App Store上線以來最大的一次改版。與此同時也宣布釋出iOS 8的開發人員套件（SDK），內含超過4000種新的程式設計介面（API），也是iOS有史以來規模最大的SDK版本。
有鑑於iOS 8具備了多種重大的新功能，包含智慧家庭應用HomeKit、健康應用HealthKit、新繪圖技術Metal，及新程式語言Swift等，新的API將允許開發人員在程式中利用這些新應用或技術，以及擴充的通知中心工具與第三方鍵盤等功能。
其中，支援HealthKit的各種API將讓開發人員打造可與其他程式互通的健康或瘦身程式，例如測量血壓的程式能夠與醫師程式分享資料，讓醫師能夠基於第三方程式的資料提供更適當的照護。開發醫師程式的Mayo Clinic執行長John Noseworthy表示，蘋果的HealthKit將革新健康產業與人們的互動方式。
HomeKit則是藉由共同的協定與匹對來控制各種家中的裝置，而且整合了Siri，例如當你告訴Siri你要去睡覺的時候，它就能自動關閉車庫的門、鎖住大門、把燈調暗，以及設定睡眠溫度。
蘋果軟體工程資深副總裁Craig Federighi表示，有鑑於全球已售出逾8億臺iOS裝置，開發人員將擁有巨大的機會，iOS 8 SDK內含逾4千種新的API，涉及新的框架、更強大的擴充能力，以及革命性的新程式語言。
iOS的擴充功能包括新的分享選項、客製化的照片篩選功能、客製化的動作與文件API，蘋果亦首度允許開發人員把自己開發的工具嵌入通訊中心，或是使用第三方的鍵盤當作輸入工具。
此外，蘋果宣稱新的繪圖技術Metal可最大化A7晶片的效能，因而能夠將遊戲機上的3D遊戲帶到行動裝置上。針對iOS與OS X設計的新程式語言Swift則結合了編譯語言的效能與效率，以及腳本語言的簡單及互動，能與Objective-C並存及可消除常見錯誤的特性將讓開發人員方便將Swift嵌入既有的程式中，以及打造更可靠的程式。
現階段App Store在155個國家提供120萬種的程式，平均每周的造訪人數超過3億人，迄今用戶所下載的程式數量已突破750億。
iOS開發人員已可下載iOS 8測試版、Swift測試版，及iOS 8 SDK，其中，iOS 8與Swift正式版皆預計於今年秋天出爐，屆時也將開放開發人員提交以Swift撰寫的iOS 8或OS X Yosemite程式。文⊙陳曉莉
相關報導請參考「蘋果軟硬、雲端大整合」
",https://www.ithome.com.tw/news/88451,"新聞,蘋果,WWDC,Cloud,Swift"
88450,34,2014-06-09,【WWDC 14快報】蘋果正式進軍智慧家庭醫療市場,蘋果除了發表全新HomeKit智慧家庭平臺，未來可整合各種智慧家庭App，並推出全新Health健康管理App，可用來追蹤使用者的身體數據," 蘋果於一如預期在WWDC 2014開發者大會上宣布進軍智慧家庭市場，發表全新HomeKit智慧家庭平臺，未來可整合各種智慧家庭App，像是透過iPhone一鍵就能遠端開啟燈光、門鎖與溫度調控，也能透過Siri語音加以聲控，還提供有安全監控功能，未來也可望應用於蘋果全新穿戴裝置上。
根據蘋果執行長Tim Cook表示，新發表HomeKit智慧家庭平臺，主要作為下代iOS 8平臺推出的軟體開發套件（API），只要單一應用介面就能進行管理，使用者不需要像以往App得個別進行操作，還未進家門前就能先透過iPhone遠端開啟家中燈光、門鎖和溫度調控等，過程中僅需一鍵就能完成非常方便。
而HomeKit平臺也能支援Siri語音操控，只要對著Siri下達指令就能自動替你關閉燈光、音樂、門鎖、降低室內空調、調暗燈光等，甚至當家中車庫門超過15分鐘以上沒關時，還會自動發出通知提醒你，就像是你的智慧小管家一樣，將智慧和生活緊密結合在一起。
Health App可追蹤用戶身體數據，且具備運動追蹤功能
而除了HomeKit外，蘋果本次也推出了全新Health健康管理App，可用來追蹤使用者的身體數據，包括像是血壓、心跳、運動、睡眠等健康資訊，也可提供運動追蹤功能，包括走路或慢跑的距離及消耗的卡路里，並集中存放在HealthKit雲端平臺管理，還可同步連線醫療機構提供醫師進行診療及追蹤。
在Health App中包含儀表板（Dashboard）、健康資料（Health Data）、來源（Sources）、醫療身份證（Medical ID）4個主要頁面，其中Medical ID提供用戶建立緊診卡（Emergency Card），記錄用戶的血型或過敏等重要病史和基本資料，而這些資料在行動裝置的螢幕鎖住的情況下也可以存取。
此外，HealthKit也能支援第三方健康及運動App，像是Nike+FuelBand App等，可以整合HealthKit蒐集的睡眠與營養資料，還提供來自健康服務供應商如Epic Systems及知名醫院Mayo Clinic醫生群的健康資訊，提供用戶更全面的健康管控。
蘋果也於大會中表示，未來HomeKit也將與Philips、Chamberlain、August（智慧型門鎖）、Schlage、Netatmo（天氣偵測及溫度調控）、Withings（健康管理）等多家智慧家電大廠聯手合作，打造全新蘋果智慧家庭生活。另外，透過搭配HealthKit健康App，未來也可望全面應用於蘋果穿戴科技裝置上。文⊙余至浩、林妍溱

HealthKit可整合第三方健康及運動App
HealthKit能支援第三方健康及運動App，像是Nike+FuelBand App等，可以整合HealthKit蒐集的睡眠與營養資料，還提供來自健康服務供應商如Epic Systems及知名醫院Mayo Clinic醫生群的健康資訊，提供用戶更全面的健康管控。

相關報導請參考「蘋果軟硬、雲端大整合」
",https://www.ithome.com.tw/news/88450,"新聞,蘋果,WWDC,Cloud"
88449,34,2014-06-09,【WWDC 14快報】iOS 8大改版，今秋問世,iOS 8號稱是自有App Store以來最大的一次改版，使用者可直接在通知中心回覆訊息，iMessage可單向廣播簡短的語音及影像," WWDC 2014上，蘋果執行長Tim Cook發表了iOS 8預覽版，iOS 8號稱是自有App Store以來最大的一次改版，將賦予使用者全新功能，並提供開發人員創造精彩App的新工具。
iOS 8可相容於iPhone 4s、5、5s及5c以及iPad 2、具備Retina顯示器的iPad、iPad Air和mini iPad。目前為開發人員預覽版，正式版預定秋天推出。
蘋果表示，iOS 8使用者介面更簡潔、更直覺，且重新定義了iOS 8的通知中心，使用者可以與通知中心互動，直接在通知中心回覆訊息，例如臉書、簡訊等通知，在螢幕鎖住的情況下依然可以回覆訊息。
此外，iOS 8也整合Siri及Shazam，提供音樂辨識服務。使用者可以利用iOS裝置的麥克風收集一小段音樂上傳，Siri就會告訴使用者歌曲名稱或歌手等基本資料，並且導引到iTunes商店，促進使用者購買。
iMessage方面，現在用戶可為對話串命名，移除群組訊息成員，並封鎖不相關的訊息串。此外，iMessage還增加一對多廣播（Tap-to-talk），可單向廣播簡短的語音及影像，也能和多人分享用戶自己的位置訊息。
QuickType鍵盤增加預測輸入，可學習用戶輸入習慣及經常聯絡對象，日後則可建議可能的收訊人或相關字詞，加速輸入速度。但蘋果強調這類習性只以加密留存在裝置上，不會上傳雲端。此外，iOS並支援第三方鍵盤應用如Swype及SwiftKey。
如果家庭成員都擁有Apple ID，用戶就能透過Family Sharing分享其他成員的iTunes、iBooks或App Store，看到彼此採購商品、相片、行事曆，父母也能為未成年子女建立Apple ID，這項功能最多支援6個家庭成員。
對擁有iPhone、iPad及Mac的用戶來說，可利用Handoff功能配合Instant Hotspot功能設定在不同裝置上傳送及接收簡訊或通知。
新版iOS加強App資料保護和郵件加密，強化企業應用
新版iOS也特別加強企業應用，根據蘋果在發表會上表示，財星500大企業中有98％的企業都使用iOS。
在iOS 8中，增加企業等級安全技術來加強更多App的資料保護，以及更好的郵件加密功能。
除了郵件和第三方Apps之外，行事曆、連絡人、提醒、筆記和訊息等Apps也都有提供用戶密碼保護。而新的郵件訊息安全性讓S/MIME（Secure Multipurpose Internet Mail Extensions）用戶可以選擇簽名和加密個人訊息。
現在在收件匣中，用戶可以標記訊息已讀或未讀，或是快速向左或向右滑來標幟要跟進的訊息，還可以指定個人郵件主題為VIP，可以更簡易追蹤訊息的更新，收件匣的呈現方式也可以以VIP主題分類顯示。
為增加郵件的安全性，用戶可以選擇標記為紅色的外部信箱，如果是Exchange的用戶，還可以設定自動從iOS裝置回覆訊息。
在行事曆上，用戶可以看見其同事們的空檔時間，以便快速安排會議時間，還可以標記行事曆上的事件為隱私（Private）。此外，用戶還可透過行事曆寄送郵件給會議與會者，告知與會者遲到的消息。
而第三方文件Apps讓用戶更容易從其他Apps取得文件，例如，用戶有一個App可以存取企業檔案伺服器，用戶就可以直接透過該App取得所需文件，且能直接編輯。
此外，AirDrop在沒有網路連接的情況下，仍然可支援iOS和OS X裝置間的檔案傳輸。
另外，新版iOS新增電子書和PDF文件的管理工具，行動裝置管理工具（Mobile Device Management，MDM）可以自動推播iBooks、ePub和PDF等文件的訊息至用戶的裝置，當用戶不需要這些文件時，可以遠端刪除。文⊙林妍溱、戴廷芳

使用者可直接在通知中心回覆訊息
使用者可以與通知中心互動，直接在通知中心回覆訊息，例如臉書、簡訊等通知，在螢幕鎖住的情況下依然可以回覆訊息。


iMessage可傳送影音訊息
iMessage增加一對多廣播（Tap-to-talk），可單向廣播簡短的語音及影像，也能和多人分享地點。


iOS 8加強郵件加密和資料保護
在iOS 8中，增加企業等級安全技術來加強更多App的資料保護，以及更好的郵件加密功能。除了郵件和第三方Apps之外，行事曆、連絡人、提醒、筆記和訊息等Apps也都有提供用戶密碼保護。


Family Sharing分享家庭相片或行事曆
iOS支援第三方鍵盤應用如Swype及SwiftKey。用戶能透過Family Sharing分享其他成員的iTunes、iBooks或App Store，看到彼此採購商品、相片、行事曆，這項功能最多支援6個有Apple ID的家庭成員。

相關報導請參考「蘋果軟硬、雲端大整合」
",https://www.ithome.com.tw/news/88449,"新聞,蘋果,WWDC,Cloud,iOS 8"
88448,35,2014-06-09,【WWDC 14快報】挾OS與雲端整合優勢，iCloud Drive來勢洶洶,iCloud Drive具有與蘋果裝置高度整合的優勢，文件或檔案的變更，都能立即在所有裝置同步顯示，對Google Drive、Dropbox形成極大競爭壓力," 蘋果於WWDC 2014發表了全新的iOS 8，並揭露全新的iCloud服務，其中iCloud Drive將成為Google Drive、Dropbox與微軟OneDrive的競爭對手。
有別於舊版iCloud主要用來進行蘋果裝置的備份，新一代的iCloud新增了iCloud Photo Library，可用來儲存及管理來自各種裝置的照片及影片。此外，蘋果也改善了iCloud的相片搜尋，並增加色彩、高度調整及裁剪，以及自動清晰功能。
而iCloud Drive將成為真正的雲端儲存服務，能夠儲存各種類型的資料或文件、開放不同的程式存取，同時也能在iOS、OS X或Windows上直接把檔案拖曳到iCloud Drive程式中。
使用者於iCloud Drive文件或檔案中所進行的改變，都會同步出現在所有的裝置上，也能在不同的裝置上編輯；同時它也建立了程式間的全新協作體驗，例如，使用者可利用素描程式畫出一張圖，將之儲存在iCloud Drive上，之後再以繪圖程式於該圖上加入色彩，不需要再經由複製或匯出，而是直接在同一張圖上作畫。
新的iCloud仍維持原有的5GB免費空間，付費容量的價格也向眾多競爭對手宣戰，20GB的月費為0.99美元，200GB的月費為3.99美元，蘋果也計畫推出1TB的儲存方案。至於Dropbox則有每月2GB的免費空間，100GB的月費為9.99美元。Google Drive的免費空間為15GB，100GB的月費為1.99美元，是Dropbox的五分之一，而1TB的月費為9.99美元。微軟OneDrive有7GB的免費空間，50GB的年費則要價25美元，100GB年費為50美元。

Handoff可將活動切換至不同裝置進行
Handoff是連續性（Continuity）功能之一，可以將活動切換至不同裝置進行，也就是當使用者的iPhone或iPad置放於Mac附近時，Handoff允許使用者在其中一個裝置啟動一項行為，並切換到另一個裝置將工作接續完成。


Instant Hotspot便於連結iPhone熱點
連續性功能也包含了Instant Hotspot，提供Yosemite用戶更容易連結iPhone的熱點服務，也就是說，用戶若是有開啟iPhone的個人熱點分享，在Mac電腦上只需要點擊搜尋附近網路的服務，就可以連線該用戶的iPhone熱點。


新增Today View檢視今日行程
新版通知中心有今日檢視功能（Today View），可以檢視今日的行程，而且還可以幫用戶整理明日的行程總結。此外，使用者還可以從Mac App Store安裝小工具（Widgets）來存取重要的個人資訊及增加功能，例如日曆、天氣、股市、世界時鐘、計算機、提醒等，讓使用者依據新增的小工具客製化今日檢視功能的樣貌。


iCloud Drive也支援Windows
iCloud Drive將成為真正的雲端儲存服務，能夠儲存各種類型的資料或文件、開放不同的程式存取，同時也能在iOS、OS X或Windows上直接把檔案拖曳到iCloud Drive程式中。

",https://www.ithome.com.tw/news/88448,"新聞,蘋果,WWDC,Cloud,iCloud Drive"
88446,35,2014-06-09,【WWDC 14快報】蘋果作業系統大更新，Mac OS X Yosemite、iOS 8雙雙升級,今年蘋果全球開發者大會（WWDC 14）兩大主題為Mac OS X 10.10與iOS 8。OS X 10.10 Yosemite最快今年秋天免費釋出，iOS 8已可下載Beta版," 蘋果的全球開發者大會Worldwide Developers Conference 2014（WWDC 14）在美國舊金山Moscone Center會議中心登場，今年WWDC的兩大主題分別為Mac OS X 10.10與iOS 8。
今年發表的重點除了新版OS X和新版iOS外，還有iCloud Drive、新程式語言Swift、HomeKit智慧家庭平臺等。同時，蘋果也釋出iOS 8的開發人員套件（SDK），內含超過4千種新的程式設計介面（API），也是有史以來規模最大的SDK版本，而「WWDC 14：Write the code. Change the world.」則是今年現場的標語。
不過，今年的發表會上沒有大會開始前所傳聞的iWatch穿戴式裝置、Apple TV、Beats、12吋的MacBook Air、iPad等，更沒有果粉都引頸期盼的iPhone 6，看來還得再等候這些消息的釋出了。
新版OS X打破Mac和iOS裝置的界線
OS X 10.10以山系命名為「優勝美地」（Yosemite），加強與iOS的整合，新版OS X著重於介面、Apps和連續性（Continuity）等3大更新。
蘋果在這次的OS X介面上是仿效iOS 7的半透明設計，而Dock工具列也採用iOS 7的平面化（Flat）設計。此外，Yosemite也精簡工具列的設計，其他比較細微的更新則是按鈕、圖標、系統字型等設計。
視窗邊欄工具列半透明的設計可讓使用者在使用視窗時，還可以隱約看見在視窗後的背景。而蘋果工具列設計精簡化，卻又不失其功能性，連Safari瀏覽器也只剩下搜尋列，其餘都是網頁的空間。此外，工具列精簡化也造福了地圖的使用，使用者因此可以看到更廣闊的地圖資訊。
而在Apps的更新上，Safari現在在網址搜尋列就可以直接存取使用者的最愛網址，且新增隱私瀏覽功能，支援不追蹤使用者的DuckDuckGo搜尋引擎，蘋果也強調新版Safari在實際網站上的JavaScript執行速度是Firefox的5倍，也比Chrome還快。另外，在新版OS X中，使用者只要點擊一下Tab View按鈕，就可以將同網站的網頁堆疊在一起。
郵件程式Mail Drop也有更新，使用者最多可傳送5GB的大型附件檔案，以及標記（Markup）功能可以在圖像和PDF文件上加上註解。而iMessage的介面更新則變得更加生動活潑，使用者還可以命名對話的標題，以便搜尋。還有Spotlight搜尋功能的位置將更明顯，搜尋結果將新增來自Wikipedia、Bing、App Store、Maps或其他知名網站等更豐富的建議。
在新版OS X的通知中心（Notification Center）只需要滑鼠向右滑至底就可以顯示，即使在全螢幕的工作環境下也可執行。新版通知中心有今日檢視功能（Today View），可以檢視今日的行程，通知中心甚至還可以總結明日的行程。此外，使用者可以用小工具（Widgets）來存取重要的資訊，例如日曆、天氣、股市、世界時鐘、計算機、提醒等，且可以依據使用者從Mac App Store新增的小工具來客製化Today View的樣貌。
另外，現在在Finder中可以使用新的iCloud Drive儲存和管理檔案，並且可用AirDrop檔案分享功能將檔案分享至Mac或iOS裝置，這就是OS X來結合iOS的連續性功能之一。
連續性功能中還有可將活動切換至不同裝置進行的Handoff，當使用者的iPhone或iPad置放於Mac附近時，Handoff允許使用者在其中一個裝置啟動一項行為，並切換到另一個裝置將工作接續完成。
Instant Hotspot也是連續性功能之一，讓Yosemite用戶更容易連結iPhone的熱點服務，Mac電腦只要搜尋到附近有該用戶的iPhone就會自動連網。
此外，iOS和OS X間的界線越趨模糊，原本只出現在iPhone上的文字或多媒體簡訊現在可於所有裝置上呈現，使用者也可在Mac電腦上執行iPhone的電話功能，像是用Mac收發簡訊、接聽或撥打iPhone電話。
蘋果軟體工程資深副總裁Craig Federighi表示，Yosemite新的設計與程式都是為了能順暢地與iOS共同運作，蘋果一併規畫了不同的平臺、服務與裝置，讓用戶在使用各種蘋果產品時能有無縫的體驗，這在業界前所未見，也只有蘋果辦得到。
蘋果已釋出Yosemite的開發人員預覽版及該平臺的各種API，並計畫在今年夏天開放一般使用者測試Yosemite，正式版則預計於秋天問世。

半透明介面與精簡化工具列
Safari瀏覽器只剩下搜尋列，工具列精簡化讓網頁可視空間變大，且新版Safari提供使用者在網址搜尋列上就可直接存取「我的最愛」，另外，也新增隱私瀏覽功能。


Mail Drop附加檔案容量最高達5GB
新版Mail Drop使用者最多可傳送5GB的大型附件檔案，以及標記（Markup）功能可以在圖像和PDF文件上加上註解。

 相關報導請參考「蘋果軟硬、雲端大整合」
",https://www.ithome.com.tw/news/88446,"新聞,蘋果,WWDC,Cloud"
88341,35,2014-06-04,IBM挑戰雲端巨頭推PaaS新武器　BlueMix平臺月底正式上路,BlueMix平臺是一套用開源Cloud Foundry平臺打造的PaaS服務，開發人員透過滑鼠拖曳各種服務元件，就能快速組合出企業級的行動App。預計6月底正式上線，率先部署在全球6地資料中心，包括北京和東京," 【美國奧蘭多直擊】在雲端市場腳步落後的IT大廠今年接連出重手，繼HP日前宣布重磅壓寶開源OpenStack之後，IBM雲端平臺服務總經理Steve Robinson也在美國奧蘭多Innovate 2014大會上宣布，使用開源Cloud Foundry平臺打造的PaaS服務BlueMix將於6月底釋出正式版（GA），並將在IBM全球6地資料中心部署BlueMix服務，包括北京、東京等地。IBM未來也預計將Bluemix服務，部署到所有已提供SoftLayer雲端IaaS服務的機房中。不過，IBM目前尚未公布BlueMix計價細節。
IBM Rational總經理Kristof Kloeckner表示，當市場需求越來越講求速度的同時也需要信任，為了兼顧這兩者來快速推出可信任的產品和服務，IBM提出了Composable Business的觀念，企業必須善用模組化的元件來打造應用程式，就像組合積木的方式，才能有效果又有效率地加速產品上市時間，並且能即時掌握重要情報來改善決策，不間斷地改造和創新企業流程。
也因此，IBM今年2月時發表了以Cloud Foundry平臺打造的BlueMix雲端PaaS平臺，可提供6大類服務，包括了分析服務、大資料服務、DevOps服務、行動應用服務、資安服務、網站和應用服務。BlueMix提供了一個應用程式的組合式開發環境，開發人員在BlueMix專案網站上透過滑鼠拖拉平臺內建的服務元件，設定服務元件之間的關聯，輸入必要的設定參數或相關商業邏輯規則，不需要撰寫複雜的程式碼，就能打造出一個App，再自動發布到不同的行動裝置上提供給使用者。
Steve Robinson表示，BlueMix的目標是讓開發人員快速實現好點子，IBM提供了可將開發流程或系統維運自動化的DevOps服務，幫助開發人員運用雲端服務，打造組合式的企業級App。
Steve Robinson也同時發布了4 項BlueMix新服務，包括了可掃描網站和App程式提高安全品質，來加快開發測試速度的AppScan服務，以及可以用來管理不同應用發布版本提高部署正確性的Continuous Delivery Pipeline服務，另外還有可用來協調和管理各種雲端服務的Workflow服務，以及最後一項是可用來蒐集App使用資訊提供進階分析的嵌入式報表服務Embeddable Reporting。IBM也推出了新的DevOps解決方案，包括了持續測試發布和部署解決方案，以及另一套持續商業計畫和協作開發環境。
 
IBM雲端平臺服務總經理Steve Robinson宣布推出4項BlueMix新服務。

 
使用開源Cloud Foundry平臺打造的PaaS服務BlueMix將於6月底釋出正式版（GA），並將在IBM全球6地資料中心部署BlueMix服務，包括北京、東京等地。

 
IBM也找來美國舊金山灣區捷運公司BART，現場示範如何運用BlueMix平臺快速推出新版App的過程。
BART提供灣區各城市間的輕軌捷運系統，例如舊金山到奧格蘭捷運線，5條路線共有44個車站，每天要運送30多萬人次通勤。為了監控各路線列車班次的調度，BART利用BlueMix先試行開發了一個列車班次監控App。
BART合作SI廠商Synchrony Systems現場透過BlueMix線上專案網頁和線上開發環境，直接修改列車班次監控App的程式碼，新增加了一個檢視問題車次資訊的功能，並立刻部署和發布新版本，數分鐘後，手機上的監控App也升級為新版本，而能提供列車檢視功能。
BART資訊長Ravindra Misra表示，透過PaaS平臺，IT部門可以將數個月的App開發時程，縮短到幾周就能上線。
 
美國舊金山灣區捷運公司BART原本用來監控各站列車班次的維運系統

 
BART利用BlueMix打造了一個試行App來監控各站列車排班。圖為這個App的BlueMix專案儀表版首頁

 
圖中顯示Concord這一站排班出現2個問題而以紅色警示。

 
進一步檢視Concord車站的月臺資訊，可看到發生問題的是ST-15軌道第一班和第二班次，但目前沒有提供列車檢視功能，無法得知列車的詳細資料。

 
BART合作SI的開發人員現場利用BlueMix線上開發環境要來幫App增加新功能

 
直接透過瀏覽器增加可查詢列車資料的函數，讓App可以顯示問題車班的列車資訊。

 
示範人員將預先寫妥的程式碼加入App後，也現在直接將新版程式碼發布到正式執行環境中。

 
幾分鐘後，示範人員手機上的列車班次監控程式也升級到新版本，可以檢視問題車班的詳細資訊了。

 
 
 
 
 
",https://www.ithome.com.tw/news/88341,"新聞,IBM,BlueMix,DevOps"
87845,35,2014-05-20,IDC首份IaaS市場追蹤報告出爐，美國大型企業採用IaaS的第一名是IBM,IDC發布首份IaaS追蹤報告，美國千人規模大企業偏好的IaaS服務供應商，以IBM、思科、惠普和電信商AT&T位居前四名，而Amazon的AWS（Amazon Web Services）則位居第七名，第五和第六名分別是Google和微軟的Azure雲端服務," IDC發布首次IaaS市場追蹤報告，調查美國千人以上規模的大企業所偏好的IaaS服務供應商，調查結果顯示，IBM、思科、惠普和電信商AT&T位居前四，而Amazon的AWS（Amazon Web Services）則位居第七名，第五和第六名分別是Google和微軟的Azure雲端服務。
IDC表示，35％的受訪美國企業選擇IBM為喜愛的雲端供應商第一名，這些企業認為IBM能有效的提供公共雲或私有雲的IaaS服務。IBM的Iaas平臺包含在2013年6月以20億美元買下的SoftLayer，以及IBM雲端管理服務（IBM Cloud Managed Services）。而緊接著IBM之後的廠商分別為思科、惠普AT&T和Google，其中，惠普投資10億美元在雲端相關的產品，與AT&T並列第三名。
然而，僅有13％的受訪企業將Amazon選為偏好的雲端供應商第一名，而微軟和Google則分別占受訪企業最喜愛的廠商15％和16％。其他的雲端供應商如戴爾、VMware、Rackspace、EMC、BT（British Telecommunications）等，皆低於10％。
此外，研究也顯示，52％的受訪企業表示，特別偏愛全方位服務的供應商，像是IBM，提供廣泛領域的能力、專業的服務、顧問系統整合、客製化軟體開發和測試等，企業需要供應商提供這些服務來協助企業打造雲端服務。
這項研究令人驚訝的是，竟然低於5％的受訪企業表示，偏好像是Amazon或Google這類的線上雲端基礎建設供應商。
",https://www.ithome.com.tw/news/87845,"新聞,IDC,IBM,Cloud"
87144,35,2014-04-29,DevOps將顛覆未來IT人角色,IBM Rational總經理Kristof Kloeckner推廣可達到軟體持續交付的開發方法DevOps，這也是臉書、Google以及許多大型雲端服務能夠快速版本更新的秘訣之一," 開發界中的兩大IDE（Integrated Development Environment）陣營之一IBM Rational的總經理，也是前IBM雲端運算部門的技術長Kristof Kloeckner來臺灣，推廣可達到軟體持續交付的開發方法DevOps（來自Development和Operations 2個字的縮寫組合），這也是不少大型雲端服務能夠快速版本更新的秘訣之一，如Flickr就運用了DevOps開發方法來加快服務改版速度，甚至一天可以因功能需求，發布10次小改版。
Kristof Kloeckner表示，DevOps開發方法藉由將各開發階段自動化以及訊息公開，幫助企業軟體研發相關部門，解決傳統流程端對端（End to end）所產生訊息不對稱，以及協作不順暢的問題，並且自動化開發流程的每個階段，進而提升軟體交付的速度。
 Q  為什麼要使用DevOps開發方法？
 A  雲端時代讓某些應用服務的載體移往雲端，這表示更有彈性的服務環境，開發人員現在已經不需要擔心基礎架構、中介軟體或是環境設定，而新的挑戰轉移到開發速度，尤其是行動裝置的App，使用者希望企業以更快的速度完成App，而且要持續不斷的提供更新，交付時程劇烈縮減，可能從月到周到日，甚至以小時為單位進行改版。
CIO在雲端時代必須聚焦在總體商業的結果，了解究竟IT提供企業什麼價值，這包含三個要點，應用程式部署的速度、衡量風險、控制成本。如果守著過去開發及營運模式，對於以上提及的三點將失去競爭力，也因為如此，傳統的方式必須改變。
這也是為什麼我們談DevOps開發方法，開發以及營運團隊要更緊密合作，這過程需要一些工具支援任務交接以及達到訊息傳遞等，讓問題快速被解決，IBM推廣DevOps開發方法的觀念及工具，可以做到快速的實作、快速的部署、快速的完成軟體週期以及快速的得到用戶回饋。
 Q  為什麼要注重軟體交付速度？
 A  CIO知道從開發到營運的過程，很多做法是很沒有效率的，尤其當想要趕工加速軟體交付的速度，軟體品質會因為沒有充裕的時間測試而下降，抑或是頻繁要求更改環境設定，整體控制缺乏一致性。
開發團隊與營運團隊經常溝通發生障礙，開發團隊認為營運團隊粗心又沒有良好規畫，反之營運團隊覺得開發團隊組織很僵化，最後因為CEO認為軟體開發效率不彰，不幸的CIO就被炒魷魚了，我看過這一切發生。
從企業角度來說，軟體交付很重要，如果你交付了有問題的App，或是讓有問題的網站上線了，商譽立即會受到影響，而這必須付出極高的代價，因此軟體公司的成功，依靠IT讓開發團隊與營運團隊的密切合作，從而弭平文化鴻溝是重要的。
就典型的例子，網路零售商想要在網站新增品項，此時影響商譽不光是商店營運本身，很大一部分是IT能否幫助零售商維持高品質的網站服務。
 Q  DevOps開發方法與傳統開發流程有什麼不一樣？
 A  DevOps開發方法是敏捷（Agile）以及精實（Lean）開發概念的延伸，有別於傳統開發流程，DevOps開發方法打破每個獨立的階段，從需求分析、系統設計、程式開發、安裝測試、後續維護再回到第一階段，形成一個封閉迴圈。
DevOps開發方法要開發人員持續改善並整合不同的階段，加以組織過去任務所發生的事，開發人員需要自動化的工作流程，自動化開發周期的每一個階段，不僅需要自動化測試，還要自動化部署，且提供自動化的數據給所有參與的人，讓所有人可以合作。
過去的文化需要改變，現在必須量化每件事，依照量化的數據，改善每個階段，這些是根本性的改變，企業主可監看過程產生的數字而不僅是是生意上的結果，才可以用更快的速度創新，更快地抓住市場佔有率，讓顧客開心，以上都是DevOps開發方法的關鍵改變。
 Q  DevOps開發方法對於既有開發及維運的團隊有什麼衝擊？
 A  我們看到的衝擊都是好的，就如同精實開發的精隨，減少不必要的浪費以及重複性的程序，做到剛好符合需求。
DevOps開發方法自動化維運過程，不需要手動做一些繁複的事，因此可以減少錯誤發生，開發人員也可以專注在產生更有品質的程式碼，避免之後不停的修補程式碼，有更多心力去做一些有趣的事，我們也從一些客戶案例看到，開發人員不只更有生產力，他們也更快樂了，而且良好軟體讓維運更容易。
團隊的組織架構必然需要改變，開發和維運團隊需要更緊密合作，這是第一點。第二點是，開發周期循環變快，團隊的人需要不同的技能，並整合這些能力，甚至有一些公司是沒有開發和維運團隊之分，不再有2個團隊或3個團隊，而只有1個團隊。目前已有公司開始徵求DevOps工程師。
 Q  DevOps工程師需要具備什麼能力？
 A  DevOps工程師需要很廣的技能，第一個，他需要能夠了解軟體對於使用者的易用性（Usability），因為使用者回饋是很重要的。另外，也需要能團隊合作，讓應用程式開發更有效率，任務不能分你我，因為這是整個團隊的事。
以企業的角度，企業主必須提升開發人員的熱忱，主動的關注開發工作，並讓他們了解使用DevOps開發方法可以為他們帶來什麼好處。這也不是僅是對開發人員好，而是企業主願意投資在開發工作，也會取得在生意上的回報。
 Q  目前國外企業採用DevOps開發方法的情況？
 A  這跟企業的成熟度有關，我們無法提供確切有多少比例採用DevOps開發方法，大部分的企業還在DevOps開發方法旅程的初期階段，大部分企業會先採用一些比較簡單的實際做法，如自動建置和測試，而網站或雲端服務普遍開始採用自動化部署。
 Q  採用DevOps開發方法可以縮短多少開發時程？
 A  我們有一些來自客戶的數據，軟體測試可以減少90％的時間，版本釋出和部署的頻率可以大幅提升。實際案例顯示，過去要兩年才能釋出1個新產品，導入DevOps開發方法後，一年半可以發布18個成品。
DevOps小百科
DevOps是來自Development和Operations這2個英文字的縮寫組合，顧名思義，DevOps開發方法最主要改善的是開發團隊以及維運團隊的關係。
傳統的端對端開發流程（End to end）概念是指，每一個團隊都有的獨立功能，開發團隊專注軟體開發，維運團隊做軟體部署，但是當功能被明顯切割，必定會影響團隊間訊息的同步，例如維運團隊無法確切掌握軟體執行的環境，當開發團隊遞交的軟體不符合部署環境，或是更改軟體規格時，維運團隊就必須把軟體退回給開發團隊，這樣一來一往耗費時日，軟體交付速度便會受到嚴重影響。
因此如果導入DevOps開發方法中的自動化部署，便可由開發團隊設定部署環境，由工具做自動化部署，減少手動以及傳遞的時間，且可以避免人為錯誤，改善軟體交付品質。 
 

IBM依據DevOps開發的原則，設計出一套IBM的DevOps流程，是以敏捷（Agile）以及精實（Lean）開發概念為延伸，持續且自動化每個階段，使開發流程形成一個封閉迴圈。資料來源：IBM，2014年4月

",https://www.ithome.com.tw/news/87144,"新聞,IBM,DevOps,敏捷開發,精實開發"
88753,35,2012-07-06,Oracle公有雲專攻商業應用平臺的整合運用,提供商業應用軟體和技術解決方案，強調資料能配合商業流程。用戶能以訂閱方式使用Oracle應用軟體、中介軟體和資料庫，並由Oracle提供託管和支援服務," 在Oracle的雲端策略中，過去，Oracle提供程式開發和應用軟體技術給PaaS和SaaS的供應商，在併購伺服器大廠昇陽公司(Oracle)之後，也具備提供IaaS解決方案的能力。他們的雲端環境，軟硬體全部都是採用自家的技術，這是與多數雲端服務提供商最大的不同之處。
去年10月，在甲骨文全球大會中，Oracle正式發布公有雲的服務（Oracle Public Cloud），他們主要透過Oracle Cloud雲端平臺，提供商業應用軟體和技術解決方案齊全的公有雲端產品，主要可以分成應用程式服務（Application Services），以及平臺服務（Platform Services）。
在Oracle的公有雲服務中，從雲端運算的服務形式來看，其中Platform Services包含Java雲端服務與資料庫雲端服務。
Java應用平臺可提供WebLogic Server執行Java應用，方便企業用戶開發、部署、管理Java應用軟體，資料庫雲端服務則是提供Oracle資料庫管理與建立資料庫應用軟體。
而SaaS應用程式服務方面，Oracle推出客戶關係管理Fusion Customer Relationship Management Cloud Service、人力資本管理Fusion Human Capital Management Cloud Service，以及社群網絡Oracle Social Network等。簡單來說，上述這些主要分成客戶關係管理雲端服務、人力資本管理雲端服務，以及商業性質的社群網路協作工具Social Network應用程式服務。
每項不同的服務皆可單獨購買，部署相當彈性
在Oracle的公有雲服務中，從雲端運算的服務形式來看，最大特色是以PaaS與SaaS的服務為主要的銷售重點，並搭配自家的IaaS基礎平臺，不同於多數廠商僅以IaaS基礎設施服務供應為主。因此，Oracle在公有雲服務上，能夠提供相當全面的應用服務，包含SaaS、PaaS與IaaS。
這些雲端服務中，Oracle提供全面性的管理、託管和支援服務，租賃以月費的形式計算，企業用戶可以訂閱、註冊的方式來購買各項服務。由於各項服務皆可單獨購買，建置彈性上也相當大。值得注意的是，Oracle將其公有雲資料中心設於美國當地，非當地用戶需考量資料傳輸品質與延遲的問題。不過，Oracle也針對各式需求提供顧問服務，協助企業依據各專案需求，選擇合適的服務應用模式。
強調全方面的整合性
在應用程式服務中，Oracle也強調雲端平臺的整合性，可以透過共有的管理平臺整合資料庫、中介軟體、企業應用軟體等領域，透過融合應用軟體Oracle Fusion Application，讓企業用戶能順利將內部資料中心的應用程式與資料，可以移到Oracle Cloud雲端平臺上。此外，此公有雲也基於各種產業標準，例如Java、SQL、XML等，能與其他雲端或企業內部的資料中心互動，讓企業的應用程式，可在內部環境跟雲端環境中相互切換。
除了上述企業應用程式外，Oracle也提供許多企業共享服務，像是在資源管理、資料交換、病毒掃描、安全、備份等，用戶可以針對個別功能訂閱所需要的服務。重要的是，這些應用程式與功能，每一項都能單獨註冊以啟用服務，因此在彈性部署上，具有相當大的優勢。
Oracle所提供的公有雲服務特色中，由於軟硬體皆採用自家技術，不論是應用程式服務、平臺服務，加上自家的伺服器虛擬化平臺、刀鋒伺服器與儲存設備，他們期望提供具可靠性和安全性的架構的公有雲端環境，減少企業對於設備系統的維護，並能夠配合企業需求，打造彈性的系統配置，並可避免使用不同雲端服務所出現的問題。
開始重視社群網路，ERP租賃系統也將上線
Oracle為強化公有雲的服務內容，今年6月，他們所推出的Oracle Cloud是以Oracle Public Cloud為基礎，延伸更多的產品服務，將此產品分成3大區塊，包含應用服務、平臺服務與社群服務。
同時，Oracle也將更進一步地把旗下所有應用程式，搬上公有雲服務產品中，像是ERP服務ERP Services與人才管理服務Fusion Talent，以及銷售和行銷服務Sales and Marketing Services等應用程式服務。
社群網路也是Oracle很注重的領域。他們在Oracle Social Network的服務中，偏重於協同合作，提供使用者在使用公有雲服務的同時，透過網頁式的介面環境，可以進行交談、文件分享、會議等互動。這項服務目前包含在CRM產品裡面，也可以單獨訂購。綜合來看，CRM產品算是較早雲端化的產品，Oracle也看準此領域的發展，並不斷強化其應用。
相較於其他公有雲服務廠商，Oracle在應用程式的選擇性多，企業用戶可以從本身需要的角度來決定。舉例來說，企業可以選擇用Oracle的CRM、HCM公有雲服務，當自己要開發一個客製化的應用程式，還可以加上Database Cloud Service、Java Cloud Service。未來如果希望擴充需求，在這樣的公有雲平臺之中，也可以方便管理，或是訂購一些Oracle周邊的服務。
[圖表]Oracle 公有雲架構 (點此看圖)
 
公有雲小檔案
Oracle Cloud
產品名稱：
    ●  Fusion CRM Cloud Service
    ●  Fusion HCM Cloud Service
    ●  Oracle Social Network
    ●  Java Cloud Service
    ●  Database Cloud Service
雲端類型：SaaS、PaaS
網址：cloud.oracle.com
上市時間：2011年10月7日
相關報導請參考「IT大廠進軍公有雲」
",https://www.ithome.com.tw/tech/88753,"Cloud,公有雲,OpenStack"
88750,35,2012-07-06,IBM公有雲服務強調企業環境使用,IBM以雲端運算的SmartCloud Foundations為基礎，提供針對企業用戶的SmartCloud Enterprise雲端環境，提供虛擬機器、軟體、線上儲存空間的租賃等服務。," 在2011年，IBM重新定義了他們的雲端服務SmartCloud Enterprise，將全部雲端服務分為基礎（Foundation）、服務（Services）與解決方案（Solutions）3種類型。但實際上，它們是由基礎架構服務（IaaS）、平臺服務（PaaS）與軟體服務（SaaS）等多種雲端服務，所組合而成的。
其中Foundation與Services都是結合PaaS與IaaS，提供了不同面相的服務，而Solutions則是融合了SaaS與商業運算服務（Business Process as a Service），在整體雲端運算的架構上，融合更多元的服務。而針對企業環境的公有雲IBM SmartCloud Enterprise，就是基於SmartCloud Foundation架構下所提供的服務。
IBM的公有雲是針對企業環境，並基於他們的私有雲 SmartCloud所架設的，目前在國際間一共有6個公有雲資料中心，包括美國2座，而加拿大、德國、新加坡與日本各一座，使用者在租用時，就要選擇使用哪一個雲資料中心。選擇不同的資料中心，在雲端的使用與功能上，不會有任何差別，但是要注意會因為網路距離而產生的不同延宕。不過依現在的網路傳輸速度來看，IBM表示，延宕的時間不會超過100毫秒，在使用上並不會明顯的感覺。不過整體來說，以臺灣的使用者而言，還是就近選擇日本或新加坡的雲資料中心比較適合。
能提供企業用戶9種x86平臺的虛擬機器規格
在公有雲服務方面，IBM的公有雲SmartCloud Enterprise提供了虛擬機器租賃的方式，讓企業可以依照需求選擇適合的虛擬機器規格。
而平臺方面，IBM的公有雲服務目前僅支援x86平臺的作業系統，目前尚未支援Power System與System Z等系統平臺，但是預計將會支援Power System，不過時間尚未確認。
目前他們一共提供了9種x86系統選擇，包括4種32位元，以及5種是64位元。以32位元的系統來看，使用者可選擇1顆、2顆或4顆處理器，而64位元則是2顆到16顆；在記憶體方面，32位元的有2GB與4GB等2種配置，而64位元的虛擬機器，記憶體則有4GB、8GB與16GB等。
根據表1以最低規格的32位元銅級來看，IBM公有雲的每臺VM搭配1顆時脈1.25GHz的處理器、2GB記憶體，以及60GB的磁碟容量，在作業系統方面，則有Redhat、Novell SUSE與Windows Server 2003／2008等，以每小時的使用量來看，未稅的價格分別是4.125、3.135與3.300元（新臺幣），如果使用者自備的作業系統，不必額外租賃作業系統，價格則是每小時約2.475元。
會採用每小時的計費方式，IBM表示，是因為使用者所需要的系統，不見得都需要24小時開機，因此才會以每小時計費。以他們提供的32位元銅級的配備，搭配Windows Server 2008 R2作業系統為例，而且每天開機12小時、1個月30天來看，每月的費用大約是1,188元，一年則是14,256元。要注意的是，這些費用只包含虛擬機器的數量與規格，而資料傳輸的費用是另外計算的。
除了提供Windows與Linux等作業系統平臺之外，在應用程式方面，目前IBM提供了多達上百種應用程式的映像檔案（image），包括Rational、Lotus、WebSphere、Tivoli等IBM本身的軟體產品，另外也有Aviarc、Kaavo IMOD 試用版與SugarCRM Professional等第三方軟體。
而這些軟體的租賃方式也相當多種，包括線上直接選擇軟體映像檔、使用自有的軟體序號，或是使用自有的軟體與序號等。
要使用這些軟體，我們也只要在選擇雲端中心、虛擬硬體規格、網路設定與作業系統之後，再勾選要啟用的軟體映像檔，SmartCloud Enterprise就會自動部署。要使用IBM的公有雲服務，只要到SmartCloud網站，輸入帳號與密碼即可。
另外，IBM基礎架構服務還提供了線上的檔案儲存服務，最大的特色，在於使用者可用的儲存空間趨近無限大，沒有單一檔案的容量限制，儲存的每一筆檔案都有加密，且使用者可透過網頁，或IBM合作夥伴Nirvanix的CloudNAS設備管理。
提供線上試算，可評估服務所需花費
目前臺灣的企業用戶要使用SmartCloud Enterprise，要先與臺灣IBM確認服務的內容，例如虛擬機器硬體規格、數量、連線設定、使用時間，以及搭配的作業系統與軟體等，並與他們簽訂合約才可開始使用IBM的公有雲服務，目前不能直接線上註冊帳號，以及使用信用卡刷卡。因此，在啟用IBM公有雲服務的過程，需要建立與簽訂合約，因此公有雲服務無法隨時申請與立即啟用，不過這樣的好處，是他們可開立發票。
此外，對一些想先測試與了解的企業而言，IBM的公有雲服務目前並沒有提供免費試用，對此，他們會建議用戶，初期先以使用單一虛擬機器的方式，嘗試一個月之後，再來評估是否符合需求。
另一方面，他們還提供了線上的價格試算功能，使用者可以選擇作業系統與軟體的數量、預計使用時間以及資料傳輸量，即可估算出每月所需要的費用。
比較要注意的是，在選擇平臺、軟體、數量與使用時間之外，在費用的計算上，還有一項是額外計算的，那就是數據資料的傳輸。
在使用者端所能獲得的服務方面，IBM SmarCloud Enterprise提供了免費的線上諮詢服務，不過這個服務比較像是論壇的形式，也就是用戶可以在上面提出任何關於SmartCloud的問題，管理人員會在上面解決或回應，但是在回應的時間上比較不即時。
就整體使用狀況而言，目前IBM的SmartCloud Enterprise提供了整合PaaS、IaaS與SaaS的公有雲服務，提供多種x86平臺虛擬化系統，並結合上百種軟體，價格透明且可以線上估算費用，但很可惜無法試用。
[圖表]IBM公有雲可租用虛擬機器規格表 (點此看圖)
【註：規格與價格由廠商提供，因時有異動，正確資訊請洽廠商。】
 
公有雲小檔案
IBM SmartCloud Enterprise
產品名稱：
    ●  Virtual Machine
    ●  Software License Pay As You Go
    ●  SmartCloud Enterprise Object Storage
雲端類型：IaaS、PaaS、SaaS
網址：http://www-935.ibm.com/services/us/en/cloud-enterprise
上市時間：2012年7月（臺灣）
【註：規格與價格由廠商提供，因時有異動，正確資訊請洽廠商。】
相關報導請參考「IT大廠進軍公有雲」
",https://www.ithome.com.tw/tech/88750,"Cloud,公有雲,OpenStack"
88749,35,2012-07-06,HP公有雲擁抱OpenStack公開標準,HP以開放原始碼技術打造公有雲服務，並遵循OpenStack公開標準，免除使用者擔心被廠商綁死而無法移轉的問題，未來HP的公有雲將提供多種不同的應用程式開發環境," HP在5月10日推出公有雲服務HP Cloud Services，採用OpenStack公開標準，目前已有3項服務開始提供公開測試（Public Beta），使用者只要註冊帳號與信用卡，即可使用按時計價的雲端運算服務。
HP在推出HP Cloud Services之前，已經針對特定應用程式提供代管雲（Managed Cloud）服務，例如為企業提供Microsoft Exchange、SAP ERP等應用的雲端環境；至於HP Cloud Services，則是一般所認知的公有雲服務，提供虛擬機器、儲存空間、流量快取等雲端服務，就像Amazon Web Services的服務一樣。
HP Cloud Services目前提供6項公有雲服務，分別是HP Cloud Compute、HP Cloud Object Storage、HP Cloud CDN、HP Cloud Block Storage、HP Relational Database for MySQL及HP Cloud Identity Services。其中，Compute、Object Storage與CDN皆是公開測試，使用者已可購買使用，而Block Storage、Relational Database for MySQL則仍在封閉測試（Private Beta）階段，預計在2012年下半年會開始進入公開測試。
HP著眼PaaS開放平臺
這6項公有雲服務分別屬於IaaS與PaaS模式，雖然HP提供的Compute、Object Storage與CDN等IaaS服務看起來與Amazon類似，但是惠普企業業務事業群雲端運算總監范欽輝表示，HP的目標與Amazon不同，HP的重心會放在PaaS，因為HP打造公有雲並不只是為了提供運算服務，更重要的是思索下一個世代的雲端應用程式。未來的應用程式可能就是直接在雲端PaaS平臺上開發，因此HP想要打造一個開放的PaaS生態圈，可以容納各種不同的開發環境，讓軟體開發者可以有所選擇。
相較於其他提供PaaS服務的廠商，不論是微軟或Google，其PaaS平臺都只支援自家的開發框架，然而HP則希望建立一個基於OpenStack開放雲端標準的PaaS環境，讓這個平臺可以提供多種應用程式開發環境，目前HP正與應用程式框架開發者洽談合作。
OpenStack聯盟目前正在打造開源雲端標準，讓雲端服務有共通的標準，使用者即可不受服務商的限制，而能自由地將服務轉移到不同的平臺，不論是在公有雲服務之間移轉，或是在私有雲與公有雲之間移轉。
目前已有將近200家公司加入OpenStack，其中包括多家知名IT廠商，如英特爾、AMD、HP、Cisco、Juniper、NetApp、Citrix、Red Hat等等。OpenStack主要推動者之一的Rackspace，也在今年5月1日推出OpenStack公有雲服務。
擁抱公開標準，確保雲端服務互通
企業對於公有雲服務主要有兩大擔憂：怕被廠商綁死以及雲端的全安全性，范欽輝表示，所以HP對於雲端服務有3大訴求，首先是確保客戶擁有選擇權，因此必須採納公開標準，提供多樣化的平臺；再者是可信賴，要保障雲端服務的安全性與提供良好的管理；第三則是一致性，確保應用程式與資訊的一致。因為支援OpenStack公開標準，用戶就不必擔心無法轉移，而針對安全與管理性的問題，范欽輝指出，HP將旗下的伺服器、網路、儲存、網管軟體、應用程式管理軟體、資安軟體等產品，以及雲端建置的經驗，整合為針對雲端服務優化的平臺，因而提出融合式雲端架構，而HP的公有雲即是融合式雲端架構的成果。此外，HP也利用其原始碼檢測產品找出OpenStack的軟體漏洞，提報給OpenStack聯盟修改，以強化此一平臺的安全性。
HP公有雲目前只由美國機房提供服務。以HP Cloud Compute來說，現在有3個地區的運算池可供選擇。范欽輝說，未來機房會繼續擴充，並且將會在美國以外的其他地區建置機房，以就近提供更好的服務；此外，HP也會尋求在地的雲端服務代理商，透過雲端服務代理商提供企業技術支援，以及滿足臺灣企業需要開發票的帳務需求。

HP Cloud Compute運算服務
HP Cloud Compute虛擬機器服務是以開源虛擬化技術KVM所建置，目前所支援的作業系統皆為Linux的分支版本，包括CentOS、Debian Squeeze、Fedora、Ubuntu，未來將會支援更多的作業系統。
HP Cloud Compute提供REST格式API，並且提供Ruby Fog的API Binding工具，由於採用OpenStack標準，亦可採用OpenStack支援的API Binding，如PHP、Apache libcloud、Python、C#等。

【註：規格與價格由廠商提供，因時有異動，正確資訊請洽廠商。】
HP Cloud Object Storage儲存服務
：HP Cloud Object Storage平臺運行在HP的高階伺服器，可儲存的單一物件最大容量為5GB，若檔案超過5GB，亦可將檔案切散分開儲存。
在HP Cloud Object Storage的每一個儲存物件，都會自動複製3份，分別儲存在3個地理位置不同的機房，而這些機房皆有雙電力與雙網際網路連線的備援機制，以確保資料儲存的安全。

【註：規格與價格由廠商提供，因時有異動，正確資訊請洽廠商。】
 
公有雲小檔案
HP Cloud Services
產品名稱：
    ●  HP Cloud Compute
    ●  HP Cloud Object Storage
    ●  HP Cloud CDN
    ●  HP Cloud Block Storage
    ●  HP Relational Database for MySQL
    ●  HP Cloud Identity Services
雲端類型：IaaS、PaaS
網址：hpcloud.com
上市時間：2012年5月10日
相關報導請參考「IT大廠進軍公有雲」
",https://www.ithome.com.tw/tech/88749,"Cloud,公有雲,OpenStack"
88744,35,2012-07-06,微軟公有雲在臺上市主打中文在地支援,微軟逐步擴大公有雲服務類型，Windows Azure從早期的PaaS服務，進一步延伸到IaaS，再加上新推出的線上辦公室軟體服務Office 365，這些服務都正式在臺上市，且能提供統一發票方便企業報帳," 微軟兩大雲端服務接連在臺上市，包括了以PaaS和IaaS服務為主的Windows Azure雲端平臺，以及以SaaS服務為主的Office 365。這些服務進軍臺灣後，最大的不同就是中文化與臺灣在地的技術支援。
早在2008年，微軟就發表了Windows Azure平臺，企業或開發人員可將.Net應用程式部署到Windows Azure上執行。但這項服務遲遲未支援正體中文介面，臺灣企業若要使用這項服務，得到美國版網站申請使用帳號，付費方式也得採用信用卡付費機制。而且這些服務都由美國地區的資料中心負責
今年6月14日，Windows Azure終於在臺上市，提供了3種運算服務。第1種運算服務就是用來執行應用程式的Windows Azure Cloud Services。
這個服務提供了2種執行環境，一種是預先組態完成的IIS環境，稱為Web Role，可用來部署網頁應用程式或提供Web Services。另一種則是沒有提供外部HTTP存取的Worker Role執行環境，適合用來執行沒有使用者介面的後端應用系統，也可長時間非同步或批次執行。Cloud Services可以部署C#、Java、PHP、Python和Node.js語言開發的應用程式，當然也支援.NET開發框架的應用程式。
虛擬機器服務可支援非Windows作業系統
第2種運算服務則是今年剛推出的IaaS服務，名稱為Windows Azure Virtual Machines服務，可提供虛擬機器租用，微軟也準備了不同作業系統的映象檔供企業選擇，包括Windows Server 2008 R2、Windows 8、CentOS、openSUSE和Ubuntu等。企業可以利用腳本程式或透過API來管理虛擬機器。另外也可以使用Blob 儲存體來保存VM狀態。
目前微軟提供了5種虛擬機器，最低規格的是超小型（XS）虛擬機器，可提供單個1Ghz虛擬處理器、768MB記憶體和20GB儲存空間，而最高規格的超大型（XL）虛擬機器，則可提供8個1.6Ghz的虛擬處理器，14GB記憶體和2TB的儲存空間。
最後1種運算服務則是用來部署網站的Windows Azure Web Sites服務，企業可以選擇多種開源網站系統，如WordPress、Drupal等，還可以選擇搭配不同的資料庫系統，包括類似微軟SQL Server的SQL Database資料庫或是MySQL資料庫。
在Windows Azure上，微軟目前提供兩種付費租用方式，包括線上付費購買，以及企業大量授權模式（EA）。線上付費模式包括了按用量多寡收費的隨用付費（Pay as you go）以及有價格折扣的6個月付費兩種。用量計算項目包括對外頻寬、資料庫用量、儲存空間、虛擬機器規格和執行時間等。EA授權則按租用服務多寡另外提供授權計價優惠。微軟目前也提供3個月試用，試用環境會提供20GB記憶體、1GB SQL Azure以及20GB的資料傳輸頻寬。
除了IaaS和PaaS以外，微軟也剛在臺灣推出了Office 365服務，可以提供包括電子郵件、行事曆和聯絡人管理的Exchange Online，提供協作網站空間的SharePoint Online，可提供線上會議和即時訊息通訊的Lync Online，以及線上版文書處理工具Office Web Apps。另外微軟在Office 365的部分高階搭售方案中，也結合了Office Professional Plus套裝軟體的訂閱授權。
Office 365採按月付費方式，銷售方式可分成中小企業使用的P1方案，以及中大型企業使用的E1、E2、E3和E4方案等4種。P1方案鎖定中小企業，可提供內部共用的行事曆、電子郵件系統、視訊會議、即時通訊、電腦語音通話、小組網站、外部網站、防毒及垃圾郵件過濾等，也能提供Office文件的線上編輯功能，但使用者上限是50人。
E1則包含了P1所有的服務內容，但不提供Office文件線上編輯而只能瀏覽，但可以提供進階同步機制、可建立300個內部子網站，可設定的反垃圾郵件篩選以及24小時全年無休的客服。E2方案則是E1方案再加上Office文件線上編輯功能。E3和E4方案除了涵蓋原有E1功能，增加信件容量限制等，也增加了Office Professional Plus 2010桌面軟體的訂閱，E4則是多了企業語音服務。另外，企業也可以單獨訂閱某一項線上軟體服務，例如SharePoint Online或Exchange Online，費用另計。
東京機房提供的服務速度不輸在臺建置
目前，微軟在臺灣提供的Office 365服務，是透過微軟在新加坡與香港的機房來提供，企業不能自選機房。臺灣微軟營運暨行銷事業群資訊工作者事業部副總經理丁維揚表示，兩座機房都會存放Office 365的資料，並互相備份。
而Windows Azure服務由全球8個資料中心提供服務，而且臺灣企業可選用位於日本、香港或新加坡等地的東亞資料中心。實際租用過美國Windows Azure服務的九福科技總經理黃國紋表示，他們透過東京資料中心對臺灣使用者提供網頁服務的速度與在臺建置相當。
不過，目前Windows Azure美國帳號資料無法和臺灣帳號資料互通，已申請美國帳號的企業，必須重新申請臺灣帳號，再自行轉移應用系統到臺灣帳號所提供的執行環境中。
可開立統一發票與中文語音電話服務
不管是Windows Azure或是Office 365服務，除了基本的網站中文化和文件中文化之外，微軟也提供中文語音電話服務，甚至Office 365的語音電話還可以提供臺語服務。此外，臺灣微軟會開立統一發票，供企業報帳之用，也採臺幣計價。
另外，微軟也與本地端SI業者合作來提供中文技術支援，臺灣也有軟體業者利用Windows Azure來架設自家服務，例如正航資訊就利用了Windows Azure平臺來提供EIP服務來試水溫。

 
公有雲小檔案
Windows Azure
產品名稱：
    ●  Windows Azure Cloud Service
    ●  Windows Azure Virtual Machines
    ●  Windows Azure Web Sites
雲端類型：PaaS、IaaS
網址：www.windowsazure.com
上市時間：2012年6月14日在臺上市
【註：以上資訊由廠商提供，因時有異動，正確資訊請洽廠商。】
 
公有雲小檔案
Office 365
產品名稱：
    ●  Exchange Online
    ●  Lync Online
    ●  SharePoint Online
    ●  Office Web Apps
雲端類型：SaaS
網址：www.microsoft.com/zh-tw/office365
上市時間：2012年6月27日在臺上市
【註：以上資訊由廠商提供，因時有異動，正確資訊請洽廠商。】
相關報導請參考「IT大廠進軍公有雲」
",https://www.ithome.com.tw/tech/88744,"Cloud,公有雲,OpenStack"
88736,35,2012-07-06,臺灣大學計算機及資訊網路中心：臺大將打造Pay as you grow服務,臺灣大學計算機及資訊網路中心打造的「觔斗雲」平臺，第一階段要讓使用者能自選合用的運算資源，第二階段則是希望能讓使用者可以快速地動態調整所需資源，最後的目標則要做到自動擴充運算資源的Pay as you grow服務," 臺灣大學（簡稱臺大）身為臺灣第一學府，為了營造自由的學術風氣，研究領域包羅萬象，組織架構也相對地複雜。在偌大的校園裡共涵蓋12個學院、54個學系、100多個研究所等學術單位，加上9個校級行政單位，林林總總共包含上百個單位。一個單位可能多達數百人，如同一間獨立營運的小公司，除了校方提供的資金之外，這些單位還有自己的資金來源與發展目標，甚至會設立自己的IT部門，自行建置與維運IT基礎設施與系統。
臺灣大學計算機及資訊網路中心（簡稱臺大計中）相當於臺大IT部門，又如同面對上百間小公司的IT廠商，因為經費與資源有限，計中原本只負責學院或行政處室等校級單位的IT需求，以及全校共用的應用系統，包括研究單位的高效能運算（HPC）、全校的電子郵件服務，以及183套校務行政系統等，其他系所或非校級單位則必須自行建置IT系統。
不過，自從2009年，臺灣大學計算機及資訊網路中心主任孫雅麗上任以後，她發現臺大ICT兩方面的缺陷，包括了臺大計中主導的校務行政系統經常有穩定度與效能管理不佳等問題，其他單位則經常面臨自建與維運IT的困境。 2009年適逢虛擬化技術逐漸普及，雲端運算服務興起，孫雅麗決定打造全校的私有雲來克服這些問題。
臺大早在7年前就展開全面e化，由臺大計中負責將紙本作業的校務行政流程電腦化，目前已開發了多達183套校務行政系統，並負責日後的維運管理。
不過，當初臺大計中為各業務單位開發這些系統時，為了求盡快上線，只是將紙本作業流程原封不動地e化，沒有對系統架構做整體的規畫，也沒有確實建立系統效能監控與資安隔離等配套措施。導致數百個系統間後來互相干擾影響效能和穩定性，卻因為系統架構與區隔不明確，維護人員難以找出系統故障的癥結點究竟發生在哪一個環節。
二來，這些問題也導致IT團隊的維運管理工作職掌很難明確地畫分，因每套系統必須橫跨網管、系統管理、程式開發等不同IT技能的人員來負責，這3種職掌又經常互相重疊，容易發生效能監控的盲點。每當系統故障，這3種IT人員容易互相推託責任，難以找到負責的人員，往往拖延了排除系統故障的時間。
另外，許多校務系統離尖峰的流量落差懸殊，只有在特定的尖峰時間才需要大量的運算資源，平時甚至不太需要運作。例如，新生報到系統與選課系統只有在開學前，必須支援多達上萬名學生的上線流量，但學期過程中都不太需要運作，承載這些系統的伺服器通常會有很長的閒置時間，無法有效地運用。
研究單位常有臨時性IT需求及自建困境
除此之外，臺大校內的各個單位也面臨了類似的資源閒置問題，不過，原因主要是缺乏長期經費的支持和後續維護人力不足。
孫雅麗發現，許多研究單位的教授向外部機構申請了研究計畫後，必須在短時間內自建IT設施與系統。為了節省研究經費，這些教授會請研究生或工讀生協助開發與建置IT系統，或委外給廠商來做，但研究計畫在數個月內就結束了，研究生與工讀生離開校園，經費也耗盡了，教授難以繼續維運這些軟硬體設施，因而荒廢不用，原本可運作5年IT設施只用了數個月很不划算，白白浪費了研究經費。
不僅研究單位，其他非校級的行政單位自建系統時，也面臨長期維運的問題，尤其是缺乏IT團隊的小型單位，像是保健中心及各處室內部的小型系統。這些小型的系統也容易因為建置的學生畢業了，或給廠商的維運費用不足，而成為無人維運的孤兒系統。
按資源供應彈性，將雲端服務分為3大層次
在內外雙重困境的促發下，在2010年臺大計中決定採用微軟MCloud解決方案來打造全校共用的私有雲，名為「觔斗雲」服務。
孫雅麗表示，希望將IT轉換為如同使用水電資源一般的動態計費服務，讓這些單位不必臨渴掘井，也不必自建IT基礎建設，只要開啟臺大私有雲的網頁就能訂購與取用IT資源，搭配自助式平臺與付費機制，讓使用單位按照使用量計價，用多少算多少，就能夠滿足短期且大量使用或自建系統的需求。
孫雅麗表示，臺大計中按資源供應彈性的不同，來擬定觔斗雲的3大發展階段。
第一階段，讓使用者認為雲端運算的資源無窮無盡、用多少算多少，此為Pay as you use，也是臺大觔斗雲目前已完成的階段。不過，在此階段使用者仍必須事先掌握資源用量，才能選購對的服務方案，必須要等到第二階段，使用者才可不必預先掌握IT系統的資源用量，隨時用量有變動時，就能在短時間內動態調整服務方案，如同在自家機房內擴充資源一般，稱為Pay as you go。在第三階段，觔斗雲可按使用者的業務成長需求，自動擴充運算資源，稱為Pay as you grow。
從硬體、平臺到應用發展5大服務，2年內完工
臺大觔斗雲從IaaS基礎設施層、PaaS平臺層及SaaS應用層逐步發展，預計在2年內推出5大服務項目，目前已推出虛擬主機租用服務（NTU VM）、儲存空間租用服務（NTU Backup），以及免費雲端檔案服務空間（ NTU Space）。前兩者採用微軟MCloud解決方案，並由微軟客製觔斗雲的自助式網頁平臺，供使用者自行線上點選或更改服務方案；後者採用華碩WebStorage線上儲存服務，提供校內師生跨平臺的線上儲存空間。
今年中以後，臺大預計推出另外兩項服務，包括免費雲端虛擬桌面系統（NTU Desktop）及免費雲端軟體協同應用共享系統（NTU AppShare），讓師生線上取用虛擬桌面或其他軟體服務，如Office、ArcInfo、掃毒軟體和MatLab等。
以MatLab套裝軟體為例，以往臺大各研究單位會自行買斷50套MatLab軟體授權，再安裝於自行架設的伺服器設備上，每隔幾年還要升級版本，但這些單位不會整年都用，只有偶爾上課或做實驗才用到，容易浪費成本。未來計中只要採購2百套軟體授權，再透過線上軟體服務提供全校使用，臺大師生登入這個服務就能連線至NTU Desktop或NTU AppShare平臺來使用，再針對用量計價，來達到按需付費的好處。
孫雅麗表示，待觔斗雲的5套服務都順利上線後，臺大計中會串連這5項服務，打造全套的雲端電腦教室服務。屆時臺大師生可在不同地方、使用任何裝置登入雲端電腦教室的平臺，開啟建立在NTU VM平臺之上的NTU Desktop虛擬桌面服務，點選及取用NTU AppShare清單上共用的軟體來進行線上課程。
此外，師生可將需要長期備份且較少使用的資料存放在NTU Backup平臺，另將要隨時隨地跨裝置取用的資料，放上免費雲端檔案服務空間NTU Space平臺。如此一來，各單位就不必自建電腦教室，師生也不必非得前往計中，只要登入觔斗雲，就能上課和做研究。
先整頓IT系統架構與組織分工，再做虛擬化
NTU VM租用服務在2011年2月正式上線後，目前臺大183套校務行政系統及第二代全校電子郵件系統、單一帳號登入（SSO）系統已移轉至該平臺，由於這些系統原來就屬於計中的管轄範圍，所以計中沒有額外收費。有些研究單位及非校級行政單位也開始採用此平臺，並按照用量付費，這些外部系統已有30套左右，包括總務處文書組的公文管理系統、臺大訪客中心系統等。孫雅麗表示，未來此NTU VM平臺也會作為雲端電腦教室的IT基礎設施。
計中建置NTU VM平臺時，評估了VMware與微軟Hyper-V這兩套伺服器虛擬化軟體。當時單套VMware vSphere軟體要價為15萬元左右，但微軟Hyper-V內建在Windows Server 2008 R2伺服器作業系統當中，不會增加太多經費，加上多數臺大校務行政系統大多以.Net平臺開發而成，也大多採用SQL Server資料庫系統。臺大計中考量成本與系統相容性後，選擇微軟Hyper-V作為私有雲的虛擬層。
不過，當時的Hyper-V對Linux作業系統的支援度不足，只支援少數幾個版本的Linux作業系統，多數版本都不支援，導致許多研究單位自行開發的Linux程式難以移轉，所以也有不少研究單位自行購買VMware軟體。而且2009年時，能支援虛擬化技術的伺服器款式不多，臺大計中必須額外採購IBM、HP等品牌的伺服器。
完成虛擬化平臺的建置後，接下來，臺大計中先將校務行政系統移植到虛擬化環境，系統移植的過程中，還必須清查不同年代建置的應用系統，將原本採舊版Windows作業系統的應用系統全數升級為2008 R2版，同時也升級舊版SQL Server資料庫版本，以支援Hyper-V軟體。
將系統陸續移轉至虛擬化平臺的同時，計中也重新擬定了系統架構與組織分工，以避免在虛擬化平臺犯下效能監控與穩定度的老問題。因此，計中重新清查所有校務行政系統，進行程式的最佳化，並重新畫分了IT系統架構與IT團隊的職掌，按應用系統的生命週期畫分為開發測試、上線、備份與系統管理這4大領域，制定標準化的IT作業流程，包括界定出程式開發、網路管理與系統管理的專業權責，讓每位IT人員專注於份內工作，避免職掌重疊。
孫雅麗表示，伺服器虛擬化後，不僅加快系統故障時的反應速度，同時因為標準化的IT作業流程與軟硬體規格，讓管理者更容易掌握整體IT運作機制，不會全部混雜在一起。
舉例來說，每學期開學之前，所有學生都要登入教務處的選課系統規畫整學期的課程，因而常造成選課系統當機，所以教務處在自家機房擴充了選課系統的伺服器臺數，來支援更大量的使用者。但計中負責的單一帳號登入系統（SSO）卻無法支援如此大量的使用者，反倒成為選課系統運作時的另外一個瓶頸。當時計中IT人員透過System Center系統管理平臺，找出SSO系統的效能瓶頸，立刻增設1～2個虛擬機器（VM），每個VM配置6顆虛擬處理器，不必採取傳統擴充主機的作法，還要完成共同供應契約等採購程序，擴充速度從以往1周縮短為1小時之內。
按設備購置與維運成本，制訂收費機制
校務行政系統移植到NTU VM平臺後，臺大計中也開始向校內其他單位推廣這個服務。雖然臺大計中並非營利單位，但孫雅麗堅持NTU VM和NTU Backup服務必須搭配收費機制，來分攤計中整體的建置與維運成本。
孫雅麗表示，臺大這兩項服務的訂價策略是，將伺服器主機的整體建置與維運成本加上配套設施的成本再攤提至5年，包括電力、UPS、油槽、防火牆、專業IT人員、虛擬化軟體、作業系統、IBM或HP主機等都包含在成本當中，粗估平均1臺基本規格的VM租用1年所需的經費。具體來說，計中採用的IBM H系列刀鋒伺服器當中，每片刀鋒大概容納了48GB，假設1臺基本規格的VM配置1GB記憶體，加上進行系統管理的VM，還能另外開設20～30個VM，加上其他配套設施，藉此計算出平均1臺VM租用1年的價格約為43,000元。
確定價格後，接著臺大計中開始擬定收費流程。為了讓各單位能夠申報費用，臺大計中先向會計室確認有「設備使用費」這項會計科目，讓各單位依此科目制定會計審核流程，才能付費給計中。另外，孫雅麗還將收費辦法送到校務會議上審查通過，這朵觔斗雲才開始營運。孫雅麗表示，觔斗雲服務的定價與收費機制，不單是計中訂出來就好，過程中還必須牽涉全校的會計審核流程與組織政策。
雖然NTU VM平臺在2010年時就建置完畢，但收費辦法直到2011年1月才確立，所以，臺大計中去年2月才推出NTU VM租用服務。去年10月時也推出了NTU Backup備份空間租用服務。
以華碩WebStorage平臺，為師生打造線上儲存空間
今年4月，臺大計中推出了如同Dropbox般的 NTU Space線上儲存服務，在推出的36小時內，使用人數就突破5千人，目前全校4萬多人已有1萬2千人登入使用，推廣速度頗快。
此服務提供學生免費10GB儲存空間，老師則有免費25GB容量，可享有跨裝置取用、資料分享、結合計中印表機與7-11店面的ibon列印服務，使用者不用像以前那樣要透過群組郵件或FTP來分享檔案。此服務分為Web版和Agent版兩種使用方式，Web版支援Windows和Mac兩種電腦作業系統，Agent版則釋出可支援iOS、Android等系統的App，可橫跨桌上型電腦、筆電、手機、平板電腦等不同裝置，使用者只要一連網，資料就會從NTU Space平臺同步到不同裝置。
孫雅麗表示，師生對此服務的佳評如潮，尤其是檔案同步所需的時間比Dropbox快速。不過，使用者仍針對此服務提出不少可改善之處。例如，有些高層主管願意付錢來擁有更大量的儲存空間，如100多GB，但計中和華碩當初沒有規畫NTU Space服務的收費方案與付費機制，還要等未來改版時才能再新增這些服務。
另外，使用者希望整合NTU Space和NTU Backup兩項服務，將經常取用的資料存在前者，不常用但要備份的資料可直接從前者拖拉至後者，但目前使用者還無法在兩種服務的資料夾間互相拖拉檔案，必須先下載檔案到本機端，再移轉到另外一個平臺。孫雅麗表示，這是因為NTU Space屬於華碩的產品，NTU Backup屬於微軟MCloud產品，未來計中必須要求兩家廠商合作，才能串連兩種服務。
臺灣大學觔斗雲的5大服務
臺大觔斗雲從IaaS基礎設施層、PaaS平臺層及SaaS應用層逐步發展5大服務項目，目前已推出虛擬主機租用服務（NTU VM）、儲存空間租用服務（NTU Backup），以及免費雲端檔案服務空間（ NTU Space）。今年7月，計中還會推出免費雲端虛擬桌面系統（NTU Desktop）及免費雲端軟體協同應用共享系統（NTU AppShare），讓師生線上取用虛擬桌面或其他軟體服務。


隨著觔斗雲使用量攀升，臺大計中要擴充機房空間，也成為另外一項挑戰，必須調整機房空調系統、檢視樓地板載重能力及建築物結構。目前給研究單位使用的HPC伺服器機櫃已搬遷至另外一間機房，原機房專門擺放用來部署觔斗雲平臺的機櫃。圖為去年底臺大機房放置觔斗雲機櫃的角落。


臺大觔斗雲的VM租用服務提供系統管理平臺，讓使用者可以隨時監控VM運算資源的使用狀態，並透過遠端連線來進行系統管理。

雲端服務上線後的挑戰
NTU VM租用服務上線已屆1年多，計中面臨了不少挑戰，包括改變使用習慣、使用者認為價格太貴、資源調度不夠即時、機房必須擴充等等。臺灣大學計算機及資訊網路中心主任孫雅麗表示，首先要說服各單位與上層主管接受新的雲端服務使用型態，改變以往取用IT資源的習慣，將IT營運從自家搬上雲端環境，設備和系統都不在手邊，使用者必須在觔斗雲的網頁變更服務方案，或透過遠端連線的方式進行系統管理。
孫雅麗表示，推雲端服務時，最困難的是改變各單位既有使用IT的方式，來接受新的雲端服務。
此外，有些使用者認為，自建主機與系統頂多2萬多元，若是租用NTU VM服務必須付4萬多元，價格反而更貴，使用者就更不願意採用。
但孫雅麗表示，計中為了維持高水準的雲端機房環境，就要提供建立完整的配套措施，包括雙備援主機、資料備份、不斷電系統、專業維運人力等，這些配套都需要成本，但使用者自建IT設備與系統時，大多不會做完整配套，可省略這些成本，所以使用者只看表定價格，就會認為雲端服務的價格過高。
為了讓使用者更容易接受雲端服務，臺大計中也釋出優惠方案，吸引使用者前來體驗雲端的好處。計中目前規定前6個月為試用期，使用單位可以不用付費，6個月後，還想續用才要付費，而且計中只要求支付原價約4折，所以一臺VM可從4萬多元降為1萬多元。
另外，限於臺大會計室的審核流程還沒有完全e化，孫雅麗表示，臺大計中目前無法建立如電子商務平臺般的自動化付費機制，使用者還必須先取得臺大計中的收據，才能向會計室或其他單位申報使用費，來完成紙本申報流程，由於申報過程較繁複，所以目前臺大計中規定，VM租期最少6個月，6個月之後才能以月為單位延長租用時間。
不過，目前使用者要開通服務時，還必須等待40多分鐘，無法立刻取得資源，主要原因是受限於系統管理平臺變更速度過慢，以及人工要先確認整體運算資源容量所花的時間。
使用者在觔斗雲平臺上勾選完需要的方案後，必須先去收電子郵件確認要開通此服務，確認之後，臺大計中IT人員就會收到使用者確認完畢的郵件，就使用者的研究計畫配置的經費及需要的資源容量，來確認NTU VM整體資源容量足夠因應，才會利用微軟System Center系統管理平臺來開通服務，此平臺開通服務的時間就需要將近40分鐘。孫雅麗表示，系統管理平臺也可以自動開通服務，但現在仍需要人工開通，是為了審核經費，並確認整體運算資源不會超量使用。

臺灣大學計算機及資訊網路中心主任孫雅麗表示，推雲端服務時，最困難的是改變各單位既有使用IT的方式，來接受新的雲端服務型態。

 
機關小檔案
國立臺灣大學
● 校長：李嗣涔
● 地址：臺北市羅斯福路四段一號
● 網址：www.ntu.edu.tw
相關報導請參考「企業雲端實踐術」
",https://www.ithome.com.tw/news/88736,"新聞,Cloud,雲端服務,雲端運算,雲端應用"
88734,35,2012-07-06,成功大學計算機與網路中心：成大IT打造有感服務吸引用戶,成功大學計算機與網路中心主任陳響亮表示，要推出雲端服務，就要以「有感」的服務規模打動使用者。而計網中心人員更要化身成校內師生專屬的服務業者，以百分百的服務滿意度，實現IT效益," 相信每一位初入大學的校園新鮮人，都曾聽過這句話：「大學，就彷彿是小型社會的縮影。」而對於雲端服務來說，校園環境，也正是開發測試的最好溫床。
位首於臺灣南部教學重鎮的國立成功大學，是臺灣少數的全科系綜合大學之一，其中包含的教學系所，可謂包羅萬象。不管是充滿人文歷史風情的文史學院，或是培養白衣天使的醫學系所等，各類教學聖殿，齊聚一堂，因此，也可稱為小型社會縮影的最好代表。
這樣複雜的校園環境，也造成學校內的資訊應用，十分異質化。成功大學計算機與網路中心主任陳響亮表示，光成功大學的教學老師，就有將近1千1百位，更遑論來自四面八方的全校學生，人數十分眾多。再加上處理各項師生問題的行政人員，例如教務處、總務處等，人數也是十分眾多。校內每一名師生、每位行政人員所使用的各種e化系統，都是計算機與網路中心（簡稱計網中心）負責的業務。
陳響亮表示，早期全校各行政單位只要有資訊需求，就會向學校申請採購經費，再自行採買軟硬體設備。但自行採購的結果，也造成各單位所使用的軟硬體設備等級參差不齊，有的單位使用的軟硬體設備比較新穎，有的則十分老舊。當計網中心要統一開發校務e化系統時，就很難找到一個標準的使用者環境。
因此，約末從6年以前，陳響亮表示，計網中心就開始規畫整併各行政單位的軟硬體設備。透過機房的集中，由計網中心統合來提供軟硬體設備，並且統一規畫與管理，如此，當計網中心需要開發各項e化系統時，也能以齊頭式的服務標準提供。
在整併全校各單位機房之後，陳響亮表示，更大的效益是，讓計網中心還有餘力去管理學校千位老師的研究計畫採購，甚至以此來收取部分的維運費用，提供更多的資訊服務。
自行採購軟硬體設備，維護人力流失成最大困難
陳響亮解釋，過去除了各行政單位之外，學校教授老師，如有研究計畫上的需要，也會自行採購伺服器等軟硬體設備，例如成功大學資訊工程學系、電機所、資訊管理等資訊相關系所，教授老師都會從研究經費中，撥取部分款項來採購各項軟硬體設備，並自行在研究室、教授辦公室等處，架設自己的小型機房系統，以此來讓學生練習開發，或自行研究使用。
對於資訊相關科系的老師、教授而言，在資訊的應用上，也有一定的專長與知識，因此即使自行架構系統或開發，也幾乎沒有使用上的困難。
但其實除了與資訊相關科系的老師需要自行採購以外，文學系等其他科系學院老師，也常需要自行採購軟硬體，例如最基礎的辦公教學用個人電腦、或文書處理軟體等，這些設備，過去都要由老師自行管理，甚至自行維護。
學校老師通常都會先聘僱學生來充當維修人員，如再有問題，則再請計網中心協助管理。但這麼做最大缺點是，陳響亮表示：「這些學生會畢業的」。當學生畢業後，系統維護的作業工作就很難持續維持，甚至在學生交接的期間，這些系統的運作就會進入作業混亂期。
有些學生對於系統維護很有興趣，系統維護的工作，就可以很輕易的上手。但對於某些系所而言，願意擔任維護工作的學生很少，系統維護的作業就沒有人執行。
導入2座刀鋒伺服器來運行高達90臺的虛擬機器
學生能力不一，系統的維護品質也是參差不齊。為了解決這些問題，6年前成大計網中心在統整全校行政單位的軟硬體設備時，就採用了集中化的機房架構，並導入2組刀鋒伺服器，汰換舊有設備，改用虛擬環境來執行各項校務系統。
現有成功大學實際運行的虛擬機器已高達90臺，而行政e化系統已有將近70％在虛擬機器上運行，陳響亮表示，其中節省的硬體設備採購成本和空間，效益可為十分明顯。
另一方面，計網中心也開始規畫將部分虛擬資源，提供給學校老師或職員租用。那些為了研究計畫而需自行採購軟硬體設備的師生，就可以轉而租用計網中心所提供的虛擬機器。計網中心提供雲端服務中的基礎設備租用服務（Infrastructure as a Service，IaaS），不用親自採購實體設備。
如此一來，學校老師不用再擔心系統維護的作業問題，而計網中心也可以租用收取的費用來進行服務的維護作業，由計網中心統一進行管理。
民國100年起，國立成功大學的租用服務「雲端計算租用服務」就已成功上線，至今，約已有50位教授老師租用服務，來進行研究開發等使用。
雖然從整體教師的人數來看，服務租用的比例不算高，但陳響亮表示，這是全臺首次由校園推出的收費雲端服務，也是成功大學教育雲的前身。行政e化系統的虛擬化和雲端計算租用服務只是成大教育雲的部分服務，以服務業自居的計網中心，還要提供更多好用的雲端服務。下一步，陳響亮就是要讓成功大學的教育雲使用範圍，擴及到全校每位師生。
陳響亮解釋，成功大學的教育雲區分為兩個部分。第一部份，就是每位師生幾乎每天都會接觸到的校務e化系統，包括每位學生的選課系統、學生的成績登入、註冊等等，這些資訊，在集中化架構後，通通都上到成大教育雲，由計網中心，統一替各行政單位管理。
而在這些系統之中，攸關每位學生權益的選課系統，每到每年的學期之初，就很容易發生系統不可用的情形。因為成功大學採用的是搶課制度，學生先上到系統，先點選到的課程，就可以優先選取。因此每到學期之初，選課系統開放之時，全部學生都想搶在第一時間上線，選課系統就必定會發生超載負荷的情形。
以虛擬環境徹底解決選課超載使用難題
學生選不到課，就一定會抱怨系統不好用，而這也是每次校務會議，學生必定會提到的首要問題。面對多數學校都會面臨的選課系統問題，陳響亮堅決的說，與其每次都拖的不管，「不如一次性的徹底解決」。因此，這套選課系統今年也要轉移到虛擬環境中，以便需要時可以調度更多虛擬機器，來因應瞬間暴增的使用人數上線。
陳響亮規畫，將這套選課系統在多臺虛擬機器上運行，透過負載平衡軟體來分流不同學院學生的使用情形。例如文學院就設定專屬的4臺虛擬主機來應付選課作業，而人數較多的其他學院，則再分配5至6臺的虛擬機器來執行。以此類推，來化解系統超載的情形。
而為了避免虛擬機器發生問題，陳響亮表示，原有執行選課系統的4臺實體伺服器也擴充到20臺，其中12臺伺服器作為虛擬機器選課系統的備援，而8臺伺服器則作為這12臺伺服器的二次備援。
陳響亮表示，預計今年度，選課系統所採用的新型系統架構，就可以實際採用。而今年9月即將到來的選課服務，就是此服務可用與否的最佳驗證時期，計網中心可謂積極備戰，
除了行政e化系統的服務可用之外，成功大學的教育雲的第二部分，就是提供給成大學生的加值服務。
陳響亮表示，目前除了讓老師、教授租用的虛擬主機基礎服務之外，預計今年，還要再推出全校師生都可用的線上儲存服務，讓成大的每一份子，都可以享用到計網中心所推出的教育雲服務。
要推雲端服務，就要推出真正「有感」的服務
面對市面上已有多種選擇的線上儲存服務，陳響亮堅決的說，「既然成大也要推儲存服務，就要推真正有感的服務」。陳響亮表示，如果每個學生都只給1GB或2GB的小小空間，與現在市面上服務相似性太多，選擇太多，學生也不一定會想用成大自己的服務。
但如果服務擴大10倍至每人20GB、30GB的超大儲存容量，而且是免費的，不管是學生或老師，也會增加想用的意願。因此，在服務規畫之初，陳響亮就將「有感」的服務概念，深植在成大教育雲服務內。
各類應用程式雲集成為成大線上App Store
而在儲存服務之外，成大教育雲也同步將各類應用程式，例如一般辦公室文書處理Office、統計軟體、繪圖軟體等各類學術可用的應用程式，通通都上到虛擬環境上，透過桌面虛擬化技術，來執行這些應用程式。
當學生或教師離開學校環境時，例如學校老師需要至北部開會，在開會現場，需要立即使用辦公室文書處理Office文件時，使用者只要登入虛擬桌面的用戶端程式後，就可以使用計網中心運行在虛擬主機上的應用程式，遠端操控使用。即使使用者是使用平板電腦、智慧型手機等設備時，也可以使用計網中心內的運算資源，來執行不同的應用程式。目前成功大學測試可用的應用軟體，就已多達60套。
但其實，打造這些桌面虛擬化服務的同時，陳響亮還有個最終目標，就是要成立成功大學自有的線上應用市集App Store。這個App Store可以讓學生測試開發，甚至成為實際商品化的平臺。學生一部份可以練習開發，一部份也可以做為教師的教學平臺，此外也可與廠商合作提供教學軟體，供學生免費下載。這些新型態的應用，都將建構在成大教育雲底下。
行政校務雲強調安全與穩定，學生加值應用雲則要強調彈性與靈活
成功大學教育雲的兩大類功能的發展策略不同，陳響亮表示，執行虛擬環境的校務e化系統將以安全與穩定為運作重心。因為任何校務系統的資料，都必需要安全的保存，如果因為上至虛擬環境，而發生系統資訊錯置、或斷線的問題，對學校行政流程來說，就會發生問題，所以對這部分的系統架構，也要用高標準來檢視。
而專為全校師生提供的加值應用服務，陳響亮表示，則要以彈性、靈活為主。因為不管是線上儲存服務，或線上應用程式市集，都要讓全校師生共同使用，使用人數隨時都會擴增，因此服務也要能配合隨時擴增儲存容量，或讓各類服務都能順利可用。
讓使用者從買硬體，逐漸轉型習慣買軟體、買服務
其中，陳響亮表示，唯一要突破的，就是要讓使用者從買硬體的傳統觀念，逐漸轉型到租用軟體的概念。他形容，過去不管是各行政單位，或者是教師職員，每當有資訊需求，在直覺上，就會各自添購適合的軟硬體設備，部署上好像比較快速。硬體設備架設在自己可見的地方，資料存放的地方也很清楚，使用者相對會比較安心，感覺上也比較紮實。
但事實上，自己管理硬體設備的結果，卻造成師生自行維護的困難。因此，陳響亮表示，要讓使用者觀念轉型，就必需要透過宣傳，來讓使用者知道轉型後的不同。
目前成功大學的作法，是透過電子報、研討會等行銷手法，來讓使用者知道雲端服務的好處。而計網中心也會定期推出免費使用的活動，來吸引使用者使用。
但陳響亮認為，單純的行銷作法還是不夠，計網中心推出各種雲端服務，除了要讓使用者知道雲端服務的好處之外，最重要的，還要取得服務與使用者之間的互信。
以承諾來加強使用者與服務之間的信任感
而要做到互信，陳響亮表示，「計網中心還必需要對使用者有所承諾。」這樣的承諾是要透過第三方中介角色來實現，而對學校環境來說，各處室行政單位就是這樣的角色。
舉例說明，過去存放在學務處內的全校學生成績資料，改由計網中心集中管理後，不管是學生或老師，總會對資訊的管理有所疑慮。例如有學生可能會質疑，「成績都放在計網中心，計網中心要修改成績，一定也會比較容易」。
如果有這樣的疑慮產生，對於採用計網中心雲端服務的信心就會大幅降低。因此，陳響亮表示，這部分，就是計網中心要努力維繫的服務關係。
陳響亮表示，採用雲端架構後，系統化全面集中，雖然彷彿由計網中心一統天下，但職權並非就能無限上綱，計網中心主要是承擔管理、保護資料的責任，而任何與行政單位相關的業務作業，仍要由各處室負責執行。
例如學生需要修改成績，仍要透過教務處修改成績流程，由教務主任蓋章授權後，計網中心才能執行修改。或像是颱風發生時，計網中心不能自行對外發布學校停課，而要取得成大新聞中心的授權後，才能在學校官方網站上對外發布。
這些正式授權的流程，就成為使用者信任計網中心的來源。陳響亮表示，當計網中心掌握的資料越多時，各處室越需要職權分明，尤其要有特別的區分方法與重視作為，教育雲提供的服務才能取得校內師生的信任，而這也是讓使用者觀念轉型的關鍵，使用者才會更願意採用雲端服務。
對於陳響亮而言，他自詡能引導計網中心成為全校e化使用的服務業者。因為他深信，唯有將硬梆梆的資訊，轉型成在前線接觸使用者的服務人員，資訊的價值才能真正被發揮，因此，「IT也要重視滿意度」，他說。而這也是成功大學教育雲服務上線成功的原因。

國立成功大學從6年前開始整併各行政單位機房，並導入2座刀鋒伺服器來打造虛擬化環境，以提供IaaS租用服務。今年，成功大學預計還要推出全校師生的個人儲存服務，讓教育雲使用範圍可以更廣泛。

成功大學桌面虛擬化服務

成功大學在各項校務應用系統搬上虛擬化環境，例如辦公室軟體Office、或會計統計軟體等，讓使用者可以透過Citrix桌面虛擬化技術，在遠端透過手機、平板電腦等設備，取用計網中心所提供的各項應用程式資源。

 
機關小檔案
國立成功大學
● 校長：黃煌煇
● 地址：台南市大學路1號
● 網址：www.ncku.edu.tw
相關報導請參考「企業雲端實踐術」
",https://www.ithome.com.tw/news/88734,"新聞,Cloud,雲端服務,雲端運算,雲端應用"
88733,35,2012-07-06,老字號貿易商永和順：用雲端自助服務，創造差異化優勢,臺灣的中小企業永和順用雲端客戶關係管理系統，記錄所有同仁的努力過程，讓永和順不用打價格戰，就可以用IT系統帶來的優勢服務，搶占代理產品20％的市占率," 雲端服務是近年來非常熱門的IT技術字眼，但是對於許多臺灣企業而言，類似雲端這樣的先進服務，往往不是臺灣中小企業懂得如何應用的先進IT技術。
但是，臺灣有一間成立迄今46年的貿易商永和順，負責代理許多日本的軸承、門鎖、鏈條、滾珠等商品，不僅早在1985年就已經使用IBM大型主機，更早在2008年，便成為美國Salesforce.com雲端客戶關係管理系統（CRM）的早期使用者。
永和順董事長陳光源表示，IT已經是公司營運重要的核心之一，不論是採用大型主機、導入ERP系統的決策，或者是利用雲端服務的彈性，採用適合永和順產品特性的雲端客戶關係管理系統，看重的是這些對IT系統的投資，對公司營運帶來多大的效益。
趁早奠定公司e化基礎
早在1985年，永和順就導入了IBM的System 36大型主機，之後也一步一腳印客製化出適合自己的ERP系統。到了1989年，公司又順勢將主機更新為AS/400。
現任董事長陳光源就是發動e化的推手，他回憶表示，當時的合作夥伴已經是日本IBM的模範客戶，有一定的e化基礎和流暢的作業模式，公司整體營運效率很好。但在臺灣這端，當時的一切都還只能仰賴紙本作業，效率遠遠跟不上日本的合作夥伴。他當時便開始在思考，如果不能跟上供應商前進的步伐，那永和順的競爭力會在那裡？
當時陳光源建議公司斥資二百多萬元買進昂貴的設備，的確有很多的同業不以為然，內部也需要說服董事會和同仁認同這樣的決策。他認為，在公司還有盈餘的前提下，加碼提升自己公司的競爭優勢是必然的。事後也證明，永和順跟著供應商夥伴前進的決定是對了，除了關係更密切外，整體效率也大幅提升。
汰換ERP不成，另覓客戶關係管理系統補強
早期採用COBOL語言撰寫的系統，操作介面並不友善，加上面臨COBOL語言與大型主機的維護人才有斷層之虞，永和順總經理室特助劉懿萱表示，該公司開始評估是否應該順應潮流，將公司從封閉系統轉成開放系統，也同時希望能將舊有的EPR系統翻新。
在2008年年初時，當時永和順希望能夠升級公司的ERP系統，便開始尋訪各家軟體廠商，希望能夠找出一套適合永和順的ERP套裝軟體。只不過，汰換ERP系統的希望終究落空了。
劉懿萱指出，永和順代理銷售的產品非常多元化，以軸承產品為例，大到風力發電廠的發電機，或者是小到牙科使用的洗牙機器，都必須用到軸承。她說，光是要把各種軸承產品列出一致性的產品編碼原則，就具有相當的難度。
後來，永和順在遍尋不著適合的ERP產品時，因為找到有IBM大型主機軟硬體開發和維護經驗的合作廠商後，ERP雖然無法汰換，卻把原本呆板、沒彈性的ERP操作介面在2008年2月升級成Web版，讓ERP系統多了很多的使用彈性。
劉懿萱指出，在訪查適合的ERP產品的同時，也發現有客戶關係管理系統可以補足永和順一直希望能夠強化的客戶關係。雖然ERP以Web化的方式取代原本的系統汰換，但新增一套CRM產品則成為永和順的新目標。
雲端版的客戶關係管理系統更具有彈性
永和順產品編碼複雜已經是不爭的事實，當ERP系統汰換不成後，便希望能藉由引進新的客戶關係管理系統，作為永和順業務同仁在拜訪客戶的重要輔助系統。
只不過，劉懿萱說，在和許多國內外客戶關係管理系統的業者打交道時就發現，光是產品編碼的支援長度要能超過55碼的廠商，就已經少之又少，而許多原本允諾可以進行產品客製化的廠商，在聽完永和順的需求後，不是產品報價過高，形同完全客製化一套全新的客戶關係管理系統外，就是回覆永和順說，無法修改永和順提出的要求。
因此，劉懿萱說，當臺灣代理Salesforce.com的天新資訊找上永和順時，他們根本是抱持半信半疑的態度，開始去了解什麼是雲端版的客戶關係管理系統。
她表示，永和順最困擾的產品編碼長度，對於Salesforce.com而言一點都不是問題，因為可以任意設定欄位的長、寬、高，怕長度不足，產品編碼長度至少可以255字起跳。不只是產品編碼長度，連規定要請業務同仁填寫的文章內容字數，如果有需要，內容長度設個10萬字也不是問題。
有了好的第一印象，永和順也開始評估是否適合使用這套雲端版的客戶關係管理系統。劉懿萱表示，Salesforce.com提供各種設定的彈性，讓這套系統成為一個情報分析的平臺。以永和順的作業模式為例，董事長陳光源在每周朝會後，都會根據同仁的報告，希望同仁在拜訪客戶時，可以另外蒐集某些類型的資料，可以作為進一步的情報分析之用。
若是一般的套裝軟體，往往缺乏修改的彈性；若是客製化的產品，除非IT部門有同仁可以立即修改，若需要透過委外廠商進行修改，除了會拖時間外，也經常需要另行支付系統修改的費用。
但劉懿萱說，使用Salesforce.com的感受和效率完全不同，由她擔任這套雲端客戶關係管理系統的系統管理員，董事長只要確定要新增任何欄位的資料，藉由Salesforce.com提供的欄位設定與報表的彈性，她平均只要10分鐘內，就可以把新增的欄位開立完成，完全不需要仰賴廠商的協助，也不需要經由IT部門做複雜的設定，才能達到類似的功能。而且，Salesforce.com也針對管理員角色，提供各種詳細的完整後臺功能的教育訓練資料與操作解說，她認為，差別在於你對系統是否熟悉，可以在最短的時間內，找到需要新增欄位的位置。
而且，現在只要同仁將所有規定必填的欄位填寫完畢，並按下送出鍵後，系統就會執行電子簽核流程，劉懿萱表示，不僅情報蒐集的效率變快，也因為同仁都已經將各種欄位填寫完畢，公司便可以依照需要，進行各種類型的情報分析並提供即時各種報表呈現。「這樣的轉變，對於公司在制定各種營運決策以及提供客戶服務上，都是一個很好的參考數據。」她說。
安全是選雲端產品的最大考量
劉懿萱不諱言，剛開始接觸到Salesforce.com的產品時，因為對於雲端服務還是感到非常陌生，全部的資料都存放在國外廠商某個不知名的機房中，對於相關的安全性，是抱持相當大的疑慮。
不過，陳光源在美國工作的女兒，扮演了一個重要的推手角色。陳光源表示，當時公司在評估是否採用Salesforce.com的產品，在美國思科工作的女兒知道永和順評選之一的客戶關係管理系統就是Salesforce.com時表示，因為思科本身就是Salesforce.com的使用者，有思科公司的背書下，加上女兒平時使用經驗的推薦，便開始了永和順接觸雲端客戶關係管理系統的第一步。
而雲端服務和網路品質與環境又息息相關，劉懿萱說，當年還曾經遇到海纜斷線的情況。為此，她也特別打聽到，Salesforce.com雖然受到海纜斷線影響，但只是連線速度較慢，客戶還是能夠連得上該CRM系統，並且存取所需要的客戶資料。
陳光源表示，原本對於資料沒有放在自家環境還會感到不放心，但看到許多國際級的企業都是Salesforce.com的使用者時，反而不由自主的產生一股，資料雖然不放在自家環境中，但其實是Salesforce.com幫忙將相關的系統資料作異地備援的感受。這種安心的感受，加上企業對於各種e化系統的操作使用已經很嫻熟，都是讓永和順可以在早期就搭上這趟雲端順風車的主因。
對永和順而言，不只有成交的客戶才重要，劉懿萱說，如何記取開發客戶過程中的失敗經驗，從實際的客戶經驗去了解客戶對於產品在組裝與設計上的想法，也可以回饋給原廠做為未來日後產品改良的重要參考依據。「這些重要的努力過程，都只有在這套客戶關係管理系統中才看得見。」她說。
雲端服務跨平臺特性，打造永和順的差異化優勢
陳光源認為，永和順投資這套雲端客戶關係管理系統，一剛開始建置費用超過200萬元，之後就是每年支付使用者帳戶費用，但是雲端CRM系統跨平臺的特性，讓業務同仁隨時可以透過各種終端設備，登入這個雲端客戶關係管理系統，「可以第一時間知道產品資訊和以往曾經提供給客戶的報價資料，這樣就很值得。」他說。
不只如此，劉懿萱也說，採用雲端服務每年一定要支付帳戶的使用費用，但Salesforce.com承諾一年有4次的大升級，加上便於新增和修改的彈性，整體的初期系統建置成本，雲端和套裝產品或許相去不遠，但長期來看，雲端服務的彈性才是永和順最在意的效益。她表示，如果未來永和順不再使用Salesforce.com，該公司也會打包過往的系統資料給永和順，差別在於，使用者還是可以查詢使用，但無法新增任何資訊。
對陳光源而言，IT系統的投資看重的是對同仁帶來的效益為何，整個同仁的作業流程，如果少了IT系統的有效串接，或者少了某一項重要系統的投資，都可能讓以往的IT系統投資功虧一簣。因此，從30年前永和順開始e化的進展之後，IT系統就是一項必須長期投資的公司營運關鍵。
永和順是臺灣非常典型的中小企業，公司規模不大，人數遍及臺灣北、中、南部及中國。為了彌補只有ERP系統的不足之處，陳光源認為，客戶關係管理系統可以累積並記錄同仁業務開發努力的過程，是有助於臺灣中小企業營運升級的重要關鍵之一。他說，除了B2C的服務業適合建置這樣的系統外，提供各種B2B服務的客戶關係管理系統，只要用的好，都可以成為公司和其他同業競爭的優勢。
陳光源肯定的指出，永和順代理的各種產品中，因為長期在IT系統的投資帶來的客戶經營效益，讓永和順不用打價格戰，可以用優勢的客戶服務優勢，取得相關代理產品大約20％的市占率。

永和順董事長陳光源是該公司早期e化的重要推手，他認為，有早期e化基礎為公司營運帶來的效益，後來才有勇氣去採用新興的雲端服務。

 
公司小檔案
永和順公司
● 董事長：陳光源
● 地址：臺北市中山區南京東路二段98號10樓
● 網址：www.yhsco.com.tw
相關報導請參考「企業雲端實踐術」
",https://www.ithome.com.tw/news/88733,"新聞,Cloud,雲端服務,雲端運算,雲端應用"
88665,36,2012-07-06,臺灣微軟開發工具暨平臺推廣處總經理劉念臻：雲端服務Coding不是問題 架構設計才是挑戰,臺灣微軟開發工具暨平臺推廣處總經理劉念臻認為，雲端服務就是服務元件的組合，要成功上雲端的關鍵是架構設計，而不是Programming," 對臺灣開發者而言，最熟悉的開發技術，除了Java之外，就是微軟的.NET，不少IT人更是從學校畢業就靠.NET技術一路江湖十多年。在臺推廣這些微軟開發技術的關鍵人物，就是臺灣微軟開發工具暨平臺推廣處總經理劉念臻，他曾在貝爾實驗室擔任研究員，返國後在臺灣軟體公司負責軟體產品研發。從1996年加入臺灣微軟後，從Windows NT開發技術的推廣，.NET開發框架熱潮，到現在微軟Windows Azure興起，今年引進臺灣，他一路見證了臺灣IT人從傳統軟體開發，網頁應用開發，一直到現在開始要進入雲端應用開發的過程。
劉念臻觀察，雲端應用的第一波受益者是臺灣的ISV（獨立軟體開發商），因為雲端服務將會改變ISV的營運模式。他進一步解釋，過去ISV的軟體產品有兩種部署方式，一種是部署在使用企業的機房內，但要到每一家用戶企業的機房中維運，成本和人力需求很高。或者是可以建置在電信業者的代管機房中，但臺灣代管服務不夠發達，服務品質不穩定，老闆常常半夜睡不著擔心服務會中斷。這兩種作法都讓ISV業者難以擴大規模，拖累了ISV的發展速度，但是，「有了雲端，ISV就可以擺脫硬體伺服器的限制。」他說。
若用孫悟空來比喻雲端時代的應用模式，劉念臻表示，雲端資源可以像金箍棒那樣無限擴充，需要的時候可以伸長，不需要的時候可以縮小，而遇到大量敵人的時候，孫悟空還可以拔一把身上的毛，複製出很多分身來應敵，雲端環境也可以無限複製來滿足快速暴增的需求。
成功上雲端的關鍵是架構設計
但是，要讓應用程式要能善用各種雲端技術自然伸縮與無限複製的特性，劉念臻認為：「Coding不是問題，架構設計才是挑戰。」
對熟悉傳統開發技術的IT人，劉念臻認為，很容易就可以適應新的雲端環境，技術轉換的門檻其實不大，而真正的挑戰則是，ISV開發應用程式時，一開始就要想像出雲端運作的架構，而不是在單臺機器上執行。
這兩者的差別是，以前的應用程式可以是一個執行檔就能運作，但是到了雲端以後，是一群Web Services間互相呼叫來提供應用服務，程式架構和過去截然不同。「就像SOA觀念，雲端服務就是服務元件的組合。所以，上雲端的關鍵是架構，不是Programming。」
企業IT上雲端是要延伸機房，不是取代機房
劉念臻表示：「對ISV而言，上雲端是改變經營模式，是全新的變革，但是對企業的資訊部門而言，上雲端是延伸機房，而不是要取代機房。」
因為企業資訊部門的的工作就是維護機房裡的伺服器，倘若所有伺服器都被雲端取代了，就是挑戰IT人的飯碗。以現階段臺灣的發展來看，劉念臻認為，雲端不能完全取代機房，企業還是希望將核心應用系統，部署在企業內部比較放心，機房還是有存在的必要，「這是種可以控制，可接觸得到的信賴感。」而且，有些應用系統其實不需要彈性擴充，放上雲端執行的效益不高，也沒有必要，就可以使用原有的硬體設備來執行。
有的情況則是實體空間有限，必須透過雲端來延伸現有機房，例如新竹園區有家規模很大的公司，高層要求IT部門不准擴增機房，但對這家公司的CIO而言，還是要繼續提供更多資訊應用系統，
「這就是雲端的機會，採用IaaS就能擴充虛擬機房，這也是雲端的好處之一。」劉念臻表示，就像是美國親戚來家裡拜訪，家裡客房不夠了，我們會到附近旅館訂房。企業也可以將現有機房中不常用的應用，反而是放上雲端，騰出機房來開發新的需求。對IT部門而言，雲端可以讓資訊應用多一個靈活調配的空間，不需要困在機房裡。
對ISV而言，雖然企業導入雲端服務的門檻很低，看起來似乎比過去更容易銷售給企業使用，不需要好幾個月才能導入系統，但是，現在的客戶游離度更高，企業隨時可以停止使用。ISV的壓力變成得隨時提供新的功能，要讓顧客有驚喜。
要能隨時強化新服務，讓客戶持續認為有價值
不過，在雲端提供新功能是非常簡單的事，ISV也很容易透過雲端來提供測試功能或新應用程式的潛力，一旦沒有效果以可以馬上結束，再換新的產品。ISV業者可以更專注於本業的軟體創新，「真正做雲端服務，要能隨時強化新服務，讓客戶一直覺得有價值。」這個價值可以是新功能或是大降價，也可是顧客發生問題時，能透過客服中心取得很好的協助。「未來的的軟體生意就會是這樣的模樣，這是ISV經營型態的轉移。」劉念臻表示。
對ISV而言，需要善用PaaS服務，而企業則是可以運用PaaS、IaaS和自家內部機房，找出至這三者最佳化的配置方式，而新創公司則是可以善用雲端的環境，要短期快速嘗試新想法，「雲端讓IT可以有選擇，不像以前只能在機房發展，可以利用雲端創造更多靈活運用和選擇，這些都是IT發布模式和通路的變革。」劉念臻表示：「那些上雲端的企業，從來沒有想要回頭的。」
相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88665,"Cloud,雲端服務,App,IaaS"
88664,36,2012-07-06,台大計中主任孫雅麗：CIO要化身超級業務員將IT資源集中化,雲端服務透過IT資源集中化達到共有共享的效益，卻必須逐步改變企業運用與分配IT資源的模式，為此，CIO必須化身超級業務員，從內外上下集中掌握IT資源," 雲端服務平臺透過資源集中化，來達到共有共享及資源最有效運用，然而，企業要將資源集中化，不光是IT技術的問題，整間企業運用與分配IT資源的模式也必須隨之調整，逐步集中至提供雲端服務的IT部門。為此，CIO必須化身為超級業務員，由內而外、從上到下將IT資源集中化，包括系統、人力與經費等不同層面。
對於全校共100多個單位的臺灣大學（簡稱臺大），單位更獨立分散、規模更龐大，CIO要打造共用的雲端服務更是難上加難。
2009年適逢雲端運算技術興起，當時臺灣大學計算機及資訊網路中心（簡稱計中）主任孫雅麗開始思考，雲端運算能夠帶給臺灣大學什麼好處？雲端可以怎麼與臺大的營運目標結合。
臺大董事會當時設立的營運目標就是邁向一流頂尖大學，進軍全球前1百名大學排行榜。大學要闖出名號，有賴於校內研究單位建立豐碩的研究成果。孫雅麗認為，計中自比為全校的IT部門，雖然不能代替研究單位做研究，卻可以讓這些單位更方便、快速、低價地取用更好的ICT基礎設施。
但孫雅麗認為，過去IT部門因為無法突破一項重大的挑戰，所以提供的服務向來無法逼近需求，這項挑戰就是「規畫」這兩個字。「企業IT部門總要編列明年要多少預算、採購多少設備與系統，才能達到企業營運目標，這些規畫工作向來都是IT最大的挑戰，不能等到業務突然有需求時，才花了數個月的時間架好服務，而雲端運算能解決這項挑戰。」孫雅麗說。
孫雅麗發覺校內各單位預先規畫IT資源的難題後，進而打造了給全校共用的私有雲服務。這套雲端服務不僅解決各級單位自建與維運IT系統的負擔，同時也滿足研究單位難以預先掌控的臨時性運算需求。
計中建置這朵觔斗雲的第一步，先完成內部IT系統的大體檢，不僅進行程式最佳化，還重新規畫了整體的IT系統架構，按照應用系統的生命週期畫分開發測試、上線、備份、系統管理這4大領域，並依此畫分IT團隊的職掌範圍，讓每個IT人員可以專注於份內的工作上，避免職掌重疊的問題。
孫雅麗表示，為了防範未來雲端服務平臺的規模不斷擴大時，各種運作環節因缺乏制度而全部混雜在一起，計中建置雲端平臺的同時，也一併建立標準化的作業流程與軟硬體規格，讓IT團隊的分工更明確，管理者也更容易掌握整體IT架構與運作機制，提升整體管理的透明度。
向廠商借力，彌補IT人力不足
改善了對內IT系統的體質後，接下來CIO還要向外爭取資源。孫雅麗表示，CIO必須意識到，在打造一朵雲之前，所有資源都必須到位，包括IT人力、廠商、經費、組織政策、上層主管支持與否，以及使用單位的接受度等等。然而，在一間公家機關建置雲端服務，容易受制於公家機關行之已久的法規與組織政策，CIO想要重新分配企業的IT資源並不容易。
為了爭取資源，CIO必須變身超級業務員，從內部IT團隊到外部廠商、從上層主管往下到不同使用單位，逐一掌握資源，並透過調度來彌補資源補足之處。「不只是技術層面，還有企業的組織架構、政策、運作流程都要考慮進來。」孫雅麗說。
以孫雅麗的經驗來說，得先克服公家機關IT人力不足的問題，但公家機關的組織層級必須按照制式的明文規定，提高了IT增設人員的困難度。以臺大來說，臺大的人事甄審委員會將計中視為行政單位，如同總務處文書組，限制了碩士以上員工的名額與薪資，當孫雅麗希望招募更多的IT人員來建置私有雲時，困難重重，目前只能利用計中約4位IT人員來建置。
為了跳脫體制下人事政策的束縛，孫雅麗一再說服人事甄審委員調高薪資，並開放更多的碩士以上的人員名額。在計中內部組織架構上，孫雅麗開始將行政缺額轉換為IT的職位，透過精簡行政人力以擴編IT團隊。
在現有IT人力不足的情況下，孫雅麗便採用借力使力的策略，率先導入外部廠商的產品，不只讓臺大能夠優先推出雲端服務給使用者，同時也提供這些廠商練兵的機會，讓臺大成為該產品的首家成功案例，廠商就會願意投入IT資源與人力來協助建置，臺大就能以更少的資源完成服務。
確立雲端收費機制來補足經費
除了人力不足的問題之外，CIO能否爭取足夠的IT經費，來長期建置與維運雲端服務平臺也是一大關鍵。　因此孫雅麗堅持使用者付費的原則，規定VM租用與備份服務必須搭配收費機制，分攤計中建置與維運成本。
計中在擬定收費機制的過程中，必須涉及全校的會計制度與校務流程。為了讓各單位能夠申報費用來付費給計中，計中先向會計室確認有「設備使用費」這項會計科目後，各單位就能依此科目制定會計審核流程進行付費與報帳。另一方面，當時計中向各單位收取費用前，還必須先在全校的校務行政會議上通過的收費辦法，才能開始營運。
未來孫雅麗打算說服上層主管雲端運算的新觀念與效益，將IT層級提升至臺大董事會，設立全校發展IT的共同目標，藉此匯聚足夠的資源，並以更高的視野統合與順應各方的需求。孫雅麗表示，即使在資源有限的狀況下，臺大也要抱持著拋磚引玉的態度：做了再說，做了才知道效益與缺陷在哪裡。
相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88664,"Cloud,雲端服務,App,IaaS"
88663,36,2012-07-06,台達電子雲端技術中心資深處長翟本喬：企業軟體要上雲端必備的3大關鍵,企業要將軟體搬上雲端平臺時，每支軟體都要具備Scale-out和容錯能力，所有軟體彼此之間還要建構起模組化的SOA架構," 台達電子雲端技術中心資深處長翟本喬曾為Google研發省電伺服器，目前正在開發台達電自家的雲端服務平臺。翟本喬認為，企業若要將自家軟體移轉上雲端平臺，必須把握3大關鍵來實踐軟體即服務（SaaS）平臺的彈性，達到快速甚至自動化地開關、伸縮與搬移，而且不受底層故障或不相容的影響。在應用上，SaaS平臺不再以獨立運作的單套軟體為中心，所有軟體功能及其功能元件都轉化為一個個服務窗口，環繞著使用者，透過API介面進行協同合作來完成使用者的任務。
真正要實踐這樣理想的SaaS平臺，在單套軟體與整體系統架構都必須符合雲端的概念。首先，SaaS平臺上的單套軟體都具備了Scale-out與容錯的能力，以充分發揮雲端兼顧高彈性與穩定的效益，而所有應用集結而成的SaaS平臺，整體的系統架構設計是高度模組化的服務導向架構（SOA），因而能打通個別應用的大門，讓所有功能元件沒有上下層級之分，都能在同一水平互相介接存取，以使用者為中心來提供服務。
關鍵1：要能Scale-out
在翟本喬的心目中，理想的雲端平臺要能讓企業Pay as you grow，企業使用這樣的雲端平臺時，不必理會每臺虛擬機器（VM）的規格大小，或要買多少臺VM才足夠，企業只要將軟體丟上雲端平臺，此平臺就能按軟體的負載量變動，來自動增減資源用量。
好比企業從頭到尾只用了一臺能彈性伸縮的VM，否則企業每次在軟體負載量攀升時，還要考慮將整套軟體搬到更大臺的VM，如此又會重回傳統Scale-up的觀念。
企業要實現Scale-out軟體，不只是IaaS和PaaS底層架構的協助，上層應用軟體也要設計為分散式運算架構，來支援負載平衡功能，才能做到Scale-out，軟體能夠Scale-out，才能充分發揮雲端平臺自動擴充資源的效益。
翟本喬表示，目前絕大多數軟體應用都偏向執行交易（Transaction-based）的需求，如訂票系統、一般網站服務等，每筆交易與服務要求（Service Request）的關聯度不高，很適合設計為分散式運算架構。透過分散式運算的設計，這套應用就能支援負載平衡功能，將過剩的負載量移轉到別的機器，可及時Scale-out。
然而，許多企業會用虛擬化軟體的vMotion或Live Migration功能，將負載量過高的應用系統從小機器搬上大機器，這樣只做到了Scale-up，與雲端訴求Scale-out的概念背道而馳。「企業真正需要的是負載平衡功能，而不是vMotion或Live Migration。」翟本喬坦言。
當企業設計分散式運算的軟體架構時，必須讓每臺機器都能互相溝通，合力完成軟體設定的任務，不會有特定任務必須交給特定機器執行的情況。翟本喬打了一個比方，一個大型的巨蛋運動場設立了數百個入口，每個人都必須拿門票於入口處驗票才能入內，每個入口處如同執行任務的機器，每次的驗票工作就是任務或稱為交易。
如果管理員開放所有入口處都提供驗票服務，容易發生不同入口重複放行拿了同一張票去影印的觀眾。為了避免分散驗票的作法造成重複放行的問題，以傳統的作法來說，巨蛋管理員只會開放單一個入口處進行驗票，因此降低驗票的速度。
翟本喬表示，正確作法應該是數百個入口都同時開放驗票，當A入口處查核過一張票後，必須通知其他所有入口已查核過此票，若其他入口又查到此票，就不許放行，其他入口收到A入口的通知，也必須發布已知此消息的回應。如此一來，所有入口就能同時驗票，且不會出錯了。更重要的是，當特定入口擁塞了過多人潮，還能將這些人潮移轉到其他入口，以分攤工作量，這就是分散式運算可達到負載平衡的好處。
這項驗票的例子呼應了企業設計傳統與雲端軟體架構的不同：傳統軟體往往有一個核心的集中式模組，底下延伸出許多子模組，建構起階層式且垂直林立的軟體架構，所有子模組必須經過上層的集中式模組，才能繼續工作。例如，所有元件都要存取同一套資料庫，這個集中式模組因為難以將工作量分攤給其他模組，容易成為整套軟體無法Scale-out的瓶頸。翟本喬表示，企業設計雲端軟體架構時，必須時時把握去中央化的概念，這樣的軟體才能Scale-out。
關鍵2：建立容錯機制
為了讓雲端軟體在動態Scale-out的過程中，仍能夠兼顧穩定性，雲端軟體還必須具備嚴密的容錯機制。此外，雲端平臺的龐大規模，也促使企業必須打造具備高容錯能力的軟體，因為雲端平臺上的軟體正在存取的資料或執行的任務，通常不知道現在正在哪臺機器上，任務可能隨時動態移轉到不同機器來執行，軟體在這一秒沒有存檔，下一秒這個檔案的儲存空間可能就被其他檔案複寫掉。以前IT人員尋找資料存放的磁區再復原的作法已不可行。
企業若要讓雲端軟體完全不受底層平臺影響，在最初設計軟體架構時，就必須把握容錯的觀念。容錯的核心觀念是讓軟體在執行程式的途中，在任何狀態下都要能夠挽救。
翟本喬舉了一個例子，當使用者編輯完檔案，要存檔時，系統若將舊檔刪除，再寫入新檔，那麼從刪除舊檔到存完新檔的過程，就可能遺失檔案，萬一新檔存到一半當機，使用者就會失去這筆檔案而難以挽救。正確的軟體容錯機制應該是，使用者替正在編輯的檔案以不同檔名開設成另一個新檔，同時保存舊檔，當使用者完成編輯後，先存好新檔，再將新檔復寫到舊檔上，萬一新檔或舊檔在編輯或讀寫過程當機，都還有另一個檔案存在，不會無法挽救。翟本喬指出，企業設計雲端軟體架構和程式運作程序時，也必須把握類似的容錯觀念，讓軟體隨時都能被挽救。
關鍵3：SOA系統架構
Scale-out與容錯是單套雲端軟體的關鍵特性，若是從整套的SaaS平臺來看，企業整體的系統架構設計必須符合雲端的精神，盡量設計為高度模組化的SOA架構，才能讓軟體實現任意開關、動態搬遷等雲端的彈性。「雲端時代的開發趨勢，就是SOA架構。」翟本喬說。
傳統企業軟體架構會依據不同部門來建立軟體，如財務、法務、人資、工程等在不同部門之下的軟體，個別軟體之間都是垂直並立或上下階層的關係，當使用者要跨部門取用不同軟體時，就必須自行前往個別軟體來使用，或在不同軟體之間的資料庫互相匯入和匯出資料。這樣的使用經驗是以軟體為中心，使用者必須掌握軟體之間的關係才能完成任務。
例如，每個月人事單位必須匯出人資系統的資料，再匯入薪資系統，才能計算出每位員工的薪水，若薪資系統改版或更換廠牌時，人資系統可能面臨資料格式不同或系統不相容等問題，而無法完成任務。
SOA架構可以解決這些問題，建立以使用者為中心的SaaS服務平臺。翟本喬說明，在SOA系統架構下，個別軟體當中的每個軟體元件都是服務，每個服務都提供API介面，開放給其他軟體取用，即使底層平臺執行服務的方式改變了，也不影響服務的運作。
此外，每個軟體元件具備無狀態（Stateless）的特性，每項任務要求傳遞給軟體元件時，該元件只在處理此要求時，會記得處理狀態。一旦將處理結果移交給使用者後，此元件就會忘記這項要求。藉此，這套軟體就能在沒有任何要求的狀態下，可隨時關閉和搬遷。
這樣的SOA架構做到極致，就能夠打造出以使用者為中心的SaaS平臺。因為每套軟體的功能元件都釋出了API介面，如同打通了個別軟體的大門，大門裡，所有元件都轉變為一個個的服務窗口，讓軟體與軟體之間、功能與功能之間能任意介接存取，彼此不是階層式的上下關係，而是同在一個水平面上的協同合作關係，協力完成使用者交付的任務。
此SaaS平臺可依據使用者的任務，串連起原本個別軟體的功能元件。例如，當企業要建立網路購物服務，SaaS平臺可透過API介面結合信用卡付款、美工編輯、貨運服務等不同功能元件，串連出這項服務。又如，每個月人事單位不必匯入和匯出不同系統的資料，人資系統會透過API介面自動存取薪資系統的年資和部門別等欄位的資料，自動計算每位員工的薪水。
翟本喬建議，現在企業還擁有許多傳統的軟體，不必急著一次轉換為雲端軟體，可以等到軟體自然汰換時，再把握Scale-out、容錯與SOA架構來開發，而企業目前正在開發的新軟體，就應該把握這3大關鍵來設計，才足以稱為雲端軟體。
改變軟體架構，而不是改變開發方式
以開發團隊的運作來說，翟本喬認為，企業不需要改變開發方式，要改變的是軟體架構設計，運用Scale-out、容錯與SOA等觀念來設計架構，軟體元件也要API化，這樣就能打造出SaaS平臺。
相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88663,"Cloud,雲端服務,App,IaaS,翟本喬"
88662,36,2012-07-06,神通資科行政中心資訊服務研發處處長趙元瀚：開發人員要培養一流雲端服務的眼界,培養雲端開發人才的培訓不是難事，因為容易找到不少IT能力高強的員工，但CIO要做的事是鼓勵他們拉高自己的眼界，多去了解國外第一流的雲端建置技術與經驗," 這幾年，雲端服務趨勢竄起暴紅時，身為臺灣大型的系統軟體開發業者的神通資科，卻發現公司有近千名IT專業的開發人員，有.NET、有Java的開發人才，有少數懂得Web Services的開發人才，但是，仔細一找，全公司竟然沒有半個人懂PHP、Ruby網站開發技術，也沒有人懂Hadoop等雲端技術。
神通資科行政中心資訊服務研發處處長趙元瀚回憶指出，當神通資科決定對內部同仁提供雲端服務，回頭盤點自家的人才庫時，竟然發現，神通資科卻沒有懂得雲端相關熱門技術的人才。
為了彌補這中間的人才斷層，趙元瀚表示，神通資科必須自行從既有的研發同仁和比較年輕的同仁，去重新訓練和培養他們在雲端技術不足的部分，鼓勵他們多去涉獵相關的技術領域，進行大量的文獻閱讀，並透過彼此的互相討論和砥礪，摸索出對於各種技術問題的最佳解。
他說，透過這樣大量閱讀、互相討論技術的人才訓練方式，在一邊實做MiCloud雲端服務的同時，也一邊訓練神通資科的雲端人才。
透過認證落實開發SOP
由於神通資科負責的多是包括政府、金融等大型專案的開發，趙元瀚說，為了確保提供IT服務的水準一致，則採用ITIL v3（IT Infrastructure Library）版的IT服務管理架構，並藉由這套流程協助神通資科對現有各種資源做最佳化的利用，進而提升IT技術服務水準，讓IT人員的開發能和企業營運的目的結合，而不只是單就技術面向的考量。
另外，為了讓系統開發能夠做到最妥善的開發，趙元瀚說，神通資科也取得CMMI軟體成熟度第三級的認證，提升軟體開發的品質。他表示，第三級表示經歷過「初始階段」、「已管理階段」來到了「已調適階段」，意味著相關軟體發展、維護和相關的管理活動，不僅都標準化，也都在這個標準基礎上運作順暢，並成為組織的標準和資產的一環了。
隨著資訊安全成為企業發展重要的一環，神通資科也必須藉由取得ISO 27001資安認證，向提供軟體開發服務的業者，證明其對資安的確保與努力，盡可能降低外界對於資安的疑慮。
廣納多元專長人才
除了藉由各種外在的認證，來形塑軟體開發的制度、IT服務的品質和確保資訊安全外，趙元瀚說，隨著IaaS的基礎開始穩定，逐步走向PaaS和SaaS的階段時，便需要有同仁從內部服務流程開始做設計。
他認為，當內部有產生新的業務流程時，就需要新的人才投入，因此，神通資科也開始廣納多方專長的人才，不論是資料採礦（Data Mining）、統計分析、HPC（高效能電腦運算），因為神通資科還有提供客服中心，包括中文專長人才也很需要。
除了補足不同專長的人才外，為了讓同仁對於什麼是雲端服務更為了解，也能對外推廣神通資科的雲端服務，趙元瀚表示，該公司也率先針對業務同仁和Presales進行推廣和訓練，讓這群第一線的同仁了解雲端服務後，才有機會藉由業務拓展的方式，讓其他更多人了解什麼是神通資科推出的雲端服務。
對於趙元瀚而言，雲端開發人才的培訓不是難事，因為神通資科原本就有不少IT能力強的員工，但CIO要做的事是鼓勵他們拉高自己的眼界，提升自己的高度，多去了解國外第一流的雲端建置技術與經驗，透過這樣的討論和回饋後，就可以再將類似的技術概念應用在內部的產品或流程開發上。
CIO應扮演幫公司看清未來技術趨勢的關鍵人物
趙元瀚說，雲端時代的來臨改變系統整合開發商傳統對B2B或B2G的開發方式，當有新的業務流程出現，以及新的雲端服務出現時，都可以讓企業在各種的IT應用上更有彈性。
因此，他認為，身為企業的CIO，應該要責無旁貸的扮演起，能幫忙公司看清未來技術趨勢的人；而對於神通資科而言，他則希望自己在MiCloud發展的過程中，能夠成為一路協助MiCloud成為臺灣夠格的雲端軟體服務業者的角色之一。
由於神通資科多數的同仁都和IT部門同仁一樣，都具有專業的IT背景，趙元瀚認為，雖然這個MiCloud雲端服務剛開始是由IT部門帶頭發想和執行的，但是，當MiCloud不僅服務內部同仁，也同時可以對外提供服務時，帶頭的IT部門就不能一直在原地踏步打轉，如何化被動為主動，進一步讓IT同仁感受到，目前大家正在做的事情是有價值、有意義的，對於MiCloud的未來發展都有實質的助益。
趙元瀚認為，對於企業而言，雲端服務企業最好的委外夥伴，企業只要能夠完全掌握企業核心關鍵系統或競爭力的前提下，其餘的都可以盡可能委外，讓企業的IT資源做更有效率的應用。
他說，至於MiCloud未來要提供的雲端服務，其中一個很重要的關鍵就是在於，將要扮演許多國外第三方獨立軟體仲介者的角色，讓MiCloud成為一個和國外好用軟體的介接平臺，讓臺灣企業可以站在巨人的肩膀看世界，這也是趙元瀚和IT部門打造MiCloud時，一個很想要達成的重要目標。
相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88662,"Cloud,雲端服務,App,IaaS"
88661,36,2012-07-06,神通資科從SI轉型IaaS供應商 藉助國際IaaS業者經驗加速建置,臺灣系統廠商神通資科打造MiCloud雲端服務，原先是為了服務內部承接專案開發同仁，後來因為借力Joyent公有雲架構，讓原本對內提供的服務也能對外提供," 臺灣唯一一家由系統整合廠商神通資科推出的IaaS公有雲服務MiCloud，引進美國第四大公有雲服務廠商Joyent的架構。神通資科行政中心資訊服務研發處處長趙元瀚表示，這朵公有雲提供的服務，原本是從服務神通資科內部專案的私有雲服務開始的。他指出，為了解決內部專案同仁，以往申請測試環境時，從採購到建置完成，往往必須曠日廢時的困擾為出發點，不僅打造了屬於企業內部的MiCloud雲端服務，而且還將這項服務進一步提供給外部顧客。
邁向雲端服務，第一步先從伺服器虛擬化著手
神通資科和其他許多企業一樣，也看好虛擬化的效益，不論是伺服器虛擬化或者是儲存虛擬化等，都可以讓原本散落的各種運算資源，獲得比較好的整合成效。
最明顯的例子就是，神通資科負責各種政府大型專案和科專的系統開發，從專案啟動後，每一個階段都需要不同的測試環境。
趙元瀚當時便開始思索，面對這麼多專案經費採購的測試機器，如果可以做好更有效率的IT資源整合，甚至進一步以雲端服務的方式，自動化提供測試環境給專案同仁使用，將可以大幅降低專案同仁為了採購測試環境設備所浪費的等待時間。
因此，在2年前，趙元瀚和IT部門同仁便開始盤點公司散落在各部門的各種測試機器，希望先透過集中化與虛擬化的方式，將所有的IT資源進行統整後再另行分配。
不過這件事並不好做，他說，當年伺服器正好處於32位元和64位元的交接時期，許多32位元的伺服器在記憶體與效能上的限制較大，相較於64位元的伺服器，並不是適合做伺服器虛擬化的首選產品。
再者，趙元瀚當時也發現，要提供虛擬機器供內部同仁使用，因為有許多同仁在客戶端駐點開發，因此這個雲端服務必須能夠同時提供公司內部和外部同仁使用，而且為了滿足不同的專案需求，還必須要能夠提供雲端服務的計價方式。
藉助美商Joyent經驗打造MiCloud雲端服務
神通資科剛開始和所有臺灣企業一樣，先從虛擬化整併和集中化企業內的伺服器著手。但是，臺灣多數企業使用的VMware或是微軟Hyper-V等虛擬化方式，還沒有提供計價收費的機制，趙元瀚說，這也使得這個雲端服務因為無法克服計價問題而暫停。
後來有一個機會，趙元瀚認識了Joyent大中華區的高階主管。趙元瀚認為，Joyent是全美第四大提供公有雲服務的業者，一定可以協助神通資科解決從私有雲邁向公有雲以及如何提供雲端計費服務的瓶頸；更重要的是，Joyent是以Solaris作業系統為主，對於長期針對政府進行專案開發的神通資科而言，若和Joyent合作，神通資科本身有許多Solaris的專家可以協助做相關的雲端技術接軌，未來在使用軟體平臺的授權成本也會比較低。
這背後也潛藏一個關鍵因素在於，神通資科剛開始推動雲端服務時，該公司雖然有數百名懂得.NET和Java的開發人才，少數懂Web Services的開發人才，但是沒有人懂PHP、Ruby的網站開發人才，更沒有人懂Hadoop等雲端開發的人才。而神通資科透過和Joyent的合作，除了有雲端的技術合作和交流外，也是一個實際了解國外公有雲業者如何實際維運的好機會。
趙元瀚指出，對神通資科而言，虛擬化只是雲端服務的基礎，並不是雲端服務。而雲端服務的3個階段，最底層的IaaS（基礎設施服務化）、中層的PaaS（平臺架構服務化）和最上層的SaaS（軟體服務化），神通資科提供的MiCloud主要努力的方向在於打造IaaS和PaaS；至於SaaS到更進一步的SaaS Market Place（軟體市集），則是系統整合廠商神通資科和神達電腦適合扮演的角色。
MiCloud雲端服務的四個階段進程
神通資科打造MiCloud進度可以分成4個階段，第一階段從2010年～2011年3月，主要是落實虛擬化的基礎工程，整併伺服器並集中化管理。第二階段則從2011年3月～9月，趙元瀚說，當時因為虛擬化到一個階段後，就面臨無法提供雲端計價服務的瓶頸，因為遇到Joyent團隊，引進Joyent的公有雲架構而有了轉圜餘地。他說，神通資科在引進Joyent的公有雲架構下，開始打造神通資科MiCloud的IaaS雲端服務。第三階段從2011年9月～2012年3月則是MiCloud試營運階段，將相關的服務提供給內部與外部成員測試使用。最後的階段就是2012年4月迄今，這也是MiCloud正式營運的階段，許多新的應用程式服務也陸續上線。
引進Joyent新的雲端服務在打造IaaS架構時，趙元瀚表示，採用LAMP架構，作業系統使用OpenSolaris分支的Smart Machine，網頁伺服器使用Apache進階版的Nginx網頁伺服器，資料庫使用MySQL進階版Percona資料庫，網頁開發工具則使用Ruby等。
此外，為了讓使用者在串接雲端服務上可以更簡單，趙元瀚說，神通資科也引進美國Amazon及各大公有雲平臺都有在使用的雲端流量管理軟體Stingray Traffic Manage，可以做到SSL加速，提供伺服器負載平衡、全球伺服器負載平衡（Globe Server Load Balance）、應用程式防火牆（WAF）、壓縮和內容快取（Content Cache）等功能，最終的目的則是希望讓每一個雲端服務的提供者和使用者，都可以達到自動擴展（Auto Scaling）的目的。
也就是說，如果有某一個服務，例如訂票系統、選課系統，在流量顛峰時期必須要有100臺伺服器才能夠順利運作，但平常的服務，則只要需10臺伺服器就已經足夠。那提供該服務的單位，應該要採購100臺還是10臺伺服器呢？
趙元瀚認為，企業透過和MiCloud服務的串接，使用者可以自行設定，在使用流量暴增時，自動化增加所需要的伺服器，一直到可以滿足需求為主；同樣的，當流量減少時，也可以自動關機。他說，下一步則要利用網路海纜來提供CDN內容快取服務。
找出和別人不一樣的特色服務
趙元瀚說：「對於MiCloud而言， Everything as a Services就是未來發展的目標。」因此，在SaaS的架構中，針對中小企業推出MiERP、MiCRM、MiProject和MiBI等新的應用服務；針對醫療要推出MiHIS門診系統、MiCare遠端照護，和針對化療給藥、巡房和血液透析等醫療需求推出一個相關生技產業MiGeno的軟體市集（Market Place）；針對大學和文教業者也推出教育雲。
除了針對不同的產業應用推出不同的SaaS軟體服務外，MiCloud和其他IaaS在技術上具備的特色就是，Joyent提供DTrace的偵測技術以及SnapShot快照技術。
他指出，Joyent奠基在Solaris核心，發展一套虛擬主機作業系統SmartMachine，趙元瀚表示，Solaris內建DTrace的偵測技術，可以偵測包括處理器或者是應用程式在執行的過程中，究竟是哪一個環節出錯，並提供視覺化的呈現方式，讓使用者可以第一時間察覺系統問題，進而可以立即處理。這樣的功能也內建在Mac OS中。
至於MiCloud也採用Joyent奠基在Solaris的ZFS檔案架構，透過快照的功能進行增量備份（Incremental Backup）。趙元瀚表示，ZFS的檔案快照功能，將第一次快照的起始點定為0GB，設定為一個系統增量備份的基準點後，不論有幾次的快照備份存檔，都可以任意刪減其中一個快照備份，成為一個完整的全備份檔案資料。
他強調，因為這個技術不是在備份資料，而是讓使用者可以自己決定調整快照備份的起始點。未來，這也將成為MiCloud提供的SaaS線上服務之一。此外，ZFS檔案也可以做Clone（複製），進行實體機的備份，並可以做到自動擴展；若在負載平衡下，還可以做到直接在指定的空間複製後並直接啟用。
臺灣雲端服務業者面臨的考驗
由於神通資科希望讓MiCloud扮演一個和國外優質軟體與臺灣企業交流的一個平臺，趙元瀚表示，後端的介接應用可以由MiCloud執行，但對於臺灣企業而言，因為MiCloud已經可以提供企業使用介接軟體時，必須支付的金流問題，加上有神通資科作為相關軟體在臺灣的技術顧問，都可以大幅簡化臺灣企業想使用其他國外軟體的使用門檻。他也說，MiCloud也將會和其他國外公有雲業者，包括Joyent、Amazon等做介接，也可作為MiCloud的跨國雲端服務備援機制。
此外，企業使用各種雲端服務的費用在企業帳目上，往往只能做費用的折抵，也會降低企業的使用意願。未來如何從政策與稅制上，為臺灣雲端服務與軟體業者提供更多的彈性，也將是未來相關產業發展蓬勃與否的關鍵助力之一。

對於神通資科的MiCloud而言，未來的發展目標就是Everything as a Services，也會針對不同的產業內容，提供適合使用的SaaS應用服務。
——神通資科行政中心資訊服務研發處處長 趙元瀚

 
公司小檔案
神通資訊科技
● 總經理：蔣臺方
● 地址：臺北市內湖區堤頂大道二段187號
● 網址：www.mitac.com.tw
相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88661,"Cloud,雲端服務,App,IaaS"
88659,36,2012-07-06,力可科技打造App下載冠軍的關鍵 瞄準千萬用戶規模的高擴充架構,力可科技推出的即時通訊App風行東南亞，從臺灣、香港到泰國、新加坡或馬來西亞等地，在短短3個月內，超過2百萬人次下載，快速撐起這些用量的關鍵，就是一開始就瞄準了千萬用戶規模的高擴充架構," 你若走到曼谷街頭，不少泰國智慧手機用戶手機中的即時通訊App，不是老牌的WhatsApp、也不是在臺灣狂打廣告的Line，而是一個以綠色貓頭鷹為Logo的Cubie Messenger。在短短幾個月內，這個App光是在泰國就有超過70萬人下載，還成為泰國App Store不分類免費App熱門排行榜的冠軍，超越任何其他App，像是大家熟知的憤怒鳥。而且不只泰國，Cubie Messenger在新加坡、馬來西亞也都曾是免費App的排行榜冠軍，而在臺灣和香港，則曾登上App Store社交類App的冠軍。
Cubie Messenger在今年3月推出後，35天就達到1百萬次下載量的佳績，3個月後更是累計達到2百萬人次的下載量，不論在iPhone平臺或是Android平臺上，都約各有1百萬人次。每天活躍用戶近百萬人，Cubie Messenger的後臺伺服器，每天要傳遞4百萬則簡訊。
打造出這個冠軍App的正是臺灣少數專職開發社群遊戲的軟體公司力可科技，這個規模只有15人的公司，2年前就打造出4百多萬用戶的Facebook遊戲平臺嘎姆擂台（Gamelet），不過，這兩年社群遊戲的成長趨緩，Gamelet的用戶數成長腳步也變慢，力可科技總經理馮彥文想要尋找新的機會，作為力可科技的下一個戰場，最後他選擇了手機上的即時通訊軟體。
馮彥文的目標是未來市場規模大的產品，他評估，像Line這類聊天App，現在有幾千萬用戶，未來可以成長到幾億用戶，就算不是第一名的App，也有機會發展成數千萬名用戶規模的產品市場。
另一方面在桌面系統的即時通訊軟體就已經是分眾市場，而且不同族群、國家或地區會使用不同的即時通訊軟體，這是一個可以有區隔的市場，不像社交平臺只會有一個Facebook。「只要是大眾市場就會分群，就像汽車，而即時通訊軟體也是。」馮彥文說。
所以，去年8月開始，他帶領著旗下4名開發人員和1名美術設計人員組成開發團隊，開始打造一個具有病毒式串聯功能（Viral）的手機即時通訊App，也就是Cubie Messenger。
Cubie Messenger（簡稱Cubie）是一個社交型的即時通訊軟體，也就是聊天軟體，但結合了繪畫功能，讓使用者不只可以傳遞文字或照片，還可以自己用手指頭畫一張圖傳給朋友。Cubie後臺系統每天傳送的簡訊中，有近1成的訊息會傳送使用者自己畫給朋友的圖。
Cubie在取得使用者同意後，還能夠自動發送訊息邀請用戶手機通訊錄上的每一個朋友加入，如此循環，還可以繼續透過這個朋友邀請更多的朋友，就像病毒感染一樣，只要環境允許就可以快速擴張，這就是病毒式軟體的擴張特性。
打造千萬用戶等級的系統架構
力可科技資深軟體架構師陳彥任表示，Cubie後端系統採Java語言開發，包括了3個子系統，分別是負責傳遞訊息的Message Server，第二是用來保存暫存記錄和帳號資料的資料庫系統，第三則是處理外部發簡訊的服務，這項服務用來處理手機簡訊認證帳號的工作。
一開始，馮彥文就打定主意要做一個上千萬用戶使用的服務，所以在系統架構上，陳彥任也採用了水平擴充（Horizontal Scale）的架構設計，而且是非集權式架構，不會有一臺中控式的主機，而是像P2P服務那樣，每一臺伺服器都是主控，彼此是對等關係，陳彥任解釋，這麼做的好處是可避免任何單點故障的情況，而且可以任意擴張。
選擇NoSQL資料庫，跨資料中心建立即時備份
這樣的設計也是用戶數突然暴增時，Cubie能快速增加新伺服器來分擔流量的關鍵，避免中斷服務的關鍵。
所以，在資料庫系統上，也就選擇採用了分散式的NoSQL資料庫Cassandra。但原本力可科技在遊戲平臺上使用的Message Server是集權式架構的ActiveMQ，所以，陳彥任改用Java平臺用來開發分散式應用的Akka 框架和和Java NIO開發框架Netty ，重新來打造一個P2P架構的Message Server。
力可科技在Amazon EC2上部署Cubie Messenger的後臺系統，目前已在Amazon東京資料中心租用了12臺虛擬機器組成4個叢集來部署Cassandra資料庫，以及9臺虛擬機器部署Messenger Server。另外為了避免發生先前EC2北美資料中心整間資料中心當機的情況，因為Cassandra能自動跨資料中心同步，力可科技還租用了新加坡機房來作為資料庫叢集的即時備份。
不過，服務剛開始上線時，力可科技只建置了3臺Messenger Server，陳彥任表示，因為沿用在傳統Java開發習慣，也用同步操作（Synchronous Operation）的方式來設計Messenger Server遠端連線中訊息傳遞的方式，結果一臺伺服器只能承載二、三千人，系統效能就會因為程式中被Block的Method而大受影響。
後來，改用非同步操作來設計訊息傳送，讓下一個動作的程式不用等待前一個動作完成，而是可以各自進行，再透過訊息通知機制來告知前一個動作完成的結果。如此一來，一臺Messenger Server的承載量，就可以增加到了10萬人。
但是，到了10萬人的等級，Cubie服務再度凍結，這次的問題發生在Cassandra資料庫的存取效能，陳彥任表示，因為用戶成長速度太快，短短一個月就達到百萬人次，相當於1個禮拜就增加了20、30萬人，但是，當時來不及進行資料庫最佳化，幸好一開始就採取水平擴充架構，所以，當時就緊急增加更多Cassandra伺服器，以空間換取時間的方式來爭取到1周調校系統的時間。
用戶繼續成長，下載量在4月底達到了百萬人次，東南亞用戶也越來越多。在Messenger Server上的JVM Heap記憶體用量越來越多，系統執行記憶體垃圾回收（Garbage Collect，GC) 的次數非常頻繁。
陳彥任發現，因為 Android版的Client程式為了持續保持連線狀態，平均每一臺裝置每隔10分鐘就會重新連線一次，甚至手機螢幕關閉時，就有可能斷線需要重新連線，但是每次重新連線都要重新進行SSL加密計算，負責加密運算的Java SSLEngine占用了龐大的記憶體，一個連結的加密處理就要耗用32KB，而且加密動作也拖累了處理器的運算效能。
後來，另一位團隊成員力可科技資深工程師林康司，找到了減少重連次數的做法，讓頻率變成每小時1次。同時間，陳彥任繼續增加更多Message Server來處理大量的重連運算。後來採用新做法後，一臺部署在EC2 Large型虛擬機器上的Message Server最後可以承載5萬名用戶連線。
陳彥任表示，用戶數越高，越難找出系統效能的瓶頸，例如他也曾遇過JVM的Full GC Stop 問題，導致服務會挺擺30秒，只得詳細研究JVM設定參數，找出優化設定來改善，另外也遇到像是用來開發Messenger Server的Akka開發框架的連線問題，只好想辦法繞過這項機制，改用自己寫的程式取代。
採取Fat Client設計，讓App更聰明來減少後端複雜性
除了後端採取水平式擴充架構的設計，另一個讓Cubie容易擴充的關鍵是在用戶端App採取了Fat Client的設計。陳彥任選擇簡化Message Server的工作，只負責接收、發送以及保存沒有發送成功的離線訊息，但是許多訊息的判斷和過濾或是例外處理，則通通由Cubie Messenger的App來負責。
例如某一個用戶的裝置因為網路斷線，重複發送了2次訊息，Message Server就會照樣傳遞兩次，但是接收端的Cubie Messenger App則會判斷，這兩則訊息其實是同一則，就會自動過濾。或者是訊息是否送出成功，是否要重送，或是網路斷線時產生的錯誤資訊或例外判斷，通通由App來判斷。
由App選擇可用伺服器來分攤流量
另外像是伺服器端的負載平衡也是透過App來進行。所有的Message Server彼此會互相溝通，產生一份所有伺服器可用程度的優先順序清單，Cubie Messenger App會定期下載這份清單，再與可用程度最高的Message Server伺服器連線，若無法連線，App則切換到第二優先的伺服器，若不行再依序切換其他伺服器，幾次無法連線，則會自動更新這份清單，取得最新的伺服器可用狀況。透過這個做法，就不用在伺服器端部署負載平衡機制。
陳彥任解釋，Fat Client設計的優點是簡化伺服器端的複雜性，方便快速擴充更多伺服器，但是缺點是，因為iOS和Android的程式無法共用，同樣的Fac Client程式邏輯，就必須撰寫兩份程式碼，因此，Cubie團隊也分別有兩組開發人員，分別負責開發iOS版本和Android版本。
採用雙人搭配開發，共享開發知識
這兩組開發人員，還採用了少見的Pair Programming方法。這是XP（eXtreme Programming）開發方法論中的一種雙人搭檔的開發方法。比如說，陳彥任和林康司就是負責開發Cubie Messenger的iOS版本和後端系統的Pair。Pair Programming開發時，兩個人共用一臺電腦，使用一個鍵盤和兩個螢幕，一位擔任Driver角色，負責拿鍵盤寫程式碼，另一位擔任Navigator的角色，坐在一旁，負責檢視Driver寫的程式碼。
陳彥任表示，通常是Driver專注於他當下正在寫的那一行程式碼，而Navigator則要思考下一步，或前後幾行程式碼的關聯和發展。而且更重要的是，兩個人彼此要對話，例如Navigator看不懂時就要發問，或發現有錯誤時，也要提醒Driver，而Driver也要主動詢問Navigator的看法。
另外一個重點是，兩個人必須定期輪流更換角色，陳彥任和林康司的經驗是，大約是寫完一個小功能，或是每個小時，彼此的角色會對換一次。
林康司表示，Pair Programming的目的是分享，這個做法可以讓兩個人彼此都了解所有的程式碼，可以相互代理工作，萬一其中一個人有事，另一個人也能立即接手所有工作。
雙人搭配的效率其實比單人開發更高
這個作法看似負責寫的Driver要比自己開發時，花更多時間和對方溝通，但其實「雙人搭配的效率反而很高。」林康司表示，一個人寫程式往往要花很多時間來確定自己是否犯錯，而不是真正可以產出程式碼，兩個人搭配可以減少開發盲點，Driver也可以因為獲得Navigator的認可而放心，能夠繼續進行下一段程式碼的撰寫，不用因為一個問題而卡住很久。另一個好處是，兩個人搭配時，因為要顧及另一人，就不容易分心從事其它工作，反而是可以專注地進行數小時的開發。
不過，陳彥任表示，剛開始進行Pair Programming開發的人，老手容易搶鍵盤，忘記由另一個人接手開發程式，而新手也因為經驗不足而不敢發問質疑，他認為，至少要能交換鍵盤，輪流撰寫，而且要能有出聲，就算吵架也沒關係，萬一爭執不下淪為意氣之爭時，則需要另外一個人負責仲裁。久而久之，形成一種討論的文化，彼此就不會覺得爭執是尷尬的。
讓開發知識分享，避免負擔集中少數人
其實不只Cubie開發團隊採用Pair Programming的方法，馮彥文早在力可科技開發遊戲平臺時，只要人力足夠，就會使用這個作法，他表示，這樣的作法比較制度化，能夠維持固定目標持續產出程式碼，而且可以讓所有人都共享開發知識，人人都了解這個系統，而不是由特定人把持程式碼，也才不會造成知識的不平均，因為「能寫越多程式碼的人若越寫越多，到後來，就會變成只有少數人能寫，其他人無法參與。」馮彥文說。
截至今年6月，Cubie Messenger雖然已經過了暴衝期，但仍舊是臺灣iOS社交類排行榜Top 10之一，馮彥文評估，未來有機會挑戰千萬名用戶的規模。但他也坦言，自己還不曉得為何能快速成長的關鍵。他觀察到玩家喜歡好玩的App，而Cubie的塗鴉效果類似遊戲，很多人因此而覺得Cubie好玩而願意下載，但是力可科技沒有採取特別的行銷方式，只是提供了一個病毒式產品，目前都是透過用戶自行推薦給朋友而擴散的成果。
馮彥文表示，目前的大方向是要吸引更多人使用，以及確保已經使用的人不會流失，新功能的開發都需要滿足這兩個條件之一。
在Cubie上線初期，力可科技的團隊會透過A/B Test的做法來判斷用戶喜歡甚麼樣的功能。這個作法是先挑選出受測使用者，在這群人使用的App版本中提供不一樣的功能，例如在App第一頁是否要列出推薦朋友列表，力可科技會抽取一成使用者作為受測者，他們的App會列出這項功能，但其他人就不會。後來發現，會使用的人就算不列在第一頁，還是會自己去找出增加朋友的方法，不會加人的用戶，就算在第一頁推薦還是不會加人，所以這項功能就取消了。
如何找出對的功能，這也是馮彥文認為自己還在摸索的方向，而且還有更多的問題有待了解，他稍微比較掌握的是已經使用Cubie的用戶，但是對於還未使用的人，他則是有更多的問號。
儘管未來的發展還未明朗，但馮彥文表示：「創業就是這樣，勇往前進後又會發現更多問題，但我們已經習慣了，至少力可科技做了別人沒有做的選擇，目前看起來，這是一個正確的方向。」

Cubie Messenger不只是聊天軟體，還可以傳送手繪圖案給朋友，就像遊戲一樣好玩，因而獲得不少用戶的青睞。


力可科技採用Pair Programming的開發方法，兩個人共用一臺電腦，使用一個鍵盤和兩個螢幕，一名擔任Driver角色（圖左），負責拿鍵盤寫程式碼，另一位擔任Navigator的角色（圖右），坐在一旁，負責檢視Driver寫的程式碼。


為了打造能承載千萬用戶規模的服務，力可科技資深軟體架構師陳彥任採用了水平擴充的架構設計，而且是非集權式架構，好處是可避免任何單點故障，而且能任意擴張。

相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88659,"Cloud,雲端服務,App,IaaS"
88658,36,2012-07-06,華碩雲端總經理吳漢章：Information的力量遠大於Technology,過去的軟體開發，著重於功能與效能，而當雲端服務來臨，華碩雲端總經理吳漢章認為，服務(Service)、規模(Scale)、與安全(Security)，是IT人必需具備的新思維," 雲端兩字，近年來廣泛被引用。在臺灣，不管是由廠商對外提供的公有雲服務，或企業內部自主開發使用的私有雲，各類雲端服務型態，逐步成形。
這些新的應用型態出現，讓雲端開發，與過去單套軟體的開發方式，有著完全不同的開發模式，雲端服務超大規模的使用型態，讓開發人員不得不拋棄過去以功能為導向的開發模式，轉向全新的開發思維。
華碩雲端總經理吳漢章認為，在雲端開發時代，服務（Service）、規模（Scale）、安全（Security）等三大特點，是在面對全新營運模式時，IT人所必備的三大新思維。
雲端將使IT轉型為服務
吳漢章表示，雲端等同於由IT提供服務，讓使用者可透過網路連取IT所提供的資源。這些資源，不管是由廠商所提供的公有雲資源，或企業內部自用的私有雲資源，都必須讓使用者可以無縫的取得，「隨時隨地掌握取得資訊的力量」，就是雲端服務帶給使用者的改變。
「就像是電信營運商提供通話服務一樣」，吳漢章舉例。電信營運商提供電訊門號的租用服務，使用者只要依照所需，向電信服務商承租通話門號，就可依照自己的通話需求，來選用適用的通話費率，採月租模式，用多少時間就繳交多少的通話費用。
通話服務的通話時間，如果類比到雲端服務，就彷彿是使用者所使用的資訊量和使用量。例如企業租用公有雲廠商Amazon所提供AWS服務，每月所使用的虛擬機器多寡、使用時間等，就是計費依據。
而企業所擁有的雲端服務帳號，也就可以類比代表著用戶的通話門號。
吳漢章表示，對企業而言，過去IT較像是專為滿足特定功能的應用模式。例如企業需要使用ERP來管理營運資源，企業才導入ERP來改善，一切都以企業需求為導向。
但在雲端服務時代，使用者成為影響IT應用的根源。以使用者可用為出發點的服務模式，每個使用者都要能連取雲端，取得所需資訊，因此，雲端服務的可用性，就必須重新被檢視。
吳漢章表示，如以一整年的時間來看雲端服務的可用性，服務停機的時間，幾乎要以最高標準來檢視，服務的可用性才得以被使用者信賴。
因此，服務要隨時可用，如何在設備有可能損壞的前提下，還能維持服務的可用性，就是雲端開發與過去開發方式的不同。
過去傳統IT應用，吳漢章表示，因為應用都限縮在特定範圍內，例如公司內網，因此雖然在過去，系統的可用性對企業來說仍屬重要，但因為使用的範圍較小，當企業員工離開公司內網時，就不可取用企業內部資訊，因而也脫離IT人員的管轄範圍。
雲端服務要隨時可用
但在雲端服務的架構下，並隨著各類行動裝置的出現，以中央雲端服務平臺為主，延伸到各使用者的端點設備，服務隨處可用的概念，逐漸在使用者經驗中成形。
此外，除了維持雲端服務的可用性之外，吳漢章表示，在雲端，「所有的資源都會被服務化」，因此每個使用者都可能會取用到不同的資源。IT開發人員，就必須要依照使用者的權限，來彈性開放不同可使用的資源。
例如在使用者付費的原則下，只要使用者付費取得更高等級的使用帳號，雲端服務就必須開放更多資源讓使用者取用。同理，在企業環境之下，高層主管可取得的資源與一般員工可用的資源也一定不同，因此在雲端服務中，識別使用者身分的機制，相對過去軟體開發，就必須更為彈性。
過去在傳統軟體開發中，因為大多以特定功能為需求導向，每個版本只提供了定量功能，即使企業需要擴充功能，也必須另外購買軟體金鑰或授權，才得以擴充。
但在雲端服務中，因此一切資源都被服務化，這個服務平臺就包含各種不同資源，而只是依照使用者需求選擇，需要擴充時，就必須要很彈性的提供服務擴充。
因此，當使用者需要時，就給他資源，當使用者不需要時，就必須關閉營運設備，來降低雲端服務的營運成本，讓服務即使持續營運，成本也在可控制的範圍，以此來達到服務的彈性可用。為了能快速的因應使用者的需求，並彈性的調度可用資源，雲端服務也產生了集中化的架構。
超大營運規模成為雲端服務的特色之一
而為了彈性提供服務的前提，雲端服務將資源集中管理，隨之而來也將是超大規模的服務模式。
吳漢章表示，IT人員必須要有能力管理更多的IT資源，而又要同時兼顧成本和效能的考量。
因此，在確知未來要管理超大規模服務的目標下，每一次的開發，每一個程式碼的編寫，都要考量到未來超大規模服務的可管理性和可擴充性，讓雲端規模即使逐漸擴充，服務也能持續運行。
安全成為雲端服務的基本門檻
當雲端平臺開發完成後，服務的安全，就是影響企業採用意願的基本門檻。使用者都不信任你的服務安全時，服務的可用性基本上就已經不再成立。因此，吳漢章表示，「安全是所有雲端服務供應商的最大本錢」。
而在安全的定義下，不光只是資訊安全的保護，甚至要考慮到服務的可用性，例如當使用者想要連取服務時，服務卻發生當機的情形，他不能使用，或任何不好的使用經驗等等，這些因素，都將影響使用者對雲端服務的信賴感。
因此，在雲端服務之下，安全的定義不光只在資訊安全的保護，而是更廣義的牽扯到使用者對服務的信任感。信任與否，就能決定企業是否採用雲端服務。
吳漢章表示，過去企業雖然也會重視各類軟體工具的資安防護，但相較於雲端服務，門檻就會降低許多。企業即使不信任某一套軟體的安全程度，也會額外採購資安防護軟體工具，功能與效能才是企業重視的重點。
但在雲端服務的情境，尤其在公有雲服務之下，企業任何營運資訊都將存放在服務營運商內，「服務營運商對於資訊的保護責任加重了」，因此，使用者對於服務的信賴感，無庸置疑的，已成為開發雲端服務平臺，最不容忽視的必備因素。
使用者使用IT服務，因此開發人員也要有隨時被檢視服務的決心
另一方面，當使用者隨時隨地取用雲端服務時，服務本身好用與否，使用者都能有立即且深刻的感受，因此，吳漢章表示，IT人員也要有隨時被放大檢視的決心。
開發人員預先掌握雲端服務的觀念，就能減少使用者的質疑。例如，事先預想到服務將被多平臺使用，開發方向就要朝更容易跨平臺平行轉移。或事先預想服務將被超大規模的用戶使用，開發服務時，就要能更彈性的負載多人使用等需求。
甚至，使用者不需要了解技術的可行性與否，也能對IT應用的好用與否提出質疑，「IT人員面對的挑戰更大了」，吳漢章表示，這就是IT人員必須適應的改變。
而除了適應使用者與新科技所帶來的改變之外，吳漢章表示，透過雲端服務，IT人員也要能更重視資訊應用所帶來的好處。
例如在雲端服務之下，資源全面集中，連帶而來的，如何善用這些資訊，就成為資訊人員，可協助企業成長的利器。
吳漢章認為，在雲端時代的發展之下，資訊（Information）的力量將遠遠大於科技（Technology）。
在微觀（MicroView）的面向上，吳漢章表示，IT人員可透過雲端服務深入協助企業每位員工的生產力。例如結合各項行動化設備，來管理每位企業員工的工作狀況，甚至協助他們創造更有效率的工作力。
而在巨觀（MacroView）的資訊使用上，企業則可結合雲端服務所產生的巨量資料。透過這些巨量資料的分析，來創造意想不到的管理哲學，例如將全球各地的天氣因素，結合銷售產品的近銷存管理數據，來產生不同且有意義的管理哲學。
而對於這些新穎的創新運用，吳漢章表示，要創造每位員工的的生產力，「就從擁抱BYOD開始吧」。
而在巨觀的巨量資料管理哲學上，則需要培養IT人員擁有更前瞻的思維，這些，就是企業CIO，最能夠協助企業創造效益的新利器。
相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88658,"Cloud,雲端服務,App,IaaS"
88656,36,2012-07-06,華碩雲端服務千萬用戶的關鍵，一出手就要敢做大,華碩雲端從開發初期，就以超大規模的雲端服務為開發方向。歷經4年戰場，現在已有千萬用戶使用華碩雲端服務，其中，持續維持服務可用，就是最大挑戰," 談起雲端服務，國外早有多項成功案例。不管是由Amazon提供的Amazon Web Services（AWS），或由全球最大搜尋引擎公司Google所提供的各項雲端服務。甚至成功以智慧型手機iPhone影響使用者的蘋果電腦，也在2011年，首次喊出iCloud的概念，至今，擁有蘋果電腦iCloud帳戶的使用者，早已超過一億位使用者，高達全球人口的60分之一。
國外有iCloud，但其實在臺灣也有類似的服務，以硬體起家的華碩電腦，所提供的華碩雲端儲存服務Asus Cloud，不管是購買華碩各項終端裝置的用戶，或其他裝置的使用者，都可連上華碩雲端儲存空間，使用一定的儲存容量。
這樣的服務不只吸引了不少民眾的使用，就連國泰金控、臺灣大學等企業，都引進了華碩雲端的儲存服務來打造自家的儲存私有雲。曾經參與打造Google雲端機房的台達電子雲端技術中心資深處長翟本喬，肯定華碩雲端是真正有做到雲端服務的臺灣廠商。
華碩雲端總經理吳漢章表示，從2008年9月服務上線以來，Asus Cloud服務就一次躍升為千萬使用者的超大規模。這個速度不是百倍、千倍的成長，而是千萬倍的衝擊。
大量的使用者進駐，就彷彿一棟由使用者堆砌而成的超高摩天高樓，空降至華碩雲端的自有機房內，其中面對的困難與衝擊，吳漢章表示，是過去傳統軟體開發廠商，甚至一般企業IT，都很難能碰觸到的領域。「但這種超大規模的衝擊，卻是面對新的雲端開發時代，每一位開發者都必須正視的新問題。」他說。
說起Asus Cloud的發展歷史，Asus Cloud雖然直至2008年才正式上線，看起來到現在不過4、5年，但吳漢章表示，「華碩雲端團隊可是磨了整整十年」，這些經驗才是真正讓Asus Cloud服務成功的原因。
吳漢章表示，從2000年開始，華碩雲端早期只提供醫療照護相關的資訊應用，一直到2004年才跨入雲端儲存的服務。
2004年時，臺灣多媒體簡訊應用起飛，電信業者開始想要推廣這樣的服務。但多媒體簡訊相較於傳統的文字簡訊，不管是圖檔或影音檔的傳遞上，資料類型都比文字更為複雜，且每份簡訊的檔案規格沒有統一。
當時電信業者為了解決這樣的問題，開始想要成立一個專屬於多媒體簡訊的資源池，用一個很大的儲存空間來集中管理和保存每個用戶的多媒體簡訊。當使用者想要觀看多媒體簡訊內的內容時，就可以從這個資源池撈取相對應的檔案，而不怕檔案遺失，或存取不到等問題。
華碩雲端就是提供給電信業者這樣的加值服務，能夠協助動輒數千萬用戶的電信業者，建立大規模的儲存資源池。吳漢章表示，上千萬用戶每天所產生的多媒體簡訊資料量，十分驚人，因此，華碩雲端得隨時隨地都要能提供兼具高彈性和高可擴充性的服務，來因應使用者需求的暴增或銳減。過去這段建置大規模服務的經驗，也成為華碩雲端成功跨足雲端服務的關鍵原因。
在2008年時，當時還未併購華碩雲端的華碩電腦，面臨了經營上的轉型。華碩電腦想要將舊有的代工製造業務與華碩品牌分家，讓代工各家筆記型電腦、主機板等硬體設備的同時，也能推出華碩自有品牌的產品，重新面對市場。
這樣的轉型也促使華碩電腦決定要增加新的服務。吳漢章表示，過去製造代工，製造的品質與技術代表了製造業的一切，而當走入品牌時，「創造使用者的使用經驗」，才是品牌最終的目的。因此在2008年，華碩除了持續推出多款硬體終端產品之外，也併購了雲碩雲端，推出華碩雲端儲存服務，成為當時華碩轉型後的新服務之一。
當華碩雲端進入華碩電腦體系後，也把過去服務電信商的大規模建置經驗，帶進華碩電腦內。
設備要遷就人的需求，而不是人遷就設備的位置
剛開始華碩雲端儲存服務的構想，就是從打造華碩的個人雲（Personal Cloud）開始。吳漢章形容，個人雲所代表著，是當人需要資訊時，不再需要遷就於設備所在位置，反而是設備需要遷就於人。
過去不管是工作，或個人需要，我們需要回到辦公室，或回到住家個人電腦前，才能取得所需資訊。但在華碩個人雲的概念下，吳漢章認為，最終的結果，就是要不管人在何處、何地、何時，設備都要能提供資訊。
因此，設備也會依照不同的場合，有不同的適用情境，例如智慧型手機外觀較輕巧，適合在行動通訊中使用；而筆記型電腦或平板電腦因為螢幕較大，則適合在戶外等定點式使用；個人電腦則就適合在家中使用等等。裝置以不同的形式出現，最終的目的只是為了符合「使用者無時無刻取得資訊」這件事。
跨裝置的資料轉換，要達到像用同一份資料
而不只是資料無時無刻的取得，吳漢章表示，雲端服務除了要確保使用者隨時隨地都可取得資料之外，這些不同裝置之間的資料轉換，對使用者來說，也都要是無感的，使用者在不同裝置中，都要能感受到使用同一份資料的感覺。
確定服務的最終輪廓後，要開始打造這樣雲端服務，吳漢章表示，這也是華碩雲端儲存服務發展的第一階段，要將所有的構想付諸實現，實際營運，並成功上線。
華碩雲端在2008年初加入華碩集團時，開始構想AsusCloud服務，並花了將近9個月的時間，將過去協助電信商所打造的大規模服務化架構經驗，重新引進華碩AsusCloud服務內，並將整個服務重新設計。
雲端服務要學習電信服務不中斷的精神
這之中，吳漢章表示，因為過去長期與電信商合作，讓華碩雲端學到電信商服務經營的整體概念，並發現了雲端服務與電信營運的共同點。
吳漢章形容，電信商每天都有幾百萬、甚至幾千萬的大量使用者。電信業者提供的是通訊的服務，不管是有線的，或行動通訊的，都要確保通話的可用性。「沒有用戶是可以接受行動通訊業者因為系統當機而停話的。」
這對現今的社會來說，電信服務不中斷，是理所當然的道理。但對剛起步的雲端概念來說，吳漢章認為，也要採用同樣的高可用性標準。
「因為雲端就是提供服務」，如果連服務的可用性都無法達到，那用戶對雲端服務的品質一定也沒有信心。就是這樣對自己高可用性的期許，讓華碩雲端在建置雲端服務平臺時，也同樣以高標準檢視自己。
開發人員要有服務超大規模用戶的決心
除了確保服務的可用性之外，吳漢章認為，要開發雲端平臺，開發人員就要先有服務超大規模用戶的決心。因為雲端服務講求的是資料的集中，藉由資料的集中，大規模的多人使用，才能攤提成本，來減少大規模建置的投資。
因此，吳漢章認為，每一位開發者在一開始就要設想這個服務的最終結果，是要給千萬、甚至億萬人使用的大規模服務。「大規模使用的雲端服務，才有他的價值，而沒有人使用的雲端服務，就只能稱為是空泛的服務。」他說。
所以，雲端華碩從開發專案一開始，就要求每一位開發者，對於每個程式碼的寫法，或整體架構的設計，都要先有大規模架構使用的敏感度。這樣的開發者，對於後續陸續擴充服務時，才不會讓服務擴充不彈性，甚至造成營運上的困難。
「而這也就是與過去傳統開發最大的不同，開發者對於大規模服務的敏感度，要比過去更強烈。」吳漢章表示。
雲端開發第一階段：專為營運所開發的雲端服務
但有了這樣的構想後，等到實際要執行時，卻又不是那麼簡單。吳漢章表示，雖然開發者已經知道最終要達到的結果是超大規模的服務架構，但在架設初期，又不能一次就將服務打造成超大規模的架構。而是要由小到大，依照服務的使用量，來逐步擴充。這樣服務開發的成本才不會浪費，也才能稱為雲端服務內的合理使用。依照使用需求彈性的擴充，並隨著時間，來降低儲存的成本，這就是雲端服務的特點之一。
但在逐步擴充的階段，開發者又需要設想如何在擴充階段，服務不中斷，也能持續擴充服務規模，甚至，在服務擴充時，成本可以不用持續增加，發展出大規模使用架構後，效能還可以不受到影響。
這些雲端服務的特性，早就在開發初期，開發者就不得不將這些因素考慮進去。因此，吳漢章認為，雲端服務的上線準備，既要簡單的開始，也要能夠為未來大規模的擴充設想，這也是服務上線前，最大的困難。
雲端開發第二階段：超大規模（Scale up）所面對的困難
而當2008年9月，華碩雲端服務成功上線之後。華碩雲端又再面對第二階段的挑戰。
這個階段，正是華碩雲端服務大規模是用起飛的時期。如同吳漢章的預期，華碩雲端在這個時候，從第一位使用者開始累積，一口氣衝破1千萬位超大規模使用者。
資料持續不斷地增加，是服務可用性的最大的挑戰
吳漢章認為，對華碩雲端來說，維持服務可用的最大困境，並不是瞬間用戶量的增加，也不是資料量大增，最大的困境是，「這些資料是持續不斷增加的」。
每當一個用戶加入，他每天所丟進丟出的資料，是大、是小，是文字檔，或影音檔，完全無法預期，因此整個服務架構也不斷地需要彈性擴充。這時，在使用者持續成長的狀況下，如何持續讓服務可用，就很重要。
如果說開發階段，開發人員的思維是影響服務成功的大一步，那麼，服務成功上線之後，維運團隊反而才是讓服務成功的最大功臣。因為維運團隊，就是管理服務是否可用的第一線角色，維持服務的可用，就是維運團隊最主要的角色工作。
成立維運專責團隊，主動解決用戶問題
所以，在華碩雲端團隊中，就成立了專責的維運團隊來負責，當服務出問題時，維運團隊就要在第一時間解決。此外，與過去企業IT維運不同的是，吳漢章表示，這些維運團隊還要扮演與過去相比更積極的角色。
過去的IT維護，就是被動的等著系統出問題，使用者抱怨了，才趕快進行維運救火的動作。但是，要維運雲端服務時，一切以服務為前提的新型態，IT人員不可能再被動的等待用戶回報使用狀況，因此，維運人員要如何在服務提供的同時，還能橫量自己提供的服務好不好，同時兼顧提供好的服務，就是雲端服務與過去的不同。
對吳漢章來說，當問題發生時，維運人員解決問題，只是維運人員最基本的能力，但這樣是還不夠的，當雲端服務上線後，使用者使用的同時，還要能在第一時間知道使用者的狀況，也就是確保每個服務當下的服務品質，這才是維運人員最困難的挑戰。
如果等到使用者發現問題，才提出修正需求，對服務提供者來說，服務的品質就很不穩定。此外，使用者所在位置可能遍及全臺，要如何精確的知道每地方用戶的使用狀況，成為最大的難題。
因此，為了知道用戶的使用狀況，每個用戶的使用狀況記錄檔（Log），成為華碩雲端判斷自己的服務好與不好，最好的參考點。吳漢章表示，透過每天大量用戶的使用記錄，維運人員就可以主動分析用戶狀況，進而找出服務可能的問題點。
這些問題，並不全是服務大當機的大問題，可能只是很多的小問題，例如網路傳輸的速度太慢、使用者介面設計不便等等問題，但每一個小問題，華碩雲端都認為是必須正視的問題。而這樣高規格的檢視標準，維運人員也就成為最了解整體服務架構的人，而且也是團隊中「最早能嗅出問題的癥結點」的人，維運人員必需最快能向開發人員提出改善建議。
可用性越高，封閉迴圈的程式碼越容易造成雪崩效應
而在這樣高可用性的要求下，吳漢章坦言，早在服務上線初期，華碩雲端曾面臨多數雲端服務供應商最可怕的惡夢──「雪崩效應」。吳漢章形容，雪崩效益就彷彿蝴蝶效應一般，一個小小程式碼的錯誤，就可能造就整體服務大當機，進而影響到雲端服務的全體用戶。
在當時，華碩雲端自有的監控系統與主系統發生相互干擾的情形，監控系統內部因為內含自動修復的機制，但因為在高度可用（HA）的架構下，這些高度自動化的修復程式彼此相互串連，層層連動執行，全部的系統就彷彿串接成一個封閉的迴路，一個小小的系統錯誤，隨著一個程式自動影響了另一個程式，就像是手指頭推倒第一張骨牌，一張接著一張陸續倒下，最後造成了整體迴圈的巨大風暴，甚至讓整個服務嚴重當機。
對華碩雲端來說，因為當時服務正在起步階段，服務規模仍不大，因此維運人員很快就能找到問題點，並提早修復。但這個教訓，也讓華碩雲端不得不重新檢視自己的服務架構，以更嚴謹的角度，來避免封閉迴圈的產生。
吳漢章表示，每當有問題產生，問題也要能限制在可預期的範圍內，甚至要將架構切分為不同區域，並加裝斷路器設計，即使單區域發生問題，也能將問題限縮在特定範圍內，影響範圍擴及不全面。
服務不停機也要能持續進行系統更新
維持服務的高可用性，只是華碩雲端在超大規模用戶時期，遇到的第一個困難，更大的挑戰是，發生問題後，要能夠在系統不停機的情況下，也能持續修正，甚至更新，這是華碩雲端接著面臨到的第二個困難。
吳漢章形容，早期企業軟體更新，只要在下班時間將機器全部停機，將更新檔案複製過去，更新作業就可完成。但在雲端服務堪稱365天不停機的全新營運型態之下，要完成系統的更新，就成為華碩雲端最大的難題。
當時，吳漢章表示，華碩雲端第一次在服務不停機的狀況下要進行系統更新時，全體團隊可說是一起作戰，不管是系統的開發團隊，或維運團隊，甚至連總經理自己，都親自全程參與。而在當時，吳漢章表示，在系統剛上線的初期，每次更新，全體熬夜到凌晨三、四點，早已成為常態。
甚至，這樣的更新，並不是一個月才進行一次，系統修改幾乎成為天天都要做的例行公事。這些修改可能只是單純修改一個程式碼，或改善使用者介面，甚至一個功能都沒改，只是再次調校服務參數來改善效能等修正。
因此，要讓服務持續提供的同時，也要能持續提供服務更新，並且，對使用者來說，這樣的更新必須是無感的，使用者不會因為系統要更新，服務就得暫停使用，如同電信服務，從不會因為系統要更新，電話就無法接通的同等道理。
經過4年的磨練，吳漢章表示，現在系統更新已經不再耗費那麼多的時間，團隊成員也都可以準時的下班，而這就是經過實際戰場所磨練出來的能力，更是推出雲端服務的必備基本功。
雲端服務開發第三階段：提供更彈性的開放（Open）架構擴大服務
經過瞬間使用人數爆炸性的擴張，吳漢章認為，華碩雲端服務也逐漸穩定。因此自2011年開始，華碩雲端也開始將自有服務架構轉移到企業內部。
要將原有自行開發、自行維運的系統架構，搬到完全不同環境的企業內部，吳漢章表示，需要的是更彈性的系統架構，而彈性，也等同於要和企業環境更容易的介接。
例如企業原有的員工帳號密碼，必須要能整合到雲端服務中，企業能依照員工帳號的權限，來限制雲端服務可取用的資源。這就是華碩雲端認為更彈性的雲端服務架構。
而除了開放與企業私有環境介接之外，華碩雲端也將開放第二層面的開放，就是開放更多、更好用的API，讓第三方軟體開發商，也能在華碩雲端平臺上開發自有的應用程式。
華碩雲端儲存成為整體雲端服務的基礎，而上層各項應用程式，為華碩雲端創造了更豐富的應用。
而經歷了這麼多創新，吳漢章表示，雲端服務的變動，並不是在實驗室模擬實驗，就可以創造出來的服務。打造雲端服務，就如同打仗，對華碩雲端來說，華碩的裝置與品牌提供了戰場，而華碩自己也證明了，自己的思維與架構，是足以攻下千萬使用者，4年下來，已成功拿下漂亮的一戰。

華碩雲端總經理吳漢章表示，要提供雲端服務，開發人員就要先有讓超大規模人數上線使用的決心。


 
前進華碩雲端開發現場
華碩雲端區分為一般系統、維運、APP開發等三大開發團隊，而華碩雲端為了區分一般系統與APP開發團隊，辦公室也區分為兩大區塊。
因為前端APP開發需要開發人員彼此討論、創意激盪，所以辦公桌也採開放式擺設，彼此之間可以隨時互換位置，讓需要討論的同仁可以隨時互換位置，方便討論。強調穩定服務的主要系統團隊，則採傳統辦公室模式。彼此之間有固定座位，以制式座位來區隔工作執掌的不同。
而華碩雲端的辦公室內，環繞著一整面的白板，讓需要討論的業務或開發人員，可以即時寫下文字或圖像。而攸關使用者操作的APP開發團隊，更是要實際以平板或大型投影螢幕操作內部開發的結果，以此來檢視自己服務的可用性。

開發現場1. 環繞辦公室的白板
一進到華碩雲端辦公室內，就可看到圍繞全辦公室的白板，讓開發團隊隨時需要討論時，就可聚集在白板前，寫下各自的意見，用文字讓想法具體化，互相討論。


開發現場2. 隨時以平板電腦測試開發
攸關使用者操作的APP開發團隊，則更需要隨時在白板上畫下開發使用介面或操作流程等，相互討論。甚至開發團隊也常實際以平板電腦等設備，將系統實際操作，來體驗使用者的操作狀況。


開發現場3. 共同檢視大螢幕投影的開發結果
此外，對於APP開發來說，每次系統更新，都會以最直接的方式，直接投影在大螢幕讓大家討論，因此華碩雲端APP開發團隊，幾乎在每天下午都會在討論室以大螢幕投影，討論使用介面等各種開發問題。

 
公司小檔案
華碩雲端
● 總經理：吳漢章
● 地址：新北市永和區民權路53號8樓817室
● 網址：www.asuscloud.com
相關報導請參考「2012企業雲端開發術」
",https://www.ithome.com.tw/tech/88656,"Cloud,雲端服務,App,IaaS"
73979,36,2012-05-25,Hadoop 1.0正式版3大特色,經過6年，Apache基金會終於釋出了第一個Hadoop正式版，這也代表著Hadoop已經準備好要進入企業應用市場了," Apache基金會也特別在官網上宣示，這是Hadoop專案的里程碑，代表著Hadoop已經為企業應用做好準備。
Hadoop專案的版本更新速度向來很慢，往往好一段時間才會改版。在1.0版問世前，主要有2個系列版本，0.20系列和0.23系列。0.20版是Hadoop先前的穩定版本，1.0版的前身正是0.20版系列，而0.23版本屬於開發版本，尚未穩定的新功能會先加入在0.23版系列中。
1.0版新增的關鍵功能包括了資安模式的強化、HBase資料庫套件內建了Append的支援、HDFS檔案系統支援HTTP存取，以及多項效能的改善。
在資安模式的強化上，過去Hadoop最為人詬病的是安全認證強度不足。Hadoop是由多套伺服器節點組成，過去是有授權機制，只有獲得授權的伺服器可以存取Hadoop節點上的資料，但是Hadoop沒有搭配驗證機制，無法驗證是否為真正獲得授權的伺服器。因而過去有一種存取資料的取巧作法，若Hadoop伺服器A授權給伺服器B具有存取權限，而伺服器C沒有獲得這樣的授權，但因為舊版Hadoop不會驗證伺服器的身分，所以伺服器C可以更名為伺服器B來取得伺服器A的存取權。
精誠資訊雲中心Big Data事業發展首席顧問陳昭宇表示，舊版設計原則只考慮作為內部專用系統使用，但是，企業應用時往往會將Hadoop作為企業IT架構中的一個分析平臺，並開放給多套應用系統存取，此時確認存取者的身分就很重要，否則沒有存取權限的應用程式也有可能讀取到限制存取的機密資料。1.0版增加了Kerberos認證之後，就可以與企業LDAP伺服器整合，來檢查存取者的身分。
第二項更新是檔案系統的改善，原本Hadoop底層的HDFS檔案系統的設計初衷是：資料寫入後不能修改，但是可以無限制地取用。可是這樣的設計與Hadoop資料庫系統HBase的功能衝突，HBase需要修改原本寫入的資料檔來插入資料，過去使用者得自行安裝第三方修補程式，才能順利執行HBase，1.0版中因而將HDFS直接內建檔案附加寫入（Append）的機制，解決了HBase的資料寫入需求。
另一項重要更新是HDFS對HTTP的支援。原本在HDFS檔案系統上的檔案，只能透過命令列指令或是透過應用程式控制API來存取，新版則能支援HTTP的讀取，只要透過一個網址，就能讀取到HDFS的完整資料，並且能遵循完整的HDFS安全規範，不過目前還未支援透過HTTP的HDFS寫入機制。
陳昭宇表示，透過HTTP來存取是許多開發者慣用的存取方式，如此可以更容易開發Hadoop應用，也更容易和其他網頁應用整合。陳昭宇認為，1.0版已經具備了企業應用需要的重要功能。
過去若要建置Hadoop平臺，支援上述新增功能，得自行安裝其他修補套件才行，而現在全都內建了，所以Apache基金會才會正式推出1.0版。
但是，陳昭宇認為，1.0版還有一項不足，那就是Hadoop叢集中，負責主控的Master節點只有1臺，還沒有HA的備援設計。目前只有Hadoop 0.23開發版本才支援Master HA機制，但因功能尚未穩定而沒有放入1.0版。
目前這個問題應不至於構成很大的困擾，不過，陳昭宇表示，因為Master只是負責分派任務，資料流動都是在運算節點中直接傳輸，因此Master節點的負載不高，再加上Master雖然是把所有任務調派資訊都儲存在記憶體中，但也會定期備份到磁碟系統上，所以，只要透過共享NAS系統，讓另外一臺備用伺服器可以存取相同的NAS磁碟，一旦Master節點的硬體損壞，也可以由備用伺服器開機接手Master節點的工作，頂多是損失了幾分鐘的資料落差。另外也可以透過硬體備援機制的強化，例如雙重硬碟的鏡像設計，來提高Master節點的穩定性。
相關報導請參考「巨量資料的頭號救星：Hadoop」
",https://www.ithome.com.tw/node/73979,"Hadoop,Cloud,Big Data"
73980,36,2012-05-25,擴充Hadoop功能的軍火庫,Apache基金會規畫的Hadoop體系中還有許多武功高強的周邊專案，如可支援SQL語法的Hive，不懂Java也能撰寫MapReduce的Pig，這些都是開發者不能錯過的Hadoop相關專案," HDFS和MapReduce只是打造Hadoop平臺最基本的核心套件，在Apache基金會的網站中還有其他的相關開源套件，共同組成了一個Hadoop體系（Hadoop Ecosystem）。
透過這些相關專案的延伸，開發人員就算不懂Java，也可以用特定Script語言來撰寫Hadoop上的MapReduce程式，甚至可以用SQL語法來查詢HDFS上的資料。這些周邊專案可說是大幅強化Hadoop功能的軟體軍火庫，想要善用Hadoop的開發人員不可錯過。其中重要的周邊專案包括HBase、Hive 、ZooKeeper、Pig和Mahout。
 HBase  能容納PB資料量的分散式資料庫
HBase是專門用於Hadoop檔案系統上的資料庫系統，採取Column-Oriented 資料庫設計，不同於傳統的關聯式資料庫，例如沒有資料表、Schema資料架構等功能，而是採用Key-Value形式的資料架構，每筆資料都有一個Key值對應到一個Value值，再透過多維度的對應關係來建立類似表格效果的資料架構。如此就能採取分散式儲存方式，可以擴充到數千臺伺服器，以應付PB等級的資料處理。
 Hive  可用SQL語法存取Hadoop資料
Hive是建置在HDFS上的一套分散式資料倉儲系統，可讓使用者以慣用的SQL語法，來存取Hadoop檔案中的大型資料集，例如可以使用Join、Group by、Order by等，而這個語法稱為Hive QL。不過，Hive QL和SQL並非完全相同，例如Hive就不支援Store Procedure、Trigger等功能。
Hive會將使用者輸入的Hive QL指令編譯成Java程式，再來存取HDFS檔案系統上的資料，所以，執行效率依指令複雜度和處理的資料量而異，可能有數秒鐘，甚至是數分鐘的延遲。和HBase相比，Hive容易使用且彈性高，但執行速度較慢。不少資料庫系統，都是透過先連結到Hive，才能與Hadoop整合。例如微軟就是透過Hive ODBC驅動程式，將SQL指令轉換成Hive QL，讓Excel可以存取Hadoop上的資料。
在同一個Hadoop叢集中，Hive可以存取HBase上的資料，將HBase上的資料對應成Hive內的一個表格。
 Pig  不懂Java開發也能寫MapReduce
Pig提供了一個Script語言Pig Latin，語法簡單，類似可讀性高的高階Basic語言，可用來撰寫MapReduce程式。Pig會自動將這些腳本程式轉換，成為能在Hadoop中執行的MapReduce Java程式。
因此，使用者即使不懂Java也能撰寫出MapReduce。不過，一般來說，透過Pig腳本程式轉換，會比直接用Java撰寫MapReduce的效能降低了25％。
 ZooKeeper  讓Hadoop內部伺服器能協同運作
Zookeeper是監控和協調Hadoop分散式運作的集中式服務，可提供各個伺服器的配置和運作狀態資訊，用於提供不同Hadoop系統角色之間的工作協調。
以HBase資料庫為例，其中有兩種伺服器角色：Region伺服器角色和Master伺服器角色，系統會自動透過ZooKeeper監看Master伺服器的狀態，一旦Master的運作資訊消失，代表當機或網路斷線，HBase就會選出另一臺Region伺服器成為Mater角色來負責管理工作。
 Mahout  立即可用的常用MapReduce函式庫
在Hadoop中，開發人員必須將資料處理作法拆解成可分散運算的Map和Reduce程式，因為思考邏輯和常見的程式開發邏輯不同，所以開發難度很高。Mahout則提供了一個常用的MapReduce函式庫，常見的數值分析方法、叢集分類和篩選方式，都已經有對應的MapReduce函數可呼叫，開發人員就不必再重複開發一次。
相關報導請參考「巨量資料的頭號救星：Hadoop」
",https://www.ithome.com.tw/node/73980,"Hadoop,Cloud,Big Data"
73978,36,2012-05-25,上手Hadoop不可不知的關鍵概念,MapReduce和HDFS是Hadoop最基礎的核心機制，了解其運作原理是快速上手的第一步," 在Hadoop平臺中，核心用途是儲存空間的資源管理，以及記憶體空間和程式排程的安排。透過分散式架構的HDFS檔案系統、搭配可分散運算的MapReduce程式演算方法，可以將多臺一般商用等級的伺服器組合成分散式的運算和儲存叢集，來提供巨量資料的儲存和處理能力。要了解Hadoop，首先必須先了解MapReduce和HDFS的運作原理。
MapReduce是一種解決問題的程式開發模式，開發人員需要先分析待處理問題的解決流程，找出資料可以平行處理的部分，也就是那些能夠被切成小段分開來處理的資料，再將這些能夠採用平行處理的需求寫成Map程式。
然後就可以使用大量伺服器來執行Map程式，並將待處理的龐大資料切割成很多的小份資料，由每臺伺服器分別執行Map程式來處理分配到的那一小段資料，接著再將每一個Map程式分析出來的結果，透過Reduce程式進行合併，最後則彙整出完整的結果。
先拆解任務，分工處理再彙總結果
MapReduce的運作方式就像是大家熟知的全國性選舉開票，中選會事先將開票任務分配給各地投票所，每個投票所各自負責所屬的票箱，完成計票作業後將開票結果回報給中選會，由中選會統一彙整出全國的開票結果，這樣就不需要把幾百萬張選票都集中到中選會處理，而是透過分散處理的方式來加快開票作業。
開票任務就像是Map程式，每一個投票所都執行相同的開票作業程序，也只負責處理少量的局部資料，而Reduce程式就是彙總票數的工作。
在Hadoop運算叢集架構中，這些伺服器依據用途可分成Master節點和Worker節點，Master負責分配任務，而Worker負責執行任務，如負責分派任務的中選會，角色就像是Master節點。
另外在系統的運作架構上，最簡單的Hadoop架構，可以分成上層的MapReduce運算層以及下層的HDFS資料層。
在Master節點的伺服器中會執行兩套程式，一個是負責安排MapReduce運算層任務的JobTracker，以及負責管理HDFS資料層的NameNode程式。而在Worker節點的伺服器中也有兩套程式，接受JobTracker指揮，負責執行運算層任務的是TaskTracker程式，而與NameNode對應的則是DataNode程式，負責執行資料讀寫動作，以及執行NameNode的副本策略。
在MapReduce運算層上，擔任Master節點的伺服器負責分配運算任務， Master節點上的JobTracker程式會將 Map和Reduce程式的執行工作，指派給Worker伺服器上的TaskTracker程式，由TaskTracker負責執行Map和Reduce工作，並將運算結果回覆給Master節點上的JobTracker。
在HDFS資料層上，NameNode負責管理和維護HDFS的名稱空間、並且控制檔案的任何讀寫動作，同時NameNode會將要處理的資料切割成一個個檔案區塊（Block），每個區塊是64MB，例如1GB的資料就會切割成16個檔案區塊。NameNode還會決定每一份檔案區塊要建立幾個副本，一般來說，一個檔案區塊總共會複製成3份，並且會分散儲存到3個不同Worker伺服器的DataNode程式中管理，只要其中任何一份檔案區塊遺失或損壞，NameNode會自動尋找位於其他DataNode上的副本來回復，維持3份的副本策略。
在一套Hadoop叢集中，分配MapReduce任務的JobTracker只有1個，而TaskTracker可以有很多個。同樣地，負責管理HDFS檔案系統的NameNode也只有一個，和JobTracker同樣位於Master節點中，而DataNode可以有很多個。
不過，Master節點中除了有JobTracker和NameNode以外，也會有TaskTracker和DataNode程式，也就是說Master節點的伺服器，也可以在本地端扮演Worker角色的工作。
在部署上，因為Hadoop採用Java開發，所以Master伺服器除了安裝作業系統如Linux之外，還要安裝Java執行環境，然後再安裝Master需要的程式，包括了NameNode、JobTracker和DataNode與TaskTracker。而在Worker伺服器上，則只需安裝Linux、Java環境、DataNode和TaskTracker。
 
［圖表］MapReduce執行示意圖（點此看圖）
相關報導請參考「巨量資料的頭號救星：Hadoop」
",https://www.ithome.com.tw/node/73978,"Hadoop,Cloud,Big Data"
73977,36,2012-05-25,Hadoop技術協助企業解決巨量資料難題,被眾多企業賴以解決Big Data難題的Hadoop技術，並不是一項全新的技術，早在2006年就出現了，而且Hadoop的核心技術原理，更是源自Google打造搜尋引擎的關鍵技術，後來由Yahoo支持的開源開發團隊發展成一套Hadoop分散式運算平臺，也成為Yahoo內部打造搜尋引擎的關鍵技術," 美國國會圖書館是全球最大的圖書館，自1800年設立至今，收藏了超過1.5億個實體物件，包括書籍、影音、老地圖、膠卷等，數位資料量也達到了235TB，但美國eBay拍賣網站，8千萬名用戶每天產生的資料量就有50TB，5天就相當於1座美國國會圖書館的容量。
在國外，不只eBay這種跨國電子商務業者感受到巨量資料的衝擊，其他如美國連鎖超市龍頭Wal-Mart、發行信用卡的Visa公司等，在臺灣如台灣積體電路（台積電）、中華電信等手上擁有大量顧客資料的企業，都紛紛感受到這股如海嘯般來襲的Big Data巨量資料浪潮。這樣的巨量資料並非是沒有價值的資料，其中潛藏了許多使用者親身經驗的第一手原始資料，不少企業更是從中嗅到了商機。
這些企業紛紛向最早面臨Big Data挑戰的搜尋引擎業者Google、Yahoo取經，學習處理巨量資料的技術和經驗，其中，最受這些企業青睞，用來解決巨量資料難題的技術就是Apache基金會的分散式運算技術Hadoop專案。
Wal-Mart分析顧客商品搜尋行為，找出超越競爭對手的商機
全球最大連鎖超市業者Wal-Mart就是善用Hadoop來挖掘出更多商機，甚至能超越競爭對手。Wal-Mart雖然十年前就投入線上電子商務，但線上銷售的營收遠遠落後於Amazon。後來，Wal-Mart決定採用Hadoop來分析顧客搜尋商品的行為，以及用戶透過搜尋引擎尋找到Wal-Mart網站的關鍵字，利用這些關鍵詞的分析結果發掘顧客需求，以規畫下一季商品的促銷策略。他們並進一步打算要分析顧客在Facebook、Twitter等社交網站上對商品的討論，甚至Wal-Mart能比父親更快知道女兒懷孕的消息，並且主動寄送相關商品的促銷郵件，可說是比競爭對手提前一步發現顧客。
eBay用Hadoop拆解非結構性巨量資料，降低資料倉儲負載
經營拍賣業務的eBay則是用Hadoop來分析買賣雙方在網站上的行為。eBay擁有全世界最大的資料倉儲系統，每天增加的資料量有50TB，光是儲存就是一大挑戰，更遑論要分析這些資料，而且更困難的挑戰是這些資料包括了結構化的資料和非結構化的資料，如照片、影片、電子郵件、使用者的網站瀏覽Log記錄等。
eBay分析平臺高級總監Oliver Ratzesberger也坦言，資料分析最大的挑戰就是要同時處理結構化以及非結構化的資料。
eBay在5年多前就另外建置了一個軟硬體整合的平臺Singularity，搭配壓縮技術來解決結構化資料和半結構化資料的分析問題，3年前更在這個平臺整合了Hadoop來處理非結構化資料，透過Hadoop來進行資料預先處理，將大塊結構的非結構化資料拆解成小型資料，再放入資料倉儲系統的資料模型中分析，來加快分析速度，也減輕對資料倉儲系統的分析負載。
Visa快速發現可疑交易，1個月分析時間縮短成13分鐘
Visa公司則是擁有一個全球最大的付費網路系統VisaNet，作為信用卡付款驗證之用。2009年時，每天就要處理1.3億次授權交易和140萬臺ATM的連線存取。為了降低信用卡各種詐騙、盜領事件的損失，Visa公司得分析每一筆交易資料，來找出可疑的交易。雖然每筆交易的資料記錄只有短短200位元，但每天VisaNet要處理全球上億筆交易，2年累積的資料多達36TB，過去光是要分析5億個用戶帳號之間的關聯，得等1個月才能得到結果，所以，Visa也在2009年時導入了Hadoop，建置了2套Hadoop叢集（每套不到50個節點），讓分析時間從1個月縮短到13分鐘，更快速地找出了可疑交易，也能更快對銀行提出預警，甚至能及時阻止詐騙交易。
台積電派員赴美考取Hadoop證照，尋找影響良率的製程關鍵
而在臺灣，半導體龍頭業者台積電也遇到了類似的BigData難題。隨著晶圓製程進入奈米時代，晶圓生產技術越精細，產線各種機臺設備功能就越複雜，MES製程管理系統搜集到的各種製程資料量也越龐大。為了要深入分析龐大的製程資訊，找出提高生產良率的關鍵，台積電派員學習Hadoop分析技術，甚至不惜到美國取得Hadoop專業證照，來強化分析製程Log資訊的運算能力。
中華電信打造BigData運算平臺，分析一尾式巨量資料
而中華電信則是串連了168臺伺服器組成電腦叢集，以Hadoop技術打造了一個「大資料運算平臺」系統，可儲存600TB的資料量。中華電信嘗試用此平臺來分析訊務資料、MOD每日收視率分析、影音資料等傳統關聯式資料難以處理的非結構化資料。
中華電信研究所寬網室研究員蕭毅戲稱這種非結構化的資料為「一尾式」的資料，因為一個檔案的大小可能多達數十GB甚至是TB，就像是一整篇超大型的文章，而不是像傳統資料庫因為具有一定結構的資料欄位而容易取用。但是，透過Hadoop平臺，還是可以先找出這些資料中的特徵，將「一尾式」大型資料拆解成一段段長度相同，具有資料結構的小型資料，以便放入資料庫中進行結構化分析。
這套被眾多企業賴以解決Big Data難題的Hadoop技術，並不是一項全新的技術，早在2006年就出現了，而且Hadoop的核心技術原理，更是源自Google打造搜尋引擎的關鍵技術，後來由Yahoo支持的開源開發團隊發展成一套Hadoop分散式運算平臺，也成為Yahoo內部打造搜尋引擎的關鍵技術。
2002年時，Hadoop專案的共同創始人Doug Cutting 原本要打造一個開源的搜尋引擎Nutch，遇到了儲存大量網站資料的難題，剛好Google在2003到2006年間，對外公開了內部搜尋引擎的3大關鍵技術，分別是Google的GFS檔案系統，大規模叢集上的運算技術MapReduce，以及分散式檔案系統Bigtable，這些正是Google打造出全球性網路服務的核心技術，可以用分散式架構來儲存和處理超大規模的資料。
Doug Cutting 參考了Google這3項技術的原理，利用Java語言，發展出自家的DFS檔案系統和MapReduce程式，來解決Nutch搜尋引擎的大量資料擴充需求。Yahoo則是為了開發自家的搜尋引擎，看上Nutch專案的搜尋引擎，在2006年1月聘僱了Doug Cutting 。
不過，Yahoo當時不需要DFS檔案系統和MapReduce程式，因此，Doug Cutting也在2006年1月將這些程式碼從Nutch專案中獨立出來，另外成立了開源專案來維護，並且以兒子的玩具大象名稱Hadoop，來命名這項後來聞名世界的專案，這正是Hadoop以黃色大象為Logo的由來。
後來，Yahoo看到了Hadoop可以運用在大量資料運算的價值，也開始支援Hadoop專案，並投入不少人力參與開發，也開始在內部運用Hadoop，Yahoo甚至在2008年建置了一個當時全球最大規模的Hadoop叢集，利用4千多臺伺服器，使用超過3萬個處理器核心，來索引超過16PB的網頁資料。
Google也參與了Hadoop專案的開發，並利用此專案作為教材，在世界各地培訓雲端運算的開發人才，Hadoop逐漸被視為是雲端運算的關鍵技術。因為重要性日增，Hadoop也在2008年成為Apache的頂級專案，位階等同於全球最多伺服器採用的 Apache HTTP Server。
新興社交網站如Facebook、Twitter，因為用戶資料量暴增，而且資料類型大多是非結構化資料，如照片、影片、網站瀏覽記錄等，也開始採用Hadoop來處理資料。例如Facebook就曾利用Hadoop打造了一個資料倉儲平臺，來整理和縮減龐大的用戶資料，資料量減量後再放入甲骨文資料庫中進行分析。
幾年前，不少跨國企業，也因為巨量資料的問題，而找上Hadoop專案，Visa、eBay都是這時期率先採用的企業。另有軟體業者如趨勢科技也利用Hadoop來儲存和分析防毒軟體回傳的大量病毒記錄檔。
到了近兩年，社交網站和行動裝置風行，使用者瘋狂透過手機、平板電腦、電腦等，在社交網站上大量分享各種資訊，許多熱門網站擁有的資料量都上看PB等級，而大企業擁有的資料量也逐漸從TB等級，進入了PB等級。Big Data時代，宣告來臨了。
首當其衝的就是傳統的關聯式資料庫系統，原本企業資料庫需要的容量大多是MB、GB等級，但是到了Big Data時代，企業對資料容量的需求則暴增到了數10TB，甚至會出現相當於1,000TB的PB級資料。
一般來說，傳統資料庫系統對TB級資料量的處理相當得心應手，開發人員也很容易運用SQL指令來進行各項分析，各種商業智慧工具也相當成熟。但是對於超過 TB等級的資料量就顯得效能不足，或是企業得投資重金採購效能更好也更昂貴的專屬IT硬體設備，才能提供足夠的處理效能。
參與中華電信Hadoop平臺建置的中華電信資訊處第四科科長楊秀一，他一語道出了巨量資料對企業真正的難題，「最大的問題在於沒有便宜的儲存方式。」他說。
資料達TB級，Hadoop平均儲存成本和NAS、SAN相當
不過，若用Hadoop來儲存和處理大規模資料量，擁有多年Hadoop建置經驗的精誠資訊雲中心Big Data事業發展首席顧問陳昭宇估算，只要資料量超過TB等級，Hadoop平臺的平均單位儲存成本，幾乎和一般企業儲存系統，如NAS、SAN等系統的平均單位儲存成本相當，遠低於資料庫系統的建置成本。
這正是Hadoop獲得許多先行企業青睞的其中一項關鍵原因，正是因為只要使用一般商用等級的伺服器，就可以大規模地擴充儲存容量和運算效能。Hadoop的系統架構設計，採用所謂的水平式擴充架構（Scale Out），只要在叢集中增加更多設備，就可以提高整套運算叢集的效能，像Yahoo就用4,000多臺伺服器來組成一個Hadoop運算叢集。Hadoop不需要像採用垂直式擴充架構的傳統IT設備，遇到效能不足時，得整套汰換才能提高效能和容量。
不過，2009年時，企業要自行建置Hadoop仍舊不是一件容易的事，當時許多建置部署工具還未成熟。再加上，Hadoop為了提供分散式運算，內建的資料庫系統採用一種Key-Value形式的Column-oriented架構資料庫，和傳統關聯式資料庫截然不同，不僅沒有關聯式資料庫那樣的Schema資料庫架構，而且也無法使用開發人員熟知的SQL語法來管理資料庫。企業在當時要建置Hadoop，得投入不少專門人力才行。
但是BigData的浪潮，使得企業對Hadoop的需求日益增加，許多大型軟硬體公司也開始看到Hadoop的效益。近兩年來不少知名軟硬體公司，如甲骨文、微軟、EMC、Dell、NetApp、Teradata、Dell、IBM等都紛紛擁抱Hadoop，有的是直接併購具備Hadoop技術的小型軟體公司，有得則是增加自家產品對Hadoop的支援機制，甚至有業者直接推出內建Hadoop的設備產品。
主流資料庫系統如甲骨文資料庫、微軟SQL Server、IBM的DB 2，還有開源的MySQL紛紛支援Hadoop，資料倉儲產品如Teradata的EDW、EMC的Greenplum、IBM的Netezza也不例外紛紛擁抱Hadoop，只是各家支援作法不同。
另外，也出現了專門推廣和發行Hadoop套件的軟體公司，例如Hadoop創始人Doug Cutting加入的Cloudera公司，或是由Yahoo內部Hadoop團隊獨立出來的Hortonworks 公司。這些模式就像發行Linux套件一樣，Cloudera也推出了Hadoop的發行套件，稱為CDH（Cloudera's Distribution Including Apache Hadoop )，將部署和維護Hadoop所需的工具，打包到一個發行套件中，讓企業用一張光碟就可以快速安裝Hadoop平臺。在臺灣，SI公司精誠資訊也自行發展出一個Hadoop軟硬體整合的套裝產品。相較於過去，企業部署Hadoop的難度越來越低。
Hadoop人才培育也開始受到重視，除了像有需求的軟體、網路業者，如Google與學校合作培訓人才，在臺灣像國家實驗研究院高速網路與計算中心也有提供Hadoop實驗環境，供有興趣的企業免費試用，並能提供Hadoop訓練課程。
而戮力推廣Hadoop的Cloudera也推出了Hadoop專業認證，包括了Hadoop程式開發和系統管理兩種證照。目前起碼臺灣有14個人取得Hadoop專業證照，這些人分別來自國網中心、工研院、趨勢科技、精誠資訊、中華電信，特別的是台積電也有2名員工取得Hadoop證照，這群人正是臺灣少數的Hadoop技術專家，也反映出不論是研究機構、軟體公司或是企業，都想要善用Hadoop的企圖心。
Apache基金會也在2011年12月27日正式發布了Hadoop專案第一個1.0版正式版，包括如資安模式強化，底層檔案系統對資料Append的支援、HDFS支援HTTP的存取，以及多項效能優化等。陳昭宇表示，1.0版已經具備了企業應用需要的重要功能。只剩下Master Node的HA備援還未內建，但Master Node負擔不重，當機機率不高，也可透過第三方機制或硬體備援來提高可用性。
而Hadoop專案下還有許多次專案，發展了各種Hadoop相關套件來滿足企業不同的需求，而且也越來越成熟，這些相關套件組合成了所謂的Hadoop生態體系（Hadoop Ecosystem），內有許多重要的必備套件，例如PIG是一個Script角本語言套件，可讓不懂Java的人也能透過簡單的Script語法，來撰寫MapReduce分散運算程式。
另外還有一個Hive專案，可以透過類似SQL語法的指令來查詢和存取Hadoop中的資料。甚至微軟和Hortonworks合作開發一個Hive的ODBC驅動程式，可以讓Excel程式存取Hadoop上的資料，就像是Excel可以透過ODBC驅動程式來存取SQL Server上的資料庫系統一樣。
未來微軟還打算在Windows Azure雲端平臺上提供Hadoop租用服務，透過Hive ODBC讓Excel直接調度Azure上的Hadoop服務，來處理Big Data分析，並將運算結果輸出到Excel中呈現。
換句話說，可能有一天，不需要高深的Java開發能力，也不用了解分散式運算的邏輯，只要懂得操作Excel，再連結到雲端業者提供的Hadoop服務環境，任何人都可能擁有分析Big Data巨量資料的能力。

Hadoop共同創始人Doug Cutting借鏡Google搜尋引擎的3大關鍵技術，打造出分散式運算平臺Hadoop。







從Hadoop推廣公司Cloudera在Linkedin的Hadoop認證社群中，可以發現臺灣起碼有14個人取得Hadoop專業證照，這些人分別來自台積電、工研院、國網中心、中華電信、趨勢科技、精誠資訊等。

相關報導請參考「巨量資料的頭號救星：Hadoop」
",https://www.ithome.com.tw/node/73977,"Hadoop,Cloud,Big Data"
91507,37,2011-07-01,打造高擴充網站架構的設計關鍵：Stateless Services,透過Stateless和全面API化的網站設計架構，影片租賃服務Netflix打造出高擴充性的網站架構，也因而順利度過Amazon大當機事件的考驗," 美國影片租賃服務Netflix在這次Amazon大當機事件中，除了少數用戶抱怨影片傳輸速度變慢外，幾乎不受影響，等於順利度過這次Amazon當機審判日的考驗。在Netflix負責IT架構、電子商務和系統工程的總監Adrian Cockcroft表示，Stateless Services（無狀態服務）的網站架構是不受影響的關鍵之一。
所謂的Stateless Services設計，簡單來說，就是指使用者透過瀏覽器向網站伺服提出的每一次請求（request）都是獨立的，彼此沒有相關的。因此，這一次的瀏覽器請求和下一次的請求，可以分別交給不同的網站伺服器來執行。
這個設計的優點是，因為每一次瀏覽器請求都是獨立的，即使是同一位使用者提出的每一次請求，都可以分別由不同的網站伺服器單獨執行，所以可以將這些瀏覽請求任意分散到不同的網站伺服器上，即使請求數量很大，也不會全數集中在特定伺服器上產生執行瓶頸。當使用者數量越來越多以後，造成瀏覽效果不彰時，只要增加更多的網站伺服器，就可以來分擔所有的工作量，換句話說，採取Stateless設計架構的網站可以輕易地擴充使用規模。
靜態網頁就是一種Stateless的服務，使用者瀏覽不同的靜態網頁時，任何一臺網站伺服器都可以依據使用者送出的網址來提供網頁內容，不需要從另一個網頁取得資訊。使用者越多時，只要增加越多網站伺服器，就可以透過流量平衡設備將瀏覽器請求分散到其他伺服器。
而Netflix正是採取了Stateless的網站架構，所以就可以將瀏覽器所呼叫的API服務任意指派給任意一個Amazon虛擬機器（Instance）來執行，而不需要綁定在特定虛擬機器上。
因此，在這次當機事件中，Netflix可以向Amazon購買其他地區的虛擬機器接手服務美東地區使用者的瀏覽器請求。對使用者而言，只是因執行伺服器處在更遠的資料中心而增加網頁瀏覽時間，但影片播放的功能則一點都不受影響。
不過，《AWS雲端企業實戰聖經》作者林允溥表示，要開發出Stateless架構的服務並非是一件容易的事。對於有依存關係的操作程序、瀏覽過程或有交易記錄的服務網站，例如購物車功能，若採取Stateless設計，使用者每次執行購物車中的交易動作，可能會由不同的網站伺服器執行，必須還有另外一臺負責統整瀏覽過程交易資訊的機制，才能提供最後的金額累計和訂購產品清單。
或像是身分確認機制，使用者透過某一臺網站伺服器的應用程式登入系統，登入資訊若只存放在這臺伺服器上，當這名使用者下一次瀏覽器動作改由另一臺伺服器執行時，這臺伺服器若沒有這名使用者登入成功的資訊，就會重複要求對方登入系統，造成難以登入系統的困擾。
力可科技資深軟體架構師陳彥任表示，為了打造Stateless架構的網站，有幾種常見的網站建置架構，可以保存互動網頁需要的狀態資訊。
在用戶端保存狀態資訊
第一種是在用戶端保存狀態資訊，將各種狀態資料儲存在使用者端的電腦中，例如使用Cookie儲存，或是下載一支Flash程式，在應用程式執行過程中，將狀態資料儲存在Flash程式內的本地端變數中。每次瀏覽網頁時，再透過網頁參數將這些狀態值傳遞給下一次負責執行的伺服器，來延續前一次的執行結果。這樣一來，即使每次都是由不同網站伺服器來提供服務，也能確保使用者資料的延續。
不過，這種方法的缺點是安全性較低，因為將狀態資料儲存在使用者端，即使透過加密機制避免資料遭竄改或竊取，但也有被破解的風險，或是在應用程式回傳資料給伺服器的過程中被攔截，所以，通常只會在用戶端儲存較不具機敏性質的狀態資料。
以專用Session伺服器儲存狀態
對於有機敏特性或是重要性較高的狀態資料，則是可以透過伺服器端的作法來保存。這種做法就是建立專用的Session伺服器來保存狀態資料。使用者接觸的前端應用伺服器上不保存狀態資料，而將網站應用程式執行過程需要的狀態資料，全部交由這臺Session伺服器來負責傳遞。這樣一來，只有這些少量的狀態資訊會集中，前端網站伺服器仍舊可以不斷擴充，來提高能承載的使用者規模。採用Session專用伺服器的作法比使用者端的作法更能確保資料不被惡意竄改或攔截。
不過，最終瓶頸仍舊會發生在Session伺服器，而且風險也會集中，一旦Session伺服器當機就會導致應用服務停擺，陳彥任表示，為了提高Session伺服器的可用性，可採取伺服器叢集架構，例如一般可以使用3臺伺服器組成Session伺服器叢集，以避免其中1臺發生故障。
當專用Session伺服器叢集接近滿載時，還可以透過分割使量的方式來擴充規模。例如將使用者分成10組，每一組只有原本的十分之一規模，一組使用者就由一套Session伺服器叢集來提供服務，未來增加了新的使用者，只要再多增加新的Session伺服器叢集就可以承載用量，來達到高擴充性的需求。
Stateless Services的設計能解決狀態資料集中的瓶頸來提高擴充性，陳彥任表示，另一個提高網站擴充性的作法是網頁內容API化。例如Amazon的書籍介紹網頁，對使用者而言看似只有一個網頁，但其實這個網頁組合了上百個API程式的執行結果，Amazon將網頁中的每一個功能或資訊，例如評星等、價格顯示、下訂單、推薦書籍等，都開發成一項API，在分散給不同的網站伺服器執行，使用者透過一個整合式的混搭網頁來匯集其他API伺服器提供的內容。
陳彥任表示，這類API化的網站，在架構設計上，必須盡可能簡化每一個API的功能，才能減少彼此的影響，達到分散和擴充規模的效果，這也是一種提高前端網站擴充性的方法。不過，每一個網頁都要等待其他伺服器執行完API後回傳資料，若內部網路頻寬不足，每個API的延遲時間會影響使用者看到網頁的流暢性。
Netflix在1年前決定將服務全數轉移到Amazon上時，也重新打造了新的系統架構，將網站內容全面API化，再透過API提供影音串流服務或其他功能給不同平臺或裝置上的使用者端程式，包括桌上型電腦、手機、平板電腦等，Adrian Cockcroft表示，因為網站規模成長太快，建置資料中心的速度太慢，將系統架構API化以後，就可以快速調度Amazon虛擬機器來擴充規模，不用自行準備硬體設備，甚至Netflix將常用的函式庫元件也API化，來提高內部應用程式執行共用元件時的彈性，可以由任一臺元件伺服器支援。
另外，Netflix也利用memcached記憶體式資料庫來儲存Session資料，作為API存取後端儲存系統或資料庫之間的中介。陳彥任表示，資料庫是打造網站擴充性的第一個瓶頸，除了利用叢集式資料庫架構或NoSQL資料庫來分散存取量外，也透過像memcached這類記憶體式資料庫作為常用資料的快取，也可以用來處理保存時限較短暫的Session資料。不過，若要讓多套memcached資料庫互相分享資料，則要自行建立同步機制，目前memcached還未提供自動同步資料庫內容的功能。
透過Stateless Services和API化的網站設計架構，Netflix只要將API服務複製到新的EC2虛擬機器上，就可以建立一個提供API服務的伺服器，能夠快速擴充承載規模，遇到當機事件時，也能快速將服務轉移到其他地區資料中心的虛擬機氣上，避開有問題的服務區域，這正是Netflix順利度過這次Amazon大當機的關鍵之一。
 
Netflix服務API化架構
Netflix網站架構API化以後，可以快速調度Amazon提供的虛擬機器來擴充承載規模，遇到Amazon當機事件時，也能快速將服務轉移到其他地區資料中心的虛擬機器上，避開有問題的服務區域。

 
相關報導請參考「Amazon雲端服務大當機的啟示」
",https://www.ithome.com.tw/news/91507,"新聞,雲端服務,Cloud"
91506,37,2011-07-01,不受雲端業者當機影響 Netflix安全上雲端的秘訣,全美網路流量排名第一的Netflix雖然所有服務仰賴Amazon的EC2，但幾乎不受這次大當機事件的影響，關鍵就是5項安全上雲端的秘訣," 影片租賃服務Netflix是北美網路流量最大的網站，全美網路流量有2成都是用來傳輸Netflix提供的影片。Netflix在2010年10月時才決定改用Amazon的EC2來提供所有的線上影音服務，不再建置新的資料中心。全美流量最大的服務商的這項背書，無疑是對Amazon雲端服務穩定性的一大保證。
不料，今年4月21日凌晨，Amazon北維吉尼亞機房發生了EBS（Elastic Block Service）服務大當機事件， 完全仰賴EC2提供服務的Netflix自然也受到波及，但是只有發生影音傳輸速度變慢的情況。雖然在當機期間，用者抱怨大幅增加，但沒有像有些知名網站如Quora幾乎是服務完全中斷的情況，Netflix等於是順利度過這次當機的考驗。
當Amazon美東地區（Region）的一座AZ服務區域（Availability Zone，相當於是一座資料中心）失效時，Netflix工程團隊就決定趁使用者流量還未達到顛峰前，將所有服務撤離這個區域，並且手動設定流量負載規則，避開發生問題的地區，確保服務不致中斷，也因此而沒有發生嚴重的災情。
在事件發生之後，負責IT架構、電子商務和系統工程的Netflix總監Adrian Cockcroft與2位同僚聯名在官方部落格上發表長文，分享Netflix順利度過這次當機事件的關鍵，以及從中得到的教訓。
5大防當機設計
Netflix表示，2010年底時，Netflix將全數服務轉移到Amazon上時，也重新調整了IT架構，這個新架構讓Netflix度過這次的AWS審判日的考驗。其中最重要的幾項防當機關鍵包括了，Stateless Services（無狀態服務）設計、跨區域儲存資料、功能移除機制、N+1備援、以及大量使用雲端解決方案的服務架構。
首先，無狀態服務的設計是Netflix重新打造IT架構的重點，新架構會讓所有的API服務可以指派給任意的虛擬機器（Instance）來提供服務，而不需要綁定在特定的伺服器上，有些必須要持續使用的Session資料，例如每一次放進購物車中的資料，則由另外的Session伺服器來統一管理，讓前端提供服務的伺服器不需要保留這些統合性的資料。這個設計的好處是，可以隨時切換服務節點，快速由新節點取代發生問題的節點。
其次，Netflix平時會定期將提供給使用者的影音內容和伺服器資料備份到Amazon的其他服務區域，遇到單一AZ服務區域發生問題時，就可以由其他區域快速接手提供，而不用再等待資料回復的時間。
第三、為了避免部分失功能拖累了整套系統，Netflix也預先設計了多種快速移除部分功能的機制，遇到有少數元件發生問題，可以先關閉部分功能，確保其他服務可以繼續執行。這些功能移除機制的設計原則包括了能快速中止元件（Fail Fast）、提供候補功能（Fallbacks）、可直接移除的功能（Feature Removal）等設計。
第四，在備援設計上，Netflix採取了N+1備援的作法，任何時刻，都會提供比使用量更多的運算資源，而且不是採用主從式的備援，或是部分離線的備援，而是隨時都會額外多一份資源的作法。Netflix將服務主機散布在Amazon美東地區4座服務區域（資料中心）的3座，每個服務區域內都會有提供額外AWS備援，以避免單一區域服務失效，雖然每年會增加三分之一的費用，但可以確保影音服務不會中斷。
最後一項就是大量使用雲端解決方案的作法，相較於過去實體資料中心的作法，雲端IT架構讓Netflix的應用系統很容易地在不同資料中心間切換，也搭配了NoSQL資料庫來提高可用性，另外還使用S3儲存來提供更耐用的資料備份。
整體性自動化工具不足與負載設計盲點
不過，在這次因應Amazon當機事件的過程中，Netflix也發現幾項有待改進的缺失，第一個就是手動轉移全數服務的過程中，原本用來自動部署和調整AWS設定檔的工具，無法同時調整所有的設定檔，過去只為局部性調整或特定用途而開發工具，缺乏一套整體性的自動化工具，例如無法用一個指令就將某一類服務全數搬移到另一個區域。換句話說，每一種服務的負責團隊，都得人工手動切換，也提高了轉移過程的風險。Netflix表示，因為服務規模太大，大量轉換時的工具不足，未來會先簡化轉移程序，增加更多自動化設計和工具。
其次是負載平衡的盲點，原本Netflix使用Amazon提供的ELB負載平衡服務來切換所有前端服務的流量，但因ELB只能在Amazon的單一服務區域中分散流量，而無法達到跨區域的負載平衡，如果在單一區域中過多伺服器當機，就會讓負載平衡機制失效，進而讓整個區域的服務中斷。
ELB是一種2階層式的負載平衡設計，第一層是DNS負載平衡切換，第二層則是由AWS直接提供的ELB服務，在這次當機事件中，EBS失效問題也影響了AWS的服務，進而導致這個服務區域的ELB發生問題。Netflix打算建立另一個中間層的負載平衡機制，不使用ELB機制，而且可以跨不同服務區分散流量。
3項改進重點
綜和這次當機事件，Netflix決定進行3項改進作法，首先是建立更多失效測試機制，原本Netflix就自行打造了一個自動化測試服務Chaos Monkey，可以用來模擬系統失效的情況，例如臨時中止某些服務，來測試備援機制的運作。但是這個Chaos Monkey沒有考慮到整座資料中心失效的情況，只考量到資料中心內少數虛擬機器失效的情況，未來Netflix會加入整座資料中心失效的模擬。
另外，Netflix也決定開發跨地區（Region）的自動化工具，因為Amazon提供的自動化備援機制或備份機制，只能在單一地區內跨服務區域，例如美東地區的服務區域，但就無法自動跨越美東地區和亞洲地區等多地區。這次Netflix工程團隊只能手動將服務轉移到其他地區的AZ服務區域。未來，Netflix也會針對全球各地區的服務來設計可以跨地區的影音服務，這樣的設計也有助於提高服務可用性。
最後，為了降低對EBS儲存資源的依賴，Netflix決定使用S3備份服務來提供靜態的虛擬機器映象檔備份，並且要將MySQL EBS資料庫轉移到Cassandra這類NoSQL資料庫上，利用EC2本地端資料庫搭配分散式設計來確保資料庫服務。
雖然Amazon發生了這樣的大當機事件，但Netflix仍然認為，「使用Amazon的AWS服務來取代實體資料中心的策略是正確的方向，這次大當機只是一次考驗，這些從中學習到的經驗，更加確認這個方向的信心」。負責Netflix整體架構的Adrian Cockcroft表示。
 
Netflix預防雲端服務當機的5項關鍵作法
5項防當機設計
1.API無狀態服務（Stateless Services）設計：所有的API可指派給任意虛擬機器來提供服務，而不需要綁定在特定的伺服器。
2.跨區域儲存資料：定期將提供給使用者的影音內容和伺服器資料備份到Amazon的其他服務區域，遇到單一AZ服務區域發生問題時，就可以由其他地區快速接手提供服務。
3.快速移除功能的機制：為了避免部分失效功能拖累了整套系統，預先設計了多種快速移除部分功能的機制，遇到有少數元件發生問題，可快速關閉這些有問題的功能。
4.N+1備援：任何時刻都會提供比使用量更多的運算資源，每個Amazon的服務區域內也會各自準備額外運算資源，避免單一服務區域內的故障問題。
5.大量使用雲端解決方案：Netflix將所有服務轉移到Amazon上以後，新的雲端IT架構，大量使用雲端解決方案，應用系統很容易地在不同服務區域間切換，可避開發生問題的區域。
3項未來改進重點
1.自動化失策模擬測試機制增加更多可能的服務失效情況，包括整座服務區域（資料中心）失效的情況。
2.開發跨地區（Region）的自動化工具，以及設計誇全球各地區的服務架構，來提高可用性。
3.降低對EBS儲存資源的依賴，改用S3儲存服務提供靜態資料備援，以及搭配NoSQL資料庫Cassandra，來提供資料庫的動態備援機制。
資料來源：Netflix，iThome整理，2011年6月
 
相關報導請參考「Amazon雲端服務大當機的啟示」
",https://www.ithome.com.tw/news/91506,"新聞,雲端服務,Cloud"
91505,37,2011-07-01,不受雲端業者當機影響 Netflix安全上雲端的秘訣,全美網路流量排名第一的Netflix雖然所有服務仰賴Amazon的EC2，但幾乎不受這次大當機事件的影響，關鍵就是5項安全上雲端的秘訣," 影片租賃服務Netflix是北美網路流量最大的網站，全美網路流量有2成都是用來傳輸Netflix提供的影片。Netflix在2010年10月時才決定改用Amazon的EC2來提供所有的線上影音服務，不再建置新的資料中心。全美流量最大的服務商的這項背書，無疑是對Amazon雲端服務穩定性的一大保證。
不料，今年4月21日凌晨，Amazon北維吉尼亞機房發生了EBS（Elastic Block Service）服務大當機事件， 完全仰賴EC2提供服務的Netflix自然也受到波及，但是只有發生影音傳輸速度變慢的情況。雖然在當機期間，用者抱怨大幅增加，但沒有像有些知名網站如Quora幾乎是服務完全中斷的情況，Netflix等於是順利度過這次當機的考驗。
當Amazon美東地區（Region）的一座AZ服務區域（Availability Zone，相當於是一座資料中心）失效時，Netflix工程團隊就決定趁使用者流量還未達到顛峰前，將所有服務撤離這個區域，並且手動設定流量負載規則，避開發生問題的地區，確保服務不致中斷，也因此而沒有發生嚴重的災情。
在事件發生之後，負責IT架構、電子商務和系統工程的Netflix總監Adrian Cockcroft與2位同僚聯名在官方部落格上發表長文，分享Netflix順利度過這次當機事件的關鍵，以及從中得到的教訓。
5大防當機設計
Netflix表示，2010年底時，Netflix將全數服務轉移到Amazon上時，也重新調整了IT架構，這個新架構讓Netflix度過這次的AWS審判日的考驗。其中最重要的幾項防當機關鍵包括了，Stateless Services（無狀態服務）設計、跨區域儲存資料、功能移除機制、N+1備援、以及大量使用雲端解決方案的服務架構。
首先，無狀態服務的設計是Netflix重新打造IT架構的重點，新架構會讓所有的API服務可以指派給任意的虛擬機器（Instance）來提供服務，而不需要綁定在特定的伺服器上，有些必須要持續使用的Session資料，例如每一次放進購物車中的資料，則由另外的Session伺服器來統一管理，讓前端提供服務的伺服器不需要保留這些統合性的資料。這個設計的好處是，可以隨時切換服務節點，快速由新節點取代發生問題的節點。
其次，Netflix平時會定期將提供給使用者的影音內容和伺服器資料備份到Amazon的其他服務區域，遇到單一AZ服務區域發生問題時，就可以由其他區域快速接手提供，而不用再等待資料回復的時間。
第三、為了避免部分失功能拖累了整套系統，Netflix也預先設計了多種快速移除部分功能的機制，遇到有少數元件發生問題，可以先關閉部分功能，確保其他服務可以繼續執行。這些功能移除機制的設計原則包括了能快速中止元件（Fail Fast）、提供候補功能（Fallbacks）、可直接移除的功能（Feature Removal）等設計。
第四，在備援設計上，Netflix採取了N+1備援的作法，任何時刻，都會提供比使用量更多的運算資源，而且不是採用主從式的備援，或是部分離線的備援，而是隨時都會額外多一份資源的作法。Netflix將服務主機散布在Amazon美東地區4座服務區域（資料中心）的3座，每個服務區域內都會有提供額外AWS備援，以避免單一區域服務失效，雖然每年會增加三分之一的費用，但可以確保影音服務不會中斷。
最後一項就是大量使用雲端解決方案的作法，相較於過去實體資料中心的作法，雲端IT架構讓Netflix的應用系統很容易地在不同資料中心間切換，也搭配了NoSQL資料庫來提高可用性，另外還使用S3儲存來提供更耐用的資料備份。
整體性自動化工具不足與負載設計盲點
不過，在這次因應Amazon當機事件的過程中，Netflix也發現幾項有待改進的缺失，第一個就是手動轉移全數服務的過程中，原本用來自動部署和調整AWS設定檔的工具，無法同時調整所有的設定檔，過去只為局部性調整或特定用途而開發工具，缺乏一套整體性的自動化工具，例如無法用一個指令就將某一類服務全數搬移到另一個區域。換句話說，每一種服務的負責團隊，都得人工手動切換，也提高了轉移過程的風險。Netflix表示，因為服務規模太大，大量轉換時的工具不足，未來會先簡化轉移程序，增加更多自動化設計和工具。
其次是負載平衡的盲點，原本Netflix使用Amazon提供的ELB負載平衡服務來切換所有前端服務的流量，但因ELB只能在Amazon的單一服務區域中分散流量，而無法達到跨區域的負載平衡，如果在單一區域中過多伺服器當機，就會讓負載平衡機制失效，進而讓整個區域的服務中斷。
ELB是一種2階層式的負載平衡設計，第一層是DNS負載平衡切換，第二層則是由AWS直接提供的ELB服務，在這次當機事件中，EBS失效問題也影響了AWS的服務，進而導致這個服務區域的ELB發生問題。Netflix打算建立另一個中間層的負載平衡機制，不使用ELB機制，而且可以跨不同服務區分散流量。
3項改進重點
綜和這次當機事件，Netflix決定進行3項改進作法，首先是建立更多失效測試機制，原本Netflix就自行打造了一個自動化測試服務Chaos Monkey，可以用來模擬系統失效的情況，例如臨時中止某些服務，來測試備援機制的運作。但是這個Chaos Monkey沒有考慮到整座資料中心失效的情況，只考量到資料中心內少數虛擬機器失效的情況，未來Netflix會加入整座資料中心失效的模擬。
另外，Netflix也決定開發跨地區（Region）的自動化工具，因為Amazon提供的自動化備援機制或備份機制，只能在單一地區內跨服務區域，例如美東地區的服務區域，但就無法自動跨越美東地區和亞洲地區等多地區。這次Netflix工程團隊只能手動將服務轉移到其他地區的AZ服務區域。未來，Netflix也會針對全球各地區的服務來設計可以跨地區的影音服務，這樣的設計也有助於提高服務可用性。
最後，為了降低對EBS儲存資源的依賴，Netflix決定使用S3備份服務來提供靜態的虛擬機器映象檔備份，並且要將MySQL EBS資料庫轉移到Cassandra這類NoSQL資料庫上，利用EC2本地端資料庫搭配分散式設計來確保資料庫服務。
雖然Amazon發生了這樣的大當機事件，但Netflix仍然認為，「使用Amazon的AWS服務來取代實體資料中心的策略是正確的方向，這次大當機只是一次考驗，這些從中學習到的經驗，更加確認這個方向的信心」。負責Netflix整體架構的Adrian Cockcroft表示。
 
Netflix預防雲端服務當機的5項關鍵作法
5項防當機設計
1.API無狀態服務（Stateless Services）設計：所有的API可指派給任意虛擬機器來提供服務，而不需要綁定在特定的伺服器。
2.跨區域儲存資料：定期將提供給使用者的影音內容和伺服器資料備份到Amazon的其他服務區域，遇到單一AZ服務區域發生問題時，就可以由其他地區快速接手提供服務。
3.快速移除功能的機制：為了避免部分失效功能拖累了整套系統，預先設計了多種快速移除部分功能的機制，遇到有少數元件發生問題，可快速關閉這些有問題的功能。
4.N+1備援：任何時刻都會提供比使用量更多的運算資源，每個Amazon的服務區域內也會各自準備額外運算資源，避免單一服務區域內的故障問題。
5.大量使用雲端解決方案：Netflix將所有服務轉移到Amazon上以後，新的雲端IT架構，大量使用雲端解決方案，應用系統很容易地在不同服務區域間切換，可避開發生問題的區域。
3項未來改進重點
1.自動化失策模擬測試機制增加更多可能的服務失效情況，包括整座服務區域（資料中心）失效的情況。
2.開發跨地區（Region）的自動化工具，以及設計誇全球各地區的服務架構，來提高可用性。
3.降低對EBS儲存資源的依賴，改用S3儲存服務提供靜態資料備援，以及搭配NoSQL資料庫Cassandra，來提供資料庫的動態備援機制。
資料來源：Netflix，iThome整理，2011年6月
 
相關報導請參考「Amazon雲端服務大當機的啟示」
",https://www.ithome.com.tw/news/91505,"新聞,雲端服務,Cloud"
91504,37,2011-07-01,不受雲端業者當機影響 Netflix安全上雲端的秘訣,全美網路流量排名第一的Netflix雖然所有服務仰賴Amazon的EC2，但幾乎不受這次大當機事件的影響，關鍵就是5項安全上雲端的秘訣," 影片租賃服務Netflix是北美網路流量最大的網站，全美網路流量有2成都是用來傳輸Netflix提供的影片。Netflix在2010年10月時才決定改用Amazon的EC2來提供所有的線上影音服務，不再建置新的資料中心。全美流量最大的服務商的這項背書，無疑是對Amazon雲端服務穩定性的一大保證。
不料，今年4月21日凌晨，Amazon北維吉尼亞機房發生了EBS（Elastic Block Service）服務大當機事件， 完全仰賴EC2提供服務的Netflix自然也受到波及，但是只有發生影音傳輸速度變慢的情況。雖然在當機期間，用者抱怨大幅增加，但沒有像有些知名網站如Quora幾乎是服務完全中斷的情況，Netflix等於是順利度過這次當機的考驗。
當Amazon美東地區（Region）的一座AZ服務區域（Availability Zone，相當於是一座資料中心）失效時，Netflix工程團隊就決定趁使用者流量還未達到顛峰前，將所有服務撤離這個區域，並且手動設定流量負載規則，避開發生問題的地區，確保服務不致中斷，也因此而沒有發生嚴重的災情。
在事件發生之後，負責IT架構、電子商務和系統工程的Netflix總監Adrian Cockcroft與2位同僚聯名在官方部落格上發表長文，分享Netflix順利度過這次當機事件的關鍵，以及從中得到的教訓。
5大防當機設計
Netflix表示，2010年底時，Netflix將全數服務轉移到Amazon上時，也重新調整了IT架構，這個新架構讓Netflix度過這次的AWS審判日的考驗。其中最重要的幾項防當機關鍵包括了，Stateless Services（無狀態服務）設計、跨區域儲存資料、功能移除機制、N+1備援、以及大量使用雲端解決方案的服務架構。
首先，無狀態服務的設計是Netflix重新打造IT架構的重點，新架構會讓所有的API服務可以指派給任意的虛擬機器（Instance）來提供服務，而不需要綁定在特定的伺服器上，有些必須要持續使用的Session資料，例如每一次放進購物車中的資料，則由另外的Session伺服器來統一管理，讓前端提供服務的伺服器不需要保留這些統合性的資料。這個設計的好處是，可以隨時切換服務節點，快速由新節點取代發生問題的節點。
其次，Netflix平時會定期將提供給使用者的影音內容和伺服器資料備份到Amazon的其他服務區域，遇到單一AZ服務區域發生問題時，就可以由其他區域快速接手提供，而不用再等待資料回復的時間。
第三、為了避免部分失功能拖累了整套系統，Netflix也預先設計了多種快速移除部分功能的機制，遇到有少數元件發生問題，可以先關閉部分功能，確保其他服務可以繼續執行。這些功能移除機制的設計原則包括了能快速中止元件（Fail Fast）、提供候補功能（Fallbacks）、可直接移除的功能（Feature Removal）等設計。
第四，在備援設計上，Netflix採取了N+1備援的作法，任何時刻，都會提供比使用量更多的運算資源，而且不是採用主從式的備援，或是部分離線的備援，而是隨時都會額外多一份資源的作法。Netflix將服務主機散布在Amazon美東地區4座服務區域（資料中心）的3座，每個服務區域內都會有提供額外AWS備援，以避免單一區域服務失效，雖然每年會增加三分之一的費用，但可以確保影音服務不會中斷。
最後一項就是大量使用雲端解決方案的作法，相較於過去實體資料中心的作法，雲端IT架構讓Netflix的應用系統很容易地在不同資料中心間切換，也搭配了NoSQL資料庫來提高可用性，另外還使用S3儲存來提供更耐用的資料備份。
整體性自動化工具不足與負載設計盲點
不過，在這次因應Amazon當機事件的過程中，Netflix也發現幾項有待改進的缺失，第一個就是手動轉移全數服務的過程中，原本用來自動部署和調整AWS設定檔的工具，無法同時調整所有的設定檔，過去只為局部性調整或特定用途而開發工具，缺乏一套整體性的自動化工具，例如無法用一個指令就將某一類服務全數搬移到另一個區域。換句話說，每一種服務的負責團隊，都得人工手動切換，也提高了轉移過程的風險。Netflix表示，因為服務規模太大，大量轉換時的工具不足，未來會先簡化轉移程序，增加更多自動化設計和工具。
其次是負載平衡的盲點，原本Netflix使用Amazon提供的ELB負載平衡服務來切換所有前端服務的流量，但因ELB只能在Amazon的單一服務區域中分散流量，而無法達到跨區域的負載平衡，如果在單一區域中過多伺服器當機，就會讓負載平衡機制失效，進而讓整個區域的服務中斷。
ELB是一種2階層式的負載平衡設計，第一層是DNS負載平衡切換，第二層則是由AWS直接提供的ELB服務，在這次當機事件中，EBS失效問題也影響了AWS的服務，進而導致這個服務區域的ELB發生問題。Netflix打算建立另一個中間層的負載平衡機制，不使用ELB機制，而且可以跨不同服務區分散流量。
3項改進重點
綜和這次當機事件，Netflix決定進行3項改進作法，首先是建立更多失效測試機制，原本Netflix就自行打造了一個自動化測試服務Chaos Monkey，可以用來模擬系統失效的情況，例如臨時中止某些服務，來測試備援機制的運作。但是這個Chaos Monkey沒有考慮到整座資料中心失效的情況，只考量到資料中心內少數虛擬機器失效的情況，未來Netflix會加入整座資料中心失效的模擬。
另外，Netflix也決定開發跨地區（Region）的自動化工具，因為Amazon提供的自動化備援機制或備份機制，只能在單一地區內跨服務區域，例如美東地區的服務區域，但就無法自動跨越美東地區和亞洲地區等多地區。這次Netflix工程團隊只能手動將服務轉移到其他地區的AZ服務區域。未來，Netflix也會針對全球各地區的服務來設計可以跨地區的影音服務，這樣的設計也有助於提高服務可用性。
最後，為了降低對EBS儲存資源的依賴，Netflix決定使用S3備份服務來提供靜態的虛擬機器映象檔備份，並且要將MySQL EBS資料庫轉移到Cassandra這類NoSQL資料庫上，利用EC2本地端資料庫搭配分散式設計來確保資料庫服務。
雖然Amazon發生了這樣的大當機事件，但Netflix仍然認為，「使用Amazon的AWS服務來取代實體資料中心的策略是正確的方向，這次大當機只是一次考驗，這些從中學習到的經驗，更加確認這個方向的信心」。負責Netflix整體架構的Adrian Cockcroft表示。
 
Netflix預防雲端服務當機的5項關鍵作法
5項防當機設計
1.API無狀態服務（Stateless Services）設計：所有的API可指派給任意虛擬機器來提供服務，而不需要綁定在特定的伺服器。
2.跨區域儲存資料：定期將提供給使用者的影音內容和伺服器資料備份到Amazon的其他服務區域，遇到單一AZ服務區域發生問題時，就可以由其他地區快速接手提供服務。
3.快速移除功能的機制：為了避免部分失效功能拖累了整套系統，預先設計了多種快速移除部分功能的機制，遇到有少數元件發生問題，可快速關閉這些有問題的功能。
4.N+1備援：任何時刻都會提供比使用量更多的運算資源，每個Amazon的服務區域內也會各自準備額外運算資源，避免單一服務區域內的故障問題。
5.大量使用雲端解決方案：Netflix將所有服務轉移到Amazon上以後，新的雲端IT架構，大量使用雲端解決方案，應用系統很容易地在不同服務區域間切換，可避開發生問題的區域。
3項未來改進重點
1.自動化失策模擬測試機制增加更多可能的服務失效情況，包括整座服務區域（資料中心）失效的情況。
2.開發跨地區（Region）的自動化工具，以及設計誇全球各地區的服務架構，來提高可用性。
3.降低對EBS儲存資源的依賴，改用S3儲存服務提供靜態資料備援，以及搭配NoSQL資料庫Cassandra，來提供資料庫的動態備援機制。
資料來源：Netflix，iThome整理，2011年6月
 
相關報導請參考「Amazon雲端服務大當機的啟示」
",https://www.ithome.com.tw/news/91504,"新聞,雲端服務,Cloud"
91503,37,2011-07-01,剖析Amazon大當機關鍵：人為疏失因自動化擴大連鎖效應,1個人為網路設定錯誤，導致Amazon美東地區好幾座資料中心的EBS服務大規模當機，美國數千個網站停擺，8小時以後陸續修復，少數網站甚至3天才恢復正常," 在美國太平洋時間4月21日凌晨12點47分，剛過午夜不久，負責Amazon美東地區其中一個服務區域（Availability Zone）的維護人員，不小心弄錯了一項網路設定。
這個看似微不足道的問題卻引發了Amazon的EC2（Elastic Compute Cloud ）雲端服務失效的連鎖效應，導致Amazon美東地區的4座資料中心的EC2服務嚴重大當機，Amazon陸續搶救，3天後才完全恢復正常。
例如美東有家心律調節器監控服務的廠商，有3部使用EC2服務的主機完全停擺，用來蒐集心電圖訊號的服務停止運作，導致監控人員無法即時追蹤數百位在家休養的心臟病患者身上，醫護人員無法取得這些患者身上心律調節器的ECG 心電圖訊號而非常擔心。該公司急著在Amazon論壇求助，但沒有人可以協助解決。
因為心電圖訊號並非是攸關性命的醫療系統，原本這家監控服務商以為，Amazon EC2承諾的 99.95%可用性符合這樣居家照護系統的要求，沒想到卻發生大當機，一直到4月23日當天下午2點時，主機才恢復正常。在38個小時的服務空窗期內，系統停擺的廠商只能緊急調派人手通知家屬，並以人工確認的方式來掌握病患的狀態。
這次EC2大當機事件是Amazon自2008年S3服務8小時當機事件後，最嚴重的一次當機事件。上次S3當機事件對網站服務的影響，大多只是靜態網頁資料無法呈現，例如Twitter儲存的S3服務上的圖片無法顯示，但沒有嚴重影響到Twitter服務的運作。
但是，Amazon這次失效事件卻導致了上千個網站服務完全中斷，其中包括了知名新興網站如 Foursquare、Quroa、Reddit。甚至像Heroku網站代管平臺因為大量仰賴EC2服務，更是導致了60小時的營運中斷，代管的網站也連帶無法存取。
事後，Amazon的AWS服務團隊在官方部落格公開道歉，承認這次EC2當機事件是人為引發了自動化工具的盲點，在連鎖影響下，造成美東地區的EC2服務都受到影響。
要了解這次大當機的原因，得先知道Amazon EC2的服務架構。目前， EC2服務在全球5個地區提供服務，包括了美東、美西、歐洲、亞太東南和亞太東北等地區，每一個地區，Amazon稱為一個「Region」，而每個地區下則有多座資料中心，Amazon再用Availability Zone（服務區域，簡稱AZ）來稱呼，一個資料中心也就是一個AZ服務區域。
EBS網路升級是當機導火線
事故發生當晚，Amazon正在升級美東地區其中一座資料中心內EBS（Elastic Block Store）儲存服務的網路頻寬，這正是造成這次當機事件的起源。EBS是Amazon提供的儲存服務之一，可以掛載在EC2虛擬機器上使用，就像是實體伺服器使用的SAN儲存網路一樣，使用者可以指定多個EBS的Volume儲存空間作為EC2虛擬機器的磁碟機。
相較於EC2虛擬機器上的本地端儲存空間，EBS擁有較長的資料保存期限，也有高可用性的設計架構，每個Volume會自動建立一份完全一樣的備份Volume。
為了避免備份機制干擾EBS的存取，Amazon設計了2種不同的網路傳輸方式，一種是低延遲高頻寬的主要網路傳輸服務（Primary Network），用來提供給EC2主機與EBS間的資料I/O之用，而另一種網路則是頻寬較低的傳輸服務，主要作為EBS非同步建立Volume備份時的資料傳輸。
4月21日當晚，Amazon正計畫對美東地區其中一個服務區域的EBS主要網路進行線路升級工作。一般企業升級伺服器的網路線路時，為了避免伺服器的服務中斷，通常會建立另外一套有足夠流量承載力的臨時性備援線路，將舊線路的流量導入備援線路以後，再來更換網路設備。
但Amazon維護人員輸入了錯誤的網路設定，誤將主要網路上的網路流量導向頻寬較低的非同步備份用線路，而沒有導入到備援線路，造成大量EBS的資料I/O流量塞爆了這個服務區域的EBS低頻寬傳輸網路。
頻寬不足的問題原本只會影響資料存取效能，頂多是讓網站服務變慢，但不致於完全中斷甚至當機，但是，EBS的自動備份特性卻讓網路頻寬的消耗更加雪上加霜，也衍生出更嚴重的災情。
當機關鍵是過度自動化
EBS為了提供長期儲存機制，採取了多項高可用性的架構設計。例如每個服務區域中會有很多套EBS叢集系統，每1套EBS叢集由多臺伺服器組成，稱為1個EBS節點。雖然每1個地區（Region）內有多個資料中心，但在Amazon的設計上，1個地區屬於同1個網段，同一地區下每個服務區域共用同一套命名空間，也只使用1套EBS控制服務（ Control Plane Services），用來協調這個地區下，不同服務區域中每個EBS叢集所提出的需求。
每次EC2使用者建立一個新的EBS Volume時，EBS控制服務會自動在同一個服務區域內的不同EBS節點上建立這個Volume的複製版本（Mirror Volume），作為備援之用，一旦原本的EBS Volume失效，EBS控制程式就會自動切換到另一個節點上的複製Volume接手提供儲存服務。
Amazon設計了一個自動偵測機制，來確保EBS Volume的HA架構。原始的EBS Volume會不斷向複製Volume發送偵測訊號，類似Ping功能，若複製Volume沒有在一段時間內回應，自動偵測機制就會判斷複製Volume失效，並且向EBS控制服務提出建立一個全新複製Volume的請求。EBS控制服務就會找出另一個可用的EBS節點，在數毫秒內重新建立鏡像複製版（re-mirroring），正是自動偵測機制加上re-mirroring功能導致了連鎖錯誤的發生。
大當機當晚，因為設定錯誤讓服務區域的低速網路大塞車，自動偵測程式無法透過低速網路接收到複製Volume的回覆訊息，以為是複製版本失效了，就開始向EBS控制服務大量提出re-mirroring的請求。
因為整個服務區域的網路都受到影響，所以該服務區域內的每一個EBS節點都向EBS控制服務提出請求，產生了大量建立備份Volume的請求等待執行，一旦網路塞車稍微紓解，EBS控制服務就會立刻執行建立Volume的動作，但複製Volume的資料傳輸又會用掉更多網路頻寬，讓整個資料中心的低速網路更塞車，原始Volume還是無法確認複製Volume的存在，繼續請求建立更多備份。
如此惡性循環，最終，Amazon北維吉尼亞資料中心內所有EBS節點都無法運作，因為這些EBS節點的運算資源和網路頻寬都被建立複本Volume的請求所占用，無法正常存取服務。
有一種EC2虛擬機器使用EBS來儲存開機時的分割區（Root Partition），EBS失效也連帶導致這些EC2無法讀取開機資料因而失效，Amazon提供的MySQL RDS資料庫服務也是安裝在EBS上，同樣中斷服務。
這個Amazon北維吉尼亞資料中心的EC2虛擬機器或資料庫系統當機以後，租用了這間資料中心資源的用戶網站也跟著停擺。
連鎖當機耗用API協調系統的資源，災情蔓延其他服務區域
但是，災情還沒結束，因為Amazon的架構設計上，一個地區雖然會有多座資料中心來提供AZ服務區域，但是同一個地區內的所有AZ的EBS是共用同一套EBS 控制系統，這間北維吉尼亞資料中心內EBS提出的大量建立複本要求，塞爆了美東地區的EBS控制系統，導致這個地區的EBS控制系統無法協調其他3座資料中心的EBS節點，來進行各種EBS API請求，即便這些EBS的資料一切正常也無法有效運作，整個美東地區仰賴EBS的EC2和RDS服務至此全數停擺。
Amazon在事件爆發後半小時就發現網路設定錯誤的問題，維護人員花了幾個小時，先停止了這個自動建立Volume的API，也將網路設定恢復正常，但是大量的EBS複本建置需求，已經耗用了原有的實體儲存空間，Amazon不敢驟然中止所有的EBS Volume，擔心會造成正在處理的資料遺失，只能先透過網路切割的方式，先將北維吉尼亞資料中心的EBS服務和美東地區的EBS控制系統隔離，並且建立新的EBS控制系統，協助其他3個服務區域內的EBS以及仰賴EBS的RDS服務回復正常，讓不在問題服務區域的網站可以先恢復運作。
接著，Amazon開始擴充實體設備來增加問題服務區域的儲存容量，讓等待建立複本的re-mirror程式有足夠的實體空間和運算資源可以完成待執行的指令。因為資料中心擴充實體機器的速度很慢，這也是導致少數服務得等3天才回復正常的原因。
自動化的漣漪效應
《AWS雲端企業實戰聖經》作者林允溥認為，這次大當機事件是一種自動化的漣漪效應，這些自動化程式沒有設定終止條件來限制執行次數，或是逐漸拉長執行自動化程式的時間間隔，一旦發生人為疏失，觸發了這個程式設計漏洞，惡性循環不斷耗用資源直到服務停擺。
林允溥表示，這類自動化程式的演算法應該設計很短暫的Time-Out時間，指令等待觸發的時效很短，萬一請求失效，等待再次請求的時間也應逐步延長，例如第二次請求間隔1 秒，第三次則間隔2秒，第四次4秒等指數延長等待時間的方式，並且設定重試次數等作法，就可以延緩自動化程式造成的連鎖風暴。
不過，林允溥表示，對於快速成長的網站，網站主容易只專注於開發新功能或提供新服務，卻沒有累積足夠的網站擴充經驗，尤其是用如何建置穩定又具高擴充性的自動化工具，即便像Amazon這類全球流量排名前15大的網站，他們開發的自動化工具都會有盲點，更何況是經驗不足的新興網站。
累積足夠手動經驗再全面自動化
林允溥建議，網站主即便開發出了自動化網站擴充或維護工具，也不要輕易導入全自動化，而是先採取自動化程式的最後一關是人工切換的作法，等到累積足夠多的操作經驗後，才導入全面自動化。
這次大當機事件後，有許多網站也發文反省，大量仰賴Amazon EC2服務的同時，卻忘了自行建立妥善的備援設計。林允溥解釋，很多網站將所有服務集中在Amazon單一服務區域內，而沒有建立跨區備援，一來因為單一服務區內的網路傳輸免費，二來要進行跨區備援也會增加系統架構的複雜性，管理維護的難度也就更高。
林允溥認為：「很多網站只是將機房搬上雲端，卻沿用傳統資料中心的運作概念，沒有善用雲端的彈性擴充能力來建立備援。」例如遇到這類整間資料中心失效的情況，就可以先在另一個地區建立新的EC2虛擬機器和EBS儲存內容，快速回復系統來接手服務，等到問題排除後，再切換回北美服務區域的主機中。
不過，他認為，平時必須先將EBS的資料備份到亞洲地區資料中心的S3服務中，同時也預先建立跨地區的備援計畫，並且定期演練確保計畫可行才有辦法因應這類大規模當機情況的發生。
當機事件回復正常後，Amazon也在官方部落格上發文檢討，承諾會強化網路設定變更時的稽核，以降低人為錯誤的風險。
另外從這次當機事件的經驗中，Amazon未來會預先備妥足夠的實體設備，來因應類似突發性的需求，以縮短擴充實體設備時的裝機時間。
在系統程式的改善上，會修改EBS複本程式的自動化程式判斷邏輯，增加如限制條件等作法，以免發生這種會陷入無限迴圈的情況，以避免突發性大量需求塞爆服務後衍生的其他問題，並承諾會重新檢討所有自動化程式，避免其他程式也有類似的盲點。
另一方面，Amazon也承諾要解決現有跨地區自動化工具不足的問題，首先將讓所有Amazon提供的服務，可以支援多個AZ服務區域，包括原本只能在單一服務區域存取的Amazon VPC，未來也可跨服務區域存取或部署，Amazon還會提供更多跨AZ服務地區的工具，方便網站主建立高可用性的架構，即使遇到單一資料中心失效，還能將服務轉移到其他服務區域中。
最後，Amazon還會加快EBS叢集的資料回復機制，方便網站主能自動化復原EBS上的Volume資料，提高從備援機制中恢復服務的時效，也會改善現有網路通訊和服務監控工具，來提高對營運狀態的監控等。
 

當機事件結束後，Amazon也在官方部落格道歉，並且發文說明當機事件原因，以及後續的改善作法。

 

《AWS雲端企業實戰聖經》作者林允溥認為：「很多網站只是將機房搬上雲端，卻沿用傳統資料中心的運作概念，沒有善用雲端的彈性擴充能力來建立備援。」

 
Amazon連鎖大當機歷程
階段1
美東地區升級單一服務區域的主要網路，維護人員網路設定錯誤將EBS主要網路的資料流量導向低頻寬的非同步備份網路，因而造成EBS網路大塞車。
階段2
該服務區域內所有EBS的Volume 自動備份機制因網路塞車，無法確認備份用的volume 副本是否存在，因此，大量向美東地區的EBS控制服務送出重建Volume 副本的re-mirroring請求。
階段3
大量re-mirroring請求塞爆了美東地區EBS控制服務的運算負載，連帶造成EBS控制服務無法協調美東地區其他3座資料中心內的EBS運作，造成美東地區所有服務區域的EBS當機，仰賴EBS的RDS服務也因此而停擺。
階段4
8小時以後，Amazon更正網路設定，並且關閉這個EBS控制服務的部分API，也透過網路分割的方式，隔離發生問題的服務區域，另外還增加新的EBS控制服務讓其他3座資料中心的EBS服務恢復正常，但發生問題的Amazon北維吉尼亞資料中心所提供的EBS服務仍舊還未恢復。
階段5
Amazon開始擴充Amazon北維吉尼亞資料中心的實體儲存設備，讓發生問題的EBS控制器有足夠的資源可以完成大量的EBS副本建置請求。
階段6
3天後，Amazon擴充了足夠的實體設備，讓發生問題的服務區域完成所有等待執行的EBS副本建置請求以後，EC2服務和RDS服務才恢復正常。
 
快速認識Amazon雲端服務
全球最大雲端服務網站Amazon所推出的雲端服務包括了20多種不同的服務，統稱為AWS（Amazon Web Services）。從2002年起，Amazon就開始提供內部服務給限定用戶使用，到了2006年3月，更是推出了第一個AWS服務Amazon S3儲存服務，之後陸續推出了涵蓋儲存、運算、資料庫、網路服務、訊息傳遞、監控、付款等各式各樣的網路服務。
《AWS雲端企業實戰聖經》作者林允溥表示，使用AWS的困難是，即使只是要新增一個虛擬機器來建置網站，仍然要熟悉AWS相關網路、儲存、資料庫等服務的API使用方式，才能架構出正式上線所需的執行環境。他建議，企業可以先從S3儲存服務開始熟悉AWS的API使用方式，以及透過憑證來授權服務的方式。
另外，在使用AWS服務之前，企業還需要了解地區（Region）和服務區域或稱為所在地（Availability Zone）觀念的差別，地區是實體地理的區域，例如有美國東部、歐洲西部、亞洲區等，一個地區中會有很多座資料中心，1個服務區域就代表了1座資料中心。
AWS服務對於跨區域或跨服務區域的計費方式有很大差異，例如同一地區內的EC2主機互相傳輸不收費，但跨地區就要計價。不同服務區域對全球各地的延遲時間也不同。企業要就近選擇適當的地區和服務區域的使用方式。
AWS主要服務整理
● 運算：EC2、Elastic MapReduce、Auto Scaling
● 內容發布：CloudFront
● 儲存：S3、EBS、AWS輸入輸出
● 資料庫：SimpleDB、RDS
● 網路：Route 53、ELB、VPC
● 訊息：SQS、SNS、SES
● 監控：Amazon CloudWatch
● 付款：FPS、DevPay
● 協同工作：Mechanical Turk
● 網頁流量監控：Alexa網頁資訊服務
資料來源：Amazon，iThome整理，2011年7月
 
相關報導請參考「Amazon雲端服務大當機的啟示」
",https://www.ithome.com.tw/news/91503,"新聞,雲端服務,Cloud"
91759,37,2011-05-20,雲端運算實踐經驗：遊戲橘子先從負載低的OA系統導入虛擬化,遊戲橘子將虛擬化導入分成3階段，先從影響層面較小的OA系統下手，逐步擴展到與玩家相關的Web服務和遊戲測試環境，未來遊戲產品導入虛擬化還是努力的目標," 線上遊戲業者向來高度依賴IT，為了降低伺服器採購成本和電力消耗，線上遊戲業者如遊戲橘子近年來大量導入虛擬化技術，希望能夠提升IT投資效益。
遊戲橘子資訊長許武先表示，該公司從2008年開始規畫虛擬化應用，並針對不同的應用範圍分成3階段導入，最終目的在於能夠建立屬於遊戲橘子的雲端服務平臺，除了可以作為內部服務提供，也可以提供外部遊戲玩家使用。
虛擬化第一階段：從OA系統下手
遊戲橘子員工多達1,200人，但因員工平時多使用即時通訊溝通，對電子郵件等辦公室自動化系統的依賴不高，因此，許武先導入虛擬化的第一階段，和其他公司導入虛擬化都先從測試環境下手不同，遊戲橘子先從辦公室OA系統著手，包括了目錄服務（AD）伺服器、Exchange電子郵件伺服器、執行SharePoint平臺的伺服器等，遊戲橘子先將為數不少的OA伺服器，全部導入虛擬化技術，來善用單一伺服器的運算效能。
許武先表示，因為該公司當時採用微軟虛擬化技術Hyper-V，和公司使用的OA系統有很好的整合，加上OA系統影響程度相較營運系統低，才列為優先導入虛擬化的標的。此外，因為採用了效能較高的伺服器，並預載大量記憶體，所以可以在一臺實體伺服器中承載較多的虛擬機器，平均1臺實體伺服器上可以安裝6臺虛擬機器。
虛擬化第二階段：將記錄玩家資料的平臺導入虛擬化
遊戲橘子為了確保玩家身分的安全性，陸續提供各種身分認證工具和平臺，但是，當遊戲橘子推出越多款遊戲時，玩家們每進入一個新遊戲，就需要重新登入來確認身分，許武先表示，是否可以提供玩家們一個在安全前提下的「單一帳號登入」，便成為遊戲橘子思索的方向。
對於遊戲橘子而言，建立玩家們的向心力、維繫玩家們的情誼，也是一個遊戲公司對玩家們的承諾。因此，遊戲橘子希望能夠幫玩家記錄他們參與遊戲的軌跡與歷程，不論是成績記錄或是和組隊打戰戰友們的互動過程。
所以，遊戲橘子在2009年底成立了一個樂豆（beanfun！）的Web服務，整合玩家們所有遊戲的登入帳號，並且可以記錄玩家們在不同遊戲中的組隊行為和交友情況，來建立一個玩家社群。
「因為樂豆是一個Web Services，所以是一個最好導入虛擬化服務的標的。」許武先說道。在2009年底建立樂豆後，便開始評估導入虛擬化技術，從2010年2月迄今，遊戲橘子逐步將公司OA內部非營運環境導入虛擬化技術，包含AD（目錄服務）伺服器、資料庫、ERP系統、Web伺服器和官方網站等等；至於營運系統，以及登入樂豆後必須同時撈取大量資料的後端SQL資料庫，因為擔心會有存取上的疑慮，都不會導入虛擬化平臺。
許武先表示，由於玩家數量多，臺灣樂豆平臺導入虛擬化技術後，平均1臺實體伺服器可以安裝10臺虛擬機器，伺服器採購成本節省9成。此外，遊戲橘子也將某些海外子公司的樂豆平臺，一半導入虛擬化技術，一半仍只放置在實體伺服器中運行。
虛擬化第三階段：遊戲測試平臺導入虛擬化技術
遊戲橘子是一個提供線上遊戲服務的業者，最終還是會希望能夠把一些現階段玩家數量沒有那麼大的遊戲產品，透過虛擬化技術整併到數量較少的伺服器上；或者是，利用線上遊戲在高峰及離峰的伺服器使用量有很大差異的特性，思考是否可以將高、離峰的伺服器做其他妥善合併利用，這也是IT部門念茲在茲的思考方向。
因此，遊戲橘子在虛擬化第三階段中，除了先前將2款自製遊戲部署到虛擬化平臺上進行測試外，許武先表示，也將透過這次測試來了解虛擬化平臺對遊戲效能的影響。
因為遊戲橘子的遊戲為全球發行，需要做不同語言版本測試，基於成本考量，公司就採購少數伺服器，透過預載不同語系作業系統硬碟的插拔，供研發部門針對不同語系進行測試。因此，許武先改用虛擬化來提供不同語系的測試環境，大幅提升了測試部門的效率。「除了壓力測試之外，大多可以在虛擬平臺中進行。」他說道。
不過，遊戲開發環境目前還沒有導入虛擬化平臺。許武先解釋，遊戲開發工程師不了解虛擬化技術，再加上遊戲程式經常需要直接呼叫作業系統內的特殊元件，他說，在開發同仁無法徹底掌握虛擬化技術前，避免遊戲除錯時會有太多變數，故暫不在虛擬平臺開發遊戲。
遊戲橘子在臺灣雖然沒有把遊戲上到虛擬平臺，但在歐洲已將數款遊戲放到虛擬平臺，只待該款遊戲正式營運。他說：「以目前採購16核心伺服器，48GB記憶體來看，1臺實體伺服器可以安裝8臺虛擬機器。」
長期而言，許武先認為從虛擬化到雲端化，還是遊戲橘子應該努力的方向，而在這個過程中，公司也必須在組織文化上做配套調整，讓各款產品的專案經理願意釋出資源，並且有合理的營利計價方式作為呼應。
管理虛擬化平臺面臨的挑戰
遊戲橘子把幾個主要應用環境導入虛擬化技術後，接下來就是做到虛擬機器自動化管理。許武先指出，目前虛擬平臺多無法做事件管理，加上建立虛擬機器仍必須由IT部門建立，多數使用者為了方便，虛擬機器都不會關機。雖然虛擬機器有開機快、設定快的優點，但使用過後的虛擬機器若無法自動回收再利用，長期以往，仍然會面臨到虛擬機器不敷使用。他說：「2011年遊戲橘子的目標就是虛擬機器管理自動化。」
為了監控虛擬機器的使用效率，遊戲橘子自行開發一套虛擬機器的監控系統（GSMS），監控各個虛擬機器在實體伺服器上的處理器、記憶體、硬碟存取和網路流量的運作狀況是否有異常，相關監控資訊並彙整到一個後端儀表板上，一旦任何虛擬機器運行異常，問題出在那裡將一目了然。
許武先表示，隨著市場變化和技術演進，遊戲橘子未來的雲端平臺將以何種面貌呈現，目前都還有許多變數。但他認為，只要遊戲橘子在能夠滿足企業營運與資訊安全的兩大前提下，虛擬化技術怎麼用，雲端服務怎麼演變都不會是問題。
 
遊戲橘子虛擬化技術應用一覽表

 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91759,"新聞,雲端服務,Cloud,私有雲,虛擬化"
91758,37,2011-05-20,雲端運算實踐經驗：趨勢科技善用虛擬化讓機房搬家只停機3小時,善用虛擬化平臺的vMotion功能，趨勢科技只用了3小時停機時間，就將德國慕尼黑舊資料中心提供的應用系統，全數遷移到10公里外的新資料中心," 機房搬家對任何企業的資訊部門而言，都是一件非常困難的挑戰，上百臺伺服器的轉移工作，往往得中斷服務數十小時，甚至1~2天才能完成。但趨勢科技在今年初，只用了3個小時的停機時間，就將位於德國慕尼黑舊資料中心的200臺伺服器，轉移到10公里外的新資料中心。負責制定全球IT策略的趨勢科技資訊服務部資深協理沈捷明表示，順利快速轉移的關鍵正是虛擬化技術。
因為原本的資料中心服務商要結束營業，趨勢科技只好將伺服器全數轉移到慕尼黑另一家服務商的資料中心。這些伺服器包括了應用程式伺服器、網站伺服器和資料庫系統等。除了資料庫系統外，趨勢利用VMware的虛擬機器線上轉移技術vMotion，來搬移其他應用系統的執行環境。
趨勢從2010年底開始進行這項搬家任務，沈捷明表示，事前要先備妥網路架構，包括從控制辦公室到新舊2座資料中心的網路連線，另外還特別租用了一條10Gb頻寬的專用線路，以供虛擬機器線上轉移之用。接著，趨勢團隊用了一個月的時間來進行伺服器轉移的練習，同時測試可行性。
雖然vMotion功能可以在短短數秒內，將虛擬機器轉移到另一臺實體伺服器上，使用者可能都還沒有察覺服務已經轉移，但是，沈捷明表示，了解這批伺服器之間的關聯性，確認哪些伺服器必須先轉移，而哪些必須最後轉移。「找出轉移順序才能降低停機時間。」
例如，有些網頁服務建置了多套前端應用系統來分散流量，就可以先轉移其中一套系統的虛擬機器到新資料中心，再轉移後端的資料庫。只要將新的網頁系統重新連結新的資料庫後就能啟用服務，再逐步轉移剩下的前端應用系統。
沈捷明表示，已建置備援系統的服務，也可以如法炮製，先轉移一套系統到新機房接手提供服務，再陸續轉移其他系統。若是沒有建置備援的服務，則是要先產生一個暫時性的伺服器來轉移。最後，趨勢啟用這些透過vMotion轉移成功的服務後，才會進行DNS切換，讓遠端使用者真的連結到新資料中心的伺服器上使用各項服務。
轉移過程中，沈捷明表示，要先計算出需要的虛擬機器數量，並且事先備妥實體伺服器，趨勢趁機將部分網頁應用整併到同一臺效能更強的實體伺服器。
用Single VM作法快速轉移非網頁應用
其他非網頁的應用程式則是採取1對1的轉移方式，將舊機房的實體伺服器，先透過P2V工具將執行環境轉移到虛擬機器中，再使用vMotion將虛擬機器轉移到新機房中只執行單一虛擬機器（Single VM）的實體伺服器上，也就是說，在新資料中心裡，同樣由一臺實體伺服器來執行這個服務，只是多了一個虛擬機器和虛擬層的負載。例如最後轉移的資料庫系統，就是採取Single VM的轉移方法。
趨勢最後才轉移資料庫系統，沈捷明表示，因為vMotion轉移的作法需要在新舊資料中心各準備一套資料庫系統的授權，會產生額外的授權費用，所以，資料庫系統採取停機轉移的作法，而不是透過vMotion線上轉移。這個停機轉移，也是先將資料庫系統轉移到虛擬機器中，再停機將這個虛擬機器的映像檔複製到新資料中心的伺服器中啟用，並且搭配具有重複資料刪除功能的網路加速設備來減少資料傳輸量，盡可能地縮短停機時間。這次資料中心搬家的3小時停機，就是為了轉移資料庫系統。
透過事前充分的準備和規畫，再加上執行團隊擁有豐富的虛擬化導入經驗，趨勢順利在今年1月完成這項資料中心的轉移任務。
執行團隊的虛擬化經驗並非憑空產生，而是趨勢過去幾年推動虛擬化累積的成果。早從2007年，趨勢科技就開始嘗試虛擬化，最初花了6個月到1年時間驗證虛擬化應用的可行性，同時累積足夠的自行導入經驗。
例如2008年中時，臺灣趨勢就將150臺編譯伺服器，整併到5臺實體伺服器中，後來更擴大將虛擬化架構應用到上千臺的測試伺服器，一方面加快測試環境的提供，另一方面也整併老舊的測試伺服器。沈捷明表示，透過這些先期導入計畫，讓虛擬化技術逐漸獲得使用者部門和業務部門的信賴。
2009年後，趨勢開始將各種應用系統虛擬化，除了測試環境外，還包括了ERP、CRM、財務系統、OA系統等應用。將160個機櫃的伺服器，整併為100多櫃，節省了不少機房空間。
2010年下半年時，趨勢更進一步發布政策，規定所有新開發的應用系統都要使用虛擬機器，除非有特殊考量。當時趨勢科技虛擬化比例已高達45%，虛擬機器的數量達到3,000臺之多，平均1臺實體伺服器可以承載5～10臺虛擬機器。沈捷明表示，今年目標是在年底前達到80～85％的虛擬化比例。
建立自動化服務平臺提高虛擬機器配置效率
為了管理數量高達數千臺的虛擬機器，趨勢在2010年初也展開了一項Instant VM專案，自行打造了一個自助式的虛擬機器部署平臺，讓虛擬機器的調配可以自動化。
Instant VM的使用者是負責評估專案需求的專案經理，當他需要申請虛擬機器時，可以自己到Instant VM的網頁上填寫申請單，描述專案所打造的應用系統用途、專案期程、應用程式屬性，例如是處理器消耗型、記憶體消耗型或是I/O消耗型？總共需要多少臺虛擬機器？需不需要提供自動備份和回復功能？若需要備份，備份頻率是每日、每周或其他？以及是否需要提供虛擬機器使用量報告資料等。
Instant VM會依據申請單內容，自動調度和配置虛擬機器，同時建立備份和回復機制的設定檔，讓備份儲存系統可以依據設定來維護虛擬機器。
趨勢在每年的年度計畫中，都會要求各專案經理先提出今年計畫專案的虛擬機器容量需求，以供虛擬平臺管理人員事先預估今年需要採購的實體伺服器與儲存系統的容量。不過，沈捷明表示，自動化服務一定要搭配資源回收機制，才不會是跛腳的自動化，否則再多的資源也很容易用完。所以，Instant VM也搭配了資源回收功能，專案完成後就回收臨時性的虛擬機器，例如開發階段或測試階段使用的虛擬機器，而正式上線環境的虛擬機器則不需要回收。
過去，趨勢科技基礎架構維運人員需要1周才能提供專案所需的執行環境，導入虛擬化之後縮短到2小時就能完成虛擬機器的部署，而透過Instant VM自動化配置平臺，更能在1小時內完成提供。
專案經理使用自助服務是為了更容易取得使用量報表
不過，對專案經理而言，沈捷明表示，他們願意使用自助式服務的動機，是可以很容易取得使用量的報告。過去，專案經理需要各種執行環境使用量資訊，例如伺服器使用量、網路使用量時，必須額外花時間向不同的IT維運負責窗口申請。但現在，Instant VM結合了報表系統，會自動將各種使用量監控資訊寄送到專案經理的電子郵件中，專案經理比以前更容易取得各種平臺管理資訊。
目前，趨勢科技正展開Instant VM 2.0的改版計畫，除了增強更多監控功能，涵蓋更多網路效能和磁碟容量管理機制與監控資訊，還希望能整合更多虛擬化技術，自動配置不同虛擬化技術的虛擬機器資源，除了VMware以外，還能自動配置微軟Hyper-V和Citrix平臺。
除此之外，趨勢科技還希望能結合過去各種應用程式的使用量趨勢，來提供應用系統的使用量預測，協助專案經理規畫未來需要的容量，例如在特定事件時，需要額外準備多少虛擬機器才足以承載突然暴增的用量。
雖然預測數據只是參考值，但沈捷明認為，透過這些監控工具提供的使用量透明度，系統管理者就可以結合過去經驗，來判斷未來特定事件需要的運算容量，例如出現新的攻擊木馬，或是病毒碼更新等情況時，可以預先管理這些事件帶來的可能衝擊，這正是他認為系統管理者最重要的價值。
 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91758,"新聞,雲端服務,Cloud,私有雲,虛擬化"
91757,37,2011-05-20,雲端運算實踐經驗：台灣大哥大自製監控平臺掌握上百臺VM狀態,為了管理數百臺虛擬機器，台灣大哥大自行打造了一套監控系統，透過視覺化的IT架構地圖即時呈現核心應用系統的執行狀態," 走進台灣大哥大系統規劃暨維運處處長王衛道的辦公室，一定會看到牆上掛著一個19吋螢幕，畫面中的圖形顯示出台灣大哥大（台哥大）每一個重要營運系統的執行狀態，這正是王衛道用來管理台哥大資訊基礎架構的利器。
台哥大IT部門依據不同AP的特性，來定義不同顏色所代表的狀態臨界值，一眼望去，馬上可以清楚知道北、中、南區直營門市或加盟店門市人員的電腦設備，連結到後端應用系統的過程中，每一段的網路連線、虛擬機器上的AP伺服器，或後端資料庫系統的運作狀態。綠色燈號代表正常，而不同顏色的線條則反應出每一段網路的流量負載。
對王衛道而言，維運部門最重要的任務是監控系統服務的營運狀態，但目前，台哥大虛擬機器的數量多達3、4百臺，雖然王衛道帶領的維運處只需要負責管理網路、伺服器、中介軟體和資料庫系統，但他認為，虛擬化以後，伺服器的管理複雜度更高，「虛擬機器的數量越來越多後，就需要發展成私有雲，開始使用自動化的管理軟體。」
市售套裝管理軟體功能遠多於台哥大的需求，而且售價也相當昂貴，因此他決定自行打造管理工具，將各種監控資訊彙整到單一資料庫中，再透過免費的NagVis工具來繪製出網頁版的系統和網路架構圖以便呈現運作狀態。
管理人員只要透過瀏覽器就能隨時看到各系統的運作情形，王衛道辦公時，只需要抬頭就能掌握企業內部這朵私有雲的最新動態，也不用等待部屬通知或系統示警簡訊。
虛擬化前要先標準化
不過，王衛道表示，台哥大先進行標準化以後，才能順利導入虛擬化。2005年，為了降低成本，台哥大開始推動標準化，將原本的主從式架構，轉換到三層式架構，使用者透過IE瀏覽器登入中間層的Web化應用程式，後端則是資料庫系統。另外也將中間層的應用程式轉移到x86伺服器。
為了轉換架構，台哥大也重新改寫應用程式，讓應用程式和資料庫系統分開，並且簡化了支援瀏覽器、Web伺服器和底層作業系統的版本。
執行環境標準化以後，王衛道發現伺服器的平均利用率不高，有些前臺AP白天使用率100％，但晚上跌到10％ ，有些AP則是一周才會用到一次。6、7百個應用系統，執行伺服器的每周平均使用率只有10～20％。
為了提高使用率，台哥大從2009年開始大規模導入虛擬化，採用VMware虛擬化技術，逐步將AP伺服器轉換到虛擬機器上執行。資料庫則因各地直營店和加盟店總數多達7百家，上班時間連線數多而且運算量高，就算是晚上，資料庫系統也要執行批次指令，而沒有轉換到虛擬機器中執行。
開發新AP限用虛擬機器
因為台哥大上線的AP多達6、7百套，幾乎每天都有AP專案需要測試用的執行環境。所以，台哥大先從測試環境開始導入虛擬化，再逐步擴大到正式上線的環境。後來每次開發新的AP時或是舊版AP要大改版時，王衛道強制只提供虛擬機器作為開發環境，「等到這些AP上線時，也自然而然地使用虛擬機器執行。」這正是王衛道擴大虛擬化應用範圍的策略。
另一方面，因為台哥大的網管人員和伺服器管理人員分屬不同團隊，王衛道也重新調整雙方的工作流程和合作模式，並且對雙方都進行跨領域訓練，相互了解對方的領域知識。他解釋，過去建置執行環境，網管和伺服器負責人可以分別進行，但現在規畫虛擬機器的建置時，網管人員就要參與設定，例如決定虛擬機器要使用哪個網段才會順暢，儲存架構要如何共享網段等。「雖然這兩種角色重疊的工作大約只有15％，但在虛擬機器管理上，必須找出雙方角色合作的方式。」
目前，台哥大的虛擬機器大約有300～400臺。台哥大觀察虛擬機器執行情形，發現VMware虛擬機器本身消耗的處理器資源大約占15%，所以，王衛道認為，可以在單一實體伺服器上採取AP混編的作法。他依據AP特性，將不同負載類型AP的虛擬機器放在同一臺實體伺服器中，例如將白天忙碌的前臺系統，和晚上忙碌的後臺AP放在一起，來提高利用率，而不是依據虛擬機器的作業系統來歸類，所以，一臺實體伺服器上可能會同時有Linux和Windows Server。
「關鍵是同類AP的虛擬機器放在相同網段，效能較佳。」王衛道說，他會依據AP之間的相互關係來切割使用的網段，讓需要相互存取資料的AP位於同一個網段中，減少跨越網段的傳輸延遲，並盡量將同類AP放在同一座刀鋒系統中，例如直營店系統相關的AP。
另外，台哥大也在2個不同地的機房中，各建置了1組刀鋒系統來執行交易量高的交易系統虛擬環境，兩套系統採取負載共享的作法，而還沒有進行異地備援，萬一其中一套系統當機，還有另一套系統可以繼續營運確保服務不中斷。單臺實體伺服器上可執行5～6個虛擬機器。
為了管理大量虛擬機器，台哥大開始自行打造管理工具。王衛道表示，目前主要需求是監控，而不是自動化配置（Auto Provision）。因為一個專案往往得花數個月才能完成，光是執行環境的配置就要花一段時間討論才能決定，「用2天完成設定和幾分鐘完成設定，對專案的差別不大。」他解釋。
台哥大自行開發的管理工具以監控用途為主，監控項目包括了虛擬機器的處理器利用率、記憶體、I/O流量、連線數量等，網路端則有封包遺失率、回應時間等一般監控實體伺服器時需要的資訊，透過這些資訊來判斷哪一個虛擬機器或服務發生當機。
另外，台哥大也開發了一些使用者端的連線偵測工具，安裝在不同地區，例如北、中、南部門市中使用者的電腦上，來監測使用者端到應用伺服器之間的連線狀態，以便監控網段中的交換器或路由器是否故障。最後，將這些監控資訊都彙總到一個監控平臺上，再透過視覺化的資訊架構地圖，在網頁上即時呈現出各種AP服務從使用者端到後端資料庫系統之間的執行狀態。
不論是王衛道或AP團隊的主管都可以透過瀏覽器監看這個服務監控平臺上的資訊。若有出現代表當機或負載過高的紅色警告，維運人員可以進一步點選畫面中代表不同網路設備或伺服器的圖示，打開更詳細的狀態報表，來判斷可能發生的問題。
使用者不易評估運算需求，自助式服務時機未到
因為台哥大內部AP的客製化程度很高，王衛道認為，使用者如行銷部門人員的資訊能力還不足以判斷需要多少運算資源，所以，他還不打算建置自助式服務，讓使用者透過網頁自己申請虛擬機器的配置。
但是，王衛道倒是打算導入計價機制，計算出不同AP使用的虛擬機器和儲存、網路資源所對應的成本結構，希望透過計價機制來了解運算資源分配的情況，而不是要收費。他認為，若要實際進行內部收費還須公司高層支持與政策配合，台哥大目前還沒有要進行這項作法。
 

台灣大哥大自行打造了一套監控應用服務的視覺化監控平臺，包括使用者端的連線狀態，到每一個執行AP的虛擬機器狀態，以及後端資料庫系統運作資訊，都呈現在NagVis工具繪製的架構圖上，透過顏色來代表不同的伺服器健康狀態，管理人員一眼就能找出發生問題的設備。

 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91757,"新聞,雲端服務,Cloud,私有雲,虛擬化"
91756,37,2011-05-20,雲端運算實踐經驗：中國人壽臺北機房x86伺服器100％虛擬化,中國人壽臺北機房200臺x86實體機器已全數虛擬化，今年中開始還要進一步導入網路、儲存與虛擬機器的監控管理工具，讓IT資源的利用更有效率," 中國人壽在2006年首度導入虛擬化，歷經5年，所有臺北機房共200臺x86伺服器已經全數虛擬化，今年6月開始，他們還打算將分公司、備援端也全數虛擬化。
現在許多企業為了降低風險，導入虛擬化都從測試環境開始，中國人壽也不例外。不過，光是在測試環境導入虛擬化就帶來不少效益。中國人壽資訊工程部資深副理林成鑫表示，在測試環境導入虛擬化就為公司減少了將近3成費用。但是，這些節省的費用並非因硬體減少而來，而是來自軟體授權費的節省。
目前不少軟體授權費用是以處理器計價，甚至還會計算處理器的核心數，再依照核心數多寡訂出每單位的價格，即使用於測試環境，企業仍要付軟體授權費，另外，不同的應用軟體也必須再依照各自使用的硬體數付費，但虛擬化以後，只要調配好不同系統上線測試的時間，就可以讓不同系統共用一套硬體。
舉例來說，中國人壽的會計系統、保險核心系統與應收票據系統是各自獨立的，過去在測試環境的授權費用也要購買三套，計費方案也選擇較昂貴的不限連線人數版本。林成鑫表示，虛擬化以後，只要資源切割清楚，並且分配好工程師上線測試的時間，提高軟體使用率後，就只需要負擔一套的軟體授權費用，在選擇計費方案時，也改成最低用量門檻的計費方式。
虛擬化對企業來說，不僅能減少支出，也可以達到成本控制。林成鑫表示，在虛擬化的過程中，發現許多硬體的使用率都偏低，代表企業的IT投資往往會高估，而虛擬化中動態配置的功能就能提高硬體的使用率，也讓IT的投資會真正隨著企業業務成長。而不是每隔2、3年就要投資一筆鉅額費用。
測試環境虛擬化之後，中國人壽的虛擬化旅程，在2009年邁入第一階段VM1，除了逐步將新專案轉移到虛擬化環境運行，重點是將老舊機器以及原廠不支援的舊版作業系統環境，都先虛擬化。藉由軟體解決了硬體的問題。
接著，2010年初開始第二階段VM2，中國人壽花了一年多的時間，將臺北機房所有x86伺服器上的系統全都轉移到虛擬化的環境中運行。
在前面這幾個階段，他們其實遇到一些困難，並且預計在今年6月開始第三階段VM3來解決這些問題。
網路交換器支援虛擬化才能最佳化網路配置
首先，由於中國人壽在4年前建置的底層網路骨幹設備，沒有支援虛擬化的功能。林成鑫表示，當虛擬機器不斷搬遷，若網路交換器不支援虛擬化，就無法進行網路配置的最佳化，而且，當網路出現問題時，也無法透過vCenter找到問題發生源。因此，接下來他們打算更換新一代的網路交換器，一旦虛擬機器搬遷不需要再重新設定就可自動建立網路對應，也有利於網路資源的監控。
另外，在儲存面也遇到困難，雖然在第一階段時，中國人壽就已經建置了2套大型的儲存池，並且在伺服器端採用2條8Gb的光纖網路整合成1個16Gb的光纖網路架構，增大了頻寬。不過，由於當時並沒有導入儲存虛擬化的管理工具，再加上因營運業務產生的大量影像格式檔案，導致儲存設備頻繁讀取輸入資料，加重了I/O存取負擔。林成鑫認為，在VM3階段會導入儲存虛擬化的管理工具，為了改善I/O瓶頸，他也打算申請經費購買存取效能更好的SSD硬碟，來加快使用者開啟影像檔案的速度。
虛擬化監控管理工具應該具備預警功能
一次導入200臺規模虛擬化工作，當然在管理上也得下不少功夫。林成鑫表示，過去管理虛擬環境時都是透過vCenter監控，這個作法有幾個缺點，像是無法在同一個畫面看到全部虛擬機器的狀態，也無法直覺地呈現資訊。若要了解各個機器的狀況必須要逐一點擊VM清單上的名稱才能察看細節，也無法預警等，為此，他同時也使用了開放原始碼的免費工具OpenNMS與CACTI來監控流量。
不過，他認為中國人壽現在的監控工具還是只能做到監控，而無法有預警的功能，因此，他打算在第三階段時導入新的監控管理工具，再根據過往的歷史資料分析，像是處理器使用率、應用程式的運作狀況、資料成長等，找出虛擬機器運作的邏輯，當VM運作達到臨界值時，才能預先警告。
而且監控的周期長度也必須要依照企業業務特性而定，才能提供分析預測的數據。以中國人壽來說，每個月都會收一次保費，並且進行回銷的動作，因此，要觀測系統的使用狀況，觀測周期就必須以1個月為基準。從今年年初開始中國人壽每周都會固定製作每日流量報告與記錄，至今已累積了超過半年的資料，就是為了在第三階段時可以配合導入新的監控管理工具時，進行分析。
除了將原先的困難在第三階段進行調整之外，在第三階段的工作中還有另一些重要工作，就是利用虛擬化建置備援機制以及把所有的ESX虛擬平臺升級到ESXi。
中國人壽的備援機房設在林口，建置方式是把現在的虛擬環境作業直接移到備援機房的虛擬環境中，初期先建置大約80臺虛擬機器，頭一個月也會先以一半的規模進行測試。目前則是要先訂出備援機制的SOP。林成鑫表示，備援的RTO訂為72個小時，RPO則為1天。
第三個階段的另一個重點是把所有的ESX轉移到ESXi，林成鑫表示，這主要是基於安全性考量。過去VMware使用Red Hat Linux，萬一Red Hat本身有漏洞，虛擬軟體也容易受到攻擊。而VMware也在ESXi 4.0.1版移除了Linux作業系統，進而降低作業系統的漏洞威脅。因此，中國人壽也打算更換掉原先的版本。
中國人壽一路披荊斬棘走到現在，虛擬化腳步早就走在臺灣企業的最前端，基於這些領先的經驗，林成鑫建議，企業若想要導入虛擬化，IT部門一定要更清楚企業內部的作業流程，否則將比實體環境更容易出問題。他以VMware的DRS功能為例，由於這個功能會自動將閒置的虛擬機器下線或是搬移到其他實體機器上，以達到節能的效果。倘若IT不夠了解作業流程，沒有嚴格定義下線的條件時，就會造成有些必要排程無法執行。以中國人壽來說，有一些批次作業是下班以後才進行的，如果IT無法掌握該流程而未將條件設定好，就會導致系統下線，而沒有執行原訂該進行的批次作業。
這些經驗也產生了其他的價值。中國人壽在今年2月正式與中國建設銀行合資購買一家保險公司，開啟了他們的合作。中國人壽為了快速協助建設銀行在廣東、江蘇、上海三地布建2,500個分行的資訊系統，也打算運用虛擬化技術來加快導入速度。林成鑫相信，虛擬化的技術會在中國萌芽，而這些經驗，也有利於中國人壽與中國的建設銀行邁向合作大門。
 

為了要確實了解IT需求變化，中國人壽從今年開始每周都會進行網管周報，等到下個月開始進行虛擬化第三階段工作時，就能藉由監控管理虛擬化機器的軟體，設定預警機制。照片提供／林成鑫

 

在周報當中，IT人要清楚記錄網路連線異常的情形，包括發生時間、機器名稱、處理人員、處理情形等。林成鑫表示，平時該做的紀錄越清楚，真正出現問題時，解決的速度就越快。照片提供／林成鑫

 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91756,"新聞,雲端服務,Cloud,私有雲,虛擬化"
91755,37,2011-05-20,雲端運算實踐經驗：元大證券集中機房為大規模虛擬化打好底子,元大證券近年來集中機房、改變儲存架構，讓後續虛擬化進行更順利，今年更打算將350套電子交易系統都虛擬化，到了今年年底資訊系統虛擬化的比例將達8成," 你可能常常聽到「IT要快速反應營運所需」這句話，但你恐怕很難想像證券業IT所謂的快速反應營運需求，完成期限竟然是一個晚上。這是因為證券業的IT會明顯受到景氣波動影響，所以，只要景氣越熱絡、各種金融交易量越大，IT需求就越大，往往一個晚上要增加數10臺伺服器，才能支援隔天的交易量。因此，元大證券在2008年底時開始嘗試導入虛擬化，藉由快速複製所需IT資源，大幅縮短提供服務的時間。
元大證券資訊部副理游庭昆表示，在景氣好的時候，一個晚上就要建置10～20臺伺服器，負責建置的IT人員，往往必須在機房過夜才能完成工作，但是導入虛擬化以後，藉由VMware中的虛擬機器Clone（複製）功能，只要設妥主機名（hostname）和IP，不到1分鐘就可以讓新增的服務系統上線。
從測試環境、內部系統到對外系統逐步虛擬化
從2008年起至今，元大導入虛擬化的過程大致分為3個階段，第一個階段是2008年到2009年，先進行虛擬化的是測試環境，規模為120臺到140臺的實體機器。緊接著2009年再將元大金控的系統虛擬化。會這麼做的原因，游庭昆表示，除了金控系統用於對內提供服務，影響較小之外，最主要的原因就是要取代過於老舊的機器。舉例來說，當時金控使用的Lotus Notes版本仍需Windows NT 4.0的環境才能運作，雖缺乏維運的人力，但Lotus Notes還是必須運作，所以元大就透過P2V（實體機器轉虛擬機器）的方式，解決機器與版本過於老舊的問題。
第二階段是從2010年開始，元大逐步將證券的應用程式虛擬化，只要遇到要提供新服務或成立新專案時，就會以虛擬化的方式建置，一直到現在，元大正式環境中的應用程式有3成比例已經進行虛擬化。虛擬化的建置方式是，只要其他單位有新專案或是新服務推出時，元大IT會說服使用者部門直接採購標準化的伺服器配備，IT部門再依新服務的實際運算量來建置虛擬機器，未來使用者要擴充時就不用再添購新設備。IT部門訂出的標準配備是一臺2U的機器，搭配64G記憶體、2顆處理器、10G的網卡以及VMware的授權費。
游庭昆表示，目前已經進行虛擬化的系統都是屬於I/O負載較低者，因為，並不是所有系統都適合進行虛擬化，像是有些資料庫的處理器使用量就很大，I/O負載也較重，就沒有必要花錢買虛擬化軟體。另外，元大也沒有虛擬化UNIX主機。
從今年開始，元大進入第三階段，就是要將擁有超過350臺實體機器的電子交易系統也全數虛擬化，預計在2011年底，整個元大的資訊系統虛擬化的比例將達八成，屆時也將成為全臺灣第一個大規模導入虛擬化的證券業者。
這麼大規模的導入，當然也讓人好奇他們的作法。元大當時選擇導入的虛擬化軟體為VMware的vSphere 4.0，每臺機器都僅規畫15臺的虛擬機器。游庭昆表示，主要是考慮到實體機器毀損時所能承受的風險。「因為當一臺實體機器擁有越多虛擬機器時，一旦毀損時，受到影響的範圍也越廣。」
他進一步說明，估算一臺機器適合虛擬出的虛擬機器數目並不是以處理器的效能來計算，而是以記憶體的使用量來估算最適合承載的量。以元大來說，實體機器的標準配備是64G的記憶體，而每一個虛擬機器約占4G，因此，每一臺實體機器可虛擬出16個虛擬機器。但他考慮到發生問題時，得預留移動虛擬機器空間，所以，仍以15臺為標準。
資料先集中才有利IT配置
回顧元大導入虛擬化的過程，其實有兩件很重要的關鍵，分別是機房的集中以及儲存技術的改變。
游庭昆認為，虛擬化要成功，就必須做到機房與資料的集中。而元大就是在2010年時進行了機房集中，將原先分散7處的資料中心整併為2個。過去10年來，元大分別在臺北有2座資料中心、中部與南部各1座資料中心，另外北中南還各有1個集線站，用來接收非交易的資料。
游庭昆表示，資料分散對建置企業私有雲的難處就在於，資料儲存在4個地方，除了資料抄寫困難，也增加在虛擬化過程中分類不同服務的困難。另外，原先各個資料中心的網路骨幹頻寬也僅有2Mb到10Mb不等，集中之後，2個機房中間就以20Gb的頻寬連接，並且互為備援。
虛擬化最需要解決的是儲存架構
在整個虛擬化的過程中，游庭昆認為，最需要解決的就是儲存問題。元大過去不論金控或是證券全都是走SAN的架構，但後來除了UNIX主機之外，其他全改用NAS的架構。
改用NAS架構主要有2個理由，一來是產業屬性，二來則是考量到管理的便利性。游庭昆表示，SAN的I/O存取穩定度較高，而NAS確實較不穩定，但是，證券業有8成作業系統都是讀取資料，而不是輸入資料，相對來說，穩定度的需求也較小。同時，他表示，採用NAS架構在虛擬化環境下搬遷虛擬機器時，比SAN架構要調整的設定工作少很多，NAS架構有助於簡化管理。
而元大也利用了不少NetApp的功能來減少儲存系統的負擔，比如他們用NetApp FAS3240的重複資料刪除功能，也用了NetApp的快取功能，游庭昆表示，這2個功能對於不斷複製新的VM來說，都能大幅減少存取的資料量，也能減少儲存系統的負擔。
在儲存的架構上，元大對內服務與對外服務分開成不同的NAS系統，每個NAS系統有2個控制中心，每個控制中心管理48顆300G的硬碟。以臺北機房來說，總共負責300臺機器的運作，那麼每個控制中心平常各自負擔150臺機器的資料，但一旦有危機發生，就會由另一個控制中心承擔300臺機器的資料儲存，另外，在臺中也建置了與臺北同樣的儲存系統，讓2地互為備援。
而在一路這樣摸索虛擬化的過程，游庭昆坦承，許多事情都得不斷嘗試並解決。以監控來說，元大最近導入VMware才剛推出的新一代監控軟體vCenter Operations，比起原先使用的vCenter來說，不需要點選展開樹狀清單就可以看到所有的虛擬機器、各自的使用率等詳細資訊，而且一旦出現問題會直接出現警示符號。他表示，虛擬化以後，虛擬機器可以快速搬遷，但也會在發生問題時，不容易找到源頭，增加解決問題的時間。因此，對他來說，可以用色塊與儀表板的方式呈現每臺實體機器與虛擬機器的狀況是非常重要的。
而這一路的摸索，對元大來說，早就不只是IT的議題。過去證交所、期交所開辦任何活動，一張需求單跑流程要1到2個月，現在只要需求單進來，IT部門可以在幾分鐘內滿足內部與外部的需求。游庭昆表示，元大現在將建立私有雲訂定為企業的商業策略，所有的業務開辦都是搶在同業之前。對元大來說，建立私有雲才能在什麼都搶快的證券業當中，展現競爭力。
 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91755,"新聞,雲端服務,Cloud,私有雲,虛擬化"
91754,37,2011-05-20,雲端運算實踐經驗：凌通科技從ERP虛擬化邁向私有雲行動化,從ERP虛擬化，到運算、儲存與網路資源的整合，下一步，凌通科技打算將私有雲延伸到行動應用," 凌通科技是一家資本額近10億元的中型IC設計公司，規模雖比不上如聯發科、聯詠科、晨星半導體等數百億元營收的設計公司，但IT應用深度卻不輸大型製造業公司。凌通科技早在2009年就將ERP系統虛擬化，內部應用虛擬化比例更高達9成。
第1階段：7成周邊AP虛擬化
凌通科技從2008年開始導入虛擬化，第一階段先用4臺伺服器（3臺ESX伺服器和1臺VE伺服器），將處理器負載較輕的應用虛擬化，整併了20多臺老舊伺服器，並將這3臺ESX伺服器連結到1臺光纖通道介面的NetApp SAN儲存設備。凌通科技資訊管理部經理周賢良表示，第一階段除了資料庫、ERP等應用，以及必須綁定特殊硬體規格的應用以外，全部都虛擬化，第一階段應用系統虛擬化比例約達到7成。
第2階段：ERP和資料庫虛擬化
到了2008年底，凌通進入第二階段，開始將ERP和資料庫系統虛擬化。因為ERP系統和資料庫的磁碟I/O負載很大，凌通添購了一套光纖交換器，以及NetAPP儲存設備，並且和第一階段的儲存設備互為備援。
周賢良建置虛擬機器時，會將不同用途的Guest OS混搭在同一臺實體伺服器上，例如將測試環境和上線環境混搭，而不是將測試環境都集中到少數幾臺伺服器上。或者是將網頁應用系統和相關的資料庫系統放在同一臺伺服器中。
他解釋，這樣的好處是可以減少這些相互關聯的應用系統間網路交換和資料I/O的負載，例如將資料庫和對應AP放在同一個資源池中，就能減少對外的資料流量。除此之外，他認為還要混用異質應用，讓不同類型的應用互補，來提高資源的利用率。「虛擬化就要拋棄硬體區隔資源的概念，關鍵就是混用。」他說。
周賢良表示，第二階段因為機房從集團中獨立出來後，IT部門新成員較多，維運資料庫的能力較弱，所以，希望透過系統來確保資料庫運作的可靠度，因此，他決定將資料庫放入虛擬機器，來建立HA架構，同時也一併將ERP系統虛擬化。凌通在2009年初完成第二階段虛擬化的建置，完成後虛擬化比例達到9成，只剩下必須使用特殊硬體無法轉移的應用系統。
但是，使用一段時間以後，周賢良開始發現一些新的問題，比如因為網路架構只使用了一臺Cisco 2960G交換器，會發生單點故障的情況，或是ESX虛擬機器主機使用的儲存系統或服務網路，只有單一網路埠有流量，負載平衡機制沒有發揮作用，流量集中到部分虛擬機器上，而不是平均分散。另外當時也無法有效監控虛擬環境的網路狀況。
再加上當時採用磁帶備份還原的作法，為了回復資料得耗費數十個小時，非常沒有效率，也無法立即驗證備份資料的正確性。遇到稽核單位要求進行資料庫系統演練時，也要花很多時間準備演練用的系統環境。
第3階段：整合運算、儲存和網路資源進行優化
因此，周賢良在2009年下半年，開始進行第三階段虛擬化，相較於第二階段的關鍵是儲存，他認為，第三階段的挑戰則是網路。
為了解決交換器單點失效的問題，凌通採購了2臺具有FlexStack功能的Cisco 2960S交換器，在ESX伺服器和儲存系統之間採用EtherChannel跨交換器的方式部署。
另外還採購了軟體版Nexus 1000v提供vSwitch功能，來取代無網管功能的VMware內建vSwitch，解決無法監控虛擬機器網路狀態的需求，還部署了2臺虛擬機器來執行Nexus 1000v的中控系統VSM，以便相互備援。另外為了提供分散式虛擬交換器的功能，也將VMware VI 3升級到vSphere Enterprise plus版。
前端虛擬機器的流量透過Nexus 1000v的vSwitch管理，而後端內部系統如管理、vMotion、儲存系統的網路流量則部署於vSphere的分散式虛擬交換器VEM上。更換成新的Cisco交換器以後就可以支援VMware，也可以解決負載平衡失效的問題。
在儲存系統的改善上，為了快速建立資料庫副本來進行測試開發和演練之用，周賢良也導入NetApp專屬的資料庫層快照機制SMVI/SMSQL來複製資料庫系統的Guest OS。
他解釋，一般複製資料庫的Guest OS時，若是沒有停止資料庫服務，在記憶體中的資訊還沒同步到資料庫檔案中，往往複製後的Guest OS會無法啟用。資料庫層快照機制和一般的快照機制不同，在進行Guest OS複製時，NetApp儲存系統會自動停用資料庫服務，可以得到真正有效的快照，若沒有這類資料庫層快照機制，IT人員就得另外撰寫腳本程式來關閉資料庫服務。
除此之外，凌通也使用NetApp的FlexClonex功能來建立具有讀寫功能的快照，讓新增的副本資料庫系統，可以提供應用程式實際寫入資料，而不只提供真實資料的讀取而已。
周賢良表示，因為凌通資料庫的用量不到1TB，透過資料庫層快照建立可讀寫的系統副本，只需要半小時就能完成，只要修改資料庫連結路徑，就可以快速提供給測試環境，或是上線前的發布環境使用真實資料來驗證系統功能，萬一系統新增功能不符使用，可以回到前一版本重新修改程式，過去得用很長的時間才能複製一份資料庫，只有歲休期間才有足夠的時間來驗證系統功能，現在隨時可以進行，可以縮短應用程式開發的周期。
周賢良表示，第一階段主要是運算資源的集中，到了第二階段則是再依據不同應用程式來搭配不同的儲存設備，解決儲存效能和備份還原的問題。到了第三階段的重點是整合運算、儲存和網路來進行優化。
去年底，凌通科技開始展開第四階段的虛擬化。一方面周賢良打算導入NetApp的硬體快取產品PAM卡更進一步加快應用程式的I/O存取效能，例如Lotus Notes郵件系統，讓使用者有系統變快的感受。
另外周賢良還要建立異地備援機制，雖然無法達到遠距離的備援，但希望透過科學園區內的主機房和次機房進行實體隔離，避免區域型的災害，例如火災等，希望透過vMotion進行應用系統和資料庫的同步，另外還打算採購儲存系統的SnapMirror功能來同步兩間機房的資料。周賢良預定今年7月完成DR架構和PAM卡的建置。
第4階段：用iPhone延伸私有雲的觸角
除此之外，周賢良還打算在第四階段達到行動化，目標是讓企業員工可以在任何時間、地點都能存取內部應用系統，先從主管開始提供行動化服務。
周賢良統一採購了50多支iPhone提供給主管使用，搭配Citrix遠端桌面的客戶端App和SSL憑證機制，讓主管可以使用AD帳號連線回企業Citrix伺服器的虛擬桌面來使用內部系統，即使出差在國外也能使用。
另外還使用了一套免費的iAnywhere軟體作為Lotus Notes系統的手機端程式，iAnywhere另外提供了付費的伺服器端模組，可以和Notes簽核引擎連結，能套用工作流程的模板，可以直接在手機上進行Lotus Notes簽核工作，周賢良只花了1個月的時間就完成建置。目前，他也正在評估iPad 2，打算做為員工視訊會議的端點裝置。
 
凌通科技4階段虛擬化重點

 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91754,"新聞,雲端服務,Cloud,私有雲,虛擬化"
91753,37,2011-05-20,雲端運算實踐經驗：聯電成功虛擬化的第一步是找對目標,"早在2005年，聯電就開始導入VMware虛擬化，2008～2009年間，更將1,200臺伺服器縮減到800臺，相當於省下了21個機櫃的空間，聯電成功導入的第一步就是要找對虛擬化目標"," 早在2004年時，臺灣才剛開始出現虛擬化這個名詞不久，聯華電子（聯電）就開始嘗試虛擬化技術的可行性，隔年就正式展開導入，在2008到2009年之間，更是將1,200臺伺服器縮減到800臺，相當於2天就要整併1臺，到了2010年初，聯電透過虛擬化共減少了21座機櫃，相當於省下一座機房的空間。
聯電廠區散布在多地，光是電腦機房就有14間，x86伺服器更多達上千臺，類似MES系統的大型AP也有上千套，小型AP更是數十萬計。
為了用最精簡、低成本而有效率的方式來提供基礎架構服務，聯電從2004年著手整併伺服器，從分散式的IT架構轉為集中式，2005年正式導入虛擬化技術，隨著虛擬化導入數量和規模越來越大，更進一步地，聯電也開始邁向自動化管理的階段。
早年聯電的管理方式採獨立伺服器的管理，有許多伺服器各自放置在各廠區，有些使用者單位即使人數不多，也會自己擁有一臺小型伺服器就近提供OA系統。在聯電資訊工程處下負責維運的EDC部門成員，得親自到各廠區才能維護這些主機，遇到主機發生問題時不容易及時提供服務。
為了能夠及時提供IT服務，聯電開始評估哪些服務可以整併到單一伺服器上，剛好2004年時，VMware開始將虛擬化技術引進臺灣，聯電遂決定嘗試透過虛擬化整併伺服器的可行性。
在2004～2006年這段期間，聯電的目標是嘗試將周邊服務虛擬化。一方面因為聯電是臺灣第一波運用虛擬化的企業，沒有可供參考的經驗，例如不知道實體機器轉換到虛擬機器後的處理器使用率會變成多少。剛開始，聯電先透過概念驗證來累積虛擬化建置經驗，同時找出1臺伺服器可承載的虛擬機器數量，以便後續評估整併需求，安排虛擬化計畫之用。
先整併具有備援機制的非核心OA服務
當時最大的挑戰其實不是虛擬化經驗不足，而是聯電的服務不能中斷。因為聯電的生產線幾乎全年無休，每天24小時，每周7天都在運轉，一年頂多歲休2～3天，伺服器實際可停機的時間只有8小時，但又不可能將所有整併轉移工作都集中到歲休時才進行。
所以，聯電先從非核心的OA服務著手，例如DHCP服務或是有備援主機的AP和網站。因為像DHCP服務原本就會建置多套系統，相互備援。聯電先將備援主機虛擬化，一方面不會中斷使用者的服務，另一方面也可以向使用者證明虛擬化的可行性。
另外還有一類應用是老舊作業系統的AP，例如Windows 95、98、NT或2000版本上的應用程式，因為購買時沒有原始碼無法自行修改，也找不到舊機器可汰換，因此也順勢轉移到虛擬機器上。
為了盡可能地減少停機時間，聯電IT先與各部門安排停機行程，並且事先完成所有準備工作，只剩下切換服務需要的停機時間。2006年時，從規畫到上線完成，聯電花了半年時間將67臺伺服器整併到10幾臺伺服器中。因為當時只有單核心處理器，所以，1臺實體伺服器只能執行3個虛擬環境。
經過2年經驗累積，聯電研究出一套導入SOP，包括如何尋找導入標地、如何計畫，評估ROI等。後來到了2008年，聯電IT更設定了一個目標，要將1,200臺伺服器整併到800臺。
不料遇到了金融風暴，聯電凍結IT投資，不能採購新的伺服器。為了仍舊要達成減少400臺伺服器的目標，聯電先篩選所有的伺服器，找出可以用來作為Host主機的伺服器，再排除執行關鍵服務不能中斷的設備，最後剩下約30～40臺可用的伺服器。因為這些伺服器在帳面上都分屬各廠區，還須經過協調進行成本轉移，改將主機歸屬到資訊工程處的EDC部門下。
這些候選主機集中以後，聯電優先將超過10年的老舊機器淘汰，將服務整併到這些Host主機上。最後在2009年時達成減少400臺伺服器的目標，而且聯電還持續推動虛擬化和AP整併，到了2010年初，有300臺實體伺服器的AP整併到58臺伺服器上，減少了242臺實體設備。而虛擬化成果上，也在92個Host主機上執行共445個虛擬機器，減少了353臺實體設備。若以機櫃數量來看，總共減少了21個機櫃，相當省下了一座機房的空間。
虛擬化能降低時間壓力，有利預先規畫工作
聯華電子資訊工程處專案管理部經理張仁寬還點出另一個虛擬化的好處，他說，過去作業系統或防毒軟體更新時，IT部門必須和使用者搶時間，2小時停機時間必須正確完成所有更新程序，一旦出錯會導致停機時間延後，維運工程師的壓力很大，反而容易發生錯誤。
導入虛擬化以後，維運工程師可以先將AP複製到另一臺虛擬機器上，然後關閉副本AP後更新作業系統，更新完成確定AP能順利執行後，再將使用者知道的AP網址切換到副本AP上，然後繼續更新第二臺AP。
對使用者而言，只有切換過程需要停機，但維運工程師可以在沒有停機時間壓力下，按照更新計畫執行。
張仁寬認為，對維運人員而言，可以預先規畫，順利執行，就是最簡單的工作模式，更容易解決維運上的盲點和不便。就算半夜AP當機，維運人員也可以先在家中遠端切換AP讓服務維持，不用急著趕到辦公室處理。
虛擬化的第一步，要鎖定最有效果的導入目標
整體來看，歸納聯電虛擬化經驗，張仁寬說，實現虛擬化可以從擴充現有環境著手，例如原本要汰換10部老舊伺服器，可趁機說服老闆擴大專案規模，順勢導入虛擬化，同時整併同類型服務，也可以從測試與開發環境著手。
另外，張仁寬建議，一定要找出「立竿見影」效果的導入目標，也就是找出效果最明顯的機器，例如像效能不足或需要升級的老舊伺服器，或者是處理器利用率只有10％的系統。他解釋，利用率低代表這個AP負載較低，重要性也不高，或是不需要經常執行，容易找出停機空檔。
這些目標包括像老舊設備、基礎建設伺服器如DNS、DHCP或檔案伺服器、測試與開發環境、工作群組或部門使用的系統，另外也可以將分支機構的需求整併到中央，以及永續經營計畫中要整併的對象。
虛擬化應用規模越來越大以後，張仁寬表示，新的挑戰是自動化管理。聯電也自行打造了4種不同的自動化管理工具，包括了IOC（Infrastructure Operation Center）、NOC（Network Operation Center）、資安入口網站和IT服務入口網站。
例如IOC平臺負責管理聯電全球伺服器、資料庫、SAN交換器和儲存系統、備份狀態、零件庫存狀態、效能和預警等。在IOC上，除了整合實體伺服器的管理資訊以外，並用相同標準來監控虛擬機器，另外也將Host主機狀態納入管理，並會依據執行效能訂定KPI指標，例如某臺伺服器執行一項服務平均要10分鐘，KPI就會是10分鐘加減3個標準差的時間，若某次運算用了15分鐘，就值得進一步細究原因。
因為聯電管理基礎架構和網路分屬不同團隊，再加上AP團隊，遇到當機事件時，這三方的負責人都會同時收到警告訊息，彼此也會同時到處詢問可能影響當機的情況。
張仁寬表示，下一步，聯電希望建立一個能自動彙總分析這些警告訊息的Smart Detect智慧平臺，從警告訊息中自動找出哪一個服務當機，減少這種多頭馬車，各自解決問題的作法。
 
聯電打造自動化工具的虛擬化管理要點
● 伺服器健康偵測與管理
● 效能報表和分析
● 透過虛擬化遷移進行伺服器整併
● VM動態配置與設定
● 修補程式管理與軟體更新
● 虛擬機器備份與回復
● 災難備援
資料來源：張仁寬，2011年5月
 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91753,"新聞,雲端服務,Cloud,私有雲,虛擬化"
91752,38,2011-05-20,邁向企業私有雲的第一步：虛擬化,國際知名分析機構Gartner歸納出企業發展雲端的5個階段，而臺灣多數導入虛擬化應用的企業大多只停留在第1階段，少數已經達成第2階段，正邁向私有雲的旅程," 國際知名分析機構Gartner每年定期對全球CIO進行調查，CIO們認為2011年最重要的技術是雲端運算，其次則是虛擬化。其實這兩項技術是一體的兩面，Gartner臺灣分公司研究部副總裁吳瑞蓮表示：「虛擬化其實是私有雲的第一步。」
吳瑞蓮表示，Gartner將企業發展雲端運算的過程分成5個階段，一般企業第一步先導入虛擬化進行內部整併，然後打造出私有雲以後，最後才會運用各種公有雲。
這5個階段包括了第1階段的伺服器虛擬化（Server Virtualization）、第2階段的分散式虛擬化（Distributed  Virtualization）、第3階段的私有雲（Private Cloud）、第4階段的混合雲（Hybrid Cloud），以及最後一個階段，公有雲（Public Cloud）。
根據Gartner判斷，國外已有不少企業發展到私有雲的階段，開始提供自助式服務。但臺灣企業則大多仍停留在第1階段伺服器虛擬化的程度，少數虛擬化深度較高者，則已經處於分散式虛擬化的階段，開始評估第3階段的可行性。
要打造私有雲，IT要成為營業單位
吳瑞蓮表示：「要打造私有雲，IT不能只是資料中心，而要變成客服中心，成為營業單位。」
她進一步解釋，從內部計費的角度來思考，IT部門計算出各部門的使用量和帳單，就能透過計價方式來提高資源的管理效率，例如臨時需要大量運算資源的部門就要付出更高的內部費用，或是在伺服器離峰階段提供更低廉的價格，就能進一步改變使用者部門的使用習慣，改利用離峰時段來處理需要運算資源的服務需求。
吳瑞蓮說：「當使用者願意按照IT部門制定的運用規則來轉移使用情形，就能提高資料中心的利用率，而不需要一直擴充規模。」她說。更進一步，透過雲端運算降低企業嘗試新專案的建置成本後，「可以讓企業更有開創性，降低成本不是目的，只是過程必然的結果而已。」
整套式私有雲解決方案紛紛出爐
目前在市面上，也有不少資訊廠商提供一種All-in-One式的雲端解決方案，在這種方案中，包括實體伺服器、儲存空間和網路交換器之外，也提供了軟體的虛擬化技術、管理監控平臺與自動化工具等，幾乎是整套導入就可以打造出一朵私有雲。
這些解決方案例如像是HP CloudSystem Matrix和HP Insight管理平臺，IBM的CloudBurst和IBM Tivoli管理平臺、甲骨文的Exalogic Elastic Cloud搭配Oracle Enterprise Manager，以及VMware與EMC、Cisco聯盟推出的Vblock Infrastructure Package，搭配EMC Ionix Unified Infrastructure Manager管理平臺。微軟也在MCloud方案中提供Hyper-V整櫃式設備，搭配System Center管理平臺。
這些產品大多能支援主流的虛擬化技術，可以協助企業打造企業內部的IaaS平臺，但也有如甲骨文的產品則是在Java中介軟體層提供PaaS平臺，而不是利用虛擬化技術。
各家產品的售價則會依據企業選配的規格而有所不同，通常可選擇的規格是記憶體容量和硬碟空間等，整套售價從百萬元等級到上千萬元不等，但都標榜著整套最佳化的效果。原廠事先依據實體伺服器的規格來調校虛擬化平臺的參數，提供最佳化的設定，並且強調快速導入的特性，讓企業可以在數天，甚至數小時內就建妥一座可提供虛擬化環境的私有雲。
不過，聯華電子資訊工程處專案管理部經理張仁寬點出臺灣企業共通的保守投資心態，他說，臺灣企業大多不願意一次性投入大筆預算，採購整套全新的產品，反而是寧可分批汰換，每次只更新必須汰換的老舊設備。
也因此，臺灣企業少見整套導入私有雲產品的作法，反倒是在學校或公家機關的意願較高，例如亞洲大學資訊長劉嘉政就決定導入HP System Matrix刀鋒系統來打造學校內部的教學雲，利用HP BSM管理平臺來控管虛擬執行環境的資源調度和設定，不過，這個專案才開始試運轉，還未進入成熟運作的階段，後續成效以及這種整套式雲端產品的管理議題還有待觀察。
不過，隨著企業虛擬化應用規模越來越大，各種管理議題和挑戰也越來越多，對於各種自動化工具的需求也越來越高。
監控工具比計費機制和動態配置更受企業重視
在套裝管理平臺中，廠商經常會強調3種自動化工具，第一是自動化動態配置資源、第二是監控工具、第三是計費機制。以目前臺灣企業的需求來看，監控工具最重要，其次是計費機制，而廠商主打的彈性且快速的自動化資源配置（Auto Provisioning），反而不是企業的迫切需求。
台灣大哥大系統規劃暨維運處處長王衛道解釋，企業只有測試環境和開發環境比較需要動態配置資源，上線後大多不會輕易變動配置，再加上企業開發專案往往需要數個月時間，討論新應用需要的運算資源也要耗費數天到1、2周，用2天完成虛擬機器的配置和10分鐘完成設定的差別其實不大。反而是每天都要提供測試環境和開發環境的大型企業而言，或像是必須快速調配資源的企業，快速配置的功能才有其價值。
監控工具的需求最高，是因為虛擬機器的管理複雜度比過去實體機器更難，當虛擬機器數量越來越多，想要快速發現服務當機的問題點也越來越難，也因此，臺灣有企業自行打造出各種監控平臺，例如聯電和台灣大哥大都有自製監控工具，目的就是要監控執行在虛擬機器上的服務是否正常運作，虛擬化平臺廠商也推出越來越視覺化的管理儀表板，讓企業更容易發現問題，例如元大證券就導入了VMware才剛發表的vCenter Operations來監控虛擬機器。
更進一步，企業希望透過監控工具的長期追蹤，一方面找出優化虛擬機器效能的參數，另一方面也能進行預防管理，提前找出可能發生當機問題或出現效能瓶頸的設備，先行排除來避免當機發生。
而計費工具則是一個不上不下的管理工具，一方面企業IT部門希望透過計費工具了解IT維運的成本結構，但另一方面在缺乏企業政策與高層支持的情況下，其實IT部門難以實際進行內部計費與成本轉嫁，計費工具的實用性還比不上監控工具。
這次封面報導中，我們也走訪了7家打造私有雲頗具規模與應用經驗的企業，包括如高科技製造業、證券業、壽險業、電信業、跨國軟體業、線上遊戲業者等。有的企業已將機房x86伺服器100％虛擬化、有的則是2004年就開始投入虛擬化應用，甚至應用規模達到數百臺虛擬機器的規模，也有企業透過虛擬機器線上搬移功能，只停機3小時就將整座資料中心搬到10公里外的新機房。
不同企業的應用環境不同，因此對私有雲的需求和定義也不同，但是，透過這些企業善用虛擬化來實踐私有雲的經驗中，可以找到共通適用的建置關鍵。
 

Gartner臺灣分公司研究部副總裁吳瑞蓮表示：「要打造私有雲，IT不能只是資料中心，而要變成客服中心，成為營業單位。」

 
相關報導請參考「私有雲實踐術」
",https://www.ithome.com.tw/news/91752,"新聞,雲端服務,Cloud,私有雲,虛擬化"
92513,38,2010-12-31,資策會MIC看2011：中小企業將成為虛擬化與公有雲市場發展主力,企業導入虛擬化技術將因為儲存與運算成本下降，降低中小企業應用IT的門檻，使中小企業將在未來幾年內成為虛擬化市場的發展主力," 在2009年景氣下滑，侵蝕了企業的IT預算，使IT需求延宕到2010年，IT投資跟著大幅成長，而投資方向不外乎使業務營運更有效率、滿足使用者的新興需求等，就這2點可延伸出2010年企業IT的發展趨勢。
資策會產業情報研究所（MIC）產業分析師李震華表示，2010年有許多企業進行新舊系統整併、新舊設備整合管理、異地機房整併、擴大海外據點、創新應用服務等，以資源共享式的IT架構，來提升業務營運的效率，也因此擴大了在虛擬化與雲端服務方面的投資。
企業導入虛擬化技術固然需要不少成本，但以中長期來看，透過省電、簡化管理、減少硬體數量等方式，反而能替企業節省一筆經費，另一方面，因為儲存與運算成本下降，降低了中小企業應用IT的門檻，使中小企業在未來幾年內，將成為虛擬化市場的發展主力。
另外，雲端服務也是企業提升業務營運效率的方式之一，據資策會MIC調查顯示，2010年臺灣雲端服務市場達到臺幣50億元，預計2013年將增加到103億元，2010年雲端服務的應用範疇以代管與虛擬的私有雲為主，而未來的雲端應用趨勢則以供應鏈的群聚型私有雲，及提供IT服務給中小企業的公有雲為主，可解決微型或中小企業IT人才不足的問題。
有了IT基礎建設之後，企業IT部門會進一步透過IT創新應用，來滿足內外部使用者的需求。
2010年隨著行動裝置的普及，資策會MIC預計，2013年用手機上網的人數將超過用個人電腦上網的人數，企業也開始將資訊系統內建到行動平臺，讓高階主管、業務人員、研發人員這些常在各地奔走的員工，可以透過行動裝置取用企業內部的資料，目前廣泛應用的產業包括製造業、服務業、房屋仲介等。
不僅如此，這些創新應用服務也可以進行外部行銷或客戶服務，替企業建立品牌形象。例如，許多品牌服飾業者透過行動平臺進行網路行銷、CRM、社群經營等，許多消費端軟體因而進入企業應用當中，資策會MIC預計，2013年將有超過一半的品牌企業都會推出行動應用服務。
這些是企業IT部門普遍的發展趨勢，然而，從2010年到2011年，企業還有幾項值得關注的議題，包括個資法、IFRS、ECFA等，就個資法來說，多數企業目前還在評估，必須等施行細則出來，才能有所舉措，而IFRS的現況也是如此，IT系統必須早一步在IFRS制度施行前上線，但企業財務部門要等待制度出爐，才能確定流程，使IT部門遲遲無法動作。
此外，因ECFA協議將於2011年生效，臺灣流通業、製造業大多前往中國大陸設廠，因而面臨IT整合的挑戰，像是CIO必須快速布建新廠的IT架構，並將原廠架構與新廠介接，或是調整系統來符合當地法規等。
 
相關報導請參考「回顧2010看未來」
",https://www.ithome.com.tw/news/92513,"新聞,虛擬化,公有雲,雲端,雲端服務,Cloud"
92512,38,2010-12-31,台灣經研院看2011：政府雲將帶動臺灣雲端服務市場,台灣經濟研究院產業發展處處長周霞麗認為，雲端運算將是未來的趨勢，而臺灣最大的趨力，是來自政府的推動," 台灣經濟研究院產業發展處處長周霞麗認為，2010年在政府政策法規的影響下，個資法三讀通過以及政府推動雲端產業，另一方面，在產業發展表現上，行動裝置如智慧型手機、平板電腦等的興等，都對企業IT產生影響，而且這些影響未來也會持續發酵。
以個資法來說，由於個資法將電腦處理個人資料的範圍擴大到個人資料的蒐集、處理和利用，此外，個資外洩企業所應付的賠償金額，最高可到2億元，因此，到了2011年企業承擔的營運風險增加，IT部門在防止資料外洩的責任也隨之增高。周霞麗也表示，資安廠商從2010年年初開始，營收表現比起過去2年成長許多。
周霞麗表示，雲端運算將是未來的趨勢，而臺灣最大的趨力，是來自政府的推動。台經院擔任國家智庫的一份子，她表示，政府政策的制訂固然會受到國際趨勢的影響，但更重要的是臺灣該相關產業的發展狀況，因此，政府在2010年宣布以5年240億元的經費打造政府雲，代表政府看好臺灣資通訊產業的發展潛力，而政府的投資也會帶進更多企業投資，促使臺灣雲端運算市場的成熟。
從政府投資的觀點出發，周霞麗也看好臺灣發展物聯網技術，因為經濟部投進龐大的經費在智慧生活的計畫中，臺灣各地已有不少城鎮開始推動智慧小鎮，其概念就是從物聯網出發，而這些計畫都將能帶動該技術更成熟的被應用。她認為，物聯網的推動跟雲端也有密不可分的關係，因為物聯網是一種將資料從機器傳到機器的技術，屆時將有大量的資料產生並傳到後端進行運算分析後，再傳送到另一個終端使用，因此，的確是需要像雲端運算這樣大型的資料中心才有辦法做到。
她指出，能夠發展雲端運算，是因為臺灣本身的資通訊技術都相當進步，若能再結合其他成熟度很高產業，如醫療照護、農業，就能更完整應用物聯網。
而目前，醫療照護已經開始運用RFID來記錄病人或是老人的健康狀況，而她認為，這些都已是物聯網的初階應用，未來若技術更為成熟的話，就可以擴大應用範圍。
除了政府投資的部分，周霞麗也指出，2010年iPhone、iPad等行動裝置的熱賣，在未來則會帶來幾項轉變，第一是資通訊市場的界線逐漸模糊，因為智慧型手機同時具有電腦與手機的功能，未來還可看電視，這將讓電信網路、網際網路、廣電網路逐漸朝向三網融合的態勢邁進。
第二，軟硬體整合的產品將成為產品成功的重要因素，因為智慧型手機內建的軟體平臺越來越重要，相形之下，對專營手機硬體製造廠商將會較為不利。第三則是平板電腦將可望打入企業應用領域，她認為，未來服務業、餐飲業都將可能大量運用平板電腦。
 
相關報導請參考「回顧2010看未來」
",https://www.ithome.com.tw/news/92512,"新聞,雲端,雲端服務,Cloud"
92511,38,2010-12-31,IDC看2011：虛擬化讓雲端運算成為未來企業IT支出成長最大宗,IDC亞太區顧問團隊研究經理曹永暉認為，在2010年對企業IT最大的影響就是虛擬化技術的成熟，而這也將帶動2011年企業採用雲端服務," IDC亞太區顧問團隊研究經理曹永暉認為，在2010年對企業IT最大的影響就是虛擬化技術的成熟，而這也將帶動2011年企業採用雲端服務，使得未來一年企業IT支出的最大成長將落在雲端運算與虛擬化上。
曹永暉表示，雖然虛擬化的技術在2005年就已經由VMware推出，但到了2010年可說是成熟應用時期，因為企業現在已有3成的實體機器運作虛擬化技術，而且應用的範圍，也從測試環境，延伸到專案性質的使用，代表虛擬化的概念已經逐漸被企業接受。
他認為，虛擬化就是私有雲的基礎，等到私有雲逐步成熟後，企業也會把越來越多應用放在公有雲上。而如今企業可接受雲端服務，最主要是因為，採用虛擬化技術可使硬體投資成本降低，尤其是虛擬化技術的動態配置功能，可讓企業遇到大型專案，而需要大量電腦運算功能時，就會選擇雲端的資源。
而雲端服務的興起，也為不同產業帶來危機與轉機。他指出，雖然IDC預估2011年臺灣企業的硬體支出會增加6.1％，不過，就更長遠來看，將有更多硬體的採購會轉移到雲端服務，因此，他認為，對硬體廠商來說將是一大威脅，像是國際大廠HP或IBM，而這些廠商的產品賣到電信公司當作雲端運算的電腦的比例也將增加，但是否能補足賣到企業硬體減少的部分，則是未知數。
曹永暉認為，對電信業來說，由於雲端的環境出現，讓電信業者從傳統的通信角色，一躍成為雲端的主角。除了大環境的轉變，他認為，電信業因為未來VoIP的發展，將嚴重侵蝕現在電信業的語音服務市場，所以，電信公司在2010年積極投資在IT領域，並尋求外部的合作，也將會是必要的轉變。
2010年社群媒體的崛起，將使BA成為企業重要協助決策工具
除了虛擬化技術之外，曹永暉認為，2010年在企業外部影響最大的就是社群媒體的風潮，將成為未來企業行銷的重要通路。比起過去企業透過傳統媒體、網站、部落格、論壇等，社群網站是擴散式的傳播方式，可以在很短的時間把資訊散布到很大的族群，更重要的是，要讓這些族群有所回應。
不過，社群媒體的資料也象徵著資訊的多樣化以及資料量暴增，當企業想分析這些資料，並讓分析出來的資料可協助做決策時，BA（Business Analytic）就成為最重要的工具。
而且他也進一步指出，未來BA將從資訊工具轉變成服務，也就是企業不再透過內部人員分析，改藉由外部的專家提供分析。換句話說，未來傳統IT解決方案廠商，為了要能提供專業服務，就得培養對該領域的了解。
另外，曹永暉也認為2010年，行動裝置的熱賣，如智慧型手機、iPad、平板電腦等，不只對消費性市場有影響，有越來越多企業將應用程式放在行動裝置上，像是房屋仲介業、保險業、醫療就診等，而且應用範圍也不僅限於前端系統的應用，他預估，2011年企業開發可用於行動裝置的應用程式將成長3成。
 
相關報導請參考「回顧2010看未來」
",https://www.ithome.com.tw/news/92511,"新聞,雲端,雲端服務,Cloud"
96351,38,2010-01-01,2010關鍵趨勢：雲端技術進入企業，私有雲應用發酵,雲端運算技術在公眾服務的成功，吸引企業尋找內部應用方式，打造私有雲端環境," 雲端運算是2009年臺灣最火紅的技術名詞，各家資訊業者紛紛強調雲端效益和資訊架構變革的衝擊。風潮所驅，不只是股市投資散戶都有雲端概念股一說，不少公司執行長、總經理也特別留意。
一時之間，雲端產品琳瑯滿目，各種雲端運算研討會到處都有，雲端運算很快地變成了2009年最被濫用的技術名詞之一，凡是網路應用，就會被資訊廠商貼上雲端產品的標籤，雲端應用變成網站服務的同義詞。
對臺灣ICT業者而言，他們深怕錯過新一波的技術變革，自然焦慮莫名地熱切擁抱雲端。但是，資訊業者浮濫炒作雲端概念的後果，反而讓原本就擔心安全問題的企業更加保守，採取觀望而不行動的態度，甚至有些企業的資訊主管認為，雲端運算只是另一個廠商行銷口號而已。
可是，也有少數臺灣企業真能找到雲端運算技術在企業中可行的應用價值。例如有間善於流程創新的半導體龍頭業者，正準備導入雲端運算技術來打造一套處理海量資料的私有雲端系統，用這套系統來分析大量的製程資料，找出調校製程的最佳數據。
在半導體產線中，一項產品往往需要上百道，甚至上千道製程作業，每一道作業的工作站機臺電腦會自動記錄各式各樣的製程資訊和品質監控資訊。
如何調校機臺設定，追蹤製程品質，甚至快速找出良率異常的原因進而排除故障，都得仰賴製程工程師對這些製程資訊的分析。
一般作法上，半導體業者往往藉助許多BI分析工具來處理這些大量產生的製程數據，例如奇美電子曾規畫打造資料倉儲系統（Data Warehouse），來儲存和分析液晶螢幕產線的各項製程數據。
那間半導體龍頭業者，卻打算導入雲端運算技術Hadoop，來打造一套內部雲端運算系統，透過Hadoop框架集中大量伺服器的運算能力，來達到快速分析龐大製程數據的效果，就像Yahoo也曾運用Hadoop技術，在1小時內分析完過去1～2天才能處理好的大量搜尋Log記錄。
這間半導體業者將私有雲端技術運用在生產製程，是臺灣企業少有的作法。
另有一些半導體業者則是考慮透過雲端作業系統來替代生產線機臺設備的監控電腦，將這些監控電腦的功能改由虛擬機器代替，將監控設備集中到雲端環境統一管理，來簡化產線設備的管理負擔，讓產線工程師可以更專注於製程流程的改善，而不用費心維護電腦設備。
對半導體業者而言，製程良率決定了企業的競爭力，而快速分析製程數據的能力，正是左右良率高低的關鍵。企業內部私有雲端平臺不只是節省成本的技術，更成為創造企業競爭力的技術。
臺灣金融業也開始出現了大規模運用雲端服務的案例。渣打銀行以獨立機房運作的形式，導入了甲骨文的SaaS CRM隨選服務平臺來強化客戶關係管理，採用範圍包括臺灣、香港、新加坡等地分行，授權數達一萬多名使用者。
渣打銀行這種將相關資料儲存的後端系統平臺，都部署在獨立機房，而非由隨選服務廠商提供的作法，就是一種企業私有的SaaS服務，也是屬於私有雲的應用型態。
雖然企業還無法像信賴銀行一樣地信賴雲端業者，還不敢將企業競爭力核心的機敏資料放到公開的雲端服務中。但是，支撐各種雲端服務背後的高擴充性分散運算技術、新一代資料中心自動化管理機制、提高伺服器利用率的虛擬化技術等，確實能有助於簡化企業日趨龐雜的IT管理工作，這也是企業真正看重的雲端技術價值。
受到企業需求的壓力，資訊廠商也逐步推出套裝軟體的私有雲工具，例如微軟就打算在2010年推出私有雲端平臺工具企業版，IBM也有提供整套打造的私有雲端系統。除了開源技術以外，企業將有更多選擇來打造私有雲。
在2010年，將會有更多企業嘗試找出各種可行的運用方式，在企業內部善用雲端運算背後的各種技術，形成一股私有雲的應用風潮。這種私有雲系統不一定用來取代既有的內部IT服務，反而最有可能運用在非IT部門的資訊系統中，就像是半導體大廠善用雲端運算優化製程來強化核心競爭力。
 
相關報導請參考「2010關鍵趨勢」
",https://www.ithome.com.tw/news/96351,"新聞,雲端應用,Cloud,私有雲"
96782,38,2009-12-25,09年IT頭條｜廠商熱炒雲端概念，企業保持觀望,雲端運算從年初一路紅到年底， IT 廠商紛紛推出雲端產品或宣示加入雲端概念，臺灣企業雖顯示出高度興趣，但甚少有實際導入者，還處於觀望階段," 雲端運算是2009年最夯的IT名詞，不論任何軟硬體資訊廠商，紛紛推出雲端運算相關產品，連學校、研究機構、政府單位都動作頻頻，積極投入雲端運算產業。
從雲端運算定義逐漸邁向統一的發展，可以看出雲端產品正趨於成熟。過去，每一家資訊廠商對於雲端運算的定義不同，各自刻意區隔不同的產品定位，最早開始喊出雲端運算的Google，訴求大規模分散式資料運算，到微軟兼顧雲和端的Service+Software，而IBM則貼近企業，主推私有雲（Private Cloud）。
但是，到了2009年，雲端運算形成兩種主要的定義，包括廣義和狹義的定義。廣義雲端運算泛指所有網路服務，Google臺灣區總經理簡立峰曾指出，只要透過網路提供服務，就是一種雲端服務。不少資訊廠商正是藉此廣義定義來標榜自身產品的雲端特質，但其實產品功能和舊有功能相差不多。
狹義的雲端運算則從使用目的來界定，將雲端運算分成軟體即服務（SaaS，Software as a Service）、平臺即服務（PaaS，Platform as a Service）和基礎架構即服務（IaaS，Infrastructure-as-a-Service）三種。
IaaS是指在雲端提供資料中心等基礎設施的服務，最典型也最成功的代表就是Amazon的EC2和S3，2010年Amazon將在新加坡建立雲端服務機房，提高亞洲客戶的服務品質，將會和運用微軟技術打造IaaS服務的中華電信競爭。
PaaS主要以應用代管平臺業者為主，提供一個網路應用程式的執行環境讓客戶打造自己的應用程式，包括如Google的App Engine、Salesforce的Force.com，以及清大明年將導入的IBM盤古平臺等。
而SaaS服務則是常見的各種網路服務，例如Gmail、Google Maps等。SaaS乘著iPhone和Android等智慧手機的風潮而出現了大量個人行動服務，這是帶動雲端風潮的一個關鍵助力，手機成為雲端服務的重要端點，讓雲端服務可以隨身帶著走，不過，目前仍以消費端產品為主。
對臺灣資訊業者而言，雲端運算是一個新的機會。不論軟硬體業者，如趨勢科技、廣達電腦、中華電信等，在2009年末時都大力宣示將加入雲端運算產品的研發，包括趨勢和廣達都將雲端產品視為未來十年的關鍵發展方向，紛紛投入大量研發經費來尋找新的商機。
也有硬體業者，如網通業者友訊科技，嘗試將網路設備和雲端網路服務整合，或者如筆電廠商則是和國際網路業者Google合作，打造雲端服務專用的Chrome OS小筆電，將臺灣本地硬體優勢和跨國雲端應用結合。
臺灣研究機構和政府機構也成立了雲端研究中心，例如經濟部和微軟簽署備忘錄，成立軟體暨服務卓越中心。工研院也成立雲端運算行動應用科技中心。
但是，對於多數臺灣企業資訊主管而言，雲端運算仍舊是一個過於遙遠的IT名詞，儘管熱門卻不是日常營運必須考慮的標的，CIO還在尋求更為可行的企業內雲端應用方式，一方面兼顧安全考量，另一方面又能發揮雲端服務的彈性和擴充性。
目前，只有預算拮据的政府機構或學校機構動作較快，開始將較無安全隱憂的內部服務，例如郵件服務，轉移到免費的雲端平臺上，例如交通大學已採用Google App來提供學生郵件服務。
 
相關報導請參考「回顧2009：2009十大IT新聞」
",https://www.ithome.com.tw/news/96782,"新聞,雲端,雲端運算,Cloud"
104013,38,2009-03-06,【圖解】如何將ASP.NET程式搬上雲端,用一個顯示日期的小程式作為範例，透過圖解方式，展示如何將ASP.NET的應用程式部署到微軟Azure雲端運算環境,"  Step1  用VS 2008開發ASP.NET程式
在Visual Studio 2008上安裝了Azure工具以後，就可以在VS2008建立Azure程式的專案。專案目錄會增加Roles這個項目，Role代表在雲端的執行角色，包括執行前端呈現程式的WebRole和執行後端商業邏輯程式的WorkerRole，開發人員可以指定哪一支程式上線後由哪一種Role來執行。目前社群預覽版的Azure僅支援ASP.NET，所有ASP.NET的元件都可使用。

 
 Step2  建立Azure程式的組態檔
上傳程式前，要先在VS 2008中，建立Azure應用程式的組態檔（附檔名cscfg）。依照Azure的XML組態標籤，設定虛擬機器需要調用的執行實例（Instances），例如圖中WebRole有4個Instances，表示會使用4個執行實例來執行WebRole負責的程式。

 
 Step3  啟動本地模擬環境進行除錯
在VS 2008中，啟用本地端雲端模擬環境Development Fabric，可以追蹤Azure程式在不同執行實例中的執行情形，有問題直接使用VS 2008進行除錯。

 
 Step4  將程式上傳到雲端測試環境（Staging）
在VS2008中將完成除錯的Azure程式打包成Azure部署檔，透過Azure服務的開發者平臺，將Azure程式的部署檔和組態檔都上傳到雲端的測試環境中(Staging)。

 
 Step5  先在Staging環境測試，再移到Production環境
先在雲端測試環境（Staging）中測試程式的執行情形，可調整組態檔，改變執行實例的數量，來觀察Azure程式的執行效率，通過測試再將程式轉移到上線環境（Production）。

 
 Step6  上線執行
將程式轉移到Production環境後，即可對外提供服務。有需要增加運算資源時，可隨時在線上調整組態檔，改變WorkerRole和WebRole需要的執行實例數量。

 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104013,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud"
104012,38,2009-03-06,開發Azure應用的5個關鍵,開發Azure應用和現今的網站開發截然不同，有5件事是你必須掌握的開發關鍵," 微軟推出的雲端運算平臺Azure，標榜要延續.NET開發人員既有的開發經驗，讓開發人員可使用同樣的程式語言，來開發雲端應用程式。
實際上，若比較Azure應用程式和傳統Client-Server的網路應用的開發過程，仍然有許多差異。開發人員若不了解這些不同之處，就無法順利開發出Azure應用程式。
 重點1 Azure內建執行環境有2種
第一個開發人員需要注意的不同是執行環境的架構不同。雖然Azure平臺中也是採用了相同的IIS 7網站伺服器，但是，微軟在Azure平臺上的虛擬機器中，安裝了兩種不同的執行環境。應用程式可以使用的執行環境還區分成兩種，包括了WebRole和WorkerRole，這兩種環境最大的不同點是網路功能不同。
WebRole環境可以提供對外的HTTP服務，就像是雲端應用程式的前臺，適合執行供使用者操作的前端網頁應用。而WorkerRole環境則不提供對外的HTTP連線，開發人員可以將不需要接觸使用者的後端商業邏輯程式，放在WorkerRole環境中執行。
微軟提供了一套支援Visual Studio 2008的Azure工具，可免費下載。安裝這套工具以後，當開發人員建立Azure專案時，就可以到Visual Studio的專案視窗中，找到WebRole和WorkerRole這兩個執行環境，開發人員可以依據應用程式的需求規畫，在這兩個環境中撰寫不同用途的程式。
實際上線時，Azure上的Fabric Contoller機制會自動將WebRole和WorkerRole環境中的程式，放到不同的虛擬機器上執行。開發人員可以在組態檔中分別設定這兩種執行環境的虛擬機器數量。
例如開發人員可以依照效能需求，在XML格式的組態檔中設定7個虛擬機器負責執行WebRole程式，而用2個虛擬機器來執行WorkerRole程式。不過，微軟釋出的Azure CTP版本，只能各使用1個虛擬機器來執行。
目前微軟已發表的Azure CTP版本中，只提供了1種規格的虛擬機器，包括了64位元Windows Server 2008作業系統、1.5～1.7Ghz的x64規格處理器、1.7GB記憶體，以及最高50GB的儲存空間。微軟表示，未來推出Azure正式版時，會提供更多規格的虛擬機器供企業選擇，企業可以決定購買哪些規格的虛擬機器來執行WebRole或WorkerRole上的程式。
 
 重點2 只能在本地端模擬雲端環境來除錯
要測試Azure應用程式的品質時，目前，只能在本地端進行除錯。測試時，開發人員必須先到Azure工具中，啟動本地端的Azure模擬環境。
這個模擬環境會依據Azure應用程式所設定的組態資訊，能夠模擬出執行WebRole和WorkerRole的所有虛擬機器，讓開發人員逐一檢視應用程式在每一個虛擬機器中的執行情形，還能進一步結合Visual Studio 2008的除錯工具，來建立程式中斷點和追蹤程式變數的數值。
完成除錯後，再將Azure專案部署到雲端。部署Azure專案時，Azure工具會將WebRole和WorkerRole中的程式一起打包壓縮成1個部署檔。
開發人員只需要將專案的部署檔和組態檔，上傳到Azure服務的開發者平臺中。開發者平臺會進一步提供線上部署功能，讓開發人員將Azure應用部署到微軟的雲端運算環境中執行。
如果開發者不想使用Visual Studio，微軟也提供了一套Azure SDK，可以在命令列的模式中進行所有的Azure開發工作，可以使用指令來建立Azure應用程式需要的部署檔。SDK中同樣也包括了除錯用的Azure環境模擬程式。
目前，微軟發表的Azure CTP版本只支援了ASP.NET語言，在Visual Studio中的ASP.NET元件都可以使用，例如可以直接用滑鼠將日曆元件托曳到WebRole環境的程式中，如同過去的開發方式一樣，設定好日曆元件需要的相關屬性，就可以使用。
 
 重點3 只能使用HTTP協定存取資料
對開發人員而言，另外一個很大的轉變是Azure應用程式存取資料的方式和過去的網頁應用程式有所不同。
在Azure的應用程式，不論是在WebRole和WorkerRole環境中，都只能運用API透過HTTP協定來存取XML格式的資料。無法像過去那樣使用關連式資料庫的查詢指令，透過資料庫連線機制，傳送SQL指令來存取想要的資料。
回到使用者的角度來看，就可以很容易地了解微軟採取這種存取方式的原因。
當使用者連線到Azure應用時，不一定會持續連線到相同虛擬機器上的應用程式。可能第一次的HTTP請求（Request）由1號虛擬機器提供服務，但是，第2次送出請求時，可能因1號虛擬機器滿載，Azure平臺會將使用者的請求轉給2號虛擬機器。
使用者瀏覽的網頁，其實是不同位置中的同一支應用程式，所以，這兩支不同應用程式不會存取到相同虛擬機器上的儲存空間。再加上1號虛擬機器和2號虛擬機器，不一定會放到同一臺實體伺服器中。所以，應用程式也無法使用到相同實體伺服器的記憶體。
例如，在ASP.NET程式中，開發人員常會使用IIS內建的Session變數，來累計每個網頁的瀏覽次數。但是，在1號虛擬機器上的Session變數和2號虛擬機器上的Session變數，即使名稱相同，但實質上是屬於不同的變數，加總時，資料無法累積。
為了確保資料的一致性，Azure平臺提供了1套共用的資料存取網址，不論哪一個虛擬機器上的程式，都透過相同網址，就能存取到相同的內容。
WorkerRole環境中的應用程式，同樣也需要先將運算結果儲存到Azure提供的資料網址中，WebRole的程式再從這個網址中取得運算結果。
這樣的資料存取方式，其實正是Web 2.0網站常用的API存取架構，讓所有資料傳遞都透過API，知名相片網站Flickr就是透過這樣的方式來提供服務。不過，對於企業內部開發人員而言，這是一個與過去習慣不同的開發方式。
因為只能透過HTTP協定來交換資料與存取資料，既有的ASP.NET程式多半無法原封不動地直接放到Azure環境中執行，所有不適合Azure環境的資料存取程式，全部都要修改才行。
對開發者而言，這兩大差異不只是技術上的不同，還需要開發流程和開發觀念上的改變，才能順利打造出Azure應用程式。
 
 重點4 Azure較適合公用運算的服務
除此之外，還有1項開發者需要了解的特質，Azure平臺屬於分散式運算的環境，適合分散式的網路應用。臺灣微軟資深應用架構技術經理李匡正表示，例如像化學分子模擬的複雜科學計算，或程式間關連度很高的ERP等，目前還不適合放到Azure上。
因為Azure可以同時用很多虛擬機器來執行1支程式，但是，這些程式彼此是獨立分開執行，無法同時去解1個問題。李匡正表示：「Azure比較適合公用運算（Utility Computing）性質的應用，例如郵件服務。」
 
 重點5 先做好服務評估與開發轉型
李匡正建議企業要採用Azure平臺前，必須先做好幾項準備工作。首先要精算現有IT系統的成本結構，了解每一項內部的網路服務需負擔多少成本，以利價格比較。
接著從企業整體需求，來規畫可以放到雲端的IT服務項目，並且依據企業內部使用者的需求，清楚地訂定出每一項IT服務需要的服務水準條款（SLA），例如，1個服務的每年當機時間不能超過多久等。
此外，Azure程式的開發思維不同，企業也需要重新培訓IT人員，讓他們熟悉Azure程式的開發方式，並且依據Azure程式的部署和除錯方式，調整開發流程等。
雖然，微軟要等到今年年底才會正式發表Azure，李匡正說：「有興趣導入Azure的企業，現在就可以開始準備。」
 
 開發者角度的Azure雲端運算環境 
1. 企業導入雲端技術前的準備
2. 精算現有 IT 成本結構
3. 全面性規劃與訂定 SLA
4. 人員技能養成
5. IT 基礎環境 (身分驗證機制) 與開發流程確立
資料來源：微軟，iThome整理，2009年3月
 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104012,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud"
104010,38,2009-03-06,Azure技術大剖析：用戶端篇,微軟用Azure Live服務整合4.6億MSN用戶。Live服務主要針對一般消費者市場，讓企業可以運用Live框架的技術，來開發Live服務上的Mesh 應用程式，或者存取各項Live 服務上的資訊," Live服務等於是過去微軟Live產品的底層功能，例如Hotmail和MSN即時通訊的帳號功能，等於是Live服務中的帳號服務。
微軟將Live產品中的底層服務，統整成一套提供網路基礎服務的功能模塊（building block）。
在Live服務提供的功能模塊，包括了帳號、目錄、儲存、搜尋、地理資訊等功能模塊。開發人員可以使用Live框架提供的API，來存取Live服務中任何一個功能模塊所擁有的資料。
因為微軟的Live產品也同樣使用這套Live服務的功能模塊，換言之，使用Live服務的Azure應用程式，可以存取到Live產品中的各種資訊，例如Azure程式就能夠透過Live服務，連結到4.6億個MSN用戶帳號。
只要顧客擁有MSN帳號，授權企業使用，企業自行開發的應用程式，就可以利用Live框架的元件，存取Live服務中的MSN帳號資訊，不需要讓使用者重新填寫帳號資料。
在Azure環境中內建了Live執行環境，可以提供一套Live框架，讓Azure應用程式來存取Live服務的資料。
Live框架包括了一套函式庫，提供如Silverlight API、.NET FX API、JavaScipt API等元件，也提供了多種使用資源的模式，例如存取資料、管理應用程式、透過點對點的方式和其他應用程式通訊等。
Live執行環境不只是支援Azure，也可安裝在其他作業系統中，例如Windows、Windows Mobile等作業系統。透過HTTP協定，不同裝置間的Live執行環境可以同步資料、檔案等。
微軟已經利用這些Live技術開發出Live Mesh服務，可讓使用者跨裝置同步資訊，例如用手機拍攝的照片可以自動同步到雲端的儲存空間，也能同步到Windows作業系統上的特定檔案目錄下，使用者不需自己手動複製。
 
Live服務架構
Live服務主要針對一般消費者市場，讓企業可以運用Live框架的技術，來開發Live服務上的Mesh應用程式，或者存取各項Live服務上的資訊，例如可連結到4.6億個MSN用戶識別服務，開發免註冊的Mesh應用。

資料來源：微軟，iThome整理，2009 年3 月
 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104010,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud"
104009,38,2009-03-06,Azure技術大剖析：儲存篇,為了處理成千上萬的資料，微軟放棄關連式資料庫，不再有Schema、不再有SQL指令，只能使用HTTP協定來存取資料," 如何在網路上處理數千GB甚至TB、PB等級的海量資料，這是雲端運算最大的難題之一。微軟為了讓應用程式可以處理這樣等級的資料量，並且還可以任意擴充資料量，在Azure平臺中，微軟放棄了傳統的關連式資料庫架構，改用全新架構。
Azure平臺不再使用關連式的資料庫架構，所以，開發人員無法使用熟悉的SQL語法，也不需要規畫資料庫欄位的架構Schema。換句話說，使用SQL語法的程式，全部無法使用，必須重新改寫，才能存取Azure上的資料。對開發人員和資料庫管理者而言，這是Azure平臺最大的變革。
目前微軟發表的Azure CTP版本，提供了兩大類儲存空間。第一類是Azure作業系統內部的儲存機制，稱為Azure Storage（Azure儲存機制），另外一類則是Azure服務平臺上的SQL Services。這是兩種不同的儲存機制，存取方式也略有不同。
Azure Storage是Azure應用程式內部執行環境的儲存機制。Azure會將實體伺服器的所有儲存資源，集中建立1個資料的共享池（Sharing pool），讓Azure應用程式存取。
在Azure Storage中，所有資料都有一個特定的網址，應用程式可以透過HTTP協定的API呼叫來存取。Azure打破了傳統資料表的結構，改用XML格式來保存資料。使用XML最大好處是可以處理非結構化的資料型態。
過去關連式資料表上的欄位名稱，在Azure Storage中等同於1個XML標籤。應用程式只要在API的查詢條件上指定那個XML標籤，就能存取到對應的內容。
目前Azure Storage提供了3種資料格式，包括類似表格結構的Tables、可儲存最多50GB大小的Blobs格式，以及僅供應用程式內部溝通使用的Queues格式。
另外一類Azure應用程式可使用的儲存空間SQL Services， 正是原來的微軟線上儲存服務SQL Server Data Service（SSDS），這是用SQL Server資料庫技術打造的高擴充性儲存服務。
SQL Services採用了新的ACE資料模式，每1筆資料記錄會儲存在1個包含Authority、Container和Entity三層名稱的網址下。Authority記錄了地理區域和計價單位的資訊，而Container則是相同資料格式類型，例如圖片資料都會儲存Image的Container中。Entity則是最基本資料儲存單位，用XML格式保存資料。
不論是Azure Storage或SQL Services的資料存取API，都是遵循REST這種新的Web Service格式，這也是許多網路開發者熟悉的API使用方式。不過，存取方法雖相同，但是，SQL Services允許網路上任何應用程式來存取，而Azure Storage只開放給Azure平臺中的應用程式使用。
目前，SQL Services只提供了資料儲存和資料同步的功能，微軟表示，為了提供相容性，3月底的MIX09會議中，也會推出SQL Services的SQL Server 2008服務，等於是讓企業可以使用微軟機房中的SQL Server 2008，不過這個服務就無法提供高擴充性，但是，可以像過去那樣使用關連式資料庫的存取指令。此外，今年內還會陸續增加分析報表或資料探勘元件的功能。
 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104009,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud"
104008,38,2009-03-06,Azure技術大剖析：運算篇,微軟Azure將執行環境和應用程式都標準化後，就能夠創造出擴充力和高可用性，而Fabric Controller便是微軟雲端運算擴充力的關鍵," 讓Windows作業系統變身為雲端作業系統的關鍵是Fabric Controller（簡稱FC）技術。這是微軟為Azure量身打造的新式管理機制，用標準化的虛擬機器（Virtual Machine ，VM），仿照叢集（Cluster）架構方式，創造出分散運算的效果。
Fabric Controller的主要任務是負責將Azure平臺中的可用資源分配給提供服務的應用程式。管理的範圍，涵蓋了1個服務從產生到結束的整個生命周期，同時還要監控Azure作業系統的健康，以確保應用程式執行環境的穩定性和擴充性。
用標準化規格增加彈性與效率
為了管理所有伺服器的運算資源，FC就如同郵局的便利箱服務一樣，透過標準化的作法來提高自動化的效率。
郵局提供了制式紙箱供民眾郵寄物品，這些紙箱就是便利箱。每個便利箱的大小容量都相同，不論寄件人要寄任何物品，只要放的進去，郵局就會運送。
因為便利箱的規格統一，而且可以事先製作，郵局就可以在紙箱上印了所有必備的郵寄欄位和作業資訊，讓郵差能夠透過標準作業流程來處理。不用像過去那樣麻煩，郵差必須在大小不一，書寫方式各異的箱子中，尋找要遞送的地址資訊。
因為統一規格，所以知道了箱子數量就可以精確地安排運送車輛。大卡車能載100箱、小貨車載20箱，而騎摩托車的茂伯，每次則可以載得動1個箱子。
當載具和包裹都標準化了以後，郵局運輸調度人員對於包裹運送的規畫，就可以更有彈性，也更有效率，即使有輛卡車臨時拋錨，也知道立刻要派多少小貨車來支援，不用多，也不會少。
FC是Azure中的主要調度員
標準化的虛擬機器，就像是這些制式便利箱。而效能不同的伺服器則是各式車輛。FC是Azure平臺中的調度人員，它不需要知道虛擬機器中執行什麼樣的應用程式，只要負責讓所有便利箱（虛擬機器）能夠順利搭上貨車（伺服器）送達目的地。
只要備用資源夠多，遇到紙箱破損（虛擬機器當機）或車輛拋錨（伺服器故障）時 ，FC只需將應用程式複製到另外一個新的虛擬機器中，就能夠繼續執行，服務不會中斷。
目前，微軟在Azure系統中，用了5～7臺伺服器來建立叢集，其中1臺伺服器擔任Fabric Controller的角色（Host），負責管理其他伺服器（Guest）。在每臺Guest伺服器上，都安裝了微軟虛擬化技術，用來建立虛擬機器。
這些虛擬機器都是相同規格，包括運算能力、記憶體、作業系統、儲存空間等，就像是一個標準規格的箱子，可以放入依據標準規格開發的應用程式。
大型伺服器，可以提供10個虛擬機器，中型伺服器可能只有5個。更甚者，也許1臺小型伺服器只能提供1個標準規格的虛擬機器，那就不用安裝虛擬化技術，直接利用原本的硬體環境來建立符合規格的作業環境。
每一個虛擬機器都視為叢集中的1個節點（Node），所有節點都統一由FC管理，FC會自動指派每個虛擬機器要負責執行的應用程式。
在每一個虛擬機器中，都有1個FC代理程式，用來監控虛擬機器的健康狀態。遇到虛擬機器發生故障當機，FC代理程式會發出警告，通知FC將應用程式轉換到另一個有效的虛擬機器中。
只要增加FC所管理的實體伺服器，就能夠增加應用程式可使用的虛擬機器，應用程式不需要知道實體伺服器，彼此沒有直接的關連。
所以，即使發現有臺實體伺服器發生故障，或者想要增加新伺服器數量，都不需要將關閉正常的實體伺服器，透過FC的安排，應用程式都能在健康的虛擬機器中執行，服務不會中斷。
這個透過FC來管理標準化虛擬機器的作法，同時讓Azure具備了高可用性以及擴充性。
FC也統管所有儲存資源
除了管理標準化的虛擬機器以外，FC也統一分配所有伺服器中的儲存資源，FC會將每臺伺服器上的可用儲存空間，統整為1個共享的儲存資源（Sharing Pool），再提供給虛擬機器上的應用程式使用。虛擬機器上的應用程式不會知道資料的實體位置，只能透過FC提供的網址來存取。
其他如應用程式所需的網路設定，頻寬負載平衡等，也都是由FC負責調度。IT人員不須像過去自行建置伺服器叢集時，必須自行設計專用的網路架構，管理負責的網域分配，才能讓伺服器叢集進行分散運算。FC等於是Azure平臺中的完美管家，在背後調度所有資源，默默服侍著應用程式，不用IT人員費心。
打包服務加快部署
為了進一步確保雲端服務的持續，微軟還採用了新的應用程式部署方式，來加快應用程式在虛擬機器之間的轉移速度。這個部署方式稱為服務映象檔（Service image）。
所謂的服務映象檔，就是將Azure應用的所有檔案，以及執行環境所需的組態設定等，都打包成1個映象檔。因為Azure的虛擬機器都有相同的規格，所以，應用程式的執行環境也相同。
在Azure的虛擬機器上，提供了2種不同的執行環境，包括可提供HTTP協定服務的WebRole環境，以及沒有提供HTTP協定服務的WorkerRole環境。FC會分別依據這兩種不同的執行環境，將應用程式分別打包成2種不同的服務映象檔。
只要FC將服務映象檔複製到任何虛擬機器中，就能夠立刻在新的虛擬機器中啟動這個應用程式，不需要進行複雜的安裝過程。應用程式的部署過程簡化為檔案複製的動作。
開發人員只需事先在應用程式的組態檔中，設定好虛擬機器的數量， FC就按照這個數量自動指派足夠的虛擬機器，將服務映象檔複製到這些虛擬機器上執行。
若遇到虛擬機器當機，FC只需要將服務映象檔複製到其他健康的虛擬機器上，就可以維持應用程式的執行效能，連部署程式需要的等待時間都可以節省下來。
整體而言，FC是微軟雲端運算中最關鍵的技術，透過虛擬化技術建立標準化的虛擬機器，同時運用服務映象檔的部署方式，讓應用程式具備了擴充彈性以及高度的可用性。
 
 Fabric Controller技術統整運算和儲存資源，隔離雲端應用程式 
在Azure環境中，由Fabric Controller（簡稱FC）統整所有的運算資源和儲存資源，來將雲端應用程式和實體伺服器隔離，FC會自動管理虛擬機器的伺服器和實體伺服器，遇伺服器故障，FC自動將虛擬機器切換到其他伺服器。
FC會依據組態檔分配足夠的虛擬機器，提供給WebRole和WorkerRole環境，而應用程式只能看見有2種執行環境，包括WebRole和WorkerRole，不會接觸到虛擬機器。共享儲存資源提供Blobs、Tables和Quesues三種資料型態，由FC負責共享儲存資源和實體儲存機制的對應和備援。

資料來源：微軟，iThome整理，2009 年3 月
 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104008,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud,Fabric Controller"
104007,38,2009-03-06,採用微軟雲端服務必知的9件事,任何應用程式都可以搬上雲端平臺嗎？採用雲端服務前你必須知道有哪些限制," 微軟在專業開發者會議上，發表了雲端作業系統Windows Azure，以及多項Azure的相關服務和技術。為了讓企業和開發人員了解Azure，微軟特別委託知名科技律師David Chappell，撰寫了Azure服務平臺白皮書，David Chappel過去也是微軟多項技術白皮書的作者。
David Chappel在白皮書中詳細介紹Azure所採用的技術特性和服務內容。我們特別從白皮書中精選出9項不可不知的重點，讓你快速認識微軟的雲端技術Azure。
 重點1 Windows Azure和Azure服務平臺是兩套不同的產品
Windows Azure是微軟的雲端作業系統，而Azure服務平臺則是利用Windows Azure作業系統作為核心，所打造出來的服務平臺，兩者是不同的產品。Windows Azure作業系統負責執行Azure應用程式，目前可支援ASP.NET開發的程式。
而Azure服務平臺上，主要提供一些基礎的雲端服務，可供其他網路應用程式透過HTTP協定和API來存取這些服務。目前已經開放了3項雲端服務，包括.NET服務、SQL服務企業和Live服務。未來在Azure服務平臺上，還會增加MS Sharepoint服務和MS Dynamics CRM服務。
 
 重點2 Windows Azure只能安裝在微軟資料中心的伺服器中，不能買回家
Windows Azure雖然是以Windows Server 2008為基礎，所發展的作業系統，但是並非是一套可購買回家安裝的產品，目前，微軟也不提供給企業安裝在企業內部的伺服器上。
Windows Azure安裝在微軟資料中心的伺服器上，企業只能將自己開發的應用程式，透過Azure服務開發者入口網站，將應用程式發布到微軟資料中心的Windows Azure環境中執行。
微軟表示，未來會推出更多功能來協助企業統整雲端應用程式和企業內部伺服器，例如未來會推出Microsoft Services Connector，讓企業可以很容易地將本地端的AD帳號資料和雲端應用程式整合。
 
 重點3 不是所有應用都適合在Azure環境執行，Azure適合執行分散式應用
Windows Azure利用新的Fabric Controller（簡稱FC）技術和虛擬化技術，來提供高擴充性的雲端運算環境，但是，並非所有應用程式都適合在Windows Azure的環境中執行。
Windows Azure透過FC技術來分配執行雲端應用程式的虛擬機器數量，FC會將1隻應用程式複製很多分，放到不同虛擬機器上執行，讓大量使用者分別連到不同虛擬機器上的應用程式，進而達到分攤負載的效果。
但是，1隻應用程式仍舊受限於1個虛擬機器的運算能力，例如在Azure環境中，執行需要高運算量的化學分子模擬運算程式，即使設定了50個虛擬機器來執行這支程式，也只是重複計算50次，而不是將程式分成50個小程式來計算，用50個虛擬機器和用1個虛擬機器的執行時間相比，這兩種作法的執行效能相當，增加越多虛擬機器並一定越快完成。
 
 重點4 Windows Azure目前只支援ASP.NET，但第三方應用程式可存取Azure服務平臺上的服務
Widnws Azure目前支援ASP.NET開發的應用程式，開發人員可利用Visual Studio 2008開發ASP.NET程式，將程式壓縮打包後，連同應用程式組態檔，透過Azure服務開發者入口網站，將檔案上傳到Azure環境中部署即可執行。
但是，Azure服務平臺所提供的服務，包括.NET服務、SQL服務、Live服務，以及未來的MS Sharepoint服務和MS Dynamics CRM服務等，都是透過REST或SOAP的API來呼叫。因此，第三方應用程式或非微軟技術平臺，都可以使用這些服務。
 
 重點5 舊有ASP.NET程式無法直接放到Azure環境執行，必須重新修改
為了讓Windows Azure上的應用程式具備擴充性（Scalability），使用者每次呼叫Azure程式時，不一定會由相同虛擬機器上的程式提供服務，所以，過去保存資料的方式，例如將資料存放在記憶體中的變數，在不同虛擬機器上的數值可能會不同。
開發人員無法使用過去儲存資料的方式，來處理Azure程式所使用的資料，換言之，企業原有的ASP.NET程式，也無法直接放到Azure環境中執行，必須重新改寫。
要保留資料，必須將使用者端的資訊透過ADO.NET儲存到Windows Azure儲存機制、或者儲存使用者端的Cookie裡面。也可以將資料透過REST API儲存到SQL服務中。
 
 重點6 無法使用SQL語法查詢，也沒有Schema，需用API存取
在Azure環境中，存取資料的方式和過去截然不同。Windows Azure提供的儲存機制，無法使用SQL語法查詢，也沒有Schema，應用程式必須使用RESTful格式的API，透過HTTP協定來存取資料，所有資料都可以透過一個特定網址來存取。
Windows Azure儲存機制提供了3種資料型態，包括Blobs、Tables和Queues。前兩種主要用來儲存資料，Blobs最大可儲存50GB的檔案，影音、圖片都可以，還有描述標籤可記錄相關資訊。Tables格式則可儲存結構式資料，但是沒有Schema，直接透過XML標籤來讀取特定欄位的資料。而第三種Queuse格式則是讓虛擬機器之間傳遞資料之用。
SQL服務並不是Windows Azure儲存機制，而是屬於Azure服務平臺所提供的其中一種服務。SQL服務建置在SQL Server 2008伺服器上，但同樣也無法讓應用程式使用SQL語法，來查詢儲存在SQL服務中的資料。微軟表示，未來會推出相容SQL Server 2008但不具擴充性的服務模組。
所有Azure環境中的資料，不特定存放在哪一臺實體伺服器中，Azure環境會提供3倍容錯能力。
 
 重點7 微軟將提供計價機制，可按使用量計費
目前微軟推出的是Azure社群技術預覽版（CTP版），採免費申請制，但是，限制可使用的儲存空間和網路流量。微軟表示，未來正式版推出時，將會增加計費機制。計費機制會監控每一支應用程式所消耗的運算資源、網路流量、儲存空間等，微軟再依不同使用量計價。
這項計費機制也將是一項Azure服務平臺上的服務， SI廠商可以開發Azure程式提供給用戶，再利用這個計費機制，來統計用戶使用產品的使用情況，作為計價的參考。
 
 重點8 Live服務不是Live系列的產品，而是Live產品的底層功能
在Azure服務平臺的Live服務不是微軟現有的Live系列產品，而是微軟將Live產品底層所用的基礎功能，整合成獨立的服務機制。例如在Hotmail和Messenger的帳號機制，都整合成為Live服務中的使用者服務。
開發人員透過Live框架的元件，可以讓自己開發的應用程式存取Live服務中的資料，也就是等同存取到Live產品中的各種資訊。
 
 重點9 Azure應用程式可透過Live框架延伸到不同裝置中執行
Live框架可以讓應用程式存取Live服務的資料，包含了微軟多種技術的集合，例如Silverlight元件、.NET FX元件等。在Live框架中有一個Live執行環境（Live Operating Environment），只要在行動裝置上安裝這套執行環境，就可以執行用Live框架開發的應用程式，包括桌上型電腦、非微軟系統電腦、手機、行動裝置等。
此外，Live框架中還有一個Mesh技術，可以用來處理跨使用者、跨裝置或跨應用程式之間的資料同步。Azure應用程式可以使用Mesh技術和Live執行環境，在各種裝置上建立客戶端程式，讓Azure應用程式延伸到各種裝置中。
 
 快速認識Azure 
1. Windows Azure和Azure服務平臺是不同產品
2. Windows Azure只安裝在微軟資料中心的伺服器
3. 不是所有應用都適合在Azure環境執行
4. Windows Azure目前只支援ASP.NET
5. 舊有ASP.NET程式無法直接放到Azure環境執行
6. 無法使用SQL語法查詢，也沒有Schema
7. 微軟將提供計價機制，按使用量計費
8. Live服務不是Live系列的產品
9. Azure應用可透過Live框架延伸到不同裝置
資料來源：Azure技術白皮書，iThome整理，2009年3月
 

微軟委託知名科技律師David Chappell 撰寫了Azure技術白皮書，可免費下載。

 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104007,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud"
104006,39,2009-03-06,搶攻企業雲端應用，微軟推出Azure雲端服務,微軟終於進軍雲端運算，推出Azure雲端作業系統，做為未來5∼10年的產品主力," 2008年10月27日早上8點半，微軟舉辦專業開發者大會（PDC2008）的現場，各家分析師、微軟競爭對手、SI業者、大企業開發人員等，都引領期盼地坐在臺下。
眾人都很好奇，接手比爾蓋茲的職位，成為微軟軟體架構長的Ray Ozzie，在未來幾年，他將會如何帶領微軟的技術發展方向。
微軟在PDC2008首度發表了雲端運算產品Windows Azure。微軟的雲端運算主要包含了兩項產品，第一個產品是作為底層的雲端作業系統Windows Azure，以及架構在這個作業系統上的Azure服務平臺。
Ray Ozzie表示：「Azure平臺可以視為一個線上作業系統環境，統整了整個資料中心的運算資源，企業可以很方便地調用這些資源，來執行各種應用程式。」
源自Windows Server 2008技術
Windows Azure並非是全新的作業系統，而是以Windows Server 2008為核心，運用微軟虛擬化技術，加上全新打造的管理機制Fabric Controller技術，所建構出來的作業系統，這個作業系統可以讓資料中心打造出雲端運算的執行環境。
當企業要使用Azure環境時，必須透過微軟提供的管理網站，將自行開發的應用程式上傳到微軟的雲端運算環境中執行，也就是必須使用微軟資料中心來執行自家的應用程式。
這麼做的好處是，企業只需要專注於程式開發，不需要知道自己的程式存放在何處，微軟會負責底層資訊架構下所有軟硬體的維護管理工作。
用虛擬化創造擴充性
讓Windows 2008變身為雲端作業系統的關鍵是Fabric Controller技術（簡稱FC）。藉由FC，所有建置在Azure平臺中的應用程式都是服務，FC可以統整所有實體伺服器的資源，再將這些資源，重新組合許多個統一規格的虛擬機器（Virtual Machine，簡稱VM），來執行這些Azure上的服務程式。
對每一支應用程式而言，都是在虛擬機器中執行。開發人員可以透過FC來分配應用程式可以使用的虛擬機器數量，需要越多運算資源，直接變更組態，就能增加越多虛擬機器來執行。不需要像過去那樣，關閉伺服器，擴充伺服器，重新部署應用程式後才能開始提供服務。
遇到實體伺服器發生故障時，FC還會自動將應用程式搬移到其他虛擬機器上執行，讓服務不會中斷。這樣的擴充彈性（scalability），正是雲端運算平臺最主要的功能。
在Azure上延續既有開發經驗
因為源自既有技術，微軟Azure也具備了大多數原本Windows Server 2008所內建的機制，例如IIS 7，換句話說，原本在IIS 7上可以執行的程式和功能，經過部分修改後，大多也能夠直接在Windows Azure中運行。
除此之外，為了協助開發，微軟還免費提供了一套Visual Studio 2008的Azure工具，讓企業使用Visual Studio 2008來開發Azure程式，而且可以在本機端模擬Azure雲端運算環境，來進行應用程式的測試和除錯。
盡可能地延續既有開發經驗來開發雲端運算，是微軟最大的目標。微軟希望能夠讓開發者運用熟悉的.NET開發方式和工具，甚至原來自行開發的元件略做修改，就可以套用，不用重新撰寫程式碼。
雖然Azure能支援.NET開發，不過，Azure架構提出了兩大變革，使得大多數ASP.NET程式必須適當修改後，才能在Azure平臺上順利執行。
執行環境和資料存取新改變
第一個變革是分工化的執行環境，就好像俗話：「男主內、女主外」的分工方式，在Azure架構中，應用程式的執行環境也區分成兩種，一種是負責前端呈現的WebRole環境，以及負責後端邏輯的WorkerRole環境。
WebRole和WorkerRole都是IIS 7的環境，最主要的差別是，前者容許外部的HTTP連線，可以讓外面的顧客或使用者透過瀏覽器打開在WebRole中的服務。但是，WorkerRole環境只容許內部連線，只有在同一個Azure環境中的內部程式可以呼叫WrokerRole上的程式，不提供對外HTTP服務。開發人員須將按照用途不同，將應用程式分別切割成兩個部分。
第二個變革則是資料存取方式的改變。要存取Azure儲存機制的資料，都必須透過HTTP協定，透過符合REST格式的Web Services來存取。每一筆資料，都有一個對應的網址，Azure應用程式必須用REST格式API來取得這個網址所對應的資料。
對.NET開發人員而言，他們可以在Azure中使用熟悉的開發技術，但是，為了因應這兩大變革，臺灣微軟資深應用架構技術經理李匡正表示：「.NET技術雖然相同，但開發人員必須學習新的運用方式。」
將常用服務模組化
在Windows Azure作業系統之上，微軟還打造了一個Azure服務平臺，以模組化的Web Services，提供一些應用程式常用的功能。開發人員可以直接在應用程式中透過HTTP協定呼叫這些模組化的服務，不用自行開發與維護。
目前已發表的Azure服務平臺服務模組，包括了Live服務、.NET服務、SQL Services（原Microsoft SSDS），這多是微軟既有服務，等於是說，微軟將過去已發表的產品，都逐步整合到Azure服務平臺上。微軟表示，未來還會增加MS SharePoint服務和MS Dynamics CRM服務。
整體而言，微軟在PDC會議上，與其說是產品發表，不如說是微軟的實力展現，向企業證明微軟進入雲端運算的行動，同時也預告了微軟未來5～10年的方向。
微軟表示，最快2009年第四季時，就會推出Windows Azure正式版，到時候，Azure服務平臺還會新增1個計價服務的模組，這個模組能統計Azure應用程式所使用的運算資源、儲存空間、頻寬等資訊，微軟會依使用量收費。此外，若資服業者運用Azure平臺提供服務，該模組也能協助SI業者追蹤客戶使用量，以供計價參考。
臺灣企業已開始試用
臺灣微軟已經開始向臺灣大型企業介紹Azure，更有電信業對Azure很有興趣，臺灣大哥大副總經理張幼祺表示：「我們已經開始嘗試開發Azure應用程式了。」
不過，臺灣微軟特約資深講師李智樺建議：「最好等到正式版推出，不論功能或安全性都穩定後，企業再正式採用。」微軟預定今年底正式推出。
 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104006,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud"
104004,39,2009-03-06,快速認識雲端運算,雲端服務五花八門，雲端運算幾乎成了網路服務的代名詞，帶你快速認識什麼是雲端運算的服務," 自Google領頭吹響雲端運算的號角之後，雲端運算成為兩年來竄紅速度最快的IT名詞。Google的成功，讓眾人對雲端運算感到高度好奇，大家都想偷學Google的秘訣，想了解Google如何運用雲端運算創造出服務全球的網路應用。
知名分析機構如Gartner、IDC、Forrester等，紛紛預言雲端運算將如同綠色節能技術一樣，都是未來幾年的IT必然趨勢。
兩年來，許多軟硬體業者陸續向雲端運算靠攏，舉凡任何IT產品或網站，只要冠上雲端運算，彷彿就能像Google那樣，擁有攝住眾人目光的吸引力。
微軟則不同，一直到去年10月，微軟軟體架構長Ray Ozzie才正式在開發者大會中，發表雲端作業系統Azure，宣布微軟進軍企業雲端市場。
不過，多數人聽到Azure這個字時，第一個反映是想查字典，大家都想弄清楚，這個源自阿拉伯語的法式英文字到底要如何發音，甚至連與會的微軟自家員工也是如此。雲端運算的定義也如同Azure的發音一樣，眾說紛紜。
在電腦科學中，原本就慣用雲的概念來代表網路，一方面化繁為簡，透過簡單的比喻來代表系統的複雜性，另一方面是表示對網路運作的信賴。對使用者而言，不需要了解複雜的網路架構，也能夠很容易地使用網路。
Google同樣也借用了雲的比喻，來形容打造Gmail的多項技術，Google所謂的雲端運算其實是多項技術的通稱。
隨著Yahoo、Amazon等知名網路業者跟進雲端服務，雲端運算幾乎成了網路服務的代名詞，軟體廠商如微軟、HP、IBM、Oracle、Salesforce等相繼宣布推出雲端產品，甚至連硬體廠商Cisco也要邁向雲端。一時之間，雲端運算成為資訊廠商的流行風尚，加入雲端，才跟得上軟體趨勢。
雲端服務是虛擬的隨選資訊服務
美國市調機構Yankee Group認為，不論是採用哪一種雲端運算技術，從服務特質來看，雲端服務是一種可以依使用者需求來提供服務的虛擬化資訊服務，有些業者的產品專注於1種服務，但也有業者屬於多類特質的服務。
Yankee Group依據雲端服務的性質和市場特徵，將雲端服務區分成四大類，包括提供儲存空間的雲端服務（Storage as a Services）、提供基礎架構的雲端服務（Infrastructure as a Services）、平臺即服務（Platform as a Services）和常見的軟體即服務（Software as a Services）。
第一類的儲存雲端服務主要提供了線上儲存空間，讓用戶可以透過API來存取資料。Amazon推出的S3（Simple Storage Service）就是最典型的代表，最近熱門的微網誌Twitter服務，就是租用S3來儲存數百萬用戶的個人圖片，而沒有自建機房。微軟發表的SQL Services也是屬於這類型的服務。
提供IT基礎架構的雲端服務則是第二類，最知名的是Amazon的EC2（Elastic Compute Cloud），EC2也是少數能成功建立商業營運模式的雲端服務。Amazon EC2利用Xen虛擬化技術，讓用戶可以建立自己的作業系統環境。由Amazon負責管理實體伺服器和網路頻寬，其餘全由使用者自行管理。IBM的Blue Cloud或HP的Flexible Computing Services也屬於這類服務。
目前新興的是第三類平臺即服務（Platform as a Services），不同於第二類只提供硬體環境，平臺即服務主要是代管用戶應用程式的執行平臺。比較知名的產品如Salesforce的Force.com、Oracle的SaaS Platform、Google去年發表的App Engine、Yahoo的Application Platform等。微軟最新推出的Azure作業系統同樣也是屬於這類提供應用平臺的服務。
最後一種則是目前最成熟的雲端服務，也是許多人經常使用的軟體即服務， 例如Google地圖、Yahoo信箱或趨勢科技的網頁信譽評等（Web Reputation Service）服務等。雖然第四類不一定和上述三類採用同樣的雲端運算技術，但從服務特質上來看，Yankee Group還是將所有透過網路能滿足隨選需求的軟體服務，都歸類為這種軟體即服務的雲端服務。
降低網路服務門檻，不用自建機房
不論哪一種雲端服務，對企業而言，工研院資通所副所長余孝先認為最大的好處是降低了網路應用的建置門檻，他說：「就像是小型IC設計公司可透過臺積電的代工廠，將產品賣到全世界一樣，只要中小企業有好點子，沒有機房也能租用雲端服務，提供全球服務。」
雲端服務的隨選彈性，也能夠協助企業解決短期的大量網路使用需求。例如安泰人壽就租用了Salseforce.com平臺，用短短1個月時間建立臨時性客服網站，來處理大量孤兒保單，幾個月後保單處理完畢，也結束網站，不需要增購伺服器或網路線路。
不過，臺灣微軟資深應用架構技術經理李匡正認為，雲端服務不一定適合所有企業應用，他說：「目前的雲端服務比較適合新創公司，或企業內部的公用服務（Utility Computing）。」
微軟年底發表正式版，雲端企業市場成形
雖然資訊業者紛紛鼓吹雲端服務的好處，但是，臺灣企業實際導入雲端技術的案例卻不多見，不少企業仍處於高度好奇的評估階段，一方面思考如何運用這項技術，另一方面也觀望主流軟體業者的投入程度。
Google上個月剛宣布了App Engine的付費方案，反映出對雲端服務的重視。微軟也預告年底推出正式版Azure雲端作業系統。全球軟體龍頭和網路霸主的正式表態，讓雲端服務市場再掀波瀾，角色終於到齊，這部雲端市場大戰的戲碼，好戲才正開始。
 
 雲端服務的類型 
美國知名的市場研究機構Yankee group 將雲端運算定義為一種在網路上提供隨選服務（ondemand）的虛擬化資訊服務方式， Yankee依據服務和市場的特徵，將雲端運算的服務區分成四種，分別是儲存雲端服務（Storage as a Services）、基礎架構雲端服務（Infrastructureas a Services）、平臺即服務（Platform as a Services）、軟體即服務（Software as aServices）。

資料來源：Yankee Group，2008 年7 月，iThome整理，2009 年3 月
 
【相關報導請參考「撥開微軟Azure雲端運算的迷霧」】
",https://www.ithome.com.tw/news/104004,"新聞,微軟,Azure,雲端運算,雲端作業系統,Cloud"
