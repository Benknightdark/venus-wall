{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## üìù ÂÆâË£ùÂ•ó‰ª∂"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "!pip install jieba -U\r\n",
    "!pip install httpx -U\r\n",
    "!pip install sklearn -U"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: jieba in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (0.42.1)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: httpx in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (0.19.0)\n",
      "Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from httpx) (0.13.6)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from httpx) (2.0.4)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from httpx) (1.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from httpx) (2021.5.30)\n",
      "Requirement already satisfied: sniffio in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from httpx) (1.2.0)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from httpcore<0.14.0,>=0.13.3->httpx) (0.12.0)\n",
      "Requirement already satisfied: anyio==3.* in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from httpcore<0.14.0,>=0.13.3->httpx) (3.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx) (3.2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\smart\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=d67a04dedb21ad04a3a9cbed73bac2c5a5a57b060c5c4a48d9a6e368e5dc4e23\n",
      "  Stored in directory: c:\\users\\smart\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üìù ÈáùÂ∞çÊ®ôÈªûÁ¨¶ËôüÊñ∑Ë°å"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "import re\r\n",
    "def splitSentense(text, delimiter):\r\n",
    "    return re.split(delimiter, text)\r\n",
    "    \r\n",
    "delimiter = \"Ôºå|„ÄÇ|„ÄÅ|Ôºà|Ôºâ|Ôºè|„Ää|„Äã|„Äë|„Äê|„Äå|„Äç|Ôºõ|Ôºö\"\r\n",
    "allNews = ['ËôõÊì¨Ë≤®Âπ£„ÄåÊØîÁâπÂπ£ÊúüË≤®„ÄçË¶Å‰æÜ‰∫ÜÔºÅÁæéÂúãÁõ£ÁÆ°Ê©üÊßãÁæéÂúãÂïÜÂìÅÊúüË≤®‰∫§ÊòìÂßîÂì°ÊúÉÔºàCFTCÔºâ‰∏ÄÊó•ÂÆ£Â∏ÉÂ∞áÊîæË°åÊØîÁâπÂπ£ÊúüË≤®ÔºåÂÖÅË®±ËäùÂä†Âì•ÂïÜÂìÅ‰∫§ÊòìÊâÄÔºàCMEÔºâÂíåËäùÂä†Âì•ÈÅ∏ÊìáÊ¨ä‰∫§ÊòìÊâÄÔºàCBOEÔºâÊé®Âá∫Áõ∏ÈóúÊúüË≤®ÂêàÁ¥ÑÔºåÂõ†ÁÇ∫ÂÖ©‰∫§ÊòìÊâÄÂ∑≤Ë≠âÊòéÊì¨Êé®Âá∫ÁöÑÂêàÁ¥ÑÂíå‰∫§ÊòìÂÆâÂÖ®Á¨¶ÂêàÂøÖË¶ÅÁöÑÁõ£ÁÆ°Ë¶èÂÆöÔºõÈÄôÊàêÁÇ∫Êé®Âãï‰∏ªÊµÅÊäïË≥á‰∫∫Ë≤∑Ë≥£Ê≠§ÂÉπÊ†ºÈ´òÂ∫¶Ê≥¢ÂãïÁöÑÊï∏‰ΩçË≤®Âπ£ÁöÑÈáçÂ§ß‰∏ÄÊ≠•„ÄÇ']\r\n",
    "sentenceAry = []\r\n",
    "for rec in allNews:\r\n",
    "    text = rec\r\n",
    "    sentenceAry += splitSentense(text,delimiter)\r\n",
    "sentenceAry    "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ËôõÊì¨Ë≤®Âπ£',\n",
       " 'ÊØîÁâπÂπ£ÊúüË≤®',\n",
       " 'Ë¶Å‰æÜ‰∫ÜÔºÅÁæéÂúãÁõ£ÁÆ°Ê©üÊßãÁæéÂúãÂïÜÂìÅÊúüË≤®‰∫§ÊòìÂßîÂì°ÊúÉ',\n",
       " 'CFTC',\n",
       " '‰∏ÄÊó•ÂÆ£Â∏ÉÂ∞áÊîæË°åÊØîÁâπÂπ£ÊúüË≤®',\n",
       " 'ÂÖÅË®±ËäùÂä†Âì•ÂïÜÂìÅ‰∫§ÊòìÊâÄ',\n",
       " 'CME',\n",
       " 'ÂíåËäùÂä†Âì•ÈÅ∏ÊìáÊ¨ä‰∫§ÊòìÊâÄ',\n",
       " 'CBOE',\n",
       " 'Êé®Âá∫Áõ∏ÈóúÊúüË≤®ÂêàÁ¥Ñ',\n",
       " 'Âõ†ÁÇ∫ÂÖ©‰∫§ÊòìÊâÄÂ∑≤Ë≠âÊòéÊì¨Êé®Âá∫ÁöÑÂêàÁ¥ÑÂíå‰∫§ÊòìÂÆâÂÖ®Á¨¶ÂêàÂøÖË¶ÅÁöÑÁõ£ÁÆ°Ë¶èÂÆö',\n",
       " 'ÈÄôÊàêÁÇ∫Êé®Âãï‰∏ªÊµÅÊäïË≥á‰∫∫Ë≤∑Ë≥£Ê≠§ÂÉπÊ†ºÈ´òÂ∫¶Ê≥¢ÂãïÁöÑÊï∏‰ΩçË≤®Âπ£ÁöÑÈáçÂ§ß‰∏ÄÊ≠•',\n",
       " '']"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üìù ngram + Èï∑Ë©ûÂÑ™ÂÖàÊñ∑Ë©û => ÂèñÂá∫ÁâπÊÆäÈóúÈçµË©û"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import operator\r\n",
    "def removeKey(text, keyword):\r\n",
    "    textAry= text\r\n",
    "    for key in keyword:\r\n",
    "        textAry = ''.join(textAry.split(key))\r\n",
    "    return textAry\r\n",
    "def ngram(input_sentence, n = 2):\r\n",
    "    word_dic = {}\r\n",
    "    sentence  = input_sentence\r\n",
    "    for i in range(0, len(sentence) - n + 1):        \r\n",
    "        if sentence[i:i+n] not in word_dic:\r\n",
    "            word_dic[sentence[i:i+n]] = 1\r\n",
    "        else:\r\n",
    "            word_dic[sentence[i:i+n]] = word_dic[sentence[i:i+n]] + 1\r\n",
    "    return word_dic    \r\n",
    "keywords=['ÊúüË≤®','Ê†∏ÂáÜ']        \r\n",
    "ret_terms={}\r\n",
    "words_freq    = []\r\n",
    "for term_length in range(4,1,-1):\r\n",
    "    word_dic = {}\r\n",
    "    for sentence in sentenceAry:\r\n",
    "        text_list = removeKey(sentence,keywords)  \r\n",
    "        ngram_words = ngram(text_list,term_length) \r\n",
    "        for word in ngram_words:\r\n",
    "            if word not in word_dic:\r\n",
    "                word_dic[word] = 1\r\n",
    "            else:\r\n",
    "                word_dic[word] += ngram_words[word]   \r\n",
    "    for word in word_dic:\r\n",
    "        if word_dic[word] >= 3:\r\n",
    "            keywords.append(word)            \r\n",
    "            ret_terms.update({word:word_dic[word]})\r\n",
    "sorted_terms = sorted(ret_terms.items(),key=operator.itemgetter(1),reverse=True) \r\n",
    "sorted_terms\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('‰∫§ÊòìÊâÄ', 3)]"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}